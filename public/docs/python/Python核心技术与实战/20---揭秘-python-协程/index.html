<!DOCTYPE html>





    

    

    

    

<html lang="zh-CN"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
    <title>揭秘 Python 协程 | 别人打药我拽管</title>
    <meta name="robots" content="noindex">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="Documentation, Hugo, Hugo Theme, Bootstrap" />
    <meta name="author" content="Colin Wilson - Lotus Labs" />
    <meta name="email" content="support@aigis.uk" />
    <meta name="website" content="https://lotusdocs.dev" />
    <meta name="Version" content="v0.1.0" />
    
    <link rel="icon" href="http://localhost:1313/favicon.ico" sizes="any">
<link rel="icon" type="image/svg+xml" href="http://localhost:1313/favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="manifest" crossorigin="use-credentials" href="http://localhost:1313/site.webmanifest">
<meta property="og:title" content="揭秘 Python 协程" />
<meta property="og:description" content="你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？
协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到举足轻重的作用。
随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。
如果将多进程/多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。
再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）
回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。
我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。
从一个爬虫说起 link爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。
话不多说，我们先看一个简单的爬虫例子：



  
  
  

  
  
  
  

  

  
  
  import time

def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    time.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

def main(urls):
    for url in urls:
        crawl_page(url)

%time main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;])

########## 输出 ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s
  
  
（注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/20---%E6%8F%AD%E7%A7%98-python-%E5%8D%8F%E7%A8%8B/" /><meta property="og:image" content="http://localhost:1313/opengraph/card-base-2_hu_8398ba8fa5eb5516.png"/><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2025-08-04T11:25:06+08:00" />
<meta property="article:modified_time" content="2025-08-04T11:25:06+08:00" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://localhost:1313/opengraph/card-base-2_hu_8398ba8fa5eb5516.png"/>
<meta name="twitter:title" content="揭秘 Python 协程"/>
<meta name="twitter:description" content="你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？
协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到举足轻重的作用。
随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。
如果将多进程/多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。
再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）
回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。
我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。
从一个爬虫说起 link爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。
话不多说，我们先看一个简单的爬虫例子：



  
  
  

  
  
  
  

  

  
  
  import time

def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    time.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

def main(urls):
    for url in urls:
        crawl_page(url)

%time main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;])

########## 输出 ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s
  
  
（注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）"/>

    
        <link rel="alternate" type="application/atom+xml" title="Atom feed for 别人打药我拽管" href="/index.xml" />
    
    
    
            
                <script type="text/javascript" src="http://localhost:1313/docs/js/flexsearch.bundle.js"></script>
            
        
    
    

    <link rel="stylesheet" href="/docs/scss/style.css" crossorigin="anonymous">
    
    
    </head>
<body>
        <div class="content">
            <div class="page-wrapper toggled">
<nav id="sidebar" class="sidebar-wrapper">
    <div class="sidebar-brand">
        <a href='/' aria-label="HomePage" alt="HomePage">
            
                <?xml version="1.0" encoding="UTF-8"?><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 250 250"><path d="m143,39.5c-18,0-18,18-18,18,0,0,0-18-18-18H22c-2.76,0-5,2.24-5,5v143c0,2.76,2.24,5,5,5h76c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h76c2.76,0,5-2.24,5-5V44.5c0-2.76-2.24-5-5-5h-85Zm63,123.5c0,1.38-1.12,2.5-2.5,2.5h-60.5c-18,0-18,18-18,18,0,0,0-18-18-18h-60.5c-1.38,0-2.5-1.12-2.5-2.5v-94c0-1.38,1.12-2.5,2.5-2.5h51.5c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h51.5c1.38,0,2.5,1.12,2.5,2.5v94Z" style="fill:#06f;"/></svg>
            
        </a>
    </div>
    <div class="sidebar-content" style="height: calc(100% - 131px);">
        <ul class="sidebar-menu">
            
                
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">Newsmode</i>
                                AI
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/ai/mcp-%E5%88%9D%E8%AF%95%E9%AA%8C/">MCP 初试验</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  current active">
                            <button class="btn">
                                <i class="material-icons me-2">Summarize</i>
                                Python
                            </button>
                            <div class="sidebar-submenu d-block">
                                <ul>
                                    
                                        
                                        
                                            <li class="sidebar-dropdown nested  current active">
                                                <button class="btn">
                                                    
                                                    Python核心技术与实战
                                                </button>
                                                <div class="sidebar-submenu d-block">
                                                    <ul>
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">Python核心技术与实战</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/01---%E5%A6%82%E4%BD%95%E9%80%90%E6%AD%A5%E7%AA%81%E7%A0%B4%E6%88%90%E4%B8%BApython%E9%AB%98%E6%89%8B/">如何逐步突破，成为Python高手？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/02---jupyter-notebook%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E7%8E%B0%E4%BB%A3python%E7%9A%84%E5%BF%85%E5%AD%A6%E6%8A%80%E6%9C%AF/">Jupyter Notebook为什么是现代Python的必学技术？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/03---%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84%E5%88%B0%E5%BA%95%E7%94%A8%E5%93%AA%E4%B8%80%E4%B8%AA/">列表和元组，到底用哪一个？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/04---%E5%AD%97%E5%85%B8%E9%9B%86%E5%90%88%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3%E5%90%97/">字典、集合，你真的了解吗？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/05---%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AD%97%E7%AC%A6%E4%B8%B2/">深入浅出字符串</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/06---python-%E9%BB%91%E7%AE%B1%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/">Python “黑箱”：输入与输出</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/07---%E4%BF%AE%E7%82%BC%E5%9F%BA%E6%9C%AC%E5%8A%9F%E6%9D%A1%E4%BB%B6%E4%B8%8E%E5%BE%AA%E7%8E%AF/">修炼基本功：条件与循环</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/08---%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7/">异常处理：如何提高程序的稳定性？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/09---%E4%B8%8D%E5%8F%AF%E6%88%96%E7%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/">不可或缺的自定义函数</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/10---%E7%AE%80%E7%BA%A6%E4%B8%8D%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/">简约不简单的匿名函数</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/11---%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8A%E4%BB%8E%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%AF%94%E8%AF%B4%E8%B5%B7/">面向对象（上）：从生活中的类比说起</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/12---%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/">面向对象（下）：如何实现一个搜索引擎？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/13---%E6%90%AD%E5%BB%BA%E7%A7%AF%E6%9C%A8python-%E6%A8%A1%E5%9D%97%E5%8C%96/">搭建积木：Python 模块化</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/14---%E7%AD%94%E7%96%91%E4%B8%80%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/">答疑（一）：列表和元组的内部实现是怎样的？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/15---python%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%AF%94%E8%BE%83%E6%8B%B7%E8%B4%9D/">Python对象的比较、拷贝</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/16---%E5%80%BC%E4%BC%A0%E9%80%92%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92or%E5%85%B6%E4%BB%96python%E9%87%8C%E5%8F%82%E6%95%B0%E6%98%AF%E5%A6%82%E4%BD%95%E4%BC%A0%E9%80%92%E7%9A%84/">值传递，引用传递or其他，Python里参数是如何传递的？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/17---%E5%BC%BA%E5%A4%A7%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8/">强大的装饰器</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18---metaclass%E6%98%AF%E6%BD%98%E5%A4%9A%E6%8B%89%E9%AD%94%E7%9B%92%E8%BF%98%E6%98%AF%E9%98%BF%E6%8B%89%E4%B8%81%E7%A5%9E%E7%81%AF/">metaclass，是潘多拉魔盒还是阿拉丁神灯？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/19---%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8/">深入理解迭代器和生成器</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class="current "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/20---%E6%8F%AD%E7%A7%98-python-%E5%8D%8F%E7%A8%8B/">揭秘 Python 协程</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/21---python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bfutures/">Python并发编程之Futures</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/22---%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Basyncio/">并发编程之Asyncio</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/23---%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82python-gil%E5%85%A8%E5%B1%80%E8%A7%A3%E9%87%8A%E5%99%A8%E9%94%81%E5%90%97/">你真的懂Python GIL（全局解释器锁）吗？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/24---%E5%B8%A6%E4%BD%A0%E8%A7%A3%E6%9E%90-python-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/">带你解析 Python 垃圾回收机制</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25---%E7%AD%94%E7%96%91%E4%BA%8Cgil%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%98%AF%E4%BB%80%E4%B9%88%E5%85%B3%E7%B3%BB%E5%91%A2/">答疑（二）：GIL与多线程是什么关系呢？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/26---%E6%B4%BB%E9%83%BD%E6%9D%A5%E4%B8%8D%E5%8F%8A%E5%B9%B2%E4%BA%86%E8%BF%98%E6%9C%89%E7%A9%BA%E6%B3%A8%E6%84%8F%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC/">活都来不及干了，还有空注意代码风格？！</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/27---%E5%AD%A6%E4%BC%9A%E5%90%88%E7%90%86%E5%88%86%E8%A7%A3%E4%BB%A3%E7%A0%81%E6%8F%90%E9%AB%98%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%AF%BB%E6%80%A7/">学会合理分解代码，提高代码可读性</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/28---%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E5%88%A9%E7%94%A8assert/">如何合理利用assert？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/29---%E5%B7%A7%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8%E5%92%8Cwith%E8%AF%AD%E5%8F%A5%E7%B2%BE%E7%AE%80%E4%BB%A3%E7%A0%81/">巧用上下文管理器和With语句精简代码</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/30---%E7%9C%9F%E7%9A%84%E6%9C%89%E5%BF%85%E8%A6%81%E5%86%99%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%90%97/">真的有必要写单元测试吗？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/31---pdb--cprofile%E8%B0%83%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E7%9A%84%E6%B3%95%E5%AE%9D/">pdb &amp; cProfile：调试和性能分析的法宝</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/32---%E7%AD%94%E7%96%91%E4%B8%89%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/">答疑（三）：如何选择合适的异常处理方式？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/33---%E5%B8%A6%E4%BD%A0%E5%88%9D%E6%8E%A2%E9%87%8F%E5%8C%96%E4%B8%96%E7%95%8C/">带你初探量化世界</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/34---restful--socket%E6%90%AD%E5%BB%BA%E4%BA%A4%E6%98%93%E6%89%A7%E8%A1%8C%E5%B1%82%E6%A0%B8%E5%BF%83/">RESTful &amp; Socket：搭建交易执行层核心</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/35---restful--socket%E8%A1%8C%E6%83%85%E6%95%B0%E6%8D%AE%E5%AF%B9%E6%8E%A5%E5%92%8C%E6%8A%93%E5%8F%96/">RESTful &amp; Socket：行情数据对接和抓取</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/36---pandas--numpy%E7%AD%96%E7%95%A5%E4%B8%8E%E5%9B%9E%E6%B5%8B%E7%B3%BB%E7%BB%9F/">Pandas &amp; Numpy：策略与回测系统</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/37---kafka--zmq%E8%87%AA%E5%8A%A8%E5%8C%96%E4%BA%A4%E6%98%93%E6%B5%81%E6%B0%B4%E7%BA%BF/">Kafka &amp; ZMQ：自动化交易流水线</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/38---mysql%E6%97%A5%E5%BF%97%E5%92%8C%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/">MySQL：日志和数据存储系统</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/39---django%E6%90%AD%E5%BB%BA%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0/">Django：搭建监控平台</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/40---%E6%80%BB%E7%BB%93python%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%85%A8%E6%99%AF/">总结：Python中的数据结构与算法全景</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/41---%E7%A1%85%E8%B0%B7%E4%B8%80%E7%BA%BF%E4%BA%92%E8%81%94%E7%BD%91%E5%85%AC%E5%8F%B8%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%BD%93%E9%AA%8C/">硅谷一线互联网公司的工作体验</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/42---%E7%BB%86%E6%95%B0%E6%8A%80%E6%9C%AF%E7%A0%94%E5%8F%91%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/">细数技术研发的注意事项</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/43---qa%E8%81%8A%E4%B8%80%E8%81%8A%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%E5%92%8C%E9%80%89%E6%8B%A9/">Q&amp;A：聊一聊职业发展和选择</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/44---%E5%8A%A0%E9%A4%90---%E5%B8%A6%E4%BD%A0%E4%B8%8A%E6%89%8Bswig%E4%B8%80%E4%BB%BD%E6%B8%85%E6%99%B0%E5%A5%BD%E7%94%A8%E7%9A%84swig%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/">加餐 - 带你上手SWIG：一份清晰好用的SWIG编程实践指南</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/45---%E7%BB%93%E8%AF%BE%E6%B5%8B%E8%AF%95---%E5%85%B3%E4%BA%8Epython%E7%9A%84%E8%BF%99%E4%BA%9B%E7%9F%A5%E8%AF%86%E4%BD%A0%E9%83%BD%E6%8E%8C%E6%8F%A1%E4%BA%86%E5%90%97/">结课测试 - 关于Python的这些知识，你都掌握了吗？</a></li>
                                                            
                                                        
                                                            
                                                            
                                                                <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/46---%E7%BB%93%E6%9D%9F%E8%AF%AD---%E6%8A%80%E6%9C%AF%E4%B9%8B%E5%A4%96%E7%9A%84%E5%87%A0%E7%82%B9%E6%88%90%E9%95%BF%E5%BB%BA%E8%AE%AE/">结束语 - 技术之外的几点成长建议</a></li>
                                                            
                                                        
                                                    </ul>
                                                </div>
                                            </li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/python/">Python</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/python/%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84/">列表和元组</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">Newsmode</i>
                                日常资讯
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/docs/%E6%97%A5%E5%B8%B8/%E5%91%8A%E5%88%AB%E4%BB%A3%E7%A0%81%E5%B7%A5%E4%BA%BA/">告别代码工人</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
            
        </ul>
        
    </div>
    
        <ul class="sidebar-footer list-unstyled mb-0">
            
        </ul>
    
</nav>

                    <main class="page-content bg-transparent">
                        
<div id="top-header" class="top-header d-print-none">
    <div class="header-bar d-flex justify-content-between">
        <div class="d-flex align-items-center">
            <a href='/' class="logo-icon me-3" aria-label="HomePage" alt="HomePage">
                <div class="small">
                    
                            <?xml version="1.0" encoding="UTF-8"?><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 250 250"><path d="m143,39.5c-18,0-18,18-18,18,0,0,0-18-18-18H22c-2.76,0-5,2.24-5,5v143c0,2.76,2.24,5,5,5h76c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h76c2.76,0,5-2.24,5-5V44.5c0-2.76-2.24-5-5-5h-85Zm63,123.5c0,1.38-1.12,2.5-2.5,2.5h-60.5c-18,0-18,18-18,18,0,0,0-18-18-18h-60.5c-1.38,0-2.5-1.12-2.5-2.5v-94c0-1.38,1.12-2.5,2.5-2.5h51.5c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h51.5c1.38,0,2.5,1.12,2.5,2.5v94Z" style="fill:#06f;"/></svg>
                    
                </div>
                <div class="big">
                    
                            <?xml version="1.0" encoding="UTF-8"?><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 250 250"><path d="m143,39.5c-18,0-18,18-18,18,0,0,0-18-18-18H22c-2.76,0-5,2.24-5,5v143c0,2.76,2.24,5,5,5h76c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h76c2.76,0,5-2.24,5-5V44.5c0-2.76-2.24-5-5-5h-85Zm63,123.5c0,1.38-1.12,2.5-2.5,2.5h-60.5c-18,0-18,18-18,18,0,0,0-18-18-18h-60.5c-1.38,0-2.5-1.12-2.5-2.5v-94c0-1.38,1.12-2.5,2.5-2.5h51.5c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h51.5c1.38,0,2.5,1.12,2.5,2.5v94Z" style="fill:#06f;"/></svg>
                    
                </div>
            </a>
            <button id="close-sidebar" class="btn btn-icon btn-soft">
                <span class="material-icons size-20 menu-icon align-middle">menu</span>
            </button>
            
            
                    
                    <button id="flexsearch-button" class="ms-3 btn btn-soft" data-bs-toggle="collapse" data-bs-target="#FlexSearchCollapse" aria-expanded="false" aria-controls="FlexSearchCollapse">
                        <span class="material-icons size-20 menu-icon align-middle">search</span>
                        <span class="flexsearch-button-placeholder ms-1 me-2 d-none d-sm-block">Search</span>
                        <div class="d-none d-sm-block">
                            <span class="flexsearch-button-keys">
                                <kbd class="flexsearch-button-cmd-key">
                                    <svg width="44" height="15"><path d="M2.118,11.5A1.519,1.519,0,0,1,1,11.042,1.583,1.583,0,0,1,1,8.815a1.519,1.519,0,0,1,1.113-.458h.715V6.643H2.118A1.519,1.519,0,0,1,1,6.185,1.519,1.519,0,0,1,.547,5.071,1.519,1.519,0,0,1,1,3.958,1.519,1.519,0,0,1,2.118,3.5a1.519,1.519,0,0,1,1.114.458A1.519,1.519,0,0,1,3.69,5.071v.715H5.4V5.071A1.564,1.564,0,0,1,6.976,3.5,1.564,1.564,0,0,1,8.547,5.071,1.564,1.564,0,0,1,6.976,6.643H6.261V8.357h.715a1.575,1.575,0,0,1,1.113,2.685,1.583,1.583,0,0,1-2.227,0A1.519,1.519,0,0,1,5.4,9.929V9.214H3.69v.715a1.519,1.519,0,0,1-.458,1.113A1.519,1.519,0,0,1,2.118,11.5Zm0-.857a.714.714,0,0,0,.715-.714V9.214H2.118a.715.715,0,1,0,0,1.429Zm4.858,0a.715.715,0,1,0,0-1.429H6.261v.715a.714.714,0,0,0,.715.714ZM3.69,8.357H5.4V6.643H3.69ZM2.118,5.786h.715V5.071a.714.714,0,0,0-.715-.714.715.715,0,0,0-.5,1.22A.686.686,0,0,0,2.118,5.786Zm4.143,0h.715a.715.715,0,0,0,.5-1.22.715.715,0,0,0-1.22.5Z" fill="currentColor"></path><path d="M12.4,11.475H11.344l3.879-7.95h1.056Z" fill="currentColor"></path><path d="M25.073,5.384l-.864.576a2.121,2.121,0,0,0-1.786-.923,2.207,2.207,0,0,0-2.266,2.326,2.206,2.206,0,0,0,2.266,2.325,2.1,2.1,0,0,0,1.782-.918l.84.617a3.108,3.108,0,0,1-2.622,1.293,3.217,3.217,0,0,1-3.349-3.317,3.217,3.217,0,0,1,3.349-3.317A3.046,3.046,0,0,1,25.073,5.384Z" fill="currentColor"></path><path d="M30.993,5.142h-2.07v5.419H27.891V5.142h-2.07V4.164h5.172Z" fill="currentColor"></path><path d="M34.67,4.164c1.471,0,2.266.658,2.266,1.851,0,1.087-.832,1.809-2.134,1.855l2.107,2.691h-1.28L33.591,7.87H33.07v2.691H32.038v-6.4Zm-1.6.969v1.8h1.572c.832,0,1.22-.3,1.22-.918s-.411-.882-1.22-.882Z" fill="currentColor"></path><path d="M42.883,10.561H38.31v-6.4h1.033V9.583h3.54Z" fill="currentColor"></path></svg>
                                </kbd>
                                <kbd class="flexsearch-button-key">
                                    <svg width="15" height="15"><path d="M5.926,12.279H4.41L9.073,2.721H10.59Z" fill="currentColor"/></svg>
                                </kbd>
                            </span>
                        </div>
                    </button>
                
            </div>

        <div class="d-flex align-items-center">
            <ul class="list-unstyled mb-0">
                
            </ul>
            
        </div>
    </div>
    
    
            <div class="collapse" id="FlexSearchCollapse">
                <div class="flexsearch-container">
                    <div class="flexsearch-keymap">
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8M10.5 8.5l-3 3-3-3"></path></g></svg></kbd>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8M10.5 6.5l-3-3-3 3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to navigate</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4M7 11.53088l-3-3 3-3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to select</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to close</span>
                        </li>
                    </div>
                    <form class="flexsearch position-relative flex-grow-1 ms-2 me-2">
                        <div class="d-flex flex-row">
                            <input id="flexsearch" class="form-control" type="search" placeholder="Search" aria-label="Search" autocomplete="off">
                            <button id="hideFlexsearch" type="button" class="ms-2 btn btn-soft">
                                cancel
                            </button>
                        </div>
                        <div id="suggestions" class="shadow rounded-1 d-none"></div>
                    </form>
                </div>
            </div>
        
    
    
</div>


                            <div class="container-fluid">
                                <div class="layout-spacing">
                                    
                                        <div class="d-md-flex justify-content-between align-items-center"><nav aria-label="breadcrumb" class="d-inline-block pb-2 mt-1 mt-sm-0">
    <ul id="breadcrumbs" class="breadcrumb bg-transparent mb-0" itemscope itemtype="https://schema.org/BreadcrumbList">
        
            
                <li class="breadcrumb-item text-capitalize active" aria-current="page" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/docs/">
                        <i class="material-icons size-20 align-text-bottom" itemprop="name">Home</i>
                    </a>
                    <meta itemprop="position" content='1' />
                </li>
            
            
                <li class="breadcrumb-item text-capitalize" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/docs/python/">
                        <span itemprop="name">Python</span>
                    </a>
                    <meta itemprop="position" content='2' />
                </li>
            
            
                <li class="breadcrumb-item text-capitalize" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">
                        <span itemprop="name">Python核心技术与实战</span>
                    </a>
                    <meta itemprop="position" content='3' />
                </li>
            
        
            <li class="breadcrumb-item text-capitalize active" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <span itemprop="name">揭秘 Python 协程</span>
                <meta itemprop="position" content='4' />
            </li>
        
    </ul>
</nav></div>
                                    
                                    <div class="row flex-xl-nowrap">
                                        
                                        <div class="docs-toc col-xl-3    d-xl-block"><toc>
    <div class="fw-bold text-uppercase mb-2">On this page</div>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#从一个爬虫说起">从一个爬虫说起</a></li>
    <li><a href="#解密协程运行时">解密协程运行时</a></li>
    <li><a href="#实战豆瓣近日推荐电影爬虫">实战：豆瓣近日推荐电影爬虫</a></li>
    <li><a href="#总结">总结</a></li>
    <li><a href="#思考题">思考题</a></li>
  </ul>
</nav>
    </toc></div>
                                        
                                        
                                        <div class="docs-toc-mobile    d-print-none d-xl-none">
                                            <button id="toc-dropdown-btn" class="btn-secondary dropdown-toggle" type="button" data-bs-toggle="dropdown" data-bs-offset="0,0" aria-expanded="false">
                                                Table of Contents
                                            </button>
<nav id="toc-mobile">
  <ul class="dropdown-menu">
    <li><a href="#从一个爬虫说起">从一个爬虫说起</a></li>
    <li><a href="#解密协程运行时">解密协程运行时</a></li>
    <li><a href="#实战豆瓣近日推荐电影爬虫">实战：豆瓣近日推荐电影爬虫</a></li>
    <li><a href="#总结">总结</a></li>
    <li><a href="#思考题">思考题</a></li>
  </ul>
</nav></div>
                                        <div class="docs-content col-12 col-xl-9 mt-0">
                                            <div class="mb-0 d-flex">
                                                
                                                <i class="material-icons title-icon me-2">article</i>
                                                
                                                <h1 class="content-title mb-0">
                                                    揭秘 Python 协程
                                                    
                                                </h1>
                                            </div>
                                            
                                            <div id="content" class="main-content" >
                                                
    
    <div data-prismjs-copy="" data-prismjs-copy-success="" data-prismjs-copy-error="">
        <p>你好，我是景霄。</p>
<p>上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。</p>
<p>那么首先你要明白，什么是协程？</p>
<p>协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到举足轻重的作用。</p>
<p>随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。</p>
<p>如果将多进程/多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。</p>
<p>再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）</p>
<p>回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。</p>
<p>我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。</p>
<h2 id="从一个爬虫说起">从一个爬虫说起 <a href="#%e4%bb%8e%e4%b8%80%e4%b8%aa%e7%88%ac%e8%99%ab%e8%af%b4%e8%b5%b7" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。</p>
<p>话不多说，我们先看一个简单的爬虫例子：</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="45f9878" class="language- ">
  <code>import time

def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    time.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

def main(urls):
    for url in urls:
        crawl_page(url)

%time main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;])

########## 输出 ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s</code>
  </pre>
  </div>
<p>（注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）</p>
<p>这是一个很简单的爬虫，main() 函数执行时，调取 crawl_page() 函数进行网络通信，经过若干秒等待后收到结果，然后执行下一个。</p>
<p>看起来很简单，但你仔细一算，它也占用了不少时间，五个页面分别用了 1 秒到 4 秒的时间，加起来一共用了 10 秒。这显然效率低下，该怎么优化呢？</p>
<p>于是，一个很简单的思路出现了——我们这种爬取操作，完全可以并发化。我们就来看看使用协程怎么写。</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="f7b63b8" class="language- ">
  <code>import asyncio

async def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    await asyncio.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

async def main(urls):
    for url in urls:
        await crawl_page(url)

%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))

########## 输出 ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s</code>
  </pre>
  </div>
<p>看到这段代码，你应该发现了，在 Python 3.7 以上版本中，使用协程写异步程序非常简单。</p>
<p>首先来看 import asyncio，这个库包含了大部分我们实现协程所需的魔法工具。</p>
<p>async 修饰词声明异步函数，于是，这里的 crawl_page 和 main 都变成了异步函数。而调用异步函数，我们便可得到一个协程对象（coroutine object）。</p>
<p>举个例子，如果你 <code>print(crawl_page(''))</code>，便会输出<code>&lt;coroutine object crawl_page at 0x000002BEDF141148&gt;</code>，提示你这是一个 Python 的协程对象，而并不会真正执行这个函数。</p>
<p>再来说说协程的执行。执行协程有多种方法，这里我介绍一下常用的三种。</p>
<p>首先，我们可以通过 await 来调用。await 执行的效果，和 Python 正常执行是一样的，也就是说程序会阻塞在这里，进入被调用的协程函数，执行完毕返回后再继续，而这也是 await 的字面意思。代码中 <code>await asyncio.sleep(sleep_time)</code> 会在这里休息若干秒，<code>await crawl_page(url)</code> 则会执行 crawl_page() 函数。</p>
<p>其次，我们可以通过 asyncio.create_task() 来创建任务，这个我们下节课会详细讲一下，你先简单知道即可。</p>
<p>最后，我们需要 asyncio.run 来触发运行。asyncio.run 这个函数是 Python 3.7 之后才有的特性，可以让 Python 的协程接口变得非常简单，你不用去理会事件循环怎么定义和怎么使用的问题（我们会在下面讲）。一个非常好的编程规范是，asyncio.run(main()) 作为主程序的入口函数，在程序运行周期内，只调用一次 asyncio.run。</p>
<p>这样，你就大概看懂了协程是怎么用的吧。不妨试着跑一下代码，欸，怎么还是 10 秒？</p>
<p>10 秒就对了，还记得上面所说的，await 是同步调用，因此， crawl_page(url) 在当前的调用结束之前，是不会触发下一次调用的。于是，这个代码效果就和上面完全一样了，相当于我们用异步接口写了个同步代码。</p>
<p>现在又该怎么办呢？</p>
<p>其实很简单，也正是我接下来要讲的协程中的一个重要概念，任务（Task）。老规矩，先看代码。</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="7b1a887" class="language- ">
  <code>import asyncio

async def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    await asyncio.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    for task in tasks:
        await task

%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))

########## 输出 ##########

crawling url_1
crawling url_2
crawling url_3
crawling url_4
OK url_1
OK url_2
OK url_3
OK url_4
Wall time: 3.99 s</code>
  </pre>
  </div>
<p>你可以看到，我们有了协程对象后，便可以通过 <code>asyncio.create_task</code> 来创建任务。任务创建后很快就会被调度执行，这样，我们的代码也不会阻塞在任务这里。所以，我们要等所有任务都结束才行，用<code>for task in tasks: await task</code> 即可。</p>
<p>这次，你就看到效果了吧，结果显示，运行总时长等于运行时间最长的爬虫。</p>
<p>当然，你也可以想一想，这里用多线程应该怎么写？而如果需要爬取的页面有上万个又该怎么办呢？再对比下协程的写法，谁更清晰自是一目了然。</p>
<p>其实，对于执行 tasks，还有另一种做法：</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="5c04efa" class="language- ">
  <code>import asyncio

async def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    await asyncio.sleep(sleep_time)
    print(&#39;OK {}&#39;.format(url))

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    await asyncio.gather(*tasks)

%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))

########## 输出 ##########

crawling url_1
crawling url_2
crawling url_3
crawling url_4
OK url_1
OK url_2
OK url_3
OK url_4
Wall time: 4.01 s</code>
  </pre>
  </div>
<p>这里的代码也很好理解。唯一要注意的是，<code>*tasks</code> 解包列表，将列表变成了函数的参数；与之对应的是， <code>** dict</code> 将字典变成了函数的参数。</p>
<p>另外，<code>asyncio.create_task</code>，<code>asyncio.run</code> 这些函数都是 Python 3.7 以上的版本才提供的，自然，相比于旧接口它们也更容易理解和阅读。</p>
<h2 id="解密协程运行时">解密协程运行时 <a href="#%e8%a7%a3%e5%af%86%e5%8d%8f%e7%a8%8b%e8%bf%90%e8%a1%8c%e6%97%b6" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>说了这么多，现在，我们不妨来深入代码底层看看。有了前面的知识做基础，你应该很容易理解这两段代码。</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="51fe3b0" class="language- ">
  <code>import asyncio

async def worker_1():
    print(&#39;worker_1 start&#39;)
    await asyncio.sleep(1)
    print(&#39;worker_1 done&#39;)

async def worker_2():
    print(&#39;worker_2 start&#39;)
    await asyncio.sleep(2)
    print(&#39;worker_2 done&#39;)

async def main():
    print(&#39;before await&#39;)
    await worker_1()
    print(&#39;awaited worker_1&#39;)
    await worker_2()
    print(&#39;awaited worker_2&#39;)

%time asyncio.run(main())

########## 输出 ##########

before await
worker_1 start
worker_1 done
awaited worker_1
worker_2 start
worker_2 done
awaited worker_2
Wall time: 3 s</code>
  </pre>
  </div>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="12c9bb2" class="language- ">
  <code>import asyncio

async def worker_1():
    print(&#39;worker_1 start&#39;)
    await asyncio.sleep(1)
    print(&#39;worker_1 done&#39;)

async def worker_2():
    print(&#39;worker_2 start&#39;)
    await asyncio.sleep(2)
    print(&#39;worker_2 done&#39;)

async def main():
    task1 = asyncio.create_task(worker_1())
    task2 = asyncio.create_task(worker_2())
    print(&#39;before await&#39;)
    await task1
    print(&#39;awaited worker_1&#39;)
    await task2
    print(&#39;awaited worker_2&#39;)

%time asyncio.run(main())

########## 输出 ##########

before await
worker_1 start
worker_2 start
worker_1 done
awaited worker_1
worker_2 done
awaited worker_2
Wall time: 2.01 s</code>
  </pre>
  </div>
<p>不过，第二个代码，到底发生了什么呢？为了让你更详细了解到协程和线程的具体区别，这里我详细地分析了整个过程。步骤有点多，别着急，我们慢慢来看。</p>
<ol>
<li><code>asyncio.run(main())</code>，程序进入 main() 函数，事件循环开启；</li>
<li>task1 和 task2 任务被创建，并进入事件循环等待运行；运行到 print，输出 <code>'before await'</code>；</li>
<li>await task1 执行，用户选择从当前的主任务中切出，事件调度器开始调度 worker_1；</li>
<li>worker_1 开始运行，运行 print 输出<code>'worker_1 start'</code>，然后运行到 <code>await asyncio.sleep(1)</code>， 从当前任务切出，事件调度器开始调度 worker_2；</li>
<li>worker_2 开始运行，运行 print 输出 <code>'worker_2 start'</code>，然后运行 <code>await asyncio.sleep(2)</code> 从当前任务切出；</li>
<li>以上所有事件的运行时间，都应该在 1ms 到 10ms 之间，甚至可能更短，事件调度器从这个时候开始暂停调度；</li>
<li>一秒钟后，worker_1 的 sleep 完成，事件调度器将控制权重新传给 task_1，输出 <code>'worker_1 done'</code>，task_1 完成任务，从事件循环中退出；</li>
<li>await task1 完成，事件调度器将控制器传给主任务，输出 <code>'awaited worker_1'</code>，·然后在 await task2 处继续等待；</li>
<li>两秒钟后，worker_2 的 sleep 完成，事件调度器将控制权重新传给 task_2，输出 <code>'worker_2 done'</code>，task_2 完成任务，从事件循环中退出；</li>
<li>主任务输出 <code>'awaited worker_2'</code>，协程全任务结束，事件循环结束。</li>
</ol>
<p>接下来，我们进阶一下。如果我们想给某些协程任务限定运行时间，一旦超时就取消，又该怎么做呢？再进一步，如果某些协程运行时出现错误，又该怎么处理呢？同样的，来看代码。</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="0b80188" class="language- ">
  <code>import asyncio

async def worker_1():
    await asyncio.sleep(1)
    return 1

async def worker_2():
    await asyncio.sleep(2)
    return 2 / 0

async def worker_3():
    await asyncio.sleep(3)
    return 3

async def main():
    task_1 = asyncio.create_task(worker_1())
    task_2 = asyncio.create_task(worker_2())
    task_3 = asyncio.create_task(worker_3())

    await asyncio.sleep(2)
    task_3.cancel()

    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)
    print(res)

%time asyncio.run(main())

########## 输出 ##########

[1, ZeroDivisionError(&#39;division by zero&#39;), CancelledError()]
Wall time: 2 s</code>
  </pre>
  </div>
<p>你可以看到，worker_1 正常运行，worker_2 运行中出现错误，worker_3 执行时间过长被我们 cancel 掉了，这些信息会全部体现在最终的返回结果 res 中。</p>
<p>不过要注意<code>return_exceptions=True</code>这行代码。如果不设置这个参数，错误就会完整地 throw 到我们这个执行层，从而需要 try except 来捕捉，这也就意味着其他还没被执行的任务会被全部取消掉。为了避免这个局面，我们将 return_exceptions 设置为 True 即可。</p>
<p>到这里，发现了没，线程能实现的，协程都能做到。那就让我们温习一下这些知识点，用协程来实现一个经典的生产者消费者模型吧。</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="f8cf98d" class="language- ">
  <code>import asyncio
import random

async def consumer(queue, id):
    while True:
        val = await queue.get()
        print(&#39;{} get a val: {}&#39;.format(id, val))
        await asyncio.sleep(1)

async def producer(queue, id):
    for i in range(5):
        val = random.randint(1, 10)
        await queue.put(val)
        print(&#39;{} put a val: {}&#39;.format(id, val))
        await asyncio.sleep(1)

async def main():
    queue = asyncio.Queue()

    consumer_1 = asyncio.create_task(consumer(queue, &#39;consumer_1&#39;))
    consumer_2 = asyncio.create_task(consumer(queue, &#39;consumer_2&#39;))

    producer_1 = asyncio.create_task(producer(queue, &#39;producer_1&#39;))
    producer_2 = asyncio.create_task(producer(queue, &#39;producer_2&#39;))

    await asyncio.sleep(10)
    consumer_1.cancel()
    consumer_2.cancel()
    
    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)

%time asyncio.run(main())

########## 输出 ##########

producer_1 put a val: 5
producer_2 put a val: 3
consumer_1 get a val: 5
consumer_2 get a val: 3
producer_1 put a val: 1
producer_2 put a val: 3
consumer_2 get a val: 1
consumer_1 get a val: 3
producer_1 put a val: 6
producer_2 put a val: 10
consumer_1 get a val: 6
consumer_2 get a val: 10
producer_1 put a val: 4
producer_2 put a val: 5
consumer_2 get a val: 4
consumer_1 get a val: 5
producer_1 put a val: 2
producer_2 put a val: 8
consumer_1 get a val: 2
consumer_2 get a val: 8
Wall time: 10 s</code>
  </pre>
  </div>
<h2 id="实战豆瓣近日推荐电影爬虫">实战：豆瓣近日推荐电影爬虫 <a href="#%e5%ae%9e%e6%88%98%e8%b1%86%e7%93%a3%e8%bf%91%e6%97%a5%e6%8e%a8%e8%8d%90%e7%94%b5%e5%bd%b1%e7%88%ac%e8%99%ab" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>最后，进入今天的实战环节——实现一个完整的协程爬虫。</p>
<p>任务描述：<a href="https://movie.douban.com/cinema/later/beijing/" rel="external" target="_blank">https://movie.douban.com/cinema/later/beijing/<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"/></svg></a> 这个页面描述了北京最近上映的电影，你能否通过 Python 得到这些电影的名称、上映时间和海报呢？这个页面的海报是缩小版的，我希望你能从具体的电影描述页面中抓取到海报。</p>
<p>听起来难度不是很大吧？我在下面给出了同步版本的代码和协程版本的代码，通过运行时间和代码写法的对比，希望你能对协程有更深的了解。（注意：为了突出重点、简化代码，这里我省略了异常处理。）</p>
<p>不过，在参考我给出的代码之前，你是不是可以自己先动手写一下、跑一下呢？</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="306e2e5" class="language- ">
  <code>import requests
from bs4 import BeautifulSoup

def main():
    url = &#34;https://movie.douban.com/cinema/later/beijing/&#34;
    init_page = requests.get(url).content
    init_soup = BeautifulSoup(init_page, &#39;lxml&#39;)

    all_movies = init_soup.find(&#39;div&#39;, id=&#34;showing-soon&#34;)
    for each_movie in all_movies.find_all(&#39;div&#39;, class_=&#34;item&#34;):
        all_a_tag = each_movie.find_all(&#39;a&#39;)
        all_li_tag = each_movie.find_all(&#39;li&#39;)

        movie_name = all_a_tag[1].text
        url_to_fetch = all_a_tag[1][&#39;href&#39;]
        movie_date = all_li_tag[0].text

        response_item = requests.get(url_to_fetch).content
        soup_item = BeautifulSoup(response_item, &#39;lxml&#39;)
        img_tag = soup_item.find(&#39;img&#39;)

        print(&#39;{} {} {}&#39;.format(movie_name, movie_date, img_tag[&#39;src&#39;]))

%time main()

########## 输出 ##########

阿拉丁 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
龙珠超：布罗利 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
五月天人生无限公司 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
... ...
直播攻略 06月04日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
Wall time: 56.6 s</code>
  </pre>
  </div>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="48437a4" class="language- ">
  <code>import asyncio
import aiohttp

from bs4 import BeautifulSoup

async def fetch_content(url):
    async with aiohttp.ClientSession(
        headers=header, connector=aiohttp.TCPConnector(ssl=False)
    ) as session:
        async with session.get(url) as response:
            return await response.text()

async def main():
    url = &#34;https://movie.douban.com/cinema/later/beijing/&#34;
    init_page = await fetch_content(url)
    init_soup = BeautifulSoup(init_page, &#39;lxml&#39;)

    movie_names, urls_to_fetch, movie_dates = [], [], []

    all_movies = init_soup.find(&#39;div&#39;, id=&#34;showing-soon&#34;)
    for each_movie in all_movies.find_all(&#39;div&#39;, class_=&#34;item&#34;):
        all_a_tag = each_movie.find_all(&#39;a&#39;)
        all_li_tag = each_movie.find_all(&#39;li&#39;)

        movie_names.append(all_a_tag[1].text)
        urls_to_fetch.append(all_a_tag[1][&#39;href&#39;])
        movie_dates.append(all_li_tag[0].text)

    tasks = [fetch_content(url) for url in urls_to_fetch]
    pages = await asyncio.gather(*tasks)

    for movie_name, movie_date, page in zip(movie_names, movie_dates, pages):
        soup_item = BeautifulSoup(page, &#39;lxml&#39;)
        img_tag = soup_item.find(&#39;img&#39;)

        print(&#39;{} {} {}&#39;.format(movie_name, movie_date, img_tag[&#39;src&#39;]))

%time asyncio.run(main())

########## 输出 ##########

阿拉丁 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
龙珠超：布罗利 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
五月天人生无限公司 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
... ...
直播攻略 06月04日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
Wall time: 4.98 s</code>
  </pre>
  </div>
<h2 id="总结">总结 <a href="#%e6%80%bb%e7%bb%93" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>到这里，今天的主要内容就讲完了。今天我用了较长的篇幅，从一个简单的爬虫开始，到一个真正的爬虫结束，在中间穿插讲解了 Python 协程最新的基本概念和用法。这里带你简单复习一下。</p>
<ul>
<li>协程和多线程的区别，主要在于两点，一是协程为单线程；二是协程由用户决定，在哪些地方交出控制权，切换到下一个任务。</li>
<li>协程的写法更加简洁清晰，把async / await 语法和 create_task 结合来用，对于中小级别的并发需求已经毫无压力。</li>
<li>写协程程序的时候，你的脑海中要有清晰的事件循环概念，知道程序在什么时候需要暂停、等待 I/O，什么时候需要一并执行到底。</li>
</ul>
<p>最后的最后，请一定不要轻易炫技。多线程模型也一定有其优点，一个真正牛逼的程序员，应该懂得，在什么时候用什么模型能达到工程上的最优，而不是自觉某个技术非常牛逼，所有项目创造条件也要上。技术是工程，而工程则是时间、资源、人力等纷繁复杂的事情的折衷。</p>
<h2 id="思考题">思考题 <a href="#%e6%80%9d%e8%80%83%e9%a2%98" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>最后给你留一个思考题。协程怎么实现回调函数呢？欢迎留言和我讨论，也欢迎你把这篇文章分享给你的同事朋友，我们一起交流，一起进步。</p>
<!-- raw HTML omitted -->
<p>在 python 3.7 及以上的版本中，我们对 task 对象调用 add_done_callback() 函数，即可绑定特定回调函数。回调函数接受一个 future 对象，可以通过 future.result() 来获取协程函数的返回值。</p>
<p>示例如下：</p>
<p>import asyncio</p>
<p>async def crawl_page(url):
print('crawling {}'.format(url))
sleep_time = int(url.split('_')[-1])
await asyncio.sleep(sleep_time)
return 'OK {}'.format(url)</p>
<p>async def main(urls):
tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
for task in tasks:
task.add_done_callback(lambda future: print('result: ', future.result()))
await asyncio.gather(*tasks)</p>
<p>%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))</p>
<p>输出：</p>
<p>crawling url_1
crawling url_2
crawling url_3
crawling url_4
result:  OK url_1
result:  OK url_2
result:  OK url_3
result:  OK url_4
Wall time: 4 s<!-- raw HTML omitted -->2019-07-01<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->Jingxiao<!-- raw HTML omitted --> 👍（77） 💬（10）<!-- raw HTML omitted -->发现评论区好多朋友说无法运行，在这里统一解释下：</p>
<ol>
<li>%time 是 jupyter notebook 自带的语法糖，用来统计一行命令的运行时间；如果你的运行时是纯粹的命令行 python，或者 pycharm，那么请把 %time 删掉，自己用传统的时间戳方法来记录时间也可以；或者使用 jupyter notebook</li>
<li>我的本地解释器是 Anaconda Python 3.7.3，亲测 windows / ubuntu 均可正常运行，如无法执行可以试试 pip install nest-asyncio，依然无法解决请尝试安装 Anaconda Python</li>
<li>这次代码因为使用了较新的 API，所以需要较新的版本号，但是朋友们依然出现了一些运行时问题，这里先表示下歉意；同时也想说明的是，在提问之前自己经过充分搜索，尝试后解决问题，带来的快感，和能力的提升，相应也是很大的，一门工程最需要的是 hands on dirty work（动手做脏活），才能让自己的能力得到本质的提升，加油！<!-- raw HTML omitted -->2019-06-25<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->Airnm.毁<!-- raw HTML omitted --> 👍（8） 💬（3）<!-- raw HTML omitted -->豆瓣那个发现requests.get(url).content/text返回都为空，然后打了下status_code发现是418，网上找418的解释，一般是网站反爬虫基础机制，需要加请求头模仿浏览器就可跳过，改为下面的样子就可通过：url = &quot;https://movie.douban.com/cinema/later/beijing/&quot;
head={
'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36',
'Referer':'https://time.geekbang.org/column/article/101855',
'Connection':'keep-alive'}
res = requests.get(url,headers=head)<!-- raw HTML omitted -->2020-04-18<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->jackstraw<!-- raw HTML omitted --> 👍（4） 💬（2）<!-- raw HTML omitted -->有点没明白，前面说任务创建后立马就开始执行了么？怎么后面在解密底层运行过程的时候，说任务创建后等待执行？到底是哪一个呀？<!-- raw HTML omitted -->2020-01-14<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->长期规划<!-- raw HTML omitted --> 👍（2） 💬（1）<!-- raw HTML omitted -->老师，在最后那个协程例子中为何没用requests库呢？是因为它不支持协程吗<!-- raw HTML omitted -->2019-12-20<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->一凡<!-- raw HTML omitted --> 👍（1） 💬（1）<!-- raw HTML omitted -->协程是单线程怎么理解？所有的协程都是吗<!-- raw HTML omitted -->2020-06-18<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->苹果<!-- raw HTML omitted --> 👍（1） 💬（1）<!-- raw HTML omitted -->asyncio.run() cannot be called from a running event loop
这个问题是如何解决，</li>
</ol>
<!-- raw HTML omitted -->
<p>其中的await asyncio.sleep(2)是否可以理解为在切出当前程序，2秒后再继续执行print('worker_2 done')代码？
那么如果我有个耗时任务 def xxx(): &hellip;，那么该如何用await asyncio来让这个xxx函数运行并切出当前程序呢？<!-- raw HTML omitted -->2019-11-28<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->扶幽<!-- raw HTML omitted --> 👍（1） 💬（1）<!-- raw HTML omitted -->请问下有木有相关的书籍，来进行这块的学习呢！有些原理性的东西还是没办法深入理解，谢谢。<!-- raw HTML omitted -->2019-10-12<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->cotter<!-- raw HTML omitted --> 👍（1） 💬（3）<!-- raw HTML omitted -->受教了，第一次听说这个高级功能！
我在工作中遇到一个需要并发的问题，用python在后台并发执行shell ,并发数量用时间范围控制，要不停的改时间分多次串行，方法比较笨拙。协程可以简化我的代码。
老师，并发很多事件应该也是需要消耗很多资源，协程改如何控制并发数量？<!-- raw HTML omitted -->2019-06-24<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->SUN<!-- raw HTML omitted --> 👍（0） 💬（2）<!-- raw HTML omitted -->Jupyter 中运行 %time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4'])) 会报错：
RuntimeError: asyncio.run() cannot be called from a running event loop
Python、Anaconda、Jupyter都安装了。
话说：Jupyter不就是为了消除个人本地开发环境差异性而诞生的吗？这个结果有点反讽。
各位学员的留言都看了，没人解决了此问题……</p>
<!-- raw HTML omitted -->
<p>综合下前面的留言和个人的学习，总结下 py 3.6 版本下 asyncio 的主要不同：
1、没有 run(), create_task()，可以用 asyncio.get_even_loop().run_until_complete() 来代替 run()，用 ensure_future() 来代替 create_task()；
2、可能会出现 RuntimeError: This event loop is already running，解决方案一：pip install nest_asyncio; import nest_asyncio; nest_asyncio.apply()；解决方案二：有些友人说是 tornado 5.x 起的版本才有此问题，可考虑将其版本降至 4.x（不推荐）；
3、%time 与 %%time 的主要区别：%time func()（必须是同一行）；%%time 必须放在单元格的开头，强烈建议单独一行 + 不要与 import、def 相关的语句放在同个单元格；
4、爬虫中的 aiohttp.ClientSession(headers=header, connector=aiohttp.TCPConnector(ssl=False)) 提及未声明的 header，要么将 headers=header 部分去掉使用默认参数，要么用诸如 header={&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36&quot;} 来显式声明；
5、tasks = [asyncio.create_task(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks);
约等于
tasks = [crawl_page(url) for url in urls]; asyncio.get_even_loop().run_until_complete(asyncio.wait(tasks));
或
tasks = [asyncio.ensure_future(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks);<!-- raw HTML omitted -->2019-06-27<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->

    </div>

    

    
                                            </div>
                                            <div><hr class="doc-hr">
<div id="doc-nav" class="d-print-none">

	<div class="row flex-xl-nowrap ">
	<div class="col-sm-6 pt-2 doc-next">
		<a href="/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/19---%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8/">
			<div class="card h-100 my-1">
				<div class="card-body py-2">
                    <p class="card-title fs-5 fw-semibold lh-base mb-0"><i class="material-icons align-middle">navigate_before</i> 深入理解迭代器和生成器</p>
					
				</div>
			</div>
		</a>
        </div>
	<div class="col-sm-6 pt-2 doc-prev">
		<a class="ms-auto" href="/docs/python/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/21---python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bfutures/">
			<div class="card h-100 my-1 text-end">
				<div class="card-body py-2">
                    <p class="card-title fs-5 fw-semibold lh-base mb-0">Python并发编程之Futures <i class="material-icons align-middle">navigate_next</i></p>
					
				</div>
			</div>
		</a>
        </div>
	</div>
</div></div>
                                        </div>
                                    </div>
                                </div>
                            </div>
<footer class="shadow py-3 d-print-none">
    <div class="container-fluid">
        <div class="row align-items-center">
            <div class="col">
                <div class="text-sm-start text-center mx-md-2">
                    <p class="mb-0">
                        
                        <strong>NineDoller</strong>@<strong><a href="http://net.chenayin.com">Chenayin</a></strong>
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>
</main>
            </div>
        </div>

        
        
        <button onclick="topFunction()" id="back-to-top" aria-label="Back to Top Button" class="back-to-top fs-5"><svg width="24" height="24"><path d="M12,10.224l-6.3,6.3L4.32,15.152,12,7.472l7.68,7.68L18.3,16.528Z" style="fill:#fff"/></svg></button>
        
        

        
        




    
    
    






    <script src="/docs/js/bootstrap.js" defer></script>


    <script type="text/javascript" src="http://localhost:1313/docs/js/bundle.js" defer></script>

        

        
        <script type="module">
    var suggestions = document.getElementById('suggestions');
    var search = document.getElementById('flexsearch');

    const flexsearchContainer = document.getElementById('FlexSearchCollapse');

    const hideFlexsearchBtn = document.getElementById('hideFlexsearch');

    const configObject = { toggle: false }
    const flexsearchContainerCollapse = new Collapse(flexsearchContainer, configObject) 

    if (search !== null) {
        document.addEventListener('keydown', inputFocus);
        flexsearchContainer.addEventListener('shown.bs.collapse', function () {
            search.focus();
        });
        
        var topHeader = document.getElementById("top-header");
        document.addEventListener('click', function(elem) {
            if (!flexsearchContainer.contains(elem.target) && !topHeader.contains(elem.target))
                flexsearchContainerCollapse.hide();
        });
    }

    hideFlexsearchBtn.addEventListener('click', () =>{
        flexsearchContainerCollapse.hide()
    })

    function inputFocus(e) {
        if (e.ctrlKey && e.key === '/') {
            e.preventDefault();
            flexsearchContainerCollapse.toggle();
        }
        if (e.key === 'Escape' ) {
            search.blur();
            
            flexsearchContainerCollapse.hide();
        }
    };

    document.addEventListener('click', function(event) {

    var isClickInsideElement = suggestions.contains(event.target);

    if (!isClickInsideElement) {
        suggestions.classList.add('d-none');
    }

    });

    


    document.addEventListener('keydown',suggestionFocus);

    function suggestionFocus(e) {
    const suggestionsHidden = suggestions.classList.contains('d-none');
    if (suggestionsHidden) return;

    const focusableSuggestions= [...suggestions.querySelectorAll('a')];
    if (focusableSuggestions.length === 0) return;

    const index = focusableSuggestions.indexOf(document.activeElement);

    if (e.key === "ArrowUp") {
        e.preventDefault();
        const nextIndex = index > 0 ? index - 1 : 0;
        focusableSuggestions[nextIndex].focus();
    }
    else if (e.key === "ArrowDown") {
        e.preventDefault();
        const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
        focusableSuggestions[nextIndex].focus();
    }

    }

    


    (function(){

    var index = new FlexSearch.Document({
        
        tokenize: "forward",
        minlength:  0 ,
        cache:  100 ,
        optimize:  true ,
        document: {
        id: 'id',
        store: [
            "href", "title", "description"
        ],
        index: ["title", "description", "content"]
        }
    });


    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


    

    

    index.add(
            {
                id:  0 ,
                href: "\/docs\/ai\/",
                title: "AI",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  1 ,
                href: "\/docs\/ai\/mcp-%E5%88%9D%E8%AF%95%E9%AA%8C\/",
                title: "MCP 初试验",
                description: "Where are we?（我们现在在哪？） link现在已经拥有了数据分析平台，拥有的基本的数据查询和数据分析能力。\nWhere are we going?（我们要到哪⼉去？） link但是我们的分析平台想和AI进行结合，能够拥有更灵活，更简单，更智能的查询方式，能够通过自然语言去执行对应的查询和分析工作，不再依赖一板一眼的面板操作\nHow can we get there?（我们如何到达那⾥？） link增加MCP服务，衔接后端服务和智能体客户端（可以是Cursor，Trae这样的，也可以是自己开发的）\n示例 link MCP实现方式并不拘泥于某种编程语言，本文以Java实现。\nSystem requirements 系统要求 linkJava 17 或更高版本已安装。 Spring Boot 3.3.x 或更高版本\n依赖选择 link通过 SpringBoot 项目初始化之后，再额外添加以下依赖\norg.springframework.ai\rspring-ai-starter-mcp-server\rorg.springframework\rspring-web\rBest Practices 最佳实践 link 作者提示： 这里虽说是最佳实践，我以为是必须要严格执行的。后文中的属性配置，其实就是这里要求的具体实现。\nUse a logging library that writes to stderr or files. 使用将日志写入 stderr 或文件的日志库。 Ensure any configured logging library will not write to STDOUT 确保任何配置的日志库不会将日志写入 STDOUT 程序属性配置 link spring.main.bannerMode=off\rlogging.pattern.console= 或者习惯yaml的话\n",
                content: "Where are we?（我们现在在哪？） link现在已经拥有了数据分析平台，拥有的基本的数据查询和数据分析能力。\nWhere are we going?（我们要到哪⼉去？） link但是我们的分析平台想和AI进行结合，能够拥有更灵活，更简单，更智能的查询方式，能够通过自然语言去执行对应的查询和分析工作，不再依赖一板一眼的面板操作\nHow can we get there?（我们如何到达那⾥？） link增加MCP服务，衔接后端服务和智能体客户端（可以是Cursor，Trae这样的，也可以是自己开发的）\n示例 link MCP实现方式并不拘泥于某种编程语言，本文以Java实现。\nSystem requirements 系统要求 linkJava 17 或更高版本已安装。 Spring Boot 3.3.x 或更高版本\n依赖选择 link通过 SpringBoot 项目初始化之后，再额外添加以下依赖\norg.springframework.ai\rspring-ai-starter-mcp-server\rorg.springframework\rspring-web\rBest Practices 最佳实践 link 作者提示： 这里虽说是最佳实践，我以为是必须要严格执行的。后文中的属性配置，其实就是这里要求的具体实现。\nUse a logging library that writes to stderr or files. 使用将日志写入 stderr 或文件的日志库。 Ensure any configured logging library will not write to STDOUT 确保任何配置的日志库不会将日志写入 STDOUT 程序属性配置 link spring.main.bannerMode=off\rlogging.pattern.console= 或者习惯yaml的话\nlogging:\rpattern:\rconsole:\rspring:\rmain:\rbanner-mode: off 相关的配置全集 ： 点击查看\n编写Service link官方文档内容如下：\n@Service 注解会自动将服务注册到应用程序上下文中。Spring AI @Tool 注解，使得创建和维护 MCP 工具变得非常容易。The auto-configuration will automatically register these tools with the MCP server. 自动配置会自动将这些工具注册到 MCP 服务器上。\n作者按： 看起来与平常编写sevice，并无二异。但其中暗藏玄机\n和前面提到的一样， 编码过程不要出现任何打印输出的内容，如果非要打印，以err的形式打印 Sysout.err.println(); @Tool 注解会将对应的方法 注册到MCP服务器上作为工具使用 package com.xmic.mcp.data.analysis.service;\rimport com.fasterxml.jackson.databind.ObjectMapper;\rimport com.xmic.mcp.data.analysis.common.Constants;\rimport com.xmic.mcp.data.analysis.common.R;\rimport com.xmic.mcp.data.analysis.common.ResponseData;\rimport com.xmic.mcp.data.analysis.dto.DataQueryDTO;\rimport com.xmic.mcp.data.analysis.dto.ItemDTO;\rimport com.xmic.mcp.data.analysis.utils.JsonUtils;\rimport org.springframework.ai.tool.annotation.Tool;\rimport org.springframework.beans.factory.annotation.Autowired;\rimport org.springframework.stereotype.Service;\rimport org.springframework.web.client.RestClient;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\rimport java.util.Objects;\r@Service\rpublic class DataQueryService {\r@Autowired\rprivate ObjectMapper objectMapper;\rprivate static final String BASE_URL = \"http://192.168.15.172/api\";\rprivate RestClient restClient;\rpublic DataQueryService() {\rthis.restClient = RestClient.builder()\r.baseUrl(BASE_URL)\r.defaultHeader(\"Accept\", \"*/*\")\r.defaultHeader(\"Content-Type\", \"application/json\")\r.defaultHeader(\"User-Agent\", \"WeatherApiClient/1.0 (zxt@xmic.com)\")\r.defaultHeader(\"Authorization\", Constants.TOKEN_NEVER_EXPIRE)\r.build();\r}\r@Tool(description = \"依据工作面code和设备因子名称查询对应的历史数据，包含 最大值，平均值，和最小值\")\rpublic String queryHistoryDataOnFaceCode(DataQueryDTO query) {\r// 判断query中 faceCode ,factorCode 不能为空\rif (Objects.isNull(query.getFaceCode()) || Objects.isNull(query.getFactorCodes())) {\rreturn \"faceCode 和 factorCode 不能为空\";\r}\rMap result = new HashMap\u003c\u003e();\rR response = restClient.post()\r.uri(\"/data/history/chart/figure2D\")\r.body(query)\r.retrieve()\r.body(R.class);\rif (Objects.isNull(response)) {\rresult.put(\"msg\", \"查询失败了\");\rreturn JsonUtils.toJson(result);\r}\rif (Objects.equals(response.getStatus(), R.OK)) {\rResponseData responseData = objectMapper.convertValue(response.getData(), ResponseData.class);\rMap"
            }
        );
    index.add(
            {
                id:  2 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/",
                title: "Python核心技术与实战",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  3 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/",
                title: "Python核心技术与实战",
                description: "课程介绍 link人工智能时代下，Python毫无疑问是最热的编程语言。有人夸它功能强大还上手轻松，有人说它学习曲线不那么陡峭，但是更多的人，在推开Python的大门后却发现，Python入门容易但精通却不易。\n你是否也曾傻傻分不清“列表”“元组”“字典”“集合”等的用法，甚至试图在集合中采用索引方式？ 你是否也曾苦苦钻研面向对象的理念，却在被要求设计一个稍复杂点的系统时束手无策？ 你是否也曾羡慕别人能巧用装饰器、生成器等高级操作，可自己在写代码时，却连异常抛出、内存不足等边界条件都战战兢兢搞不定呢？ 由此可见，想要精通这门语言，必须真正理解知识概念，比如适当从源码层面深化认知，然后熟悉实际的工程应用，独立完成项目开发。这样，你才能成为真正的语言高手。\n在这个专栏里，景霄会从工程的角度，带你学习Python。专栏基于Python最新的3.7版本，以语言知识结合工程应用为主线，其中包含了大量的独家解读和实际工作案例。内容难易兼顾，既可以带你巩固核心基础，更会教你各种高级进阶操作，让你循序渐进、系统掌握Python这门语言。\n专栏按照进阶难度分为4个模块。\n前两部分主要是Python的基础篇和进阶篇。除去必要的概念、操作讲解，基础篇和进阶篇都着重强调了学习中的重难点和易错点，并从性能分析、实际应用举例等不同维度出发，让你轻松理解和掌握它们。\n第三部分是规范篇，通过讲解合理分解代码、运用assert、写单元测试等具体编程技巧，教你写出高质量的Python程序。\n第四部分则是实战篇，这部分会通过量化交易系统项目的开发，带你串联起前面所学的Python知识，并加入大量的实战经验和技巧，让你在独立项目开发中获得质的提高。\n课程的练习代码：\nhttps://github.com/zwdnet/PythonPractice\n开篇词 link你好，我是景霄。\n我是Facebook的一名全栈工程师，目前从事机器学习的相关工作，主要工作领域是人工智能的推荐排序系统与算法。工作期间，我曾领导多个上亿用户级产品的开发与落地，有丰富的工程与实战经验。\n一听机器学习，很多人第一反应可能是“好难呀、厉害呀”。可事实上，我的编程之路并非一路高光。\n不同于大城市长大或竞赛出身、十一二岁接触编程的人，在刚上大学时，我的编程基础几乎为零。大一上的C语言，便是我出生起学到的第一门编程语言。初识计算机语言的世界，很有趣也很吸引我，这也是我成为程序员的最初动力。\n和很多对编程感兴趣的人一样，哪怕老师只是在讲台上，照本宣科地读着N年前的课件，我也会竖起耳朵认真听讲、认真做笔记。并且，私下里我还买了不少厚重的大块头书，在网上查了不少博客、帖子，照着上面的例子一行行地敲代码。很多内容我并不理解，比如指针、递归这类抽象的概念，查了一堆资料也没看明白。但靠着死记硬背，考试基本可以过关，虽然这个过程比较痛苦，也比较累。\n后来，为了更深入了解计算机，我去了哥伦比亚大学攻读计算机硕士学位，又陆续学到不少新的编程语言，比如Node.js、Python、PHP、Scala等等。这个阶段，我边学习，边做项目，却发现轻松了很多。\n这两个学习阶段，收获和感受天差地别，难道仅仅是因为“万事入门难”吗？我不止一次反思过这个问题，终于发现，问题出在了资料本身上。\n为什么这么说呢？一是因为书上或网上的很多东西，非常理论化，实例少之又少，单凭死记硬背很难真正掌握；二是这些内容中，原创的观点和经验更少，大多互相抄袭，内容雷同且不实用，远离实际工程，毫无借鉴价值。\n但显然，市面上的资料问题，我们个人是很难解决的。我们能做的，便是克服常见资料的弊端，另辟蹊径来学习。这其中，最重要的一点就是，从工程的角度思考学习，以实用为出发点，多练习、多阅读、多做项目，这样才能有质的提高。\n在Facebook工作的这么多年，也验证了我的观点。我身边的新手，他们学习新的语言总是只会啃书练习，还难以上手；而有经验的同事则不同，他们能花很短的时间看完基础语法，然后找行家去了解一些重难点、易错点，最后亲自动手完成一个项目，达到融会贯通的效果。这样下来，可能几周时间就掌握得差不多了。\n",
                content: "课程介绍 link人工智能时代下，Python毫无疑问是最热的编程语言。有人夸它功能强大还上手轻松，有人说它学习曲线不那么陡峭，但是更多的人，在推开Python的大门后却发现，Python入门容易但精通却不易。\n你是否也曾傻傻分不清“列表”“元组”“字典”“集合”等的用法，甚至试图在集合中采用索引方式？ 你是否也曾苦苦钻研面向对象的理念，却在被要求设计一个稍复杂点的系统时束手无策？ 你是否也曾羡慕别人能巧用装饰器、生成器等高级操作，可自己在写代码时，却连异常抛出、内存不足等边界条件都战战兢兢搞不定呢？ 由此可见，想要精通这门语言，必须真正理解知识概念，比如适当从源码层面深化认知，然后熟悉实际的工程应用，独立完成项目开发。这样，你才能成为真正的语言高手。\n在这个专栏里，景霄会从工程的角度，带你学习Python。专栏基于Python最新的3.7版本，以语言知识结合工程应用为主线，其中包含了大量的独家解读和实际工作案例。内容难易兼顾，既可以带你巩固核心基础，更会教你各种高级进阶操作，让你循序渐进、系统掌握Python这门语言。\n专栏按照进阶难度分为4个模块。\n前两部分主要是Python的基础篇和进阶篇。除去必要的概念、操作讲解，基础篇和进阶篇都着重强调了学习中的重难点和易错点，并从性能分析、实际应用举例等不同维度出发，让你轻松理解和掌握它们。\n第三部分是规范篇，通过讲解合理分解代码、运用assert、写单元测试等具体编程技巧，教你写出高质量的Python程序。\n第四部分则是实战篇，这部分会通过量化交易系统项目的开发，带你串联起前面所学的Python知识，并加入大量的实战经验和技巧，让你在独立项目开发中获得质的提高。\n课程的练习代码：\nhttps://github.com/zwdnet/PythonPractice\n开篇词 link你好，我是景霄。\n我是Facebook的一名全栈工程师，目前从事机器学习的相关工作，主要工作领域是人工智能的推荐排序系统与算法。工作期间，我曾领导多个上亿用户级产品的开发与落地，有丰富的工程与实战经验。\n一听机器学习，很多人第一反应可能是“好难呀、厉害呀”。可事实上，我的编程之路并非一路高光。\n不同于大城市长大或竞赛出身、十一二岁接触编程的人，在刚上大学时，我的编程基础几乎为零。大一上的C语言，便是我出生起学到的第一门编程语言。初识计算机语言的世界，很有趣也很吸引我，这也是我成为程序员的最初动力。\n和很多对编程感兴趣的人一样，哪怕老师只是在讲台上，照本宣科地读着N年前的课件，我也会竖起耳朵认真听讲、认真做笔记。并且，私下里我还买了不少厚重的大块头书，在网上查了不少博客、帖子，照着上面的例子一行行地敲代码。很多内容我并不理解，比如指针、递归这类抽象的概念，查了一堆资料也没看明白。但靠着死记硬背，考试基本可以过关，虽然这个过程比较痛苦，也比较累。\n后来，为了更深入了解计算机，我去了哥伦比亚大学攻读计算机硕士学位，又陆续学到不少新的编程语言，比如Node.js、Python、PHP、Scala等等。这个阶段，我边学习，边做项目，却发现轻松了很多。\n这两个学习阶段，收获和感受天差地别，难道仅仅是因为“万事入门难”吗？我不止一次反思过这个问题，终于发现，问题出在了资料本身上。\n为什么这么说呢？一是因为书上或网上的很多东西，非常理论化，实例少之又少，单凭死记硬背很难真正掌握；二是这些内容中，原创的观点和经验更少，大多互相抄袭，内容雷同且不实用，远离实际工程，毫无借鉴价值。\n但显然，市面上的资料问题，我们个人是很难解决的。我们能做的，便是克服常见资料的弊端，另辟蹊径来学习。这其中，最重要的一点就是，从工程的角度思考学习，以实用为出发点，多练习、多阅读、多做项目，这样才能有质的提高。\n在Facebook工作的这么多年，也验证了我的观点。我身边的新手，他们学习新的语言总是只会啃书练习，还难以上手；而有经验的同事则不同，他们能花很短的时间看完基础语法，然后找行家去了解一些重难点、易错点，最后亲自动手完成一个项目，达到融会贯通的效果。这样下来，可能几周时间就掌握得差不多了。\n这样的差距，确实让人心塞，而这也是我开这个专栏的最初动力——帮助更多入门级程序员迅速成长。至于专栏主题，我选择了Python这门编程语言，原因也很明了。\n这首先来自于我个人的重要感悟。经过多年学习工作的积累，我深刻认识到，牢牢掌握一门编程语言及其学习方法，是日后在所有领域深造的根基。而在实际工作和生活中，我更是见过不少反例，比如搞机器学习的工程师，算法、理论等极强，但是编程水平或是工程水平很一般，于是涉及到偏工程的工作或合作时，就显得力不从心，这样就非常可惜了。\n另外，不可否认，Python确实是这个时代最流行、也必须要掌握的编程语言。Python可以运用在数据处理、Web开发、人工智能等多个领域，它的语言简洁、开发效率高、可移植性强，并且可以和其他编程语言（比如C++）轻松无缝衔接。现如今，不少学校的文科生甚至中学生也开设了此课程，可见其重要程度。\n因此，我决定开设这么一个专栏，从工程的角度去讲解Python这门编程语言。我不是语言学专家，不会死抠一些很偏的知识点；相反，作为一名工程师，我会从实际出发，以工作中遇到的实例为主线，去讲解Python的核心技术和应用。\n专栏的所有内容都基于Python最新的3.7版本，其中有大量独家解读、案例，以及不少我阅读源码后的发现和体会。同时，在层次划分上，我希望能难易兼顾，循序渐进。专栏中既有核心的基础知识，也有高级的进阶操作，尽量做到“老少皆宜”。\n从内容上来说，专栏主要分为四大版块。\n1. Python基础篇\n第一部分主要讲解Python的基础知识。当然，不同于其他基础教材，专栏的基础版块并不只有基础概念、操作，我同时加入了很多进阶难度的知识，或是一些重难点、易错点等需要注意的地方。如果你觉得自己基础的东西都会了，这部分不用学了，那你就大错特错了。比如，\n列表和元组存储结构的差异是怎样的？它们性能的详细比较又如何？ 字符串相加的时间复杂度，你真的清楚吗？ 基础不牢，地动山摇。更深刻、实质的基础理解，才是更牢固的知识大厦的根基。我希望这一版块，不仅可以让入门级的程序员查漏补缺、打牢基础，也能让有经验的程序员，重新从工程角度认识基础、升华理解。\n2. Python进阶篇\n这部分讲的是 Python的一些进阶知识，比如装饰器、并发编程等等。如果你的工作只是写100行以下的脚本程序，可能不怎么会用得到。但如果你做的是大型程序的开发，则非常有必要。我希望通过这一版块，让你熟悉各种高级用法，真正理解Python，理解这门编程语言的特点。\n3. Python规范篇\n这部分着重于教你把程序写得更加规范、更加稳定。我在实际工作中见过不少程序员，会写程序，但写得实在有点“惨不忍睹”，导致最后调试起来错误不断，修改非常费劲儿。因此，我觉得用单独一个版块讲解这个问题非常有必要。\n当然，我不会用一些似是而非的规范来说教，而是会用具体的编程操作和技巧，教你提高代码质量。比如，如何合理地分解代码、运用assert，如何写单元测试等等。\n4. Python实战篇\n没上过战场开过枪的人，不可能做主官；没有实战经验的语言学习者，不可能成为高手。这部分，我会通过量化交易系统这个具体的实战案例，带你综合运用前面所学的Python知识。\n真正要掌握一门编程语言，仅仅学会分散的知识点是不够的，还必须要把知识点串联起来，做一些中型的项目才能有更深的领悟与提高。\n专栏篇幅只有40多篇，但是每篇绝对都是干货满满。我希望这个专栏，能帮助更多入门级和有一定项目基础的程序员，真正掌握Python，并且给你一些学习上的启发。\n100天后，晋级为Python高手，让我们一起加油吧！\n课程的练习代码：[https://github.com/zwdnet/PythonPractice\n"
            }
        );
    index.add(
            {
                id:  4 ,
                href: "\/docs\/",
                title: "Stay Hungry,Stay Foolish",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  5 ,
                href: "\/docs\/%E6%97%A5%E5%B8%B8\/%E5%91%8A%E5%88%AB%E4%BB%A3%E7%A0%81%E5%B7%A5%E4%BA%BA\/",
                title: "告别代码工人",
                description: "过去 25 年，从互联网到移动互联网的浪潮，创造了海量的工程需求，软件工程师也因此成为了时代的宠儿。但现在，这波巨大的增长红利期已经结束。\n那下一个浪潮是什么？文章给出了答案：Agentic AI (智能体 AI)。\n这不仅仅是一个新技术，它将彻底重塑我们的工作方式，重写“软件工程师”这个岗位的核心要求。这不是一次普通的更新，这是一场彻底的进化。\n告别“代码工人”，拥抱“智能体工程师” link文章预言，软件工程师不会被淘汰，而是将进化，去“驾驭”这波新的 AI 浪潮。我们将成为所谓的 “智能体软件工程师” (Agentic Software Engineer)。\n在这个新角色下，我们的工作不再是整天埋头编写成千上万行代码。AI Agent 可以比我们更快、更不知疲倦地完成这项任务。我们的核心职责，将转变为：\n一个指挥、协调、审查和运维 AI Agent 军团的专家。\n我们从亲自下场比赛的“运动员”，变成了运筹帷幄的“教练”。\nAI 时代的生存指南：你的技能升级清单 link那么，要成为一名合格的“智能体软件工程师”，我们需要点亮哪些新的技能树？文章为我们梳理了一份极其宝贵的“技能升值/贬值清单”。\n技能升值 (Skills++)：这 6 项能力将是你未来的护城河 link 版本控制 (Version Control) Git 不再仅仅是你个人的代码管理工具，它将成为协调你与成百上千个“AI 码农”协同工作的核心骨干。你需要用它来管理 Agent 的并行工作流、审查 Agent 提交的 PR、以及在 Agent 犯错时进行回滚。精通 Git 模型，将是从业基础。\n产品思维 (“Product”) AI Agent 擅长执行，但前提是指令必须清晰。任务分解、需求定义、接口设计等产品经理的核心技能，将成为每个工程师的必备能力。如果你无法将一个模糊的想法拆解成 Agent 可以处理的、足够小的任务块，你将无法与 Agent 高效协作。\n代码审查 (Code Review) 这是未来我们耗时最多的日常工作。当 Agent 可以在 10 分钟内生成 500 行复杂的代码时，你的价值就体现在审查这些代码的正确性、可维护性和安全性上。接受吧，你正在从一个 Code Writer 变成一个 Code Editor。\n",
                content: "过去 25 年，从互联网到移动互联网的浪潮，创造了海量的工程需求，软件工程师也因此成为了时代的宠儿。但现在，这波巨大的增长红利期已经结束。\n那下一个浪潮是什么？文章给出了答案：Agentic AI (智能体 AI)。\n这不仅仅是一个新技术，它将彻底重塑我们的工作方式，重写“软件工程师”这个岗位的核心要求。这不是一次普通的更新，这是一场彻底的进化。\n告别“代码工人”，拥抱“智能体工程师” link文章预言，软件工程师不会被淘汰，而是将进化，去“驾驭”这波新的 AI 浪潮。我们将成为所谓的 “智能体软件工程师” (Agentic Software Engineer)。\n在这个新角色下，我们的工作不再是整天埋头编写成千上万行代码。AI Agent 可以比我们更快、更不知疲倦地完成这项任务。我们的核心职责，将转变为：\n一个指挥、协调、审查和运维 AI Agent 军团的专家。\n我们从亲自下场比赛的“运动员”，变成了运筹帷幄的“教练”。\nAI 时代的生存指南：你的技能升级清单 link那么，要成为一名合格的“智能体软件工程师”，我们需要点亮哪些新的技能树？文章为我们梳理了一份极其宝贵的“技能升值/贬值清单”。\n技能升值 (Skills++)：这 6 项能力将是你未来的护城河 link 版本控制 (Version Control) Git 不再仅仅是你个人的代码管理工具，它将成为协调你与成百上千个“AI 码农”协同工作的核心骨干。你需要用它来管理 Agent 的并行工作流、审查 Agent 提交的 PR、以及在 Agent 犯错时进行回滚。精通 Git 模型，将是从业基础。\n产品思维 (“Product”) AI Agent 擅长执行，但前提是指令必须清晰。任务分解、需求定义、接口设计等产品经理的核心技能，将成为每个工程师的必备能力。如果你无法将一个模糊的想法拆解成 Agent 可以处理的、足够小的任务块，你将无法与 Agent 高效协作。\n代码审查 (Code Review) 这是未来我们耗时最多的日常工作。当 Agent 可以在 10 分钟内生成 500 行复杂的代码时，你的价值就体现在审查这些代码的正确性、可维护性和安全性上。接受吧，你正在从一个 Code Writer 变成一个 Code Editor。\n测试 (Testing) 文章说：“We’re all SDETs now.”（我们现在都是软件测试开发工程师了）。面对一个可能会“创造性”地修改代码以绕过测试的 Agent，编写精准、全面的测试用例，是约束和指导 Agent 行为的最有力工具。 那些热衷于寻找边界条件、享受“破坏”代码乐趣的工程师，将在新时代中变得极其宝贵。\n系统设计 (System Design) 未来的系统设计，需要更多地考虑如何容纳和管理不那么可靠的 Agent。你需要设计出具有清晰边界、强健接口、高度可测试性的系统，这样即使 Agent 的某个部分出错，也不会导致整个系统崩溃。\n运维 (Operations) 我们都将成为 “智能体可靠性工程师” (Agent Reliability Engineer)。你需要设计、部署、监控和调试由无数 Agent 组成的复杂网络。当仪表盘上警报响起时，你需要快速定位问题是出在哪个 Agent 的行为上。学习大规模系统的运维之道，宜早不宜迟。\n技能贬值 (Skills–)：这些技能正在被 AI 替代 link LeetCode 式算法题： AI 已经能在瞬间解决大部分算法题。 语言语法熟练度： Agent 知道所有语法细节，你只需能读懂代码即可。 打字速度： AI “思考”和“打字”的速度，是人类无法企及的。 现在，立即开始行动 link这篇文章给我们的不应是焦虑，而是行动的路线图。我们应该如何开始？\n亲自使用 Agent： 去尝试 Claude Code、Gemini CLI 等领先的编码智能体。找一个终端窗口，看着它工作 15 分钟，感受一下未来的工作形态。 “外包”你的日常工作： 在你现有的开发流程中，寻找那些可以“委托”给 Agent 的任务。比如：“为我刚才的提交补充单元测试”，或者“重构这个函数，让它更具可读性”。 刻意练习新技能： 将你的学习时间，有意识地投入到上述 6 项“升值技能”上。 小结：浪潮已至，要么驾驭，要么被吞没 link软件工程师的“25年黄金时代”或许已经落幕，但这不意味着职业的终结。\n一个由 AI 驱动的、充满无限可能的新时代正在开启。这场变革是不可避免的，拥抱 Agent 的公司，必将“碾压”那些固步自封的公司。而能够驾驭 Agent 的工程师，也必将成为这些公司的核心。\n角色的转变或许是痛苦的，甚至会像文章所说的那样，变得有些“无聊”。我们可能会失去一些亲手创造的“流心”时刻。但这是进化的代价，也是我们保持价值的唯一途径。\n现在，拿起你的冲浪板，开始学习如何驾驭这波巨浪吧。\n成为一名“智能体软件工程师”，从今天开始\n参考链接 linkAI 正在重写“软件工程师”的岗位描述：未来你需要这 6 项核心技能 - Tony Bai\nThe Agentic Software Engineer | DoltHub Blog\n"
            }
        );
    index.add(
            {
                id:  6 ,
                href: "\/docs\/python\/",
                title: "Python",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  7 ,
                href: "\/docs\/python\/python\/",
                title: "Python",
                description: " 笔者为 Javaer 所以仅记录和Java语言的不同之处，方便快速学习\n基础数据类型 link 数字 bool（布尔型）：True | False\n笔者按： 布尔值要驼峰命令\ncomplex （复数），如 1 + 2j、 1.1 + 2.2j。\n笔者按： 已经忘记复数这个数学概念啦~\n字符串 索引 字符串的组成元素为字符，每个字符在字符串中有对应的索引。\n和java不同的是，不光有正序索引，还有倒序索引\n截取 字符串的截取，都是 前闭后开 或者 叫 含头不含尾\npython字符串的截取和索引强相关；\n但又因为有正序和倒序，两排索引，所以截取时非常灵活，使用时也要谨慎\n图片来自网络，倒数第二个例子有点奇怪： 描述和结果都不对；要实现输出结果ab，可通过如下方式\nprint(str[:2]) # ab\rprint(str[:-5]) # ab str=\"abcdefg\"\rprint(str[1:]) # bcdefg\rprint(str[:5]) # abcde\rprint(str[1:5]) # bcde\rprint(str[-4:]) # defg\rprint(str[-2:-6]) # 空字符串 是 '' 不是None\rprint(str[-6:-2]) #bcde\rprint(str[::-1]) # 字符串反转 gfedcba\rprint(str[:2]) # ab\rprint(str[:-5]) # ab 列表 笔者按： 和Java中的数组特点一样； 最大最大的区别是 一个数组可以有不同类型的元素；\n",
                content: " 笔者为 Javaer 所以仅记录和Java语言的不同之处，方便快速学习\n基础数据类型 link 数字 bool（布尔型）：True | False\n笔者按： 布尔值要驼峰命令\ncomplex （复数），如 1 + 2j、 1.1 + 2.2j。\n笔者按： 已经忘记复数这个数学概念啦~\n字符串 索引 字符串的组成元素为字符，每个字符在字符串中有对应的索引。\n和java不同的是，不光有正序索引，还有倒序索引\n截取 字符串的截取，都是 前闭后开 或者 叫 含头不含尾\npython字符串的截取和索引强相关；\n但又因为有正序和倒序，两排索引，所以截取时非常灵活，使用时也要谨慎\n图片来自网络，倒数第二个例子有点奇怪： 描述和结果都不对；要实现输出结果ab，可通过如下方式\nprint(str[:2]) # ab\rprint(str[:-5]) # ab str=\"abcdefg\"\rprint(str[1:]) # bcdefg\rprint(str[:5]) # abcde\rprint(str[1:5]) # bcde\rprint(str[-4:]) # defg\rprint(str[-2:-6]) # 空字符串 是 '' 不是None\rprint(str[-6:-2]) #bcde\rprint(str[::-1]) # 字符串反转 gfedcba\rprint(str[:2]) # ab\rprint(str[:-5]) # ab 列表 笔者按： 和Java中的数组特点一样； 最大最大的区别是 一个数组可以有不同类型的元素；\n换句话说： 一个数组中可以同时存在 数字，字符串。\nlist1 = ['Google', 'baidu', 1997, 2000] 删除方法\ndel list[1] 添加方法\nlist.append('red') 【思考】如何预创建一个容量为n的列表？\n📝 注意事项\nPython 列表是动态数组，不需要像 C++ 的 vector 或 Java 的 ArrayList 那样“预分配容量”来提高性能。 如果你只是想创建一个将来要存 n 个元素的列表，直接使用空列表即可： python深色版本\nlst = [] 然后通过 append() 添加元素即可。\n如果非要创建呢？\nlst = [None] * 6\rprint(lst) # 输出: [None, None, None, None, None, None] 元组 和列表功能类似，区别有两个\n元祖不可变： 不可变指：元素数量和值在定义之后都不允许发生变化\n元祖用 () ; 列表用 [] .\ntup = (1, 2, 3, 4, 5 )\rprint(tup) # (1, 2, 3, 4, 5)\r#tup[0] = 15\r#print(tup) # TypeError: 'tuple' object does not support item assignment\r#tup.append(6)\r#print(tup) # AttributeError: 'tuple' object has no attribute 'append' 集合 使用方式:注意是 {}\n特点有三：\n可变 无序 元素唯一 （不重复） 和Java的Set的特点相似，在Python中也叫Set;\n元素唯一的特性常常用来去重\nfruits = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\rprint(fruits) # 这⾥演示的是去重功能 {'pear', 'orange', 'banana', 'apple'}\rprint( 'orange' in fruits) # 快速判断元素是否在集合内 True\rprint( 'crabgrass' in fruits) # False 字典 字典就是KV；可以依据key，查询value\n在Java中就是Map; put的方式不一样\n字典的初始化、进和出 示例如下:\nzhangsan={\r\"name\":\"zhangsan\",\r\"age\":\"17\",\r\"height\":\"180\",\r\"weight\":\"80kg\"\r}\r#给字典添加元素\rzhangsan[\"city\"]=\"BeiJing\"\r#获取字典的元素\rprint(zhangsan.get(\"age\")) 数据类型的判断和转换 link判断 linktype(变量)\n常规的判断就不展示了，展示一些有悖常规的。\n\u003e\u003e\u003e type([1,2,3])\r"
            }
        );
    index.add(
            {
                id:  8 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/01---%E5%A6%82%E4%BD%95%E9%80%90%E6%AD%A5%E7%AA%81%E7%A0%B4%E6%88%90%E4%B8%BApython%E9%AB%98%E6%89%8B\/",
                title: "如何逐步突破，成为Python高手？",
                description: "你好，我是景霄。\n工作中，我总听到很多程序员抱怨，说现在的计算机编程语言太多了，学不过来了。一些人Java用了很多年，但是最近的项目突然需要用Python，就会不知所措，压力很大。\n众所周知，Facebook的主流语言是Hack（PHP的进化版本）。不过，我敢拍着胸脯说，就刚入职的工程师而言，100个里至少有95个，以前都从未用过Hack或者PHP。但是，这些人上手都特别快，基本上一两周后，日常编程便毫无压力了。\n他们是怎么做到的呢？\n事实上，他们遵循的，正是我在开篇词中提到的方法，也是本专栏学习的中心观点：“从工程的角度去学习Python”。那么具体来说，到底要怎么学，学习的过程中又要特别注意哪些地方呢？\n不同语言，需融会贯通 link其实，如果你在学一门语言的时候多阅读、多练习、多思考，你就会发现，不同语言都是类似的。编程语言本就是人类控制计算机的指令，语法规则等方面自然大同小异。\n而在原有基础上，学习一门新的编程语言，其实也没有那么难，你首先要做到的是明确区分。比如，在学习Python的条件与循环语句时，多回忆一下其他语言的语法是怎样的。再如，遇到Python中的字符串相加时，你能分析出它的复杂度吗？再联想到其他语言，比如Java中字符串相加的复杂度，它们之间有什么相同点、又有什么区别呢？\n除了能够明确区分语言的不同点，我们还要能联系起来灵活运用。比如，最典型的“编程语言两问”：\n你了解你学过的每种编程语言的特点吗？ 你能根据不同的产品需求，选用合适的编程语言吗？ 举个例子，Python的优点之一是特别擅长数据分析，所以广泛应用于人工智能、机器学习等领域，如机器学习中TensorFlow的框架，就是用Python写的。但是涉及到底层的矩阵运算等等，还是要依赖于C++完成，因为C++的速度快，运行效率更高。\n事实上，很多公司都是这样，服务器端开发基于Python，但底层的基础架构依赖于C++。这就是典型的“不同需求选用不同语言”。毕竟，你要明白，哪怕只是几十到几百毫秒的速度差距，对于公司、对于用户体验来说都是决定性的。\n唯一语言，可循序渐进 link当然，如果Python是你学的第一门编程语言，那也不必担心。我们知道，虽然同为人机交互的桥梁，Python语言比起C++、Java等主流语言，语法更简洁，也更接近英语，对编程世界的新人还是很友好的，这也是其显著优点。这种情况下，你要做的就是专注于Python这一门语言，明确学习的重点，把握好节奏循序渐进地学习。\n根据我多年的学习工作经验，我把编程语言的学习重点，总结成了下面这三步，无论你是否有其他语言的基础，都可以对照来做，稳步进阶。\n第一步：大厦之基，勤加练习 link任何一门编程语言，其覆盖范围都是相当广泛的，从基本的变量赋值、条件循环，到并发编程、Web开发等等，我想市面上几乎没有任何一本书能够罗列完全。\n所以，我建议你，在掌握必要的基础时，就得多上手操作了。千万不要等到把教材上所有东西都学完了才开始，因为到那时候你会发现，前面好不容易记住的一堆东西似乎又忘记了。计算机科学是一门十分讲究实战的学科，因此越早上手练习，练得越多越勤，就越好。\n不过，到底什么叫做必要的基础呢？以Python为例，如果你能够理解变量间的赋值、基本的数据类型、条件与循环语句、函数的用法，那么你就达到了第一步的底线标准，应该开始在课下多多练习了。\n比方说，你可以自己动手编程做一个简易的计算器，这应该也是大多数程序员实操的第一个小项目。用户输入数字和运算符后，你的程序能够检查输入是否合法并且返回正确的结果吗？\n在做这个小项目的过程中，你可能会遇到不少问题。我的建议是，遇到不懂的问题时，多去Stack Overflow上查询，这样你还能阅读别人优秀的代码，借鉴别人的思路，对于你的学习肯定大有帮助。当然，实在解决不了的问题，也可以写在留言区，我们一起来解决。\n",
                content: "你好，我是景霄。\n工作中，我总听到很多程序员抱怨，说现在的计算机编程语言太多了，学不过来了。一些人Java用了很多年，但是最近的项目突然需要用Python，就会不知所措，压力很大。\n众所周知，Facebook的主流语言是Hack（PHP的进化版本）。不过，我敢拍着胸脯说，就刚入职的工程师而言，100个里至少有95个，以前都从未用过Hack或者PHP。但是，这些人上手都特别快，基本上一两周后，日常编程便毫无压力了。\n他们是怎么做到的呢？\n事实上，他们遵循的，正是我在开篇词中提到的方法，也是本专栏学习的中心观点：“从工程的角度去学习Python”。那么具体来说，到底要怎么学，学习的过程中又要特别注意哪些地方呢？\n不同语言，需融会贯通 link其实，如果你在学一门语言的时候多阅读、多练习、多思考，你就会发现，不同语言都是类似的。编程语言本就是人类控制计算机的指令，语法规则等方面自然大同小异。\n而在原有基础上，学习一门新的编程语言，其实也没有那么难，你首先要做到的是明确区分。比如，在学习Python的条件与循环语句时，多回忆一下其他语言的语法是怎样的。再如，遇到Python中的字符串相加时，你能分析出它的复杂度吗？再联想到其他语言，比如Java中字符串相加的复杂度，它们之间有什么相同点、又有什么区别呢？\n除了能够明确区分语言的不同点，我们还要能联系起来灵活运用。比如，最典型的“编程语言两问”：\n你了解你学过的每种编程语言的特点吗？ 你能根据不同的产品需求，选用合适的编程语言吗？ 举个例子，Python的优点之一是特别擅长数据分析，所以广泛应用于人工智能、机器学习等领域，如机器学习中TensorFlow的框架，就是用Python写的。但是涉及到底层的矩阵运算等等，还是要依赖于C++完成，因为C++的速度快，运行效率更高。\n事实上，很多公司都是这样，服务器端开发基于Python，但底层的基础架构依赖于C++。这就是典型的“不同需求选用不同语言”。毕竟，你要明白，哪怕只是几十到几百毫秒的速度差距，对于公司、对于用户体验来说都是决定性的。\n唯一语言，可循序渐进 link当然，如果Python是你学的第一门编程语言，那也不必担心。我们知道，虽然同为人机交互的桥梁，Python语言比起C++、Java等主流语言，语法更简洁，也更接近英语，对编程世界的新人还是很友好的，这也是其显著优点。这种情况下，你要做的就是专注于Python这一门语言，明确学习的重点，把握好节奏循序渐进地学习。\n根据我多年的学习工作经验，我把编程语言的学习重点，总结成了下面这三步，无论你是否有其他语言的基础，都可以对照来做，稳步进阶。\n第一步：大厦之基，勤加练习 link任何一门编程语言，其覆盖范围都是相当广泛的，从基本的变量赋值、条件循环，到并发编程、Web开发等等，我想市面上几乎没有任何一本书能够罗列完全。\n所以，我建议你，在掌握必要的基础时，就得多上手操作了。千万不要等到把教材上所有东西都学完了才开始，因为到那时候你会发现，前面好不容易记住的一堆东西似乎又忘记了。计算机科学是一门十分讲究实战的学科，因此越早上手练习，练得越多越勤，就越好。\n不过，到底什么叫做必要的基础呢？以Python为例，如果你能够理解变量间的赋值、基本的数据类型、条件与循环语句、函数的用法，那么你就达到了第一步的底线标准，应该开始在课下多多练习了。\n比方说，你可以自己动手编程做一个简易的计算器，这应该也是大多数程序员实操的第一个小项目。用户输入数字和运算符后，你的程序能够检查输入是否合法并且返回正确的结果吗？\n在做这个小项目的过程中，你可能会遇到不少问题。我的建议是，遇到不懂的问题时，多去Stack Overflow上查询，这样你还能阅读别人优秀的代码，借鉴别人的思路，对于你的学习肯定大有帮助。当然，实在解决不了的问题，也可以写在留言区，我们一起来解决。\n第二步：代码规范，必不可少 link诚然，学习编程讲究快和高效。但是，与此同时，请一定不要忽略每一种语言必要的编程规范。在你自己刚开始写代码练习时，你可以不写单元测试，但总不能几百行的代码却没有一个函数，而是从头顺序写到尾吧？你可以省略一些可有可无的注释，但总不能把很多行代码全部并到一行吧？\n比如，我们来看下面这行代码：\nv.A(param1, param2, param3).B(param4, param5).C(param6, param7).D() 显然，这样写十分不科学，应该把它拆分成多行：\nv.A(param1, param2, param3) \\ # 字符'\\'表示换行\r.B(param4, param5) \\\r.C(param6, param7) \\\r.D() 再比如，变量和函数的命名虽有一定的随意性，但一定要有意义。如果你图省事，直接把变量依次命名为v1、v2、v3等，把函数依次命名为func1、func2、func3等等，不仅让其他人难理解，就算是你自己，日后维护起来都费劲儿。\n一名优秀的程序员，一定遵守编程语言的代码规范。像Facebook的工程师，每次写完代码都必须经过别人的review才能提交。如果有不遵守代码规范的例子，哪怕只是一个函数或是一个变量的命名，我们都会要求原作者加以修改，严格规范才能保证代码库的代码质量。\n第三步：开发经验，质的突破 link想要真正熟练地掌握Python或者是任何一门其他的编程语言，拥有大中型产品的开发经验是必不可少的。因为实战经验才能让你站得更高，望得更远。\n比如我们每天都在用搜索引擎，但你了解一个搜索引擎的服务器端实现吗？这是一个典型的面向对象设计，你需要定义一系列相关的类和函数，需要从产品需求、代码复杂度、效率以及可读性等多个方面考虑，同时，上线后还要进行各种优化等等。\n当然，在专栏里我没办法让你完成一个上亿用户级的实践产品，但是我会把自己这些年的开发经验倾囊相授，并通过量化交易这个实战案例，带你踏入“高级战场”，帮你掌握必要的开发知识。\n最后，我专门为你绘制了一张Python学习的知识图谱，里面涵盖了Python最高频的核心知识，大部分内容我在专栏中都会讲到。你可以保存或者打印出来，作为学习参考。\n今天，我跟你分享了Python的学习方法和注意事项，其实这些观点不只适用于Python，也能帮助你学习任何一门其他计算机编程语言，希望你能牢记在心。在接下来的课程里，我会带你逐步突破，最终成为一名Python高手。\n那么，对于学习Python或者是其他编程语言，你有什么困扰或是心得吗？欢迎在留言区与我交流！\n"
            }
        );
    index.add(
            {
                id:  9 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/02---jupyter-notebook%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E7%8E%B0%E4%BB%A3python%E7%9A%84%E5%BF%85%E5%AD%A6%E6%8A%80%E6%9C%AF\/",
                title: "Jupyter Notebook为什么是现代Python的必学技术？",
                description: "你好，我是景霄。\nStack Overflow 曾在2017年底，发布了在该站上各种语言的提问流量。其中，Python已经超过了JavaScript成为了流量最高的语言，预测在2020年前会远远甩开JavaScript。\n可能你已经知道，Python在14年后的“崛起”，得益于机器学习和数学统计应用的兴起。那为什么Python如此适合数学统计和机器学习呢？作为“老司机”的我可以肯定地告诉你，Jupyter Notebook （https://jupyter.org/）功不可没。\n毫不夸张地说，根据我对Facebook等硅谷一线大厂的了解，一个Python工程师如果现在还不会使用Jupyter Notebook的话，可能就真的太落伍了。\n磨刀不误砍柴工，高效的工具让我们的编程事半功倍。这一节课，我就来带你学习一下Jupyter Notebook，为后面的Python学习打下必备基础。\n什么是Jupyter Notebook？ link说了这么多，到底什么是Jupyter Notebook？按照Jupyter 创始人 Fernando Pérez的说法，他最初的梦想是做一个综合 Ju （Julia）、Py （Python）和 R 三种科学运算语言的计算工具平台，所以将其命名为Ju-Py-te-R。发展到现在，Jupyter 已经成为一个几乎支持所有语言，能够把软件代码、计算输出、解释文档、多媒体资源整合在一起的多功能科学运算平台。\n",
                content: "你好，我是景霄。\nStack Overflow 曾在2017年底，发布了在该站上各种语言的提问流量。其中，Python已经超过了JavaScript成为了流量最高的语言，预测在2020年前会远远甩开JavaScript。\n可能你已经知道，Python在14年后的“崛起”，得益于机器学习和数学统计应用的兴起。那为什么Python如此适合数学统计和机器学习呢？作为“老司机”的我可以肯定地告诉你，Jupyter Notebook （https://jupyter.org/）功不可没。\n毫不夸张地说，根据我对Facebook等硅谷一线大厂的了解，一个Python工程师如果现在还不会使用Jupyter Notebook的话，可能就真的太落伍了。\n磨刀不误砍柴工，高效的工具让我们的编程事半功倍。这一节课，我就来带你学习一下Jupyter Notebook，为后面的Python学习打下必备基础。\n什么是Jupyter Notebook？ link说了这么多，到底什么是Jupyter Notebook？按照Jupyter 创始人 Fernando Pérez的说法，他最初的梦想是做一个综合 Ju （Julia）、Py （Python）和 R 三种科学运算语言的计算工具平台，所以将其命名为Ju-Py-te-R。发展到现在，Jupyter 已经成为一个几乎支持所有语言，能够把软件代码、计算输出、解释文档、多媒体资源整合在一起的多功能科学运算平台。\n英文里说一图胜千言（A picture is worth a thousand words）。看下面这个图片，你就明白什么是Jupyter Notebook了。\n你在一个框框中直接输入代码，运行，它立马就在下面给你输出。怎么样，是不是很酷？你可能会纳闷儿，这样一个看起来“华而不实”的玩意儿，真的就成了Python社区的颠覆者吗？说实话放在几年前我也是不信的。所以 Jupyter Notebook 的影响究竟有多大呢？\nJupyter Notebook 的影响力 link我们衡量一个技术的影响力，或者说要用自己的技术去影响世界时，必定绕不开这个技术对教育界的影响力。\n就拿微软的Word文本处理系统来说吧。从纯技术角度来讲，Word的单机设计理念早已落后时代20年。但以Google Doc为代表的在线文档系统，却并没有像想象中那样，实现对Word的降维打击。\n直观的原因是用户习惯，使用Word修改文档，那就来回发几十遍呗，用着也还可以。但更深刻来想，之所以养成这样的用户习惯，是因为我们的教育根源。教育系统从娃娃抓起，用小学中学大学十几年的时间，训练了用户Word的使用习惯。到工作中，老员工又会带着新员工继续使用Word，如此形成技术影响力生生不息的正向反馈。\n回到我们今天的主题，我们来看Jupyter Notebook。从2017年开始，已有大量的北美顶尖计算机课程，开始完全使用Jupyter Notebook作为工具。比如李飞飞的CS231N《计算机视觉与神经网络》课程，在16年时作业还是命令行Python的形式，但是17年的作业就全部在Jupyter Notebook上完成了。再如UC Berkeley的《数据科学基础》课程，从17年起，所有作业也全部用Jupyter Notebook完成。\n而Jupyter Notebook 在工业界的影响力更甚。在Facebook，虽然大规模的后台开发仍然借助于功能齐全的IDE，但是几乎所有的中小型程序，比如内部的一些线下分析软件，机器学习模块的训练都是借助于Jupyter Notebook完成的。据我了解，在别的硅谷一线大厂，例如Google的AI Research部门Google Brain，也是清一色地全部使用Jupyter Notebook，虽然用的是他们自己的改进定制版，叫 Google Colab。\n看到这里，相信你已经认可了Jupter Notebook现如今的江湖地位。不过，说到技术的选择，有些人会说，这个技术流行，我们应该用；有些人认为，阿里已经在用这个技术了，这就是未来，我们也要用等等。不得不说，这些都是片面的认知。不管是阿里还是Facebook用的技术，其实不一定适用你的应用场景。\n我经常会鼓励技术同行，对于技术选择要有独立的思考，不要人云亦云。最起码你要去思考，Facebook为什么选择这个技术？这个技术解决了哪些问题？Facebook为什么不选择别的技术？有哪些局限？单从选择结果而言，Facebook选择的技术很可能是因为它有几百个产品线，几万个工程师。而同样的技术，在一个十人的团队里，反而成了拖累。\n在这里，我不想忽悠你任何技术，我想教会你的是辩证分析技术的思考方法。接下来，我们就来看看，Jupyter究竟解决了哪些别人没有解决的问题。\nJupyter的优点 link整合所有的资源 link在真正的软件开发中，上下文切换占用了大量的时间。什么意思呢？举个例子你就很好理解了，比如你需要切换窗口去看一些文档，再切换窗口去用另一个工具画图等等。这些都是影响生产效率的因素。\n正如我前面提到的，Jupyter通过把所有和软件编写有关的资源全部放在一个地方，解决了这个问题。当你打开一个Jupyter Notebook时，就已经可以看到相应的文档、图表、视频和相应的代码。这样，你就不需要切换窗口去找资料，只要看一个文件，就可以获得项目的所有信息。\n交互性编程体验 link在机器学习和数学统计领域，Python编程的实验性特别强，经常出现的情况是，一小块代码需要重写100遍，比如为了尝试100种不同的方法，但别的代码都不想动。这一点和传统的Python开发有很大不同。如果是在传统的Python开发流程中，每一次实验都要把所有代码重新跑一遍，会花费开发者很多时间。特别是在像Facebook这样千万行级别的代码库里，即使整个公司的底层架构已经足够优化，真要重新跑一遍，也需要几分钟的时间。\n而Jupyter Notebook 引进了Cell的概念，每次实验可以只跑一小个Cell里的代码；并且，所见即所得，在代码下面立刻就可以看到结果。这样强的互动性，让Python研究员可以专注于问题本身，不被繁杂的工具链所累，不用在命令行直接切换，所有科研工作都能在Jupyter上完成。\n零成本重现结果 link同样在机器学习和数学统计领域，Python的使用是非常短平快的。常见的场景是，我在论文里看到别人的方法效果很好，可是当我去重现时，却发现需要pip重新安装一堆依赖软件。这些准备工作可能会消耗你80%的时间，却并不是真正的生产力。\nJupyter Notebook如何解决这个问题呢？\n其实最初的Jupyter Notebook也是挺麻烦的，需要你先在本机上安装IPython引擎及其各种依赖软件。不过现在的技术趋势，则是彻底云端化了，例如Jupyter官方的Binder平台（介绍文档：https://mybinder.readthedocs.io/en/latest/index.html）和Google提供的 Google Colab环境（介绍：https://colab.research.google.com/notebooks/welcome.ipynb）。它们让Jupyter Notebook变得和石墨文档、Google Doc在线文档一样，在浏览器点开链接就能运行。\n所以，现在当你用Binder打开一份GitHub上的Jupyter Notebook时，你不需要安装任何软件，直接在浏览器打开一份代码，就能在云端运行。\nJupyter Notebook 初体验 link学习技术的最好方法就是用技术。不过，在今天的篇幅里，我不可能带你完全学会Jupyter Notebook的所有技巧。我想先带你直接感受一下，使用Jupyter Notebook的工作体验。\n比如这样一个GitHub文件。在Binder中，你只要输入其对应的GitHub Repository的名字或者URL，就能在云端打开整个Repository，选择你需要的notebook，你就能看到下图这个界面。\n每一个Jupyter的运行单元都包含了In、Out的Cell。如图所示，你可以使用Run按钮，运行单独的一个Cell。当然，你也可以在此基础上加以修改，或者新建一个notebook，写成自己想要的程序。赶紧打开链接试一试吧！\n另外，我还推荐下面这些Jupyter Notebook，作为你实践的第一站。\n第一个是Jupyter官方：https://mybinder.org/v2/gh/binder-examples/matplotlib-versions/mpl-v2.0/?filepath=matplotlib_versions_demo.ipynb 第二个是Google Research提供的Colab环境，尤其适合机器学习的实践应用：https://colab.research.google.com/notebooks/basic_features_overview.ipynb 如果你想在本地或者远程的机器上安装Jupyter Notebook，可以参考下面的两个文档。\n安装：https://jupyter.org/install.html\n运行：https://jupyter.readthedocs.io/en/latest/running.html#running\n总结 link这节课，我为你介绍了Jupyter Notebook，并告诉你它为什么日趋成为Python社区的必学技术。这主要是因为它的三大特点：整合所有的资源、交互性编程体验和零成本重现结果。但还是那句话，学习技术必须动手实操。这节课后，希望你能自己动手试一试Jupyter Notebook，后面我们的一些课程代码，我也会用Jupyter Notebook的形式分享给你。\n思考题 link你尝试Jupyter Notebook了吗？欢迎在留言区和我分享你的使用体验。\n"
            }
        );
    index.add(
            {
                id:  10 ,
                href: "\/docs\/python\/%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84\/",
                title: "列表和元组",
                description: "一、列表和元组 link共同点 link 任意数据类型的有序集合\n都⽀持负数索引\n都⽀持切⽚操作\n可以随意嵌套（其实就是任意数据类型的一种表现）\n通过list()和tuple()函数相互转换\n不同点 link 列表 元组 动态 静态 list.reverse() 倒转列表list.sort() 排序 没有内置的这两个函数 存储空间可变包含以下内容：- 指针- 已分配内容- 元素内容 存储空间固定 各有千秋 link 占用空间 集合元素少，空间差异可忽略；\n集合元素数量级大，空间差异明显 ，列表空间明显大于元组；\n可用作选择 列表和元组的参考因素\n性能 元组性能略优\n原因如下：\npython优化静态数据-\u003e资源缓存；\n元组属于静态数据，会被缓存，资源重复利用率高；\n在初始化方面，元组性能高于列表；\n二、字典和集合 link",
                content: "一、列表和元组 link共同点 link 任意数据类型的有序集合\n都⽀持负数索引\n都⽀持切⽚操作\n可以随意嵌套（其实就是任意数据类型的一种表现）\n通过list()和tuple()函数相互转换\n不同点 link 列表 元组 动态 静态 list.reverse() 倒转列表list.sort() 排序 没有内置的这两个函数 存储空间可变包含以下内容：- 指针- 已分配内容- 元素内容 存储空间固定 各有千秋 link 占用空间 集合元素少，空间差异可忽略；\n集合元素数量级大，空间差异明显 ，列表空间明显大于元组；\n可用作选择 列表和元组的参考因素\n性能 元组性能略优\n原因如下：\npython优化静态数据-\u003e资源缓存；\n元组属于静态数据，会被缓存，资源重复利用率高；\n在初始化方面，元组性能高于列表；\n二、字典和集合 link"
            }
        );
    index.add(
            {
                id:  11 ,
                href: "\/docs\/%E6%97%A5%E5%B8%B8\/",
                title: "日常资讯",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  12 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/03---%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84%E5%88%B0%E5%BA%95%E7%94%A8%E5%93%AA%E4%B8%80%E4%B8%AA\/",
                title: "列表和元组，到底用哪一个？",
                description: "你好，我是景霄。\n前面的课程，我们讲解了Python语言的学习方法，并且带你了解了Python必知的常用工具——Jupyter。那么从这节课开始，我们将正式学习Python的具体知识。\n对于每一门编程语言来说，数据结构都是其根基。了解掌握Python的基本数据结构，对于学好这门语言至关重要。今天我们就一起来学习，Python中最常见的两种数据结构：列表（list）和元组（tuple）。\n列表和元组基础 link首先，我们需要弄清楚最基本的概念，什么是列表和元组呢？\n实际上，列表和元组，都是一个可以放置任意数据类型的有序集合。\n在绝大多数编程语言中，集合的数据类型必须一致。不过，对于Python的列表和元组来说，并无此要求：\nl = [1, 2, 'hello', 'world'] # 列表中同时含有int和string类型的元素\rl\r[1, 2, 'hello', 'world']\rtup = ('jason', 22) # 元组中同时含有int和string类型的元素\rtup\r('jason', 22) 其次，我们必须掌握它们的区别。\n列表是动态的，长度大小不固定，可以随意地增加、删减或者改变元素（mutable）。 而元组是静态的，长度大小固定，无法增加删减或者改变（immutable）。 下面的例子中，我们分别创建了一个列表与元组。你可以看到，对于列表，我们可以很轻松地让其最后一个元素，由4变为40；但是，如果你对元组采取相同的操作，Python 就会报错，原因就是元组是不可变的。\nl = [1, 2, 3, 4]\rl[3] = 40 # 和很多语言类似，python中索引同样从0开始，l[3]表示访问列表的第四个元素\rl\r[1, 2, 3, 40]\rtup = (1, 2, 3, 4)\rtup[3] = 40\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: 'tuple' object does not support item assignment 可是，如果你想对已有的元组做任何\"改变\"，该怎么办呢？那就只能重新开辟一块内存，创建新的元组了。\n",
                content: "你好，我是景霄。\n前面的课程，我们讲解了Python语言的学习方法，并且带你了解了Python必知的常用工具——Jupyter。那么从这节课开始，我们将正式学习Python的具体知识。\n对于每一门编程语言来说，数据结构都是其根基。了解掌握Python的基本数据结构，对于学好这门语言至关重要。今天我们就一起来学习，Python中最常见的两种数据结构：列表（list）和元组（tuple）。\n列表和元组基础 link首先，我们需要弄清楚最基本的概念，什么是列表和元组呢？\n实际上，列表和元组，都是一个可以放置任意数据类型的有序集合。\n在绝大多数编程语言中，集合的数据类型必须一致。不过，对于Python的列表和元组来说，并无此要求：\nl = [1, 2, 'hello', 'world'] # 列表中同时含有int和string类型的元素\rl\r[1, 2, 'hello', 'world']\rtup = ('jason', 22) # 元组中同时含有int和string类型的元素\rtup\r('jason', 22) 其次，我们必须掌握它们的区别。\n列表是动态的，长度大小不固定，可以随意地增加、删减或者改变元素（mutable）。 而元组是静态的，长度大小固定，无法增加删减或者改变（immutable）。 下面的例子中，我们分别创建了一个列表与元组。你可以看到，对于列表，我们可以很轻松地让其最后一个元素，由4变为40；但是，如果你对元组采取相同的操作，Python 就会报错，原因就是元组是不可变的。\nl = [1, 2, 3, 4]\rl[3] = 40 # 和很多语言类似，python中索引同样从0开始，l[3]表示访问列表的第四个元素\rl\r[1, 2, 3, 40]\rtup = (1, 2, 3, 4)\rtup[3] = 40\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: 'tuple' object does not support item assignment 可是，如果你想对已有的元组做任何\"改变\"，该怎么办呢？那就只能重新开辟一块内存，创建新的元组了。\n比如下面的例子，我们想增加一个元素5给元组，实际上就是创建了一个新的元组，然后把原来两个元组的值依次填充进去。\n而对于列表来说，由于其是动态的，我们只需简单地在列表末尾，加入对应元素就可以了。如下操作后，会修改原来列表中的元素，而不会创建新的列表。\ntup = (1, 2, 3, 4)\rnew_tup = tup + (5, ) # 创建新的元组new_tup，并依次填充原元组的值\rnew _tup\r(1, 2, 3, 4, 5)\rl = [1, 2, 3, 4]\rl.append(5) # 添加元素5到原列表的末尾\rl\r[1, 2, 3, 4, 5] 通过上面的例子，相信你肯定掌握了列表和元组的基本概念。接下来我们来看一些列表和元组的基本操作和注意事项。\n首先，和其他语言不同，Python中的列表和元组都支持负数索引，-1表示最后一个元素，-2表示倒数第二个元素，以此类推。\nl = [1, 2, 3, 4]\rl[-1]\r4\rtup = (1, 2, 3, 4)\rtup[-1]\r4 除了基本的初始化，索引外，列表和元组都支持切片操作：\nl = [1, 2, 3, 4]\rl[1:3] # 返回列表中索引从1到2的子列表\r[2, 3]\rtup = (1, 2, 3, 4)\rtup[1:3] # 返回元组中索引从1到2的子元组\r(2, 3) 另外，列表和元组都可以随意嵌套：\nl = [[1, 2, 3], [4, 5]] # 列表的每一个元素也是一个列表\rtup = ((1, 2, 3), (4, 5, 6)) # 元组的每一个元素也是一个元组 当然，两者也可以通过list()和tuple()函数相互转换：\nlist((1, 2, 3))\r[1, 2, 3]\rtuple([1, 2, 3])\r(1, 2, 3) 最后，我们来看一些列表和元组常用的内置函数：\nl = [3, 2, 3, 7, 8, 1]\rl.count(3) 2\rl.index(7)\r3\rl.reverse()\rl\r[1, 8, 7, 3, 2, 3]\rl.sort()\rl\r[1, 2, 3, 3, 7, 8]\rtup = (3, 2, 3, 7, 8, 1)\rtup.count(3)\r2\rtup.index(7)\r3\rlist(reversed(tup))\r[1, 8, 7, 3, 2, 3]\rsorted(tup)\r[1, 2, 3, 3, 7, 8] 这里我简单解释一下这几个函数的含义。\ncount(item)表示统计列表/元组中item出现的次数。 index(item)表示返回列表/元组中item第一次出现的索引。 list.reverse()和list.sort()分别表示原地倒转列表和排序（注意，元组没有内置的这两个函数)。 reversed()和sorted()同样表示对列表/元组进行倒转和排序，reversed()返回一个倒转后的迭代器（上文例子使用list()函数再将其转换为列表）；sorted()返回排好序的新列表。 列表和元组存储方式的差异 link前面说了，列表和元组最重要的区别就是，列表是动态的、可变的，而元组是静态的、不可变的。这样的差异，势必会影响两者存储方式。我们可以来看下面的例子：\nl = [1, 2, 3]\rl.__sizeof__()\r64\rtup = (1, 2, 3)\rtup.__sizeof__()\r48 你可以看到，对列表和元组，我们放置了相同的元素，但是元组的存储空间，却比列表要少16字节。这是为什么呢？\n事实上，由于列表是动态的，所以它需要存储指针，来指向对应的元素（上述例子中，对于int型，8字节）。另外，由于列表可变，所以需要额外存储已经分配的长度大小（8字节），这样才可以实时追踪列表空间的使用情况，当空间不足时，及时分配额外空间。\nl = []\rl.__sizeof__() // 空列表的存储空间为40字节\r40\rl.append(1)\rl.__sizeof__() 72 // 加入了元素1之后，列表为其分配了可以存储4个元素的空间 (72 - 40)/8 = 4\rl.append(2) l.__sizeof__()\r72 // 由于之前分配了空间，所以加入元素2，列表空间不变\rl.append(3)\rl.__sizeof__() 72 // 同上\rl.append(4)\rl.__sizeof__() 72 // 同上\rl.append(5)\rl.__sizeof__() 104 // 加入元素5之后，列表的空间不足，所以又额外分配了可以存储4个元素的空间 上面的例子，大概描述了列表空间分配的过程。我们可以看到，为了减小每次增加/删减操作时空间分配的开销，Python每次分配空间时都会额外多分配一些，这样的机制（over-allocating）保证了其操作的高效性：增加/删除的时间复杂度均为O(1)。\n但是对于元组，情况就不同了。元组长度大小固定，元素不可变，所以存储空间固定。\n看了前面的分析，你也许会觉得，这样的差异可以忽略不计。但是想象一下，如果列表和元组存储元素的个数是一亿，十亿甚至更大数量级时，你还能忽略这样的差异吗？\n列表和元组的性能 link通过学习列表和元组存储方式的差异，我们可以得出结论：元组要比列表更加轻量级一些，所以总体上来说，元组的性能速度要略优于列表。\n另外，Python会在后台，对静态数据做一些资源缓存（resource caching）。通常来说，因为垃圾回收机制的存在，如果一些变量不被使用了，Python就会回收它们所占用的内存，返还给操作系统，以便其他变量或其他应用使用。\n但是对于一些静态变量，比如元组，如果它不被使用并且占用空间不大时，Python会暂时缓存这部分内存。这样，下次我们再创建同样大小的元组时，Python就可以不用再向操作系统发出请求，去寻找内存，而是可以直接分配之前缓存的内存空间，这样就能大大加快程序的运行速度。\n下面的例子，是计算初始化一个相同元素的列表和元组分别所需的时间。我们可以看到，元组的初始化速度，要比列表快5倍。\npython3 -m timeit 'x=(1,2,3,4,5,6)'\r20000000 loops, best of 5: 9.97 nsec per loop\rpython3 -m timeit 'x=[1,2,3,4,5,6]'\r5000000 loops, best of 5: 50.1 nsec per loop 但如果是索引操作的话，两者的速度差别非常小，几乎可以忽略不计。\npython3 -m timeit -s 'x=[1,2,3,4,5,6]' 'y=x[3]'\r10000000 loops, best of 5: 22.2 nsec per loop\rpython3 -m timeit -s 'x=(1,2,3,4,5,6)' 'y=x[3]'\r10000000 loops, best of 5: 21.9 nsec per loop 当然，如果你想要增加、删减或者改变元素，那么列表显然更优。原因你现在肯定知道了，那就是对于元组，你必须得通过新建一个元组来完成。\n列表和元组的使用场景 link那么列表和元组到底用哪一个呢？根据上面所说的特性，我们具体情况具体分析。\n1. 如果存储的数据和数量不变，比如你有一个函数，需要返回的是一个地点的经纬度，然后直接传给前端渲染，那么肯定选用元组更合适。\ndef get_location():\r..... return (longitude, latitude) 2. 如果存储的数据或数量是可变的，比如社交平台上的一个日志功能，是统计一个用户在一周之内看了哪些用户的帖子，那么则用列表更合适。\nviewer_owner_id_list = [] # 里面的每个元素记录了这个viewer一周内看过的所有owner的id\rrecords = queryDB(viewer_id) # 索引数据库，拿到某个viewer一周内的日志\rfor record in records:\rviewer_owner_id_list.append(record.id) 总结 link关于列表和元组，我们今天聊了很多，最后一起总结一下你必须掌握的内容。\n总的来说，列表和元组都是有序的，可以存储任意数据类型的集合，区别主要在于下面这两点。\n列表是动态的，长度可变，可以随意的增加、删减或改变元素。列表的存储空间略大于元组，性能略逊于元组。 元组是静态的，长度大小固定，不可以对元素进行增加、删减或者改变操作。元组相对于列表更加轻量级，性能稍优。 思考题 link1. 想创建一个空的列表，我们可以用下面的A、B两种方式，请问它们在效率上有什么区别吗？我们应该优先考虑使用哪种呢？可以说说你的理由。\n# 创建空列表\r# option A\rempty_list = list()\r# option B\rempty_list = [] 2. 你在平时的学习工作中，是在什么场景下使用列表或者元组呢？欢迎留言和我分享。\nimport time time1 = time.clock() empty_list = [] time2 = time.clock() diff_time = time2 - time1 print (diff_time)2019-05-15Geek_59f23e 👍（24） 💬（1）1、用list()方法构造一个空列表使用的是class list([iterable])的类型构造器，参数可以是一个iterable，如果没有给出参数，构造器将创建一个空列表[ ]，相比较而言多了一步class调用和参数判断，所以用 [ ] 直接构造一个空列表的方法速度更快，刚查的官方解释，不知道我理解的对不对。。。 2、敲代码的时候我一般元祖用来传参用的比较多，能用元祖的地方尽量不用列表，这样代码性能好些。2019-05-15Mr.Chen 👍（12） 💬（1）老师，“有序”应该怎么理解。2019-10-10lizhaochao 👍（8） 💬（1）list的内部实现是over-allocate array的形式\n那在需要扩容的时候，是不是也是需要重新开辟一块连续的内存空间呢？ 每次扩容都会预留一些空间，这里面有没有公式，公式是什么呢2019-05-15Geek_59f23e 👍（8） 💬（3）实测被打脸了😂函数构建和直接构建一个空列表或数组速度上并没有什么差别，有时前者快些，有时后者快些。。。 In [1]: timeit 'lst1 = []' 9.86 ns ± 0.721 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\nIn [2]: timeit 'lst2 = list()' 9.82 ns ± 0.43 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\nIn [3]: timeit 'tup1 = (,)' 9.59 ns ± 0.294 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\nIn [4]: timeit 'tup2 = tuple()' 9.75 ns ± 0.464 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)2019-05-15安亚明 👍（7） 💬（1）老师，PYTHON学校为何要从元组和列表开始。2019-05-15蒋腾飞同学 👍（5） 💬（1）非常涨姿势，一般的课程肯定不会有的～2019-08-29武林秀才 👍（3） 💬（1）reversed()返回的是一个反转的迭代器，不是返回倒排的列表或元组。2019-05-16古明地觉 👍（3） 💬（6）print([].sizeof()) # 40 print(().sizeof()) # 24 老师 我想问一下，列表比元组多了16个字节，由于列表是可变的，所以需要分配8字节来存储已经分配的长度大小，那剩余的8字节干什么了呢？2019-05-15celia li 👍（2） 💬（1）38岁了，还来得及学吗？2019-08-13呼啦啦 👍（2） 💬（6）老师，我测试了一下，好像只有0.1nsec秒之差。没有五倍之多，我是用python3.7测试的。 C:\\Users\\wuzhaoming\u003epython -m timeit 'x=(1,2,3,4,5,6)' 50000000 loops, best of 5: 8.1 nsec per loop\nC:\\Users\\wuzhaoming\u003epython -m timeit 'x=[1,2,3,4,5,6]' 50000000 loops, best of 5: 8.2 nsec per loop2019-05-16牺牲 👍（1） 💬（2）l[1:3] # 返回列表中索引从1到2的子列表 为什么1:3是返回1到2呢2020-06-03绝望中的希望 👍（1） 💬（1）老师，想问下直接创建一个有3个元素的列表和创建空列表，再增加3个元素，为什么存储空间会不一样？2019-05-15\n"
            }
        );
    index.add(
            {
                id:  13 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/04---%E5%AD%97%E5%85%B8%E9%9B%86%E5%90%88%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3%E5%90%97\/",
                title: "字典、集合，你真的了解吗？",
                description: "你好，我是景霄。\n前面的课程，我们学习了Python中的列表和元组，了解了他们的基本操作和性能比较。这节课，我们再来学习两个同样很常见并且很有用的数据结构：字典（dict）和集合（set）。字典和集合在Python被广泛使用，并且性能进行了高度优化，其重要性不言而喻。\n字典和集合基础 link那究竟什么是字典，什么是集合呢？字典是一系列由键（key）和值（value）配对组成的元素的集合，在Python3.7+，字典被确定为有序（注意：在3.6中，字典有序是一个implementation detail，在3.7才正式成为语言特性，因此3.6中无法100%确保其有序性），而3.6之前是无序的，其长度大小可变，元素可以任意地删减和改变。\n相比于列表和元组，字典的性能更优，特别是对于查找、添加和删除操作，字典都能在常数时间复杂度内完成。\n而集合和字典基本相同，唯一的区别，就是集合没有键和值的配对，是一系列无序的、唯一的元素组合。\n首先我们来看字典和集合的创建，通常有下面这几种方式：\nd1 = {'name': 'jason', 'age': 20, 'gender': 'male'}\rd2 = dict({'name': 'jason', 'age': 20, 'gender': 'male'})\rd3 = dict([('name', 'jason'), ('age', 20), ('gender', 'male')])\rd4 = dict(name='jason', age=20, gender='male') d1 == d2 == d3 ==d4\rTrue\rs1 = {1, 2, 3}\rs2 = set([1, 2, 3])\rs1 == s2\rTrue 这里注意，Python中字典和集合，无论是键还是值，都可以是混合类型。比如下面这个例子，我创建了一个元素为1，'hello'，5.0的集合：\ns = {1, 'hello', 5.0} 再来看元素访问的问题。字典访问可以直接索引键，如果不存在，就会抛出异常：\n",
                content: "你好，我是景霄。\n前面的课程，我们学习了Python中的列表和元组，了解了他们的基本操作和性能比较。这节课，我们再来学习两个同样很常见并且很有用的数据结构：字典（dict）和集合（set）。字典和集合在Python被广泛使用，并且性能进行了高度优化，其重要性不言而喻。\n字典和集合基础 link那究竟什么是字典，什么是集合呢？字典是一系列由键（key）和值（value）配对组成的元素的集合，在Python3.7+，字典被确定为有序（注意：在3.6中，字典有序是一个implementation detail，在3.7才正式成为语言特性，因此3.6中无法100%确保其有序性），而3.6之前是无序的，其长度大小可变，元素可以任意地删减和改变。\n相比于列表和元组，字典的性能更优，特别是对于查找、添加和删除操作，字典都能在常数时间复杂度内完成。\n而集合和字典基本相同，唯一的区别，就是集合没有键和值的配对，是一系列无序的、唯一的元素组合。\n首先我们来看字典和集合的创建，通常有下面这几种方式：\nd1 = {'name': 'jason', 'age': 20, 'gender': 'male'}\rd2 = dict({'name': 'jason', 'age': 20, 'gender': 'male'})\rd3 = dict([('name', 'jason'), ('age', 20), ('gender', 'male')])\rd4 = dict(name='jason', age=20, gender='male') d1 == d2 == d3 ==d4\rTrue\rs1 = {1, 2, 3}\rs2 = set([1, 2, 3])\rs1 == s2\rTrue 这里注意，Python中字典和集合，无论是键还是值，都可以是混合类型。比如下面这个例子，我创建了一个元素为1，'hello'，5.0的集合：\ns = {1, 'hello', 5.0} 再来看元素访问的问题。字典访问可以直接索引键，如果不存在，就会抛出异常：\nd = {'name': 'jason', 'age': 20}\rd['name']\r'jason'\rd['location']\rTraceback (most recent call last):\rFile \"\", line 1, in KeyError: 'location' 也可以使用get(key, default)函数来进行索引。如果键不存在，调用get()函数可以返回一个默认值。比如下面这个示例，返回了'null'。\nd = {'name': 'jason', 'age': 20}\rd.get('name')\r'jason'\rd.get('location', 'null')\r'null' 说完了字典的访问，我们再来看集合。\n首先我要强调的是，集合并不支持索引操作，因为集合本质上是一个哈希表，和列表不一样。所以，下面这样的操作是错误的，Python会抛出异常：\ns = {1, 2, 3}\rs[0]\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: 'set' object does not support indexing 想要判断一个元素在不在字典或集合内，我们可以用value in dict/set 来判断。\ns = {1, 2, 3}\r1 in s\rTrue\r10 in s\rFalse\rd = {'name': 'jason', 'age': 20}\r'name' in d\rTrue\r'location' in d\rFalse 当然，除了创建和访问，字典和集合也同样支持增加、删除、更新等操作。\nd = {'name': 'jason', 'age': 20}\rd['gender'] = 'male' # 增加元素对'gender': 'male'\rd['dob'] = '1999-02-01' # 增加元素对'dob': '1999-02-01'\rd\r{'name': 'jason', 'age': 20, 'gender': 'male', 'dob': '1999-02-01'}\rd['dob'] = '1998-01-01' # 更新键'dob'对应的值 d.pop('dob') # 删除键为'dob'的元素对\r'1998-01-01'\rd\r{'name': 'jason', 'age': 20, 'gender': 'male'}\rs = {1, 2, 3}\rs.add(4) # 增加元素4到集合\rs\r{1, 2, 3, 4}\rs.remove(4) # 从集合中删除元素4\rs\r{1, 2, 3} 不过要注意，集合的pop()操作是删除集合中最后一个元素，可是集合本身是无序的，你无法知道会删除哪个元素，因此这个操作得谨慎使用。\n实际应用中，很多情况下，我们需要对字典或集合进行排序，比如，取出值最大的50对。\n对于字典，我们通常会根据键或值，进行升序或降序排序：\nd = {'b': 1, 'a': 2, 'c': 10}\rd_sorted_by_key = sorted(d.items(), key=lambda x: x[0]) # 根据字典键的升序排序\rd_sorted_by_value = sorted(d.items(), key=lambda x: x[1]) # 根据字典值的升序排序\rd_sorted_by_key\r[('a', 2), ('b', 1), ('c', 10)]\rd_sorted_by_value\r[('b', 1), ('a', 2), ('c', 10)] 这里返回了一个列表。列表中的每个元素，是由原字典的键和值组成的元组。\n而对于集合，其排序和前面讲过的列表、元组很类似，直接调用sorted(set)即可，结果会返回一个排好序的列表。\ns = {3, 4, 2, 1}\rsorted(s) # 对集合的元素进行升序排序\r[1, 2, 3, 4] 字典和集合性能 link文章开头我就说到了，字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作。那接下来，我们就来看看，它们在具体场景下的性能表现，以及与列表等其他数据结构的对比。\n比如电商企业的后台，存储了每件产品的ID、名称和价格。现在的需求是，给定某件商品的ID，我们要找出其价格。\n如果我们用列表来存储这些数据结构，并进行查找，相应的代码如下：\ndef find_product_price(products, product_id):\rfor id, price in products:\rif id == product_id:\rreturn price\rreturn None products = [\r(143121312, 100), (432314553, 30),\r(32421912367, 150) ]\rprint('The price of product 432314553 is {}'.format(find_product_price(products, 432314553)))\r# 输出\rThe price of product 432314553 is 30 假设列表有n个元素，而查找的过程要遍历列表，那么时间复杂度就为O(n)。即使我们先对列表进行排序，然后使用二分查找，也会需要O(logn)的时间复杂度，更何况，列表的排序还需要O(nlogn)的时间。\n但如果我们用字典来存储这些数据，那么查找就会非常便捷高效，只需O(1)的时间复杂度就可以完成。原因也很简单，刚刚提到过的，字典的内部组成是一张哈希表，你可以直接通过键的哈希值，找到其对应的值。\nproducts = {\r143121312: 100,\r432314553: 30,\r32421912367: 150\r}\rprint('The price of product 432314553 is {}'.format(products[432314553])) # 输出\rThe price of product 432314553 is 30 类似的，现在需求变成，要找出这些商品有多少种不同的价格。我们还用同样的方法来比较一下。\n如果还是选择使用列表，对应的代码如下，其中，A和B是两层循环。同样假设原始列表有n个元素，那么，在最差情况下，需要O(n^2)的时间复杂度。\n# list version\rdef find_unique_price_using_list(products):\runique_price_list = []\rfor _, price in products: # A\rif price not in unique_price_list: #B\runique_price_list.append(price)\rreturn len(unique_price_list)\rproducts = [\r(143121312, 100), (432314553, 30),\r(32421912367, 150),\r(937153201, 30)\r]\rprint('number of unique price is: {}'.format(find_unique_price_using_list(products)))\r# 输出\rnumber of unique price is: 3 但如果我们选择使用集合这个数据结构，由于集合是高度优化的哈希表，里面元素不能重复，并且其添加和查找操作只需O(1)的复杂度，那么，总的时间复杂度就只有O(n)。\n# set version\rdef find_unique_price_using_set(products):\runique_price_set = set()\rfor _, price in products:\runique_price_set.add(price)\rreturn len(unique_price_set) products = [\r(143121312, 100), (432314553, 30),\r(32421912367, 150),\r(937153201, 30)\r]\rprint('number of unique price is: {}'.format(find_unique_price_using_set(products)))\r# 输出\rnumber of unique price is: 3 可能你对这些时间复杂度没有直观的认识，我可以举一个实际工作场景中的例子，让你来感受一下。\n下面的代码，初始化了含有100,000个元素的产品，并分别计算了使用列表和集合来统计产品价格数量的运行时间：\nimport time\rid = [x for x in range(0, 100000)]\rprice = [x for x in range(200000, 300000)]\rproducts = list(zip(id, price))\r# 计算列表版本的时间\rstart_using_list = time.perf_counter()\rfind_unique_price_using_list(products)\rend_using_list = time.perf_counter()\rprint(\"time elapse using list: {}\".format(end_using_list - start_using_list))\r## 输出\rtime elapse using list: 41.61519479751587\r# 计算集合版本的时间\rstart_using_set = time.perf_counter()\rfind_unique_price_using_set(products)\rend_using_set = time.perf_counter()\rprint(\"time elapse using set: {}\".format(end_using_set - start_using_set))\r# 输出\rtime elapse using set: 0.008238077163696289 你可以看到，仅仅十万的数据量，两者的速度差异就如此之大。事实上，大型企业的后台数据往往有上亿乃至十亿数量级，如果使用了不合适的数据结构，就很容易造成服务器的崩溃，不但影响用户体验，并且会给公司带来巨大的财产损失。\n字典和集合的工作原理 link我们通过举例以及与列表的对比，看到了字典和集合操作的高效性。不过，字典和集合为什么能够如此高效，特别是查找、插入和删除操作？\n这当然和字典、集合内部的数据结构密不可分。不同于其他数据结构，字典和集合的内部结构都是一张哈希表。\n对于字典而言，这张表存储了哈希值（hash）、键和值这3个元素。 而对集合来说，区别就是哈希表内没有键和值的配对，只有单一的元素了。 我们来看，老版本Python的哈希表结构如下所示：\n--+-------------------------------+\r| 哈希值(hash) 键(key) 值(value)\r--+-------------------------------+\r0 | hash0 key0 value0\r--+-------------------------------+\r1 | hash1 key1 value1\r--+-------------------------------+\r2 | hash2 key2 value2\r--+-------------------------------+\r. | ...\r__+_______________________________+ 不难想象，随着哈希表的扩张，它会变得越来越稀疏。举个例子，比如我有这样一个字典：\n{'name': 'mike', 'dob': '1999-01-01', 'gender': 'male'} 那么它会存储为类似下面的形式：\nentries = [\r['--', '--', '--']\r[-230273521, 'dob', '1999-01-01'],\r['--', '--', '--'],\r['--', '--', '--'],\r[1231236123, 'name', 'mike'],\r['--', '--', '--'],\r[9371539127, 'gender', 'male']\r] 这样的设计结构显然非常浪费存储空间。为了提高存储空间的利用率，现在的哈希表除了字典本身的结构，会把索引和哈希值、键、值单独分开，也就是下面这样新的结构：\nIndices\r----------------------------------------------------\rNone | index | None | None | index | None | index ...\r----------------------------------------------------\rEntries\r--------------------\rhash0 key0 value0\r---------------------\rhash1 key1 value1\r---------------------\rhash2 key2 value2\r---------------------\r...\r--------------------- 那么，刚刚的这个例子，在新的哈希表结构下的存储形式，就会变成下面这样：\nindices = [None, 1, None, None, 0, None, 2]\rentries = [\r[1231236123, 'name', 'mike'],\r[-230273521, 'dob', '1999-01-01'],\r[9371539127, 'gender', 'male']\r] 我们可以很清晰地看到，空间利用率得到很大的提高。\n清楚了具体的设计结构，我们接着来看这几个操作的工作原理。\n插入操作 link每次向字典或集合插入一个元素时，Python会首先计算键的哈希值（hash(key)），再和 mask = PyDicMinSize - 1做与操作，计算这个元素应该插入哈希表的位置index = hash(key) \u0026 mask。如果哈希表中此位置是空的，那么这个元素就会被插入其中。\n而如果此位置已被占用，Python便会比较两个元素的哈希值和键是否相等。\n若两者都相等，则表明这个元素已经存在，如果值不同，则更新值。 若两者中有一个不相等，这种情况我们通常称为哈希冲突（hash collision），意思是两个元素的键不相等，但是哈希值相等。这种情况下，Python便会继续寻找表中空余的位置，直到找到位置为止。 值得一提的是，通常来说，遇到这种情况，最简单的方式是线性寻找，即从这个位置开始，挨个往后寻找空位。当然，Python内部对此进行了优化（这一点无需深入了解，你有兴趣可以查看源码，我就不再赘述），让这个步骤更加高效。\n查找操作 link和前面的插入操作类似，Python会根据哈希值，找到其应该处于的位置；然后，比较哈希表这个位置中元素的哈希值和键，与需要查找的元素是否相等。如果相等，则直接返回；如果不等，则继续查找，直到找到空位或者抛出异常为止。\n删除操作 link对于删除操作，Python会暂时对这个位置的元素，赋于一个特殊的值，等到重新调整哈希表的大小时，再将其删除。\n不难理解，哈希冲突的发生，往往会降低字典和集合操作的速度。因此，为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有1/3的剩余空间。随着元素的不停插入，当剩余空间小于1/3时，Python会重新获取更大的内存空间，扩充哈希表。不过，这种情况下，表内所有的元素位置都会被重新排放。\n虽然哈希冲突和哈希表大小的调整，都会导致速度减缓，但是这种情况发生的次数极少。所以，平均情况下，这仍能保证插入、查找和删除的时间复杂度为O(1)。\n总结 link这节课，我们一起学习了字典和集合的基本操作，并对它们的高性能和内部存储结构进行了讲解。\n字典在Python3.7+是有序的数据结构，而集合是无序的，其内部的哈希表存储结构，保证了其查找、插入、删除操作的高效性。所以，字典和集合通常运用在对元素的高效查找、去重等场景。\n思考题 link1. 下面初始化字典的方式，哪一种更高效？\n# Option A\rd = {'name': 'jason', 'age': 20, 'gender': 'male'}\r# Option B\rd = dict({'name': 'jason', 'age': 20, 'gender': 'male'}) 2. 字典的键可以是一个列表吗？下面这段代码中，字典的初始化是否正确呢？如果不正确，可以说出你的原因吗？\nd = {'name': 'jason', ['education']: ['Tsinghua University', 'Stanford University']} 欢迎留言和我分享，也欢迎你把这篇文章分享给你的同事、朋友。\n思考题 2: 用列表作为 Key 在这里是不被允许的，因为列表是一个动态变化的数据结构，字典当中的 key 要求是不可变的，原因也很好理解，key 首先是不重复的，如果 Key 是可以变化的话，那么随着 Key 的变化，这里就有可能就会有重复的 Key，那么这就和字典的定义相违背；如果把这里的列表换成之前我们讲过的元组是可以的，因为元组不可变\n第一种数据结构，如何可以o(1)的查找一个key？ 没有索引啊 这篇文章感觉写的不好，例子没有讲透 稀疏一定浪费吗，里面没有值的话能占用多少空间 我理解耗费空间的应该是k v的存储吧2019-05-29Hoo-Ah 👍（12） 💬（7）1. 直接使用大括号更高效，避免了使用类生成实例其他不必要的操作； 2. 列表不可以作为key，因为列表是可变类型，可变类型不可hash。 问题：为什么在旧哈希表中元素会越来越稀？2019-05-17力维 👍（10） 💬（3）内容挺好的，但好像有个小错误：关于查找价格的例子，列表查找并没有用到双重循环吧？A是循环，B只是判断语句，不构成循环。2019-11-14Jon徐 👍（8） 💬（1）list indices就是哈希表，None表示该位置目前尚未被占用，索引的值即是在list entries中存储dict键值和哈希值的下标。 作业中初始化dict，key不能使用可变类型吧，value可以使任意对象。2019-05-17天凉好个秋 👍（7） 💬（2）不难想象，随着哈希表的扩张，它会变得越来越稀疏。 后面例子中解释的原因没看懂，能详细说说吗？2019-05-17farFlight 👍（7） 💬（1）老师好，在王争老师的数据结构课程中提到哈希表常与链表一起使用，譬如用来解决哈希冲突。请问python底层对字典和集合的实现是否也是这样的呢？2019-05-17鱼腐 👍（4） 💬（1）Indices:none | one | none | index | none | index 是什么意思？能补充讲解下吗2019-05-17Geek_cj8r3q 👍（3） 💬（2）这些都是线程安全的么 列表 元组 集合 字典2019-10-30张胜坡 👍（1） 💬（2）d = {'name': 'jason', 'age': 20} d.get('name') 'jason' d.get('location', 'null')'null'\n其中d.get('location', 'null')，这里的写法是什么意思2020-02-13Redevil 👍（1） 💬（1）set version 的查找unique price的product的代码，不是O(1)，是O(n)吧。 至少要遍历N个元素啊。2019-05-17夜行 👍（1） 💬（1）旧的字典没有索引吗2019-05-17daowuli_chihai 👍（0） 💬（2）你好，集合的pop()我测试，好像每次都删除 集合第一个元素，下面 Microsoft Windows [版本 6.1.7601] 版权所有 (c) 2009 Microsoft Corporation。保留所有权利。\nC:\\Users\\Administrator\u003epython Python 3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:21:23) [MSC v.1916 32 bit (I tel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e set1 = {1,2,3,4,5} \u003e\u003e\u003e set1.pop() 1 \u003e\u003e\u003e set1 {2, 3, 4, 5} \u003e\u003e\u003e set1.pop() 2 \u003e\u003e\u003e set1 {3, 4, 5} \u003e\u003e\u003e\n"
            }
        );
    index.add(
            {
                id:  14 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/05---%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AD%97%E7%AC%A6%E4%B8%B2\/",
                title: "深入浅出字符串",
                description: "你好，我是景霄。\nPython的程序中充满了字符串（string），在平常阅读代码时也屡见不鲜。字符串同样是Python中很常见的一种数据类型，比如日志的打印、程序中函数的注释、数据库的访问、变量的基本操作等等，都用到了字符串。\n当然，我相信你本身对字符串已经有所了解。今天这节课，我主要带你回顾一下字符串的常用操作，并对其中的一些小tricks详细地加以解释。\n字符串基础 link什么是字符串呢？字符串是由独立字符组成的一个序列，通常包含在单引号（''）双引号（\"\"）或者三引号之中（''' '''或\"\"\" \"\"\"，两者一样），比如下面几种写法。\nname = 'jason'\rcity = 'beijing'\rtext = \"welcome to jike shijian\" 这里定义了name、city和text三个变量，都是字符串类型。我们知道，Python中单引号、双引号和三引号的字符串是一模一样的，没有区别，比如下面这个例子中的s1、s2、s3完全一样。\ns1 = 'hello'\rs2 = \"hello\"\rs3 = \"\"\"hello\"\"\"\rs1 == s2 == s3\rTrue Python同时支持这三种表达方式，很重要的一个原因就是，这样方便你在字符串中，内嵌带引号的字符串。比如：\n\"I'm a student\" Python的三引号字符串，则主要应用于多行字符串的情境，比如函数的注释等等。\ndef calculate_similarity(item1, item2):\r\"\"\"\rCalculate similarity between two items\rArgs:\ritem1: 1st item\ritem2: 2nd item\rReturns:\rsimilarity score between item1 and item2\r\"\"\" 同时，Python也支持转义字符。所谓的转义字符，就是用反斜杠开头的字符串，来表示一些特定意义的字符。我把常见的的转义字符，总结成了下面这张表格。\n",
                content: "你好，我是景霄。\nPython的程序中充满了字符串（string），在平常阅读代码时也屡见不鲜。字符串同样是Python中很常见的一种数据类型，比如日志的打印、程序中函数的注释、数据库的访问、变量的基本操作等等，都用到了字符串。\n当然，我相信你本身对字符串已经有所了解。今天这节课，我主要带你回顾一下字符串的常用操作，并对其中的一些小tricks详细地加以解释。\n字符串基础 link什么是字符串呢？字符串是由独立字符组成的一个序列，通常包含在单引号（''）双引号（\"\"）或者三引号之中（''' '''或\"\"\" \"\"\"，两者一样），比如下面几种写法。\nname = 'jason'\rcity = 'beijing'\rtext = \"welcome to jike shijian\" 这里定义了name、city和text三个变量，都是字符串类型。我们知道，Python中单引号、双引号和三引号的字符串是一模一样的，没有区别，比如下面这个例子中的s1、s2、s3完全一样。\ns1 = 'hello'\rs2 = \"hello\"\rs3 = \"\"\"hello\"\"\"\rs1 == s2 == s3\rTrue Python同时支持这三种表达方式，很重要的一个原因就是，这样方便你在字符串中，内嵌带引号的字符串。比如：\n\"I'm a student\" Python的三引号字符串，则主要应用于多行字符串的情境，比如函数的注释等等。\ndef calculate_similarity(item1, item2):\r\"\"\"\rCalculate similarity between two items\rArgs:\ritem1: 1st item\ritem2: 2nd item\rReturns:\rsimilarity score between item1 and item2\r\"\"\" 同时，Python也支持转义字符。所谓的转义字符，就是用反斜杠开头的字符串，来表示一些特定意义的字符。我把常见的的转义字符，总结成了下面这张表格。\n为了方便你理解，我举一个例子来说明。\ns = 'a\\nb\\tc'\rprint(s)\ra\rb\tc 这段代码中的'\\n'，表示一个字符——换行符；'\\t'也表示一个字符——横向制表符。所以，最后打印出来的输出，就是字符a，换行，字符b，然后制表符，最后打印字符c。不过要注意，虽然最后打印的输出横跨了两行，但是整个字符串s仍然只有5个元素。\nlen(s)\r5 在转义字符的应用中，最常见的就是换行符'\\n'的使用。比如文件读取，如果我们一行行地读取，那么每一行字符串的末尾，都会包含换行符'\\n'。而最后做数据处理时，我们往往会丢掉每一行的换行符。\n字符串的常用操作 link讲完了字符串的基本原理，下面我们一起来看看字符串的常用操作。你可以把字符串想象成一个由单个字符组成的数组，所以，Python的字符串同样支持索引，切片和遍历等等操作。\nname = 'jason'\rname[0]\r'j'\rname[1:3]\r'as' 和其他数据结构，如列表、元组一样，字符串的索引同样从0开始，index=0表示第一个元素（字符），[index:index+2]则表示第index个元素到index+1个元素组成的子字符串。\n遍历字符串同样很简单，相当于遍历字符串中的每个字符。\nfor char in name:\rprint(char) j\ra\rs\ro\rn 特别要注意，Python的字符串是不可变的（immutable）。因此，用下面的操作，来改变一个字符串内部的字符是错误的，不允许的。\ns = 'hello'\rs[0] = 'H'\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: 'str' object does not support item assignment Python中字符串的改变，通常只能通过创建新的字符串来完成。比如上述例子中，想把'hello'的第一个字符'h'，改为大写的'H'，我们可以采用下面的做法：\ns = 'H' + s[1:]\rs = s.replace('h', 'H') 第一种方法，是直接用大写的'H'，通过加号'+'操作符，与原字符串切片操作的子字符串拼接而成新的字符串。 第二种方法，是直接扫描原字符串，把小写的'h'替换成大写的'H'，得到新的字符串。 你可能了解到，在其他语言中，如Java，有可变的字符串类型，比如StringBuilder，每次添加、改变或删除字符（串），无需创建新的字符串，时间复杂度仅为O(1)。这样就大大提高了程序的运行效率。\n但可惜的是，Python中并没有相关的数据类型，我们还是得老老实实创建新的字符串。因此，每次想要改变字符串，往往需要O(n)的时间复杂度，其中，n为新字符串的长度。\n你可能注意到了，上述例子的说明中，我用的是“往往”、“通常”这样的字眼，并没有说“一定”。这是为什么呢？显然，随着版本的更新，Python也越来越聪明，性能优化得越来越好了。\n这里，我着重讲解一下，使用加法操作符'+='的字符串拼接方法。因为它是一个例外，打破了字符串不可变的特性。\n操作方法如下所示：\nstr1 += str2 # 表示str1 = str1 + str2 我们来看下面这个例子：\ns = ''\rfor n in range(0, 100000):\rs += str(n) 你觉得这个例子的时间复杂度是多少呢？\n每次循环，似乎都得创建一个新的字符串；而每次创建一个新的字符串，都需要O(n)的时间复杂度。因此，总的时间复杂度就为O(1) + O(2) + … + O(n) = O(n^2)。这样到底对不对呢？\n乍一看，这样分析确实很有道理，但是必须说明，这个结论只适用于老版本的Python了。自从Python2.5开始，每次处理字符串的拼接操作时（str1 += str2），Python首先会检测str1还有没有其他的引用。如果没有的话，就会尝试原地扩充字符串buffer的大小，而不是重新分配一块内存来创建新的字符串并拷贝。这样的话，上述例子中的时间复杂度就仅为O(n)了。\n因此，以后你在写程序遇到字符串拼接时，如果使用’+=‘更方便，就放心地去用吧，不用过分担心效率问题了。\n另外，对于字符串拼接问题，除了使用加法操作符，我们还可以使用字符串内置的join函数。string.join(iterable)，表示把每个元素都按照指定的格式连接起来。\nl = []\rfor n in range(0, 100000):\rl.append(str(n))\rl = ' '.join(l) 由于列表的append操作是O(1)复杂度，字符串同理。因此，这个含有for循环例子的时间复杂度为n*O(1)=O(n)。\n接下来，我们看一下字符串的分割函数split()。string.split(separator)，表示把字符串按照separator分割成子字符串，并返回一个分割后子字符串组合的列表。它常常应用于对数据的解析处理，比如我们读取了某个文件的路径，想要调用数据库的API，去读取对应的数据，我们通常会写成下面这样：\ndef query_data(namespace, table):\r\"\"\"\rgiven namespace and table, query database to get corresponding\rdata \"\"\"\rpath = 'hive://ads/training_table'\rnamespace = path.split('//')[1].split('/')[0] # 返回'ads'\rtable = path.split('//')[1].split('/')[1] # 返回 'training_table'\rdata = query_data(namespace, table) 此外，常见的函数还有：\nstring.strip(str)，表示去掉首尾的str字符串； string.lstrip(str)，表示只去掉开头的str字符串； string.rstrip(str)，表示只去掉尾部的str字符串。 这些在数据的解析处理中同样很常见。比如很多时候，从文件读进来的字符串中，开头和结尾都含有空字符，我们需要去掉它们，就可以用strip()函数：\ns = ' my name is jason '\rs.strip()\r'my name is jason' 当然，Python中字符串还有很多常用操作，比如，string.find(sub, start, end)，表示从start到end查找字符串中子字符串sub的位置等等。这里，我只强调了最常用并且容易出错的几个函数，其他内容你可以自行查找相应的文档、范例加以了解，我就不一一赘述了。\n字符串的格式化 link最后，我们一起来看看字符串的格式化。什么是字符串的格式化呢？\n通常，我们使用一个字符串作为模板，模板中会有格式符。这些格式符为后续真实值预留位置，以呈现出真实值应该呈现的格式。字符串的格式化，通常会用在程序的输出、logging等场景。\n举一个常见的例子。比如我们有一个任务，给定一个用户的userid，要去数据库中查询该用户的一些信息，并返回。而如果数据库中没有此人的信息，我们通常会记录下来，这样有利于往后的日志分析，或者是线上bug的调试等等。\n我们通常会用下面的方法来表示：\nprint('no data available for person with id: {}, name: {}'.format(id, name)) 其中的string.format()，就是所谓的格式化函数；而大括号{}就是所谓的格式符，用来为后面的真实值——变量name预留位置。如果id = '123'、name='jason'，那么输出便是：\n'no data available for person with id: 123, name: jason' 这样看来，是不是非常简单呢？\n不过要注意，string.format()是最新的字符串格式函数与规范。自然，我们还有其他的表示方法，比如在Python之前版本中，字符串格式化通常用%来表示，那么上述的例子，就可以写成下面这样：\nprint('no data available for person with id: %s, name: %s' % (id, name)) 其中%s表示字符串型，%d表示整型等等，这些属于常识，你应该都了解。\n当然，现在你写程序时，我还是推荐使用format函数，毕竟这是最新规范，也是官方文档推荐的规范。\n也许有人会问，为什么非要使用格式化函数，上述例子用字符串的拼接不也能完成吗？没错，在很多情况下，字符串拼接确实能满足格式化函数的需求。但是使用格式化函数，更加清晰、易读，并且更加规范，不易出错。\n总结 link这节课，我们主要学习了Python字符串的一些基本知识和常用操作，并且结合具体的例子与场景加以说明，特别需要注意下面几点。\nPython中字符串使用单引号、双引号或三引号表示，三者意义相同，并没有什么区别。其中，三引号的字符串通常用在多行字符串的场景。 Python中字符串是不可变的（前面所讲的新版本Python中拼接操作’+=‘是个例外）。因此，随意改变字符串中字符的值，是不被允许的。 Python新版本（2.5+）中，字符串的拼接变得比以前高效了许多，你可以放心使用。 Python中字符串的格式化（string.format）常常用在输出、日志的记录等场景。 思考题 link最后，给你留一道思考题。在新版本的Python（2.5+）中，下面的两个字符串拼接操作，你觉得哪个更优呢？欢迎留言和我分享你的观点，也欢迎你把这篇文章分享给你的同事、朋友。\ns = ''\rfor n in range(0, 100000):\rs += str(n) l = []\rfor n in range(0, 100000):\rl.append(str(n))\rs = ' '.join(l) 测试 1000 条数据，方式二 linkimport time start_time = time.perf_counter() s = [] for n in range(0, 1000): s.append(str(n)) ''.join(s) end_time = time.perf_counter() print('Time elapse: {}'.format(end_time - start_time)) 返回结果: Time elapse: 0.0004917513579130173\n测试 1000 条数据，方式三 linkimport time start_time = time.perf_counter() s = ''.join(map(str, range(0, 1000))) end_time = time.perf_counter() print('Time elapse: {}'.format(end_time - start_time)) 返回结果：Time elapse: 0.00021015387028455734\n分别测试一百万和一千万条数据，结果如下： 100万: 方式一：Time elapse: 0.3384760869666934 方式二：Time elapse: 0.34538754168897867 方式三：Time elapse: 0.2445415174588561\n1000万： 方式一：Time elapse: 4.24716751743108 方式二：Time elapse: 3.1754934675991535 方式三：Time elapse: 2.2939002392813563\n综上，方式三性能最优，其次是在超过1000万条数据以上时，方式二优于方式一，相反，方式一优于方式二。2019-05-20LJK 👍（59） 💬（5）最新的f\"\"用法了解一下？2019-05-20ssikiki 👍（25） 💬（8）使用加法操作符'+='的字符串拼接方法。因为它是一个例外 … 可是 x = 'a' id(x) # 4345659208 x += 'b' id(x) # 4376614424 做完+=操作后， x的内存地址变了， 说明新生成了字符串，请问老师这为什么说是例外？2019-05-21\n"
            }
        );
    index.add(
            {
                id:  15 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/06---python-%E9%BB%91%E7%AE%B1%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA\/",
                title: "Python “黑箱”：输入与输出",
                description: "你好，我是景霄。\n世纪之交的论坛上曾有一句流行语：在互联网上，没人知道你是一条狗。互联网刚刚兴起时，一根网线链接到你家，信息通过这条高速线缆直达你的屏幕，你通过键盘飞速回应朋友的消息，信息再次通过网线飞入错综复杂的虚拟世界，再进入朋友家。抽象来看，一台台的电脑就是一个个黑箱，黑箱有了输入和输出，就拥有了图灵机运作的必要条件。\nPython 程序也是一个黑箱：通过输入流将数据送达，通过输出流将处理后的数据送出，可能 Python 解释器后面藏了一个人，还是一个史莱哲林？No one cares。\n好了废话不多说，今天我们就由浅及深讲讲 Python 的输入和输出。\n输入输出基础 link最简单直接的输入来自键盘操作，比如下面这个例子。\nname = input('your name:')\rgender = input('you are a boy?(y/n)')\r###### 输入 ######\ryour name:Jack\ryou are a boy?\rwelcome_str = 'Welcome to the matrix {prefix} {name}.'\rwelcome_dic = {\r'prefix': 'Mr.' if gender == 'y' else 'Mrs',\r'name': name\r}\rprint('authorizing...')\rprint(welcome_str.format(**welcome_dic))\r########## 输出 ##########\rauthorizing...\rWelcome to the matrix Mr. Jack. input() 函数暂停程序运行，同时等待键盘输入；直到回车被按下，函数的参数即为提示语，输入的类型永远是字符串型（str）。注意，初学者在这里很容易犯错，下面的例子我会讲到。print() 函数则接受字符串、数字、字典、列表甚至一些自定义类的输出。\n",
                content: "你好，我是景霄。\n世纪之交的论坛上曾有一句流行语：在互联网上，没人知道你是一条狗。互联网刚刚兴起时，一根网线链接到你家，信息通过这条高速线缆直达你的屏幕，你通过键盘飞速回应朋友的消息，信息再次通过网线飞入错综复杂的虚拟世界，再进入朋友家。抽象来看，一台台的电脑就是一个个黑箱，黑箱有了输入和输出，就拥有了图灵机运作的必要条件。\nPython 程序也是一个黑箱：通过输入流将数据送达，通过输出流将处理后的数据送出，可能 Python 解释器后面藏了一个人，还是一个史莱哲林？No one cares。\n好了废话不多说，今天我们就由浅及深讲讲 Python 的输入和输出。\n输入输出基础 link最简单直接的输入来自键盘操作，比如下面这个例子。\nname = input('your name:')\rgender = input('you are a boy?(y/n)')\r###### 输入 ######\ryour name:Jack\ryou are a boy?\rwelcome_str = 'Welcome to the matrix {prefix} {name}.'\rwelcome_dic = {\r'prefix': 'Mr.' if gender == 'y' else 'Mrs',\r'name': name\r}\rprint('authorizing...')\rprint(welcome_str.format(**welcome_dic))\r########## 输出 ##########\rauthorizing...\rWelcome to the matrix Mr. Jack. input() 函数暂停程序运行，同时等待键盘输入；直到回车被按下，函数的参数即为提示语，输入的类型永远是字符串型（str）。注意，初学者在这里很容易犯错，下面的例子我会讲到。print() 函数则接受字符串、数字、字典、列表甚至一些自定义类的输出。\n我们再来看下面这个例子。\na = input()\r1\rb = input()\r2\rprint('a + b = {}'.format(a + b))\r########## 输出 ##############\ra + b = 12\rprint('type of a is {}, type of b is {}'.format(type(a), type(b)))\r########## 输出 ##############\rtype of a is "
            }
        );
    index.add(
            {
                id:  16 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/07---%E4%BF%AE%E7%82%BC%E5%9F%BA%E6%9C%AC%E5%8A%9F%E6%9D%A1%E4%BB%B6%E4%B8%8E%E5%BE%AA%E7%8E%AF\/",
                title: "修炼基本功：条件与循环",
                description: "你好，我是景霄。\n前面几节，我们一起学习了列表、元组、字典、集合和字符串等一系列Python的基本数据类型。但是，如何把这一个个基本的数据结构类型串接起来，组成一手漂亮的代码呢？这就是我们今天所要讨论的“条件与循环”。\n我习惯把“条件与循环”，叫做编程中的基本功。为什么称它为基本功呢？因为它控制着代码的逻辑，可以说是程序的中枢系统。如果把写程序比作盖楼房，那么条件与循环就是楼房的根基，其他所有东西都是在此基础上构建而成。\n毫不夸张地说，写一手简洁易读的条件与循环代码，对提高程序整体的质量至关重要。\n条件语句 link首先，我们一起来看一下Python的条件语句，用法很简单。比如，我想要表示y=|x|这个函数，那么相应的代码便是：\n# y = |x|\rif x \u003c 0:\ry = -x\relse:\ry = x 和其他语言不一样，我们不能在条件语句中加括号，写成下面这样的格式。\nif (x \u003c 0) 但需要注意的是，在条件语句的末尾必须加上冒号（:），这是Python特定的语法规范。\n由于Python不支持switch语句，因此，当存在多个条件判断时，我们需要用else if来实现，这在Python中的表达是elif。语法如下：\nif condition_1:\rstatement_1\relif condition_2:\rstatement_2\r...\relif condition_i:\rstatement_i\relse:\rstatement_n 整个条件语句是顺序执行的，如果遇到一个条件满足，比如condition_i满足时，在执行完statement_i后，便会退出整个if、elif、else条件语句，而不会继续向下执行。这个语句在工作中很常用，比如下面的这个例子。\n实际工作中，我们经常用ID表示一个事物的属性，然后进行条件判断并且输出。比如，在integrity的工作中，通常用0、1、2分别表示一部电影的色情暴力程度。其中，0的程度最高，是red级别；1其次，是yellow级别；2代表没有质量问题，属于green。\n如果给定一个ID，要求输出某部电影的质量评级，则代码如下：\nif id == 0:\rprint('red')\relif id == 1:\rprint('yellow')\relse:\rprint('green') 不过要注意，if语句是可以单独使用的，但elif、else都必须和if成对使用。\n另外，在我们进行条件判断时， 不少人喜欢省略判断的条件，比如写成下面这样：\nif s: # s is a string\r...\rif l: # l is a list\r...\rif i: # i is an int\r...\r... 关于省略判断条件的常见用法，我大概总结了一下：\n",
                content: "你好，我是景霄。\n前面几节，我们一起学习了列表、元组、字典、集合和字符串等一系列Python的基本数据类型。但是，如何把这一个个基本的数据结构类型串接起来，组成一手漂亮的代码呢？这就是我们今天所要讨论的“条件与循环”。\n我习惯把“条件与循环”，叫做编程中的基本功。为什么称它为基本功呢？因为它控制着代码的逻辑，可以说是程序的中枢系统。如果把写程序比作盖楼房，那么条件与循环就是楼房的根基，其他所有东西都是在此基础上构建而成。\n毫不夸张地说，写一手简洁易读的条件与循环代码，对提高程序整体的质量至关重要。\n条件语句 link首先，我们一起来看一下Python的条件语句，用法很简单。比如，我想要表示y=|x|这个函数，那么相应的代码便是：\n# y = |x|\rif x \u003c 0:\ry = -x\relse:\ry = x 和其他语言不一样，我们不能在条件语句中加括号，写成下面这样的格式。\nif (x \u003c 0) 但需要注意的是，在条件语句的末尾必须加上冒号（:），这是Python特定的语法规范。\n由于Python不支持switch语句，因此，当存在多个条件判断时，我们需要用else if来实现，这在Python中的表达是elif。语法如下：\nif condition_1:\rstatement_1\relif condition_2:\rstatement_2\r...\relif condition_i:\rstatement_i\relse:\rstatement_n 整个条件语句是顺序执行的，如果遇到一个条件满足，比如condition_i满足时，在执行完statement_i后，便会退出整个if、elif、else条件语句，而不会继续向下执行。这个语句在工作中很常用，比如下面的这个例子。\n实际工作中，我们经常用ID表示一个事物的属性，然后进行条件判断并且输出。比如，在integrity的工作中，通常用0、1、2分别表示一部电影的色情暴力程度。其中，0的程度最高，是red级别；1其次，是yellow级别；2代表没有质量问题，属于green。\n如果给定一个ID，要求输出某部电影的质量评级，则代码如下：\nif id == 0:\rprint('red')\relif id == 1:\rprint('yellow')\relse:\rprint('green') 不过要注意，if语句是可以单独使用的，但elif、else都必须和if成对使用。\n另外，在我们进行条件判断时， 不少人喜欢省略判断的条件，比如写成下面这样：\nif s: # s is a string\r...\rif l: # l is a list\r...\rif i: # i is an int\r...\r... 关于省略判断条件的常见用法，我大概总结了一下：\n不过，切记，在实际写代码时，我们鼓励，除了boolean类型的数据，条件判断最好是显性的。比如，在判断一个整型数是否为0时，我们最好写出判断的条件：\nif i != 0:\r... 而不是只写出变量名：\nif i:\r... 循环语句 link讲完了条件语句，我们接着来看循环语句。所谓循环，顾名思义，本质上就是遍历集合中的元素。和其他语言一样，Python中的循环一般通过for循环和while循环实现。\n比如，我们有一个列表，需要遍历列表中的所有元素并打印输出，代码如下：\nl = [1, 2, 3, 4]\rfor item in l:\rprint(item)\r1\r2\r3\r4 你看，是不是很简单呢？\n其实，Python中的数据结构只要是可迭代的（iterable），比如列表、集合等等，那么都可以通过下面这种方式遍历：\nfor item in :\r... 这里需要单独强调一下字典。字典本身只有键是可迭代的，如果我们要遍历它的值或者是键值对，就需要通过其内置的函数values()或者items()实现。其中，values()返回字典的值的集合，items()返回键值对的集合。\nd = {'name': 'jason', 'dob': '2000-01-01', 'gender': 'male'}\rfor k in d: # 遍历字典的键\rprint(k)\rname\rdob\rgender\rfor v in d.values(): # 遍历字典的值\rprint(v)\rjason\r2000-01-01\rmale for k, v in d.items(): # 遍历字典的键值对\rprint('key: {}, value: {}'.format(k, v))\rkey: name, value: jason\rkey: dob, value: 2000-01-01\rkey: gender, value: male 看到这里你也许会问，有没有办法通过集合中的索引来遍历元素呢？当然可以，其实这种情况在实际工作中还是很常见的，甚至很多时候，我们还得根据索引来做一些条件判断。\n我们通常通过range()这个函数，拿到索引，再去遍历访问集合中的元素。比如下面的代码，遍历一个列表中的元素，当索引小于5时，打印输出：\nl = [1, 2, 3, 4, 5, 6, 7]\rfor index in range(0, len(l)):\rif index \u003c 5:\rprint(l[index]) 1\r2\r3\r4\r5 当我们同时需要索引和元素时，还有一种更简洁的方式，那就是通过Python内置的函数enumerate()。用它来遍历集合，不仅返回每个元素，并且还返回其对应的索引，这样一来，上面的例子就可以写成:\nl = [1, 2, 3, 4, 5, 6, 7]\rfor index, item in enumerate(l):\rif index \u003c 5:\rprint(item) 1\r2\r3\r4\r5 在循环语句中，我们还常常搭配continue和break一起使用。所谓continue，就是让程序跳过当前这层循环，继续执行下面的循环；而break则是指完全跳出所在的整个循环体。在循环中适当加入continue和break，往往能使程序更加简洁、易读。\n比如，给定两个字典，分别是产品名称到价格的映射，和产品名称到颜色列表的映射。我们要找出价格小于1000，并且颜色不是红色的所有产品名称和颜色的组合。如果不用continue，代码应该是下面这样的：\n# name_price: 产品名称(str)到价格(int)的映射字典\r# name_color: 产品名字(str)到颜色(list of str)的映射字典\rfor name, price in name_price.items():\rif price \u003c 1000:\rif name in name_color:\rfor color in name_color[name]:\rif color != 'red':\rprint('name: {}, color: {}'.format(name, color))\relse:\rprint('name: {}, color: {}'.format(name, 'None')) 而加入continue后，代码显然清晰了很多：\n# name_price: 产品名称(str)到价格(int)的映射字典\r# name_color: 产品名字(str)到颜色(list of str)的映射字典\rfor name, price in name_price.items():\rif price \u003e= 1000:\rcontinue\rif name not in name_color:\rprint('name: {}, color: {}'.format(name, 'None'))\rcontinue\rfor color in name_color[name]:\rif color == 'red':\rcontinue\rprint('name: {}, color: {}'.format(name, color)) 我们可以看到，按照第一个版本的写法，从开始一直到打印输出符合条件的产品名称和颜色，共有5层for或者if的嵌套；但第二个版本加入了continue后，只有3层嵌套。\n显然，如果代码中出现嵌套里还有嵌套的情况，代码便会变得非常冗余、难读，也不利于后续的调试、修改。因此，我们要尽量避免这种多层嵌套的情况。\n前面讲了for循环，对于while循环，原理也是一样的。它表示当condition满足时，一直重复循环内部的操作，直到condition不再满足，就跳出循环体。\nwhile condition:\r.... 很多时候，for循环和while循环可以互相转换，比如要遍历一个列表，我们用while循环同样可以完成：\nl = [1, 2, 3, 4]\rindex = 0\rwhile index \u003c len(l):\rprint(l[index])\rindex += 1 那么，两者的使用场景又有什么区别呢？\n通常来说，如果你只是遍历一个已知的集合，找出满足条件的元素，并进行相应的操作，那么使用for循环更加简洁。但如果你需要在满足某个条件前，不停地重复某些操作，并且没有特定的集合需要去遍历，那么一般则会使用while循环。\n比如，某个交互式问答系统，用户输入文字，系统会根据内容做出相应的回答。为了实现这个功能，我们一般会使用while循环，大致代码如下：\nwhile True:\rtry:\rtext = input('Please enter your questions, enter \"q\" to exit')\rif text == 'q':\rprint('Exit system')\rbreak\r...\r...\rprint(response)\rexcept Exception as err:\rprint('Encountered error: {}'.format(err))\rbreak 同时需要注意的是，for循环和while循环的效率问题。比如下面的while循环：\ni = 0\rwhile i \u003c 1000000:\ri += 1 和等价的for循环：\nfor i in range(0, 1000000):\rpass 究竟哪个效率高呢？\n要知道，range()函数是直接由C语言写的，调用它速度非常快。而while循环中的“i += 1”这个操作，得通过Python的解释器间接调用底层的C语言；并且这个简单的操作，又涉及到了对象的创建和删除（因为i是整型，是immutable，i += 1相当于i = new int(i + 1)）。所以，显然，for循环的效率更胜一筹。\n条件与循环的复用 link前面两部分讲了条件与循环的一些基本操作，接下来，我们重点来看它们的进阶操作，让程序变得更简洁高效。\n在阅读代码的时候，你应该常常会发现，有很多将条件与循环并做一行的操作，例如：\nexpression1 if condition else expression2 for item in iterable 将这个表达式分解开来，其实就等同于下面这样的嵌套结构：\nfor item in iterable:\rif condition:\rexpression1\relse:\rexpression2 而如果没有else语句，则需要写成：\nexpression for item in iterable if condition 举个例子，比如我们要绘制y = 2*|x| + 5 的函数图像，给定集合x的数据点，需要计算出y的数据集合，那么只用一行代码，就可以很轻松地解决问题了：\ny = [value * 2 + 5 if value \u003e 0 else -value * 2 + 5 for value in x] 再比如我们在处理文件中的字符串时，常常遇到的一个场景：将文件中逐行读取的一个完整语句，按逗号分割单词，去掉首位的空字符，并过滤掉长度小于等于3的单词，最后返回由单词组成的列表。这同样可以简洁地表达成一行：\ntext = ' Today, is, Sunday'\rtext_list = [s.strip() for s in text.split(',') if len(s.strip()) \u003e 3]\rprint(text_list)\r['Today', 'Sunday'] 当然，这样的复用并不仅仅局限于一个循环。比如，给定两个列表x、y，要求返回x、y中所有元素对组成的元组，相等情况除外。那么，你也可以很容易表示出来：\n[(xx, yy) for xx in x for yy in y if xx != yy] 这样的写法就等价于：\nl = []\rfor xx in x:\rfor yy in y:\rif xx != yy:\rl.append((xx, yy)) 熟练之后，你会发现这种写法非常方便。当然，如果遇到逻辑很复杂的复用，你可能会觉得写成一行难以理解、容易出错。那种情况下，用正常的形式表达，也不失为一种好的规范和选择。\n总结 link今天这节课，我们一起学习了条件与循环的基本概念、进阶用法以及相应的应用。这里，我重点强调几个易错的地方。\n在条件语句中，if可以单独使用，但是elif和else必须和if同时搭配使用；而If条件语句的判断，除了boolean类型外，其他的最好显示出来。 在for循环中，如果需要同时访问索引和元素，你可以使用enumerate()函数来简化代码。 写条件与循环时，合理利用continue或者break来避免复杂的嵌套，是十分重要的。 要注意条件与循环的复用，简单功能往往可以用一行直接完成，极大地提高代码质量与效率。 思考题 link最后给你留一个思考题。给定下面两个列表attributes和values，要求针对values中每一组子列表value，输出其和attributes中的键对应后的字典，最后返回字典组成的列表。\nattributes = ['name', 'dob', 'gender']\rvalues = [['jason', '2000-01-01', 'male'], ['mike', '1999-01-01', 'male'],\r['nancy', '2001-02-01', 'female']\r]\r# expected output:\r[{'name': 'jason', 'dob': '2000-01-01', 'gender': 'male'}, {'name': 'mike', 'dob': '1999-01-01', 'gender': 'male'}, {'name': 'nancy', 'dob': '2001-02-01', 'gender': 'female'}] 你能分别用一行和多行条件循环语句，来实现这个功能吗？\n欢迎在留言区写下你的答案，还有你今天学习的心得和疑惑，也欢迎你把这篇文章分享给你的同事、朋友。\n#多行输出 list1 = [] #建议空列表 for value in values: #对值列表进行循环 dict1 = {} #简历空字典，后续对字典键值对存储 for index ,key in enumerate(attributes):#遍历建列表，返回索引与元素 dict1[key] = value[index] #键与值匹配对，组装成字典元素 list1.append(dict1) #将字典添加到列表中 print(list1)2019-11-27趣学车 👍（1） 💬（1）attributes = ['name', 'dob', 'gender'] values = [['jason', '2000-01-01', 'male'], ['mike', '1999-01-01', 'male'], ['nancy', '2001-02-01', 'female']]\nresult_list = [] for index, item in enumerate(values): result_dict = {} for i, value in enumerate(item): result_dict[attributes[i]] = value result_list.append(result_dict) print(result_list)2020-01-10建强 👍（1） 💬（1）另外，想问下老师，和Java相比，Python是不是不能用于构建企业级的应用，构建企业级的系统，是不是用Java更稳定，性能更高。另外，网上说Pyhton是一种粘合剂语言，感觉用Python是不是给人感觉很业余呢？哈哈，开个玩笑。2019-06-16daowuli_chihai 👍（0） 💬（1）文稿中下面代码，过滤掉长度小于等于5的单词，'Today'就没有了吧? 最后一行是 运行结果吧？ 也许不重要，呵呵 【\ntext = ' Today, is, Sunday' text_list = [s.strip() for s in text.split(',') if len(s.strip()) \u003e 5] print(text_list) ['Today', 'Sunday'] 】2020-06-11daowuli_chihai 👍（0） 💬（1）下面代码 第10行 except as err:\nas前面少了一个单词吧\nwhile True: try: text = input('Please enter your questions, enter \"q\" to exit') if text == 'q': print('Exit system') break … … print(response) except as err: # 第10行 print('Encountered error: {}'.format(err)) break 2020-06-11日月剑 👍（0） 💬（1）python 列表推导式的表达式是不是不能有赋值表达式？比如如下代码： a = ['A', 'B', 'C'] d = {} d[key] = 0 for key in a 这里执行的时候会有语法错误，应该怎么改呢?\n循环版： l = [] for value in values: d = {} for i in range(3): d[attributes[i]] = value[i] l.append(d)\nprint( [{ attributes[i]: value[i] for i in range(len(attributes)) } for value in values])2019-05-24呜呜啦 👍（24） 💬（4）attributes = ['name', 'dob', 'gender'] values = [ ['jason', '2000-01-01', 'male'], ['mike', '1999-01-01', 'male'], ['nancy', '2001-02-01', 'female'] ]\n多行代码版 linklist1 = [] # 建立空列表 for value in values: # 对值列表进行循环 dict1 = {} # 建立空字典，方便后续字典键值对存储 for index,key in enumerate(attributes): # 遍历键列表，返回元素与索引 dict1[key] = value[index] # 键与值配对，组装成字典元素 list1.append(dict1) # 将新字典添加到里列表中 print(list1) # 打印显示出完整列表\n一行代码版 link[{key:value[index] for index,key in enumerate(attributes)}for value in values]\n最外层[]与上面“list1=[]”和“list1.append(dict1)”等价 link\"{key:value[index] for index,key in enumerate(attributes)}\"与上面\"for value in values:\"内代码等价 link体会：先梳理逻辑，写出多行代码版，再回溯写出一行代码版，体现出Python的简洁优美2019-06-15 link "
            }
        );
    index.add(
            {
                id:  17 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/08---%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7\/",
                title: "异常处理：如何提高程序的稳定性？",
                description: "你好，我是景霄。\n今天这节课，我想和你聊聊Python的异常处理。和其他语言一样，异常处理是Python中一种很常见，并且很重要的机制与代码规范。\n我在实际工作中，见过很多次这样的情况：一位工程师提交了代码，不过代码某处忘记了异常处理。碰巧这种异常发生的频率不低，所以在代码push到线上后没多久，就会收到紧急通知——服务器崩溃了。\n如果事情严重，对用户的影响也很大，这位工程师还得去专门的会议上做自我检讨，可以说是很惨了。这类事件层出不穷，也告诉我们，正确理解和处理程序中的异常尤为关键。\n错误与异常 link首先要了解，Python中的错误和异常是什么？两者之间又有什么联系和区别呢？\n通常来说，程序中的错误至少包括两种，一种是语法错误，另一种则是异常。\n所谓语法错误，你应该很清楚，也就是你写的代码不符合编程规范，无法被识别与执行，比如下面这个例子：\nif name is not None\rprint(name) If语句漏掉了冒号，不符合Python的语法规范，所以程序就会报错invalid syntax。\n而异常则是指程序的语法正确，也可以被执行，但在执行过程中遇到了错误，抛出了异常，比如下面的3个例子：\n10 / 0\rTraceback (most recent call last):\rFile \"\", line 1, in ZeroDivisionError: integer division or modulo by zero\rorder * 2\rTraceback (most recent call last):\rFile \"\", line 1, in NameError: name 'order' is not defined\r1 + [1, 2]\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: unsupported operand type(s) for +: 'int' and 'list' 它们语法完全正确，但显然，我们不能做除法时让分母为0；也不能使用未定义的变量做运算；而让一个整型和一个列表相加也是不可取的。\n",
                content: "你好，我是景霄。\n今天这节课，我想和你聊聊Python的异常处理。和其他语言一样，异常处理是Python中一种很常见，并且很重要的机制与代码规范。\n我在实际工作中，见过很多次这样的情况：一位工程师提交了代码，不过代码某处忘记了异常处理。碰巧这种异常发生的频率不低，所以在代码push到线上后没多久，就会收到紧急通知——服务器崩溃了。\n如果事情严重，对用户的影响也很大，这位工程师还得去专门的会议上做自我检讨，可以说是很惨了。这类事件层出不穷，也告诉我们，正确理解和处理程序中的异常尤为关键。\n错误与异常 link首先要了解，Python中的错误和异常是什么？两者之间又有什么联系和区别呢？\n通常来说，程序中的错误至少包括两种，一种是语法错误，另一种则是异常。\n所谓语法错误，你应该很清楚，也就是你写的代码不符合编程规范，无法被识别与执行，比如下面这个例子：\nif name is not None\rprint(name) If语句漏掉了冒号，不符合Python的语法规范，所以程序就会报错invalid syntax。\n而异常则是指程序的语法正确，也可以被执行，但在执行过程中遇到了错误，抛出了异常，比如下面的3个例子：\n10 / 0\rTraceback (most recent call last):\rFile \"\", line 1, in ZeroDivisionError: integer division or modulo by zero\rorder * 2\rTraceback (most recent call last):\rFile \"\", line 1, in NameError: name 'order' is not defined\r1 + [1, 2]\rTraceback (most recent call last):\rFile \"\", line 1, in TypeError: unsupported operand type(s) for +: 'int' and 'list' 它们语法完全正确，但显然，我们不能做除法时让分母为0；也不能使用未定义的变量做运算；而让一个整型和一个列表相加也是不可取的。\n于是，当程序运行到这些地方时，就抛出了异常，并且终止运行。例子中的ZeroDivisionError NameError和TypeError，就是三种常见的异常类型。\n当然，Python中还有很多其他异常类型，比如KeyError是指字典中的键找不到；FileNotFoundError是指发送了读取文件的请求，但相应的文件不存在等等，我在此不一一赘述，你可以自行参考相应文档。\n如何处理异常 link刚刚讲到，如果执行到程序中某处抛出了异常，程序就会被终止并退出。你可能会问，那有没有什么办法可以不终止程序，让其照样运行下去呢？答案当然是肯定的，这也就是我们所说的异常处理，通常使用try和except来解决，比如：\ntry:\rs = input('please enter two numbers separated by comma: ')\rnum1 = int(s.split(',')[0].strip())\rnum2 = int(s.split(',')[1].strip())\r... except ValueError as err:\rprint('Value Error: {}'.format(err))\rprint('continue')\r... 这里默认用户输入以逗号相隔的两个整形数字，将其提取后，做后续的操作（注意input函数会将输入转换为字符串类型）。如果我们输入a,b，程序便会抛出异常invalid literal for int() with base 10: 'a'，然后跳出try这个block。\n由于程序抛出的异常类型是ValueError，和except block所catch的异常类型相匹配，所以except block便会被执行，最终输出Value Error: invalid literal for int() with base 10: 'a'，并打印出continue。\nplease enter two numbers separated by comma: a,b\rValue Error: invalid literal for int() with base 10: 'a'\rcontinue 我们知道，except block只接受与它相匹配的异常类型并执行，如果程序抛出的异常并不匹配，那么程序照样会终止并退出。\n所以，还是刚刚这个例子，如果我们只输入1，程序抛出的异常就是IndexError: list index out of range，与ValueError不匹配，那么except block就不会被执行，程序便会终止并退出（continue不会被打印）。\nplease enter two numbers separated by comma: 1\rIndexError Traceback (most recent call last)\rIndexError: list index out of range 不过，很显然，这样强调一种类型的写法有很大的局限性。那么，该怎么解决这个问题呢？\n其中一种解决方案，是在except block中加入多种异常的类型，比如下面这样的写法：\ntry:\rs = input('please enter two numbers separated by comma: ')\rnum1 = int(s.split(',')[0].strip())\rnum2 = int(s.split(',')[1].strip())\r...\rexcept (ValueError, IndexError) as err:\rprint('Error: {}'.format(err))\rprint('continue')\r... 或者第二种写法：\ntry:\rs = input('please enter two numbers separated by comma: ')\rnum1 = int(s.split(',')[0].strip())\rnum2 = int(s.split(',')[1].strip())\r...\rexcept ValueError as err:\rprint('Value Error: {}'.format(err))\rexcept IndexError as err:\rprint('Index Error: {}'.format(err))\rprint('continue')\r... 这样，每次程序执行时，except block中只要有一个exception类型与实际匹配即可。\n不过，很多时候，我们很难保证程序覆盖所有的异常类型，所以，更通常的做法，是在最后一个except block，声明其处理的异常类型是Exception。Exception是其他所有非系统异常的基类，能够匹配任意非系统异常。那么这段代码就可以写成下面这样：\ntry:\rs = input('please enter two numbers separated by comma: ')\rnum1 = int(s.split(',')[0].strip())\rnum2 = int(s.split(',')[1].strip())\r...\rexcept ValueError as err:\rprint('Value Error: {}'.format(err))\rexcept IndexError as err:\rprint('Index Error: {}'.format(err))\rexcept Exception as err:\rprint('Other error: {}'.format(err))\rprint('continue')\r... 或者，你也可以在except后面省略异常类型，这表示与任意异常相匹配（包括系统异常等）：\ntry:\rs = input('please enter two numbers separated by comma: ')\rnum1 = int(s.split(',')[0].strip())\rnum2 = int(s.split(',')[1].strip())\r...\rexcept ValueError as err:\rprint('Value Error: {}'.format(err))\rexcept IndexError as err:\rprint('Index Error: {}'.format(err))\rexcept:\rprint('Other error')\rprint('continue')\r... 需要注意，当程序中存在多个except block时，最多只有一个except block会被执行。换句话说，如果多个except声明的异常类型都与实际相匹配，那么只有最前面的except block会被执行，其他则被忽略。\n异常处理中，还有一个很常见的用法是finally，经常和try、except放在一起来用。无论发生什么情况，finally block中的语句都会被执行，哪怕前面的try和excep block中使用了return语句。\n一个常见的应用场景，便是文件的读取：\nimport sys\rtry:\rf = open('file.txt', 'r')\r.... # some data processing\rexcept OSError as err:\rprint('OS error: {}'.format(err))\rexcept:\rprint('Unexpected error:', sys.exc_info()[0])\rfinally:\rf.close() 这段代码中，try block尝试读取file.txt这个文件，并对其中的数据进行一系列的处理，到最后，无论是读取成功还是读取失败，程序都会执行finally中的语句——关闭这个文件流，确保文件的完整性。因此，在finally中，我们通常会放一些无论如何都要执行的语句。\n值得一提的是，对于文件的读取，我们也常常使用with open，你也许在前面的例子中已经看到过，with open会在最后自动关闭文件，让语句更加简洁。\n用户自定义异常 link前面的例子里充斥了很多Python内置的异常类型，你可能会问，我可以创建自己的异常类型吗？\n答案是肯定是，Python当然允许我们这么做。下面这个例子，我们创建了自定义的异常类型MyInputError，定义并实现了初始化函数和str函数（直接print时调用）：\nclass MyInputError(Exception):\r\"\"\"Exception raised when there're errors in input\"\"\"\rdef __init__(self, value): # 自定义异常类型的初始化\rself.value = value\rdef __str__(self): # 自定义异常类型的string表达形式\rreturn (\"{} is invalid input\".format(repr(self.value)))\rtry:\rraise MyInputError(1) # 抛出MyInputError这个异常\rexcept MyInputError as err:\rprint('error: {}'.format(err)) 如果你执行上述代码块并输出，便会得到下面的结果：\nerror: 1 is invalid input 实际工作中，如果内置的异常类型无法满足我们的需求，或者为了让异常更加详细、可读，想增加一些异常类型的其他功能，我们可以自定义所需异常类型。不过，大多数情况下，Python内置的异常类型就足够好了。\n异常的使用场景与注意点 link学完了前面的基础知识，接下来我们着重谈一下，异常的使用场景与注意点。\n通常来说，在程序中，如果我们不确定某段代码能否成功执行，往往这个地方就需要使用异常处理。除了上述文件读取的例子，我可以再举一个例子来说明。\n大型社交网站的后台，需要针对用户发送的请求返回相应记录。用户记录往往储存在key-value结构的数据库中，每次有请求过来后，我们拿到用户的ID，并用ID查询数据库中此人的记录，就能返回相应的结果。\n而数据库返回的原始数据，往往是json string的形式，这就需要我们首先对json string进行decode（解码），你可能很容易想到下面的方法：\nimport json\rraw_data = queryDB(uid) # 根据用户的id，返回相应的信息\rdata = json.loads(raw_data) 这样的代码是不是就足够了呢？\n要知道，在json.loads()函数中，输入的字符串如果不符合其规范，那么便无法解码，就会抛出异常，因此加上异常处理十分必要。\ntry:\rdata = json.loads(raw_data)\r....\rexcept JSONDecodeError as err:\rprint('JSONDecodeError: {}'.format(err)) 不过，有一点切记，我们不能走向另一个极端——滥用异常处理。\n比如，当你想要查找字典中某个键对应的值时，绝不能写成下面这种形式：\nd = {'name': 'jason', 'age': 20}\rtry:\rvalue = d['dob']\r...\rexcept KeyError as err:\rprint('KeyError: {}'.format(err)) 诚然，这样的代码并没有bug，但是让人看了摸不着头脑，也显得很冗余。如果你的代码中充斥着这种写法，无疑对阅读、协作来说都是障碍。因此，对于flow-control（流程控制）的代码逻辑，我们一般不用异常处理。\n字典这个例子，写成下面这样就很好。\nif 'dob' in d:\rvalue = d['dob']\r... 总结 link这节课， 我们一起学习了Python的异常处理及其使用场景，你需要重点掌握下面几点。\n异常，通常是指程序运行的过程中遇到了错误，终止并退出。我们通常使用try except语句去处理异常，这样程序就不会被终止，仍能继续执行。 处理异常时，如果有必须执行的语句，比如文件打开后必须关闭等等，则可以放在finally block中。 异常处理，通常用在你不确定某段代码能否成功执行，也无法轻易判断的情况下，比如数据库的连接、读取等等。正常的flow-control逻辑，不要使用异常处理，直接用条件语句解决就可以了。 思考题 link最后，给你留一个思考题。在异常处理时，如果try block中有多处抛出异常，需要我们使用多个try except block吗？以数据库的连接、读取为例，下面两种写法，你觉得哪种更好呢？\n第一种：\ntry:\rdb = DB.connect('') # 可能会抛出异常\rraw_data = DB.queryData('') # 可能会抛出异常\rexcept (DBConnectionError, DBQueryDataError) err:\rprint('Error: {}'.format(err)) 第二种：\ntry:\rdb = DB.connect('') # 可能会抛出异常\rtry:\rraw_data = DB.queryData('')\rexcept DBQueryDataError as err:\rprint('DB query data error: {}'.format(err))\rexcept DBConnectionError as err:\rprint('DB connection error: {}'.format(err)) 欢迎在留言区写下你的答案，还有你今天学习的心得和疑惑，也欢迎你把这篇文章分享给你的同事、朋友。\nprint(e) # NameError: name 'e' is not defined 这里为什么会显示e没有被定义呢？2019-05-27Hoo-Ah 👍（95） 💬（2）第一种写法更加简洁，易于阅读。而且except后面的错误类型先抛出数据库连接错误，之后才抛出查询错误，实现的异常处理和第二种一样。2019-05-27liput 👍（17） 💬（3）想请问老师，在facebook里面开发，对于异常处理有什么规范需要遵循吗？自定义异常、抛异常、捕获异常，粒度一般怎么把控呢？ 与此相应的，我对日志输出也有同样的疑问，希望老师能结合您在大公司里的实战经验多讲讲。2019-05-27John Si 👍（4） 💬（1）1. 第一種寫法比第二種寫法簡潔 2. 因我對try語法執行流程不太清楚，還是老師跟熟悉該同學多講解一下。但我自己想法是第二種寫法跟巢狀迴圈寫法很像，假設是第二句語法發生錯誤，第二種寫法會多執行一次try 語句，從而增加了程序運行時間。\n綜上所述，我認為第一種寫法較第二種好2019-05-27小豹子 👍（3） 💬（1）老师，系统异常，非系统异常能举个例子说明下吗？2019-05-27Kevin 👍（1） 💬（1）从代码行数看第一种更简洁，第一种中，使用了一个try..expect将异常统一处理，代码简洁， 第二种，代码中有嵌套，2020-06-17王大华 👍（1） 💬（2）第一种和第二种效果类似， 都是先检查数据库连接异常，再检查query执行的异常。\n更喜欢这种写法： try: db = DB.connect('') # 可能会抛出异常 raw_data = DB.queryData('') # 可能会抛出异常 except DBConnectionError as err: print('ConnectionError: {}'.format(err)) except DBQueryDataError as err: print('QueryDataError: {}'.format(err))2020-02-02一粒 👍（1） 💬（1）老师，什么样的代码才是您说的“flow-control”2020-01-02Geek_David 👍（0） 💬（1）个人觉得这个课还要加上一本python的书，那就天衣无缝了2020-03-29百年 👍（0） 💬（1）老师的课收获比较大，Python基础课也学过，Python核心机制也学过一点，但是一写代码，特别是实时读写文件，总是报一大堆错误，这结课真的是运用上了。2019-05-29Blackwang 👍（0） 💬（2）第一种更好，不过理由说不上来…… 另外老师，请问前几天思考题的答案有吗？之前说周末放 github 的？2019-05-27Robert小七 👍（0） 💬（1）为什么不直接用except Exception as err?2019-05-27栾~龟虽寿！ 👍（0） 💬（3）老师，课越听越觉得值，可是大家如何在手机上写代码的？不会是电脑上写好，利用微信，转发给自己手机上，再复制粘贴到留言吧？还有我有些着急，是否能一天播放两课，哈哈，我有基础。2019-05-27mickle 👍（0） 💬（1）我在开发中用第一种吧，第二种代码冗余，看着难受2019-05-27Geek_b6f316 👍（35） 💬（1）第一种方法简单明了，是不是少了一个as2019-05-27\n"
            }
        );
    index.add(
            {
                id:  18 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/09---%E4%B8%8D%E5%8F%AF%E6%88%96%E7%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0\/",
                title: "不可或缺的自定义函数",
                description: "你好，我是景霄。\n实际工作生活中，我曾见到不少初学者编写的Python程序，他们长达几百行的代码中，却没有一个函数，通通按顺序堆到一块儿，不仅让人读起来费时费力，往往也是错误连连。\n一个规范的值得借鉴的Python程序，除非代码量很少（比如10行、20行以下），基本都应该由多个函数组成，这样的代码才更加模块化、规范化。\n函数是Python程序中不可或缺的一部分。事实上，在前面的学习中，我们已经用到了很多Python的内置函数，比如sorted()表示对一个集合序列排序，len()表示返回一个集合序列的长度大小等等。这节课，我们主要来学习Python的自定义函数。\n函数基础 link那么，到底什么是函数，如何在Python程序中定义函数呢？\n说白了，函数就是为了实现某一功能的代码段，只要写好以后，就可以重复利用。我们先来看下面一个简单的例子:\ndef my_func(message):\rprint('Got a message: {}'.format(message))\r# 调用函数 my_func()\rmy_func('Hello World')\r# 输出\rGot a message: Hello World 其中：\ndef是函数的声明； my_func是函数的名称； 括号里面的message则是函数的参数； 而print那行则是函数的主体部分，可以执行相应的语句； 在函数最后，你可以返回调用结果（return或yield），也可以不返回。 总结一下，大概是下面的这种形式：\ndef name(param1, param2, ..., paramN):\rstatements\rreturn/yield value # optional 和其他需要编译的语言（比如C语言）不一样的是，def是可执行语句，这意味着函数直到被调用前，都是不存在的。当程序调用函数时，def语句才会创建一个新的函数对象，并赋予其名字。\n我们一起来看几个例子，加深你对函数的印象：\ndef my_sum(a, b):\rreturn a + b\rresult = my_sum(3, 5)\rprint(result)\r# 输出\r8 这里，我们定义了my_sum()这个函数，它有两个参数a和b，作用是相加；随后，调用my_sum()函数，分别把3和5赋于a和b；最后，返回其相加的值，赋于变量result，并输出得到8。\n再来看一个例子：\ndef find_largest_element(l):\rif not isinstance(l, list):\rprint('input is not type of list')\rreturn\rif len(l) == 0:\rprint('empty input')\rreturn\rlargest_element = l[0]\rfor item in l:\rif item \u003e largest_element:\rlargest_element = item\rprint('largest element is: {}'.format(largest_element)) find_largest_element([8, 1,-3, 2, 0])\r# 输出\rlargest element is: 8 这个例子中，我们定义了函数find_largest_element，作用是遍历输入的列表，找出最大的值并打印。因此，当我们调用它，并传递列表 [8, 1, -3, 2, 0] 作为参数时，程序就会输出 largest element is: 8。\n",
                content: "你好，我是景霄。\n实际工作生活中，我曾见到不少初学者编写的Python程序，他们长达几百行的代码中，却没有一个函数，通通按顺序堆到一块儿，不仅让人读起来费时费力，往往也是错误连连。\n一个规范的值得借鉴的Python程序，除非代码量很少（比如10行、20行以下），基本都应该由多个函数组成，这样的代码才更加模块化、规范化。\n函数是Python程序中不可或缺的一部分。事实上，在前面的学习中，我们已经用到了很多Python的内置函数，比如sorted()表示对一个集合序列排序，len()表示返回一个集合序列的长度大小等等。这节课，我们主要来学习Python的自定义函数。\n函数基础 link那么，到底什么是函数，如何在Python程序中定义函数呢？\n说白了，函数就是为了实现某一功能的代码段，只要写好以后，就可以重复利用。我们先来看下面一个简单的例子:\ndef my_func(message):\rprint('Got a message: {}'.format(message))\r# 调用函数 my_func()\rmy_func('Hello World')\r# 输出\rGot a message: Hello World 其中：\ndef是函数的声明； my_func是函数的名称； 括号里面的message则是函数的参数； 而print那行则是函数的主体部分，可以执行相应的语句； 在函数最后，你可以返回调用结果（return或yield），也可以不返回。 总结一下，大概是下面的这种形式：\ndef name(param1, param2, ..., paramN):\rstatements\rreturn/yield value # optional 和其他需要编译的语言（比如C语言）不一样的是，def是可执行语句，这意味着函数直到被调用前，都是不存在的。当程序调用函数时，def语句才会创建一个新的函数对象，并赋予其名字。\n我们一起来看几个例子，加深你对函数的印象：\ndef my_sum(a, b):\rreturn a + b\rresult = my_sum(3, 5)\rprint(result)\r# 输出\r8 这里，我们定义了my_sum()这个函数，它有两个参数a和b，作用是相加；随后，调用my_sum()函数，分别把3和5赋于a和b；最后，返回其相加的值，赋于变量result，并输出得到8。\n再来看一个例子：\ndef find_largest_element(l):\rif not isinstance(l, list):\rprint('input is not type of list')\rreturn\rif len(l) == 0:\rprint('empty input')\rreturn\rlargest_element = l[0]\rfor item in l:\rif item \u003e largest_element:\rlargest_element = item\rprint('largest element is: {}'.format(largest_element)) find_largest_element([8, 1,-3, 2, 0])\r# 输出\rlargest element is: 8 这个例子中，我们定义了函数find_largest_element，作用是遍历输入的列表，找出最大的值并打印。因此，当我们调用它，并传递列表 [8, 1, -3, 2, 0] 作为参数时，程序就会输出 largest element is: 8。\n需要注意，主程序调用函数时，必须保证这个函数此前已经定义过，不然就会报错，比如：\nmy_func('hello world')\rdef my_func(message):\rprint('Got a message: {}'.format(message))\r# 输出\rNameError: name 'my_func' is not defined 但是，如果我们在函数内部调用其他函数，函数间哪个声明在前、哪个在后就无所谓，因为def是可执行语句，函数在调用之前都不存在，我们只需保证调用时，所需的函数都已经声明定义：\ndef my_func(message):\rmy_sub_func(message) # 调用my_sub_func()在其声明之前不影响程序执行\rdef my_sub_func(message):\rprint('Got a message: {}'.format(message))\rmy_func('hello world')\r# 输出\rGot a message: hello world 另外，Python函数的参数可以设定默认值，比如下面这样的写法：\ndef func(param = 0):\r... 这样，在调用函数func()时，如果参数param没有传入，则参数默认为0；而如果传入了参数param，其就会覆盖默认值。\n前面说过，Python和其他语言相比的一大特点是，Python是dynamically typed的，可以接受任何数据类型（整型，浮点，字符串等等）。对函数参数来说，这一点同样适用。比如还是刚刚的my_sum函数，我们也可以把列表作为参数来传递，表示将两个列表相连接：\nprint(my_sum([1, 2], [3, 4]))\r# 输出\r[1, 2, 3, 4] 同样，也可以把字符串作为参数传递，表示字符串的合并拼接：\nprint(my_sum('hello ', 'world'))\r# 输出\rhello world 当然，如果两个参数的数据类型不同，比如一个是列表、一个是字符串，两者无法相加，那就会报错：\nprint(my_sum([1, 2], 'hello'))\rTypeError: can only concatenate list (not \"str\") to list 我们可以看到，Python不用考虑输入的数据类型，而是将其交给具体的代码去判断执行，同样的一个函数（比如这边的相加函数my_sum()），可以同时应用在整型、列表、字符串等等的操作中。\n在编程语言中，我们把这种行为称为多态。这也是Python和其他语言，比如Java、C等很大的一个不同点。当然，Python这种方便的特性，在实际使用中也会带来诸多问题。因此，必要时请你在开头加上数据的类型检查。\nPython函数的另一大特性，是Python支持函数的嵌套。所谓的函数嵌套，就是指函数里面又有函数，比如：\ndef f1():\rprint('hello')\rdef f2():\rprint('world')\rf2()\rf1()\r# 输出\rhello\rworld 这里函数f1()的内部，又定义了函数f2()。在调用函数f1()时，会先打印字符串'hello'，然后f1()内部再调用f2()，打印字符串'world'。你也许会问，为什么需要函数嵌套？这样做有什么好处呢？\n其实，函数的嵌套，主要有下面两个方面的作用。\n第一，函数的嵌套能够保证内部函数的隐私。内部函数只能被外部函数所调用和访问，不会暴露在全局作用域，因此，如果你的函数内部有一些隐私数据（比如数据库的用户、密码等），不想暴露在外，那你就可以使用函数的的嵌套，将其封装在内部函数中，只通过外部函数来访问。比如：\ndef connect_DB():\rdef get_DB_configuration():\r...\rreturn host, username, password\rconn = connector.connect(get_DB_configuration())\rreturn conn 这里的函数get_DB_configuration，便是内部函数，它无法在connect_DB()函数以外被单独调用。也就是说，下面这样的外部直接调用是错误的：\nget_DB_configuration()\r# 输出\rNameError: name 'get_DB_configuration' is not defined 我们只能通过调用外部函数connect_DB()来访问它，这样一来，程序的安全性便有了很大的提高。\n第二，合理的使用函数嵌套，能够提高程序的运行效率。我们来看下面这个例子：\ndef factorial(input):\r# validation check\rif not isinstance(input, int):\rraise Exception('input must be an integer.')\rif input \u003c 0:\rraise Exception('input must be greater or equal to 0' )\r...\rdef inner_factorial(input):\rif input \u003c= 1:\rreturn 1\rreturn input * inner_factorial(input-1)\rreturn inner_factorial(input)\rprint(factorial(5)) 这里，我们使用递归的方式计算一个数的阶乘。因为在计算之前，需要检查输入是否合法，所以我写成了函数嵌套的形式，这样一来，输入是否合法就只用检查一次。而如果我们不使用函数嵌套，那么每调用一次递归便会检查一次，这是没有必要的，也会降低程序的运行效率。\n实际工作中，如果你遇到相似的情况，输入检查不是很快，还会耗费一定的资源，那么运用函数的嵌套就十分必要了。\n函数变量作用域 linkPython函数中变量的作用域和其他语言类似。如果变量是在函数内部定义的，就称为局部变量，只在函数内部有效。一旦函数执行完毕，局部变量就会被回收，无法访问，比如下面的例子：\ndef read_text_from_file(file_path):\rwith open(file_path) as file:\r... 我们在函数内部定义了file这个变量，这个变量只在read_text_from_file这个函数里有效，在函数外部则无法访问。\n相对应的，全局变量则是定义在整个文件层次上的，比如下面这段代码：\nMIN_VALUE = 1\rMAX_VALUE = 10\rdef validation_check(value):\rif value \u003c MIN_VALUE or value \u003e MAX_VALUE:\rraise Exception('validation check fails') 这里的MIN_VALUE和MAX_VALUE就是全局变量，可以在文件内的任何地方被访问，当然在函数内部也是可以的。不过，我们不能在函数内部随意改变全局变量的值。比如，下面的写法就是错误的：\nMIN_VALUE = 1\rMAX_VALUE = 10\rdef validation_check(value):\r...\rMIN_VALUE += 1\r...\rvalidation_check(5) 如果运行这段代码，程序便会报错：\nUnboundLocalError: local variable 'MIN_VALUE' referenced before assignment 这是因为，Python的解释器会默认函数内部的变量为局部变量，但是又发现局部变量MIN_VALUE并没有声明，因此就无法执行相关操作。所以，如果我们一定要在函数内部改变全局变量的值，就必须加上global这个声明：\nMIN_VALUE = 1\rMAX_VALUE = 10\rdef validation_check(value):\rglobal MIN_VALUE\r...\rMIN_VALUE += 1\r...\rvalidation_check(5) 这里的global关键字，并不表示重新创建了一个全局变量MIN_VALUE，而是告诉Python解释器，函数内部的变量MIN_VALUE，就是之前定义的全局变量，并不是新的全局变量，也不是局部变量。这样，程序就可以在函数内部访问全局变量，并修改它的值了。\n另外，如果遇到函数内部局部变量和全局变量同名的情况，那么在函数内部，局部变量会覆盖全局变量，比如下面这种：\nMIN_VALUE = 1\rMAX_VALUE = 10\rdef validation_check(value):\rMIN_VALUE = 3\r... 在函数validation_check()内部，我们定义了和全局变量同名的局部变量MIN_VALUE，那么，MIN_VALUE在函数内部的值，就应该是3而不是1了。\n类似的，对于嵌套函数来说，内部函数可以访问外部函数定义的变量，但是无法修改，若要修改，必须加上nonlocal这个关键字：\ndef outer():\rx = \"local\"\rdef inner():\rnonlocal x # nonlocal关键字表示这里的x就是外部函数outer定义的变量x\rx = 'nonlocal'\rprint(\"inner:\", x)\rinner()\rprint(\"outer:\", x)\router()\r# 输出\rinner: nonlocal\router: nonlocal 如果不加上nonlocal这个关键字，而内部函数的变量又和外部函数变量同名，那么同样的，内部函数变量会覆盖外部函数的变量。\ndef outer():\rx = \"local\"\rdef inner():\rx = 'nonlocal' # 这里的x是inner这个函数的局部变量\rprint(\"inner:\", x)\rinner()\rprint(\"outer:\", x)\router()\r# 输出\rinner: nonlocal\router: local 闭包 link这节课的第三个重点，我想再来介绍一下闭包（closure）。闭包其实和刚刚讲的嵌套函数类似，不同的是，这里外部函数返回的是一个函数，而不是一个具体的值。返回的函数通常赋于一个变量，这个变量可以在后面被继续执行调用。\n举个例子你就更容易理解了。比如，我们想计算一个数的n次幂，用闭包可以写成下面的代码：\ndef nth_power(exponent):\rdef exponent_of(base):\rreturn base ** exponent\rreturn exponent_of # 返回值是exponent_of函数\rsquare = nth_power(2) # 计算一个数的平方\rcube = nth_power(3) # 计算一个数的立方 square\r# 输出\r"
            }
        );
    index.add(
            {
                id:  19 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/10---%E7%AE%80%E7%BA%A6%E4%B8%8D%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0\/",
                title: "简约不简单的匿名函数",
                description: "你好，我是景霄。\n上一节，我们一起学习了Python中的“常规”函数，用途十分广泛。不过，除了常规函数，你应该也会在代码中见到一些“非常规”函数，它们往往很简短，就一行，并且有个很酷炫的名字——lambda，没错，这就是匿名函数。\n匿名函数在实际工作中同样举足轻重，正确地运用匿名函数，能让我们的代码更简洁、易读。这节课，我们继续Python的函数之旅，一起来学习这个简约而不简单的匿名函数。\n匿名函数基础 link首先，什么是匿名函数呢？以下是匿名函数的格式：\nlambda argument1, argument2,... argumentN : expression 我们可以看到，匿名函数的关键字是lambda，之后是一系列的参数，然后用冒号隔开，最后则是由这些参数组成的表达式。我们通过几个例子看一下它的用法：\nsquare = lambda x: x**2\rsquare(3)\r9 这里的匿名函数只输入一个参数x，输出则是输入x的平方。因此当输入是3时，输出便是9。如果把这个匿名函数写成常规函数的形式，则是下面这样：\ndef square(x):\rreturn x**2\rsquare(3)\r9 可以看到，匿名函数lambda和常规函数一样，返回的都是一个函数对象（function object），它们的用法也极其相似，不过还是有下面几点区别。\n第一，lambda是一个表达式（expression），并不是一个语句（statement）。\n所谓的表达式，就是用一系列“公式”去表达一个东西，比如x + 2、 x**2等等； 而所谓的语句，则一定是完成了某些功能，比如赋值语句x = 1完成了赋值，print语句print(x)完成了打印，条件语句 if x \u003c 0:完成了选择功能等等。 因此，lambda可以用在一些常规函数def不能用的地方，比如，lambda可以用在列表内部，而常规函数却不能：\n[(lambda x: x*x)(x) for x in range(10)]\r# 输出\r[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] 再比如，lambda可以被用作某些函数的参数，而常规函数def也不能：\n",
                content: "你好，我是景霄。\n上一节，我们一起学习了Python中的“常规”函数，用途十分广泛。不过，除了常规函数，你应该也会在代码中见到一些“非常规”函数，它们往往很简短，就一行，并且有个很酷炫的名字——lambda，没错，这就是匿名函数。\n匿名函数在实际工作中同样举足轻重，正确地运用匿名函数，能让我们的代码更简洁、易读。这节课，我们继续Python的函数之旅，一起来学习这个简约而不简单的匿名函数。\n匿名函数基础 link首先，什么是匿名函数呢？以下是匿名函数的格式：\nlambda argument1, argument2,... argumentN : expression 我们可以看到，匿名函数的关键字是lambda，之后是一系列的参数，然后用冒号隔开，最后则是由这些参数组成的表达式。我们通过几个例子看一下它的用法：\nsquare = lambda x: x**2\rsquare(3)\r9 这里的匿名函数只输入一个参数x，输出则是输入x的平方。因此当输入是3时，输出便是9。如果把这个匿名函数写成常规函数的形式，则是下面这样：\ndef square(x):\rreturn x**2\rsquare(3)\r9 可以看到，匿名函数lambda和常规函数一样，返回的都是一个函数对象（function object），它们的用法也极其相似，不过还是有下面几点区别。\n第一，lambda是一个表达式（expression），并不是一个语句（statement）。\n所谓的表达式，就是用一系列“公式”去表达一个东西，比如x + 2、 x**2等等； 而所谓的语句，则一定是完成了某些功能，比如赋值语句x = 1完成了赋值，print语句print(x)完成了打印，条件语句 if x \u003c 0:完成了选择功能等等。 因此，lambda可以用在一些常规函数def不能用的地方，比如，lambda可以用在列表内部，而常规函数却不能：\n[(lambda x: x*x)(x) for x in range(10)]\r# 输出\r[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] 再比如，lambda可以被用作某些函数的参数，而常规函数def也不能：\nl = [(1, 20), (3, 0), (9, 10), (2, -1)]\rl.sort(key=lambda x: x[1]) # 按列表中元组的第二个元素排序\rprint(l)\r# 输出\r[(2, -1), (3, 0), (9, 10), (1, 20)] 常规函数def必须通过其函数名被调用，因此必须首先被定义。但是作为一个表达式的lambda，返回的函数对象就不需要名字了。\n第二，lambda的主体是只有一行的简单表达式，并不能扩展成一个多行的代码块。\n这其实是出于设计的考虑。Python之所以发明lambda，就是为了让它和常规函数各司其职：lambda专注于简单的任务，而常规函数则负责更复杂的多行逻辑。关于这点，Python之父Guido van Rossum曾发了一篇文章解释，你有兴趣的话可以自己阅读。\n为什么要使用匿名函数？ link理论上来说，Python中有匿名函数的地方，都可以被替换成等价的其他表达形式。一个Python程序是可以不用任何匿名函数的。不过，在一些情况下，使用匿名函数lambda，可以帮助我们大大简化代码的复杂度，提高代码的可读性。\n通常，我们用函数的目的无非是这么几点：\n减少代码的重复性； 模块化代码。 对于第一点，如果你的程序在不同地方包含了相同的代码，那么我们就会把这部分相同的代码写成一个函数，并为它取一个名字，方便在相对应的不同地方调用。\n对于第二点，如果你的一块儿代码是为了实现一个功能，但内容非常多，写在一起降低了代码的可读性，那么通常我们也会把这部分代码单独写成一个函数，然后加以调用。\n不过，再试想一下这样的情况。你需要一个函数，但它非常简短，只需要一行就能完成；同时它在程序中只被调用一次而已。那么请问，你还需要像常规函数一样，给它一个定义和名字吗？\n答案当然是否定的。这种情况下，函数就可以是匿名的，你只需要在适当的地方定义并使用，就能让匿名函数发挥作用了。\n举个例子，如果你想对一个列表中的所有元素做平方操作，而这个操作在你的程序中只需要进行一次，用lambda函数可以表示成下面这样：\nsquared = map(lambda x: x**2, [1, 2, 3, 4, 5]) 如果用常规函数，则表示为这几行代码：\ndef square(x):\rreturn x**2\rsquared = map(square, [1, 2, 3, 4, 5]) 这里我简单解释一下。函数map(function, iterable)的第一个参数是函数对象，第二个参数是一个可以遍历的集合，它表示对iterable的每一个元素，都运用function这个函数。两者一对比，我们很明显地发现，lambda函数让代码更加简洁明了。\n再举一个例子，在Python的Tkinter GUI应用中，我们想实现这样一个简单的功能：创建显示一个按钮，每当用户点击时，就打印出一段文字。如果使用lambda函数可以表示成下面这样：\nfrom tkinter import Button, mainloop\rbutton = Button(\rtext='This is a button',\rcommand=lambda: print('being pressed')) # 点击时调用lambda函数\rbutton.pack()\rmainloop() 而如果我们用常规函数def，那么需要写更多的代码：\nfrom tkinter import Button, mainloop\rdef print_message():\rprint('being pressed')\rbutton = Button(\rtext='This is a button',\rcommand=print_message) # 点击时调用lambda函数\rbutton.pack()\rmainloop() 显然，运用匿名函数的代码简洁很多，也更加符合Python的编程习惯。\nPython函数式编程 link最后，我们一起来看一下，Python的函数式编程特性，这与我们今天所讲的匿名函数lambda，有着密切的联系。\n所谓函数式编程，是指代码中每一块都是不可变的（immutable），都由纯函数（pure function）的形式组成。这里的纯函数，是指函数本身相互独立、互不影响，对于相同的输入，总会有相同的输出，没有任何副作用。\n举个很简单的例子，比如对于一个列表，我想让列表中的元素值都变为原来的两倍，我们可以写成下面的形式：\ndef multiply_2(l):\rfor index in range(0, len(l)):\rl[index] *= 2\rreturn l 这段代码就不是一个纯函数的形式，因为列表中元素的值被改变了，如果我多次调用multiply_2()这个函数，那么每次得到的结果都不一样。要想让它成为一个纯函数的形式，就得写成下面这种形式，重新创建一个新的列表并返回。\ndef multiply_2_pure(l):\rnew_list = []\rfor item in l:\rnew_list.append(item * 2)\rreturn new_list 函数式编程的优点，主要在于其纯函数和不可变的特性使程序更加健壮，易于调试（debug）和测试；缺点主要在于限制多，难写。当然，Python不同于一些语言（比如Scala），它并不是一门函数式编程语言，不过，Python也提供了一些函数式编程的特性，值得我们了解和学习。\nPython主要提供了这么几个函数：map()、filter()和reduce()，通常结合匿名函数lambda一起使用。这些都是你需要掌握的东西，接下来我逐一介绍。\n首先是map(function, iterable)函数，前面的例子提到过，它表示，对iterable中的每个元素，都运用function这个函数，最后返回一个新的可遍历的集合。比如刚才列表的例子，要对列表中的每个元素乘以2，那么用map就可以表示为下面这样：\nl = [1, 2, 3, 4, 5]\rnew_list = map(lambda x: x * 2, l) # [2， 4， 6， 8， 10] 我们可以以map()函数为例，看一下Python提供的函数式编程接口的性能。还是同样的列表例子，它还可以用for循环和list comprehension（目前没有统一中文叫法，你也可以直译为列表理解等）实现，我们来比较一下它们的速度：\npython3 -mtimeit -s'xs=range(1000000)' 'map(lambda x: x*2, xs)'\r2000000 loops, best of 5: 171 nsec per loop\rpython3 -mtimeit -s'xs=range(1000000)' '[x * 2 for x in xs]'\r5 loops, best of 5: 62.9 msec per loop\rpython3 -mtimeit -s'xs=range(1000000)' 'l = []' 'for i in xs: l.append(i * 2)'\r5 loops, best of 5: 92.7 msec per loop 你可以看到，map()是最快的。因为map()函数直接由C语言写的，运行时不需要通过Python解释器间接调用，并且内部做了诸多优化，所以运行速度最快。\n接下来来看filter(function, iterable)函数，它和map函数类似，function同样表示一个函数对象。filter()函数表示对iterable中的每个元素，都使用function判断，并返回True或者False，最后将返回True的元素组成一个新的可遍历的集合。\n举个例子，比如我要返回一个列表中的所有偶数，可以写成下面这样：\nl = [1, 2, 3, 4, 5]\rnew_list = filter(lambda x: x % 2 == 0, l) # [2, 4] 最后我们来看reduce(function, iterable)函数，它通常用来对一个集合做一些累积操作。\nfunction同样是一个函数对象，规定它有两个参数，表示对iterable中的每个元素以及上一次调用后的结果，运用function进行计算，所以最后返回的是一个单独的数值。\n举个例子，我想要计算某个列表元素的乘积，就可以用reduce()函数来表示：\nl = [1, 2, 3, 4, 5]\rproduct = reduce(lambda x, y: x * y, l) # 1*2*3*4*5 = 120 当然，类似的，filter()和reduce()的功能，也可以用for循环或者list comprehension来实现。\n通常来说，在我们想对集合中的元素进行一些操作时，如果操作非常简单，比如相加、累积这种，那么我们优先考虑map()、filter()、reduce()这类或者list comprehension的形式。至于这两种方式的选择：\n在数据量非常多的情况下，比如机器学习的应用，那我们一般更倾向于函数式编程的表示，因为效率更高； 在数据量不多的情况下，并且你想要程序更加Pythonic的话，那么list comprehension也不失为一个好选择。 不过，如果你要对集合中的元素，做一些比较复杂的操作，那么，考虑到代码的可读性，我们通常会使用for循环，这样更加清晰明了。\n总结 link这节课，我们一起学习了Python中的匿名函数lambda，它的主要用途是减少代码的复杂度。需要注意的是lambda是一个表达式，并不是一个语句；它只能写成一行的表达形式，语法上并不支持多行。匿名函数通常的使用场景是：程序中需要使用一个函数完成一个简单的功能，并且该函数只调用一次。\n其次，我们也入门了Python的函数式编程，主要了解了常见的map()，fiilter()和reduce()三个函数，并比较了它们与其他形式（for循环，comprehension）的性能，显然，它们的性能效率是最优的。\n思考题 link最后，我想给你留下两道思考题。\n第一问：如果让你对一个字典，根据值进行由高到底的排序，该怎么做呢？以下面这段代码为例，你可以思考一下。\nd = {'mike': 10, 'lucy': 2, 'ben': 30} 第二问：在实际工作学习中，你遇到过哪些使用匿名函数的场景呢？\n欢迎在留言区写下你的答案想法，与我讨论，也欢迎你把这篇文章分享给你的同事、朋友。\n这个地方map生成的是生成器，与后面的2个做比较感觉不大合适，是否更改为测试list(map(lambda x: x*2, xs))更恰当？2019-05-31向南 👍（8） 💬（2）```python sorted(d.items(), key=lambda x: x[1], reverse=True)\nlambda函数在数据清洗的时候，作用很大\n2020-03-07daowuli_chihai 👍（2） 💬（1）下面代码，print(new_list)报错，而改成print(list(new_list))可以输出所有偶数，python3.8版本 和之前版本 不同？\rl = [1, 2, 3, 4, 5]\rnew_list = filter(lambda x: x % 2 == 0, l) # [2, 4]\n2020-06-12Jackson90 👍（2） 💬（1） # 获得排序的元组，字典\rlist_1 = [item for item in ori_dict.items()]\rlist_1.sort(key=lambda val: val[1], reverse=True)\r# 重新生成字典\rdict_1 = {key: value for key, value in list_1}\n2019-10-14谁谁 👍（1） 💬（3）请问老师，如何理解这一句：\r[(lambda x: x*x)(x) for x in range(10)]\r其中的(lambda x: x*x)(x)，这个lambda函数括起来是代表直接调用？\n2019-12-23Kevin 👍（0） 💬（2）第一问：不知道这么写对不对。\rd = {\u0026#39;mike\u0026#39;: 10, \u0026#39;lucy\u0026#39;: 2, \u0026#39;ben\u0026#39;: 30}\rprint(sorted(d, key=lambda x:x[1], reverse=False))\r输出：[\u0026#39;ben\u0026#39;, \u0026#39;mike\u0026#39;, \u0026#39;lucy\u0026#39;]\n2020-06-18Steve 👍（0） 💬（1）喜欢这种讲解方式，能不能再开一个JavaScript的课？\n2020-05-02可乐泡枸杞 👍（0） 💬（1）sorted(d.items(), key= lambda x:-x[1])\n2019-06-01Jove 👍（0） 💬（1）思考题答案：\rd = {\u0026#39;mike\u0026#39;: 10, \u0026#39;lucy\u0026#39;: 2, \u0026#39;ben\u0026#39;: 30}\rsorted(d.items(), key=lambda x:x[1])\n2019-05-31小胖 👍（0） 💬（1）sorted(d.items(), key=lambda x :x[1], reverse=True)\n2019-05-31小胖 👍（0） 💬（1）sorted(d.items(), key=lambda x :x[1])\n2019-05-31程序员人生 👍（0） 💬（1）1,\rimport operator\rprint(sorted(d.items(),key=lambda x:x[1],reverse=True))\rprint(sorted(d.items(),key=operator.itemgetter(1),reverse=True))\r2,\r我不是python程序员，所以没有什么工作中例子。：P\r2019-05-31方向 👍（0） 💬（1）list comprehension不是叫列表生成式吗\n2019-05-31lmingzhi 👍（0） 💬（1）工作中常用到lambda的地方是在pandas的数据列批量处理，一般也是和map结合使用。\rIn [4]: import pandas as pd In [5]: obj=pd.Series(range(10)) In [6]: obj.map(lambda x: x*x) Out[6]: 0 0\r1 1\r2 4\r3 9\r4 16\r5 25\r6 36\r7 49\r8 64\r9 81\rdtype: int64\n2019-05-31\r"
            }
        );
    index.add(
            {
                id:  20 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/11---%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8A%E4%BB%8E%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%AF%94%E8%AF%B4%E8%B5%B7\/",
                title: "面向对象（上）：从生活中的类比说起",
                description: "你好，我是景霄。\n很多朋友最开始学编程的时候，是从 C++ 或者 JAVA 语言入手的。他们好不容易磕磕绊绊地搞懂了最基本的数据类型、赋值判断和循环，却又迎面撞上了 OOP (object oriented programming) 的大墙，一头扎进公有私有保护、多重继承、多态派生、纯函数、抽象类、友元函数等一堆专有名词的汪洋大海中找不到彼岸，于是就放弃了进阶之路。\n相比之下，Python 是一门相对友好的语言，它在创立之初就鼓励命令交互式的轻量级编程。理论上，Python 的命令式语言是图灵完备的, 也就是说命令式语言，理论上可以做到其他任何语言能够做到的所有的事情，甚至进一步，仅仅依靠汇编语言的 MOV 指令，就能实现图灵完备编程。\n",
                content: "你好，我是景霄。\n很多朋友最开始学编程的时候，是从 C++ 或者 JAVA 语言入手的。他们好不容易磕磕绊绊地搞懂了最基本的数据类型、赋值判断和循环，却又迎面撞上了 OOP (object oriented programming) 的大墙，一头扎进公有私有保护、多重继承、多态派生、纯函数、抽象类、友元函数等一堆专有名词的汪洋大海中找不到彼岸，于是就放弃了进阶之路。\n相比之下，Python 是一门相对友好的语言，它在创立之初就鼓励命令交互式的轻量级编程。理论上，Python 的命令式语言是图灵完备的, 也就是说命令式语言，理论上可以做到其他任何语言能够做到的所有的事情，甚至进一步，仅仅依靠汇编语言的 MOV 指令，就能实现图灵完备编程。\n那么为什么不这样做呢？其实，“上古时代”的程序员就是这么做的，可是随着程序功能复杂性的逐步提升，以及需求的不断迭代，很多老旧的代码修改起来麻烦无比，牵一发而动全身，根本无法迭代和维护，甚至只能推倒重来，这也是很多古老的代码被称为“屎山”的原因。\n传统的命令式语言有无数重复性代码，虽然函数的诞生减缓了许多重复性，但随着计算机的发展，只有函数依然不够，需要把更加抽象的概念引入计算机才能缓解（而不是解决）这个问题，于是 OOP 应运而生。\nPython 在 1989 年被一位程序员打发时间创立之后，一步步攻城掠地飞速发展，从最基础的脚本程序，到后来可以编写系统程序、大型工程、数据科学运算、人工智能，早已脱离了当初的设计，因此一些其他语言的优秀设计之处依然需要引入。我们必须花费一定的代价掌握面向对象编程，才能跨越学习道路中的瓶颈期，走向下一步。\n接下来，我将用两节课来讲解面向对象编程，从基础到实战。第一讲，我将带你快速但清晰地疏通最基础的知识，确保你能够迅速领略面向对象的基本思想；第二讲，我们从零开始写一个搜索引擎，将前面所学知识融会贯通。\n这些内容可能和你以往看到的所有教程都不太一样，我会尽可能从一个初学者的角度来审视这些难点。同时我们面向实战、面向工程，不求大而全，但是对最核心的思想会有足够的勾勒。我可以保证内容清晰易懂，但想要真正掌握，仍要求你能用心去阅读和思考。真正的提高，永远要靠自己才能做到。\n对象，你找到了吗？ link我们先来学习，面向对象编程中最基本的概念。\n为了方便你理解其中的抽象概念，我先打个比方带你感受一下。生物课上，我们学过“界门纲目科属种”的概念，核心思想是科学家们根据各种动植物、微生物的相似之处，将其分化为不同的类型方便研究。生活中我们也是如此，习惯对身边的事物进行分类：\n猫和狗都是动物； 直线和圆都是平面几何的图形； 《哈利波特》和《冰与火之歌》（即《权力的游戏》）都是小说。 自然，同一类事物便会有着相似的特性：\n动物会动； 平面图形有面积和周长； 小说也都有相应的作者和大致情节等各种元素。 那回到我们的Python上，又对应哪些内容呢？这里，我们先来看一段最基本的 Python 面向对象的应用代码，不要被它的长度吓到，你无需立刻看懂所有代码，跟着节奏来，我会一点点为你剖析。\nclass Document():\rdef __init__(self, title, author, context):\rprint('init function called')\rself.title = title\rself.author = author\rself.__context = context # __开头的属性是私有属性\rdef get_context_length(self):\rreturn len(self.__context)\rdef intercept_context(self, length):\rself.__context = self.__context[:length]\rharry_potter_book = Document('Harry Potter', 'J. K. Rowling', '... Forever Do not believe any thing is capable of thinking independently ...')\rprint(harry_potter_book.title)\rprint(harry_potter_book.author)\rprint(harry_potter_book.get_context_length())\rharry_potter_book.intercept_context(10)\rprint(harry_potter_book.get_context_length())\rprint(harry_potter_book.__context)\r########## 输出 ##########\rinit function called\rHarry Potter\rJ. K. Rowling\r77\r10\r---------------------------------------------------------------------------\rAttributeError Traceback (most recent call last)\rin ()\r22 print(harry_potter_book.get_context_length())\r23 ---\u003e 24 print(harry_potter_book.__context)\rAttributeError: 'Document' object has no attribute '__context' 参照着这段代码，我先来简单解释几个概念。\n类：一群有着相似性的事物的集合，这里对应 Python 的 class。 对象：集合中的一个事物，这里对应由 class 生成的某一个 object，比如代码中的 harry_potter_book。 属性：对象的某个静态特征，比如上述代码中的 title、author 和 __context。 函数：对象的某个动态能力，比如上述代码中的 intercept_context ()函数。 当然，这样的说法既不严谨，也不充分，但如果你对面向对象编程完全不了解，它们可以让你迅速有一个直观的了解。\n这里我想多说两句。回想起当年参加数学竞赛时，我曾和一个大佬交流数学的学习，我清楚记得我们对数学有着相似的观点：很多数学概念非常抽象，如果纯粹从数理逻辑而不是更高的角度去解题，很容易陷入僵局；而具体、直观的想象和类比，才是迅速打开数学大门的钥匙。虽然这些想象和类比不严谨也不充分，很多时候甚至是错误或者异想天开的，但它们确实能帮我们快速找到正确的大门。\n就像很多人都有过的一个疑惑，“学霸是怎样想到这个答案的？”。德国数学家克莱因曾说过，“推进数学的，主要是那些有卓越直觉的人，而不是以严格的证明方法见长的人。”编程世界同样如此，如果你不满足于只做一个CRUD“码农”，而是想成为一个优秀的工程师，那就一定要积极锻炼直觉思考和快速类比的能力，尤其是在找不到 bug 的时候。这才是编程学习中能给人最快进步的方法和路径。\n言归正传，继续回到我们的主题，还是通过刚刚那段代码，我想再给类下一个更为严谨的定义。\n类，一群有着相同属性和函数的对象的集合。\n虽然有循环论证之嫌（lol），但是反复强调，还是希望你能对面向对象的最基础的思想，有更真实的了解。清楚记住这一点后，接下来，我们来具体解读刚刚这段代码。为了方便你的阅读学习，我把它重新放在了这段文字下方。\nclass Document():\rdef __init__(self, title, author, context):\rprint('init function called')\rself.title = title\rself.author = author\rself.__context = context # __开头的属性是私有属性\rdef get_context_length(self):\rreturn len(self.__context)\rdef intercept_context(self, length):\rself.__context = self.__context[:length]\rharry_potter_book = Document('Harry Potter', 'J. K. Rowling', '... Forever Do not believe any thing is capable of thinking independently ...')\rprint(harry_potter_book.title)\rprint(harry_potter_book.author)\rprint(harry_potter_book.get_context_length())\rharry_potter_book.intercept_context(10)\rprint(harry_potter_book.get_context_length())\rprint(harry_potter_book.__context)\r########## 输出 ##########\rinit function called\rHarry Potter\rJ. K. Rowling\r77\r10\r---------------------------------------------------------------------------\rAttributeError Traceback (most recent call last)\rin ()\r22 print(harry_potter_book.get_context_length())\r23 ---\u003e 24 print(harry_potter_book.__context)\rAttributeError: 'Document' object has no attribute '__context' 可以看到，class Document 定义了 Document 类，再往下能看到它有三个函数，这三个函数即为 Document 类的三个函数。\n其中，init 表示构造函数，意即一个对象生成时会被自动调用的函数。我们能看到， harry_potter_book = Document(...)这一行代码被执行的时候，'init function called'字符串会被打印出来。而 get_context_length()和 intercept_context()则为类的普通函数，我们调用它们来对对象的属性做一些事情。\nclass Document 还有三个属性，title、author和 __context 分别表示标题、作者和内容，通过构造函数传入。这里代码很直观，我们可以看到， intercept_context 能修改对象 harry_potter_book 的 __context 属性。\n这里唯一需要强调的一点是，如果一个属性以 __ （注意，此处有两个_） 开头，我们就默认这个属性是私有属性。私有属性，是指不希望在类的函数之外的地方被访问和修改的属性。所以，你可以看到，title 和 author 能够很自由地被打印出来，但是 print(harry_potter_book.__context)就会报错。\n老师，能不能再给力点？ link掌握了最基础的概念，其实我们已经能做很多很多的事情了。不过，在工程实践中，随着复杂度继续提升，你可能会想到一些问题：\n如何在一个类中定义一些常量，每个对象都可以方便访问这些常量而不用重新构造？ 如果一个函数不涉及到访问修改这个类的属性，而放到类外面有点不恰当，怎么做才能更优雅呢？ 既然类是一群相似的对象的集合，那么可不可以是一群相似的类的集合呢？ 前两个问题很好解决，不过，它们涉及到一些常用的代码规范，这里我放了一段代码示例。同样的，你无需一口气读完这段代码，跟着我的节奏慢慢学习即可。\nclass Document():\rWELCOME_STR = 'Welcome! The context for this book is {}.'\rdef __init__(self, title, author, context):\rprint('init function called')\rself.title = title\rself.author = author\rself.__context = context\r# 类函数\r@classmethod\rdef create_empty_book(cls, title, author):\rreturn cls(title=title, author=author, context='nothing')\r# 成员函数\rdef get_context_length(self):\rreturn len(self.__context)\r# 静态函数\r@staticmethod\rdef get_welcome(context):\rreturn Document.WELCOME_STR.format(context)\rempty_book = Document.create_empty_book('What Every Man Thinks About Apart from Sex', 'Professor Sheridan Simove')\rprint(empty_book.get_context_length())\rprint(empty_book.get_welcome('indeed nothing'))\r########## 输出 ##########\rinit function called\r7\rWelcome! The context for this book is indeed nothing. 第一个问题，在 Python 的类里，你只需要和函数并列地声明并赋值，就可以实现这一点，例如这段代码中的 WELCOME_STR。一种很常规的做法，是用全大写来表示常量，因此我们可以在类中使用 self.WELCOME_STR ，或者在类外使用 Entity.WELCOME_STR ，来表达这个字符串。\n而针对第二个问题，我们提出了类函数、成员函数和静态函数三个概念。它们其实很好理解，前两者产生的影响是动态的，能够访问或者修改对象的属性；而静态函数则与类没有什么关联，最明显的特征便是，静态函数的第一个参数没有任何特殊性。\n具体来看这几种函数。一般而言，静态函数可以用来做一些简单独立的任务，既方便测试，也能优化代码结构。静态函数还可以通过在函数前一行加上 @staticmethod 来表示，代码中也有相应的示例。这其实使用了装饰器的概念，我们会在后面的章节中详细讲解。\n而类函数的第一个参数一般为 cls，表示必须传一个类进来。类函数最常用的功能是实现不同的 init 构造函数，比如上文代码中，我们使用 create_empty_book 类函数，来创造新的书籍对象，其 context 一定为 'nothing'。这样的代码，就比你直接构造要清晰一些。类似的，类函数需要装饰器 @classmethod 来声明。\n成员函数则是我们最正常的类的函数，它不需要任何装饰器声明，第一个参数 self 代表当前对象的引用，可以通过此函数，来实现想要的查询/修改类的属性等功能。\n继承，是每个富二代的梦想 link接下来，我们来看第三个问题，既然类是一群相似的对象的集合，那么可不可以是一群相似的类的集合呢？\n答案是，当然可以。只要抽象得好，类可以描述成任何事物的集合。当然你要小心、严谨地去定义它，不然一不小心就会引起第三次数学危机 XD。\n类的继承，顾名思义，指的是一个类既拥有另一个类的特征，也拥有不同于另一个类的独特特征。在这里的第一个类叫做子类，另一个叫做父类，特征其实就是类的属性和函数。\nclass Entity():\rdef __init__(self, object_type):\rprint('parent class init called')\rself.object_type = object_type\rdef get_context_length(self):\rraise Exception('get_context_length not implemented')\rdef print_title(self):\rprint(self.title)\rclass Document(Entity):\rdef __init__(self, title, author, context):\rprint('Document class init called')\rEntity.__init__(self, 'document')\rself.title = title\rself.author = author\rself.__context = context\rdef get_context_length(self):\rreturn len(self.__context)\rclass Video(Entity):\rdef __init__(self, title, author, video_length):\rprint('Video class init called')\rEntity.__init__(self, 'video')\rself.title = title\rself.author = author\rself.__video_length = video_length\rdef get_context_length(self):\rreturn self.__video_length\rharry_potter_book = Document('Harry Potter(Book)', 'J. K. Rowling', '... Forever Do not believe any thing is capable of thinking independently ...')\rharry_potter_movie = Video('Harry Potter(Movie)', 'J. K. Rowling', 120)\rprint(harry_potter_book.object_type)\rprint(harry_potter_movie.object_type)\rharry_potter_book.print_title()\rharry_potter_movie.print_title()\rprint(harry_potter_book.get_context_length())\rprint(harry_potter_movie.get_context_length())\r########## 输出 ##########\rDocument class init called\rparent class init called\rVideo class init called\rparent class init called\rdocument\rvideo\rHarry Potter(Book)\rHarry Potter(Movie)\r77\r120 我们同样结合代码来学习这些概念。在这段代码中，Document 和 Video 它们有相似的地方，都有相应的标题、作者和内容等属性。我们可以从中抽象出一个叫做 Entity 的类，来作为它俩的父类。\n首先需要注意的是构造函数。每个类都有构造函数，继承类在生成对象的时候，是不会自动调用父类的构造函数的，因此你必须在 init()函数中显式调用父类的构造函数。它们的执行顺序是 子类的构造函数 -\u003e 父类的构造函数。\n其次需要注意父类 get_context_length()函数。如果使用 Entity 直接生成对象，调用 get_context_length()函数，就会 raise error 中断程序的执行。这其实是一种很好的写法，叫做函数重写，可以使子类必须重新写一遍 get_context_length()函数，来覆盖掉原有函数。\n最后需要注意到 print_title()函数，这个函数定义在父类中，但是子类的对象可以毫无阻力地使用它来打印 title，这也就体现了继承的优势：减少重复的代码，降低系统的熵值（即复杂度）。\n到这里，你对继承就有了比较详细的了解了，面向对象编程也可以说已经入门了。当然，如果你想达到更高的层次，大量练习编程，学习更多的细节知识，都是必不可少的。\n最后，我想再为你扩展一下抽象函数和抽象类，我同样会用一段代码来辅助讲解。\nfrom abc import ABCMeta, abstractmethod\rclass Entity(metaclass=ABCMeta):\r@abstractmethod\rdef get_title(self):\rpass\r@abstractmethod\rdef set_title(self, title):\rpass\rclass Document(Entity):\rdef get_title(self):\rreturn self.title\rdef set_title(self, title):\rself.title = title\rdocument = Document()\rdocument.set_title('Harry Potter')\rprint(document.get_title())\rentity = Entity()\r########## 输出 ##########\rHarry Potter\r---------------------------------------------------------------------------\rTypeError Traceback (most recent call last)\rin ()\r21 print(document.get_title())\r22 ---\u003e 23 entity = Entity()\r24 entity.set_title('Test')\rTypeError: Can't instantiate abstract class Entity with abstract methods get_title, set_title 你应该发现了，Entity 本身是没有什么用的，只需拿来定义 Document 和 Video 的一些基本元素就够了。不过，万一你不小心生成 Entity 的对象该怎么办呢？为了防止这样的手误，必须要介绍一下抽象类。\n抽象类是一种特殊的类，它生下来就是作为父类存在的，一旦对象化就会报错。同样，抽象函数定义在抽象类之中，子类必须重写该函数才能使用。相应的抽象函数，则是使用装饰器 @abstractmethod 来表示。\n我们可以看到，代码中entity = Entity()直接报错，只有通过 Document 继承 Entity 才能正常使用。\n这其实正是软件工程中一个很重要的概念，定义接口。大型工程往往需要很多人合作开发，比如在 Facebook 中，在 idea 提出之后，开发组和产品组首先会召开产品设计会，PM（Product Manager，产品经理） 写出产品需求文档，然后迭代；TL（Team Leader，项目经理）编写开发文档，开发文档中会定义不同模块的大致功能和接口、每个模块之间如何协作、单元测试和集成测试、线上灰度测试、监测和日志等等一系列开发流程。\n抽象类就是这么一种存在，它是一种自上而下的设计风范，你只需要用少量的代码描述清楚要做的事情，定义好接口，然后就可以交给不同开发人员去开发和对接。\n总结 link到目前为止，我们一直在强调一件事情：面向对象编程是软件工程中重要的思想。正如动态规划是算法中的重要思想一样，它不是某一种非常具体的技术，而是一种综合能力的体现，是将大型工程解耦化、模块化的重要方法。在实践中要多想，尤其是抽象地想，才能更快掌握这个技巧。\n回顾一下今天的内容，我希望你能自己回答下面两个问题，作为今天内容的总结，写在留言区里。\n第一个问题，面向对象编程四要素是什么？它们的关系又是什么？\n第二个问题，讲了这么久的继承，继承究竟是什么呢？你能用三个字表达出来吗？\n这里不开玩笑，Facebook 很多 Launch Doc （上线文档）中要求用五个单词总结你的文档，因为你的文档不仅仅是你的团队要看，往上走甚至会到 VP 或者 CTO 那里，你需要言简意赅，让他们快速理解你想要表达的意思。\n思考题 link最后，再给你留一道思考题。既然你能通过继承一个类，来获得父类的函数和属性，那么你能继承两个吗？答案自是能的，这就叫做多重继承。那么问题来了。\n我们使用单一继承的时候，构造函数的执行顺序很好确定，即子类-\u003e父类-\u003e爷类-\u003e… 的链式关系。不过，多重继承的时候呢？比如下面这个例子。\n---\u003eB---\rA- --\u003eD\r---\u003eC--- 这种继承方式，叫做菱形继承，BC 继承了 A，然后 D 继承了 BC，创造一个 D 的对象。那么，构造函数调用顺序又是怎样的呢？\n欢迎在留言区写下你的答案想法，与我讨论，也欢迎你把这篇文章分享给你的同事、朋友。\nclass A(): def init(self): print('enter A') print('leave A')\nclass B(A): def init(self): print('enter B') super().init() print('leave B')\nclass C(A): def init(self): print('enter C') super().init() print('leave C')\nclass D(B, C): def init(self): print('enter D') super().init() print('leave D')\nD()\nenter D enter B enter C enter A leave A leave C leave B leave D2019-06-04爬行的蜗牛 👍（34） 💬（2）1. 面向对象编程的四要素是什么， 它们的关系是什么\n抽象 封装 继承 多态 个人理解： -抽象的本质是抽取不同类的的相同方法（函数）和属性， 作为父类的属性和方法； 封装就是把功能封装抽象的方法和其他属性和方法； 子类继承父类的抽象出来的属性和方法； 多态就是重写抽象的方法（函数）。 继承是什么？ 用三个字表示出来； 子类继承父类的属性和方法（函数）减少代码量和复杂度； 三个字：承接：属性\u0026函数2019-06-07奔跑的蜗牛 👍（30） 💬（3）经典类：深度优先，F-\u003eD-\u003eB-\u003eA-\u003eE-\u003eC-\u003eH 新式类：广度优先，F-\u003eD-\u003eB-\u003eE-\u003eC-\u003eH-\u003eA class A: # def test(self): # print('from A') pass class B(A): # def test(self): # print('from B') pass class C(A): # def test(self): # print('from C') pass\nclass D(B): # def test(self): # print('from D') pass\nclass E(C): # def test(self): # print('from E') pass\nclass H(A): def test(self): print('from H') pass class F(D,E,H): # def test(self): # print('from F') pass f=F() f.test() print(F.mro())2019-06-03enjoylearning 👍（9） 💬（1）写的真好，立马搞清楚了Python中的面向对象和抽象类，昨天还在看abcmeta怎么用，另外我觉得最佳实践里不提倡多重继承，感觉这样是代码坏味道2019-06-03单色 👍（7） 💬（1）问题1： 封装，继承，多态，抽象 封装使得代码更加模块化，代码复用度更高 继承使得子类不仅拥有自己的属性和方法，还能使用父类的属性和方法 多态可以实现函数重写，使得相同方法具有不同功能 抽象不同子类的相同方法和属性形成父类，在通过继承，多态，封装使得代码更加紧凑，简洁易读 问题2： 父与子\n思考题： 旧式类（经典类）：深度优先 新式类：广度优先2020-03-26Paul Shan 👍（6） 💬（1）类是对象的集合 问题1 面向对象四要素是，封装，抽象，继承，多态。封装是区分类内和类外的信息。抽象是区分接口和实现的信息，继承是一个类拓展其他类。多态是，一个接口多个实现。封装是基础。抽象和多态有赖于继承实现。\n问题2 继承 – 类生子\n思考题 多重继承，同一个超类会被构建多次。2019-11-14自主 👍（4） 💬（1）老师:我一直有个疑问，我查了一些答案讲得都不是很清楚，我想知道类中self参数的设计思想是什么？2019-11-26Lone 👍（3） 💬（1）文中的重载是不是都应该改为重写2019-06-03GentleCP 👍（2） 💬（1）老师，对于类函数还是不太懂，一般在什么情况下才需要对类函数进行定义呢2019-06-03卢三 👍（1） 💬（2）写代码用什么IDE呢，jupyter没有代码补全啊2019-09-04hlz-123 👍（149） 💬（1）第一个问题，面向对象编程四要素是什么？它们的关系又是什么？ 答：面向对象编程四要素是类，属性，函数，对象， 它们关系可以总结为：类是一群具有相同属性和函数的对象的集合。 第二个问题，讲了这么久的继承，继承究竟是什么呢？你能用三个字表达出来吗？ 三个字：父与子。儿子可以使用自己的东西，没有的可以使用父亲的东西。2019-06-03庄小P 👍（68） 💬（0）class A(): def init(self): print('A class called')\nclass B(A): def init(self): print('B class called') A.init(self) class C(A): def init(self): print('C class called') A.init(self) class D(B,C): def init(self): print('D class called') B.init(self) C.init(self) d = D() ####输出 D class called B class called A class called C class called A class called2019-06-03helloworld 👍（56） 💬（5）面向对象编程的四要素： 类、属性、函数（方法）、对象（实例）\n下面来展开总结：\n类： 一群有着相同属性和函数(方法)的对象(实例)的集合，也可以具象化的理解为是一群有着相似特征的事物的集合；用class来声明。 抽象类：是一种特殊的类，只能作为父类存在，一旦对象化（或叫实例化）就会报错；一般使用class Classname(metaclass=ABCMeta)来声明。 类的继承：子类继承父类，子类可以使用父类的属性和函数，同时子类可以有自己独特的属性和函数；子类在生成对象的时候（实例化时），是不会自动调用父类的构造函数的，必须在子类的构造函数中显示的调用父类的构造函数；继承的优势是减少重复代码，降低系统熵值（即复杂度）。\n属性：用\"self.属性名\"来表示，通过构造函数传入；表示对象(实例)的某个静态特征。 私有属性：以__开头的属性，举例：self.__属性名，只能在类内部调用，类外部无法访问。 公有属性：和函数并列声明的属性，可以理解为常量，一般用全大写表示；在类中通过\"self.常量名\"来调用，在类外使用\"对象名.常量名\"或者\"类名.常量名\"来调用。\n函数：表示对象(实例)的某个动态能力。 构造函数：用def init（self, args…）声明，第一个参数self代表当前对象的引用，其他参数是在对象化时需要传入的属性值；构造函数在一个对象生成时(即实例化时)会被自动调用。 成员函数：是正常的类的函数，第一个参数必须是self；可通过此函数来实现查询或修改类的属性等功能。 静态函数：静态函数和类没有什么关联，第一个参数也没有什么特殊性；一般用来做一些简单独立的任务，既方便测试也能优化代码结构；一般使用装饰器@staticmethod来声明。 类函数：类函数的第一个参数一般为cls，表示必须传一个类进来；最常用的功能是实现不同的init构造函数；需要装饰器@classmethod来声明。 抽象函数：一般定义在抽象类中，主要目的是要求子类必须重载该函数才能正常使用；使用装饰器@abstractmethod来声明。 函数重载：父类的某函数通过raise Exception的方式要求子类必须重写该函数来覆盖父类原有函数。\n对象：类对象化(实例化)后的某一个具体事物。2019-06-04古明地觉 👍（40） 💬（0）思考题：多重继承，是基于mro进行查找，使用的是一种C3的算法。总结一下规律就是： B F\nC G\nD H\nE I\nJ 在python3中，如果最顶层的两个类没有继承共同的类，那么查找顺序是，先从左找到头，再从右找到头，即，J-\u003eE-\u003eD-\u003eC-\u003eB-\u003eI-\u003eH-\u003eG-\u003eF\nA B F\nC G\nD H\nE I\nJ\n如果继承了共同的类，也就是形成了菱形结构，那么查找顺序为，先从左找，只找到倒数第二层，然后从右找到头，即J-\u003eE-\u003eD-\u003eC-\u003eB-\u003eI-\u003eH-\u003eG-\u003eF-\u003eA2019-06-03LiANGZE 👍（16） 💬（0）只知道多重继承时会通过mro算法生成一个顺序，可以通过 xxx.mro 查看继承的顺序，但其中原理确实没深入研究过 🤔2019-06-03\n"
            }
        );
    index.add(
            {
                id:  21 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/12---%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E\/",
                title: "面向对象（下）：如何实现一个搜索引擎？",
                description: "你好，我是景霄。这节课，我们来实现一个 Python 的搜索引擎（search engine）。\n承接上文，今天这节课的主要目的是，带你模拟敏捷开发过程中的迭代开发流程，巩固面向对象的程序设计思想。\n我们将从最简单最直接的搜索做起，一步步优化，这其中，我不会涉及到过多的超纲算法，但不可避免会介绍一些现代搜索引擎中的基础概念，例如语料（corpus）、倒序索引（inverted index）等。\n如果你对这方面本身有些了解，自然可以轻松理解；即使你之前完全没接触过搜索引擎，也不用过分担心，我会力求简洁清晰，降低学习难度。同时，我希望你把更多的精力放在面向对象的建模思路上。\n“高大上”的搜索引擎 link引擎一词尤如其名，听起来非常酷炫。搜索引擎，则是新世纪初期互联网发展最重要的入口之一，依托搜索引擎，中国和美国分别诞生了百度、谷歌等巨型公司。\n搜索引擎极大地方便了互联网生活，也成为上网必不可少的刚需工具。依托搜索引擎发展起来的互联网广告，则成了硅谷和中国巨头的核心商业模式；而搜索本身，也在持续进步着， Facebook 和微信也一直有意向在自家社交产品架设搜索平台。\n关于搜索引擎的价值我不必多说了，今天我们主要来看一下搜索引擎的核心构成。\n听Google的朋友说，他们入职培训的时候，有一门课程叫做 The life of a query，内容是讲用户在浏览器中键入一串文字，按下回车后发生了什么。今天我也按照这个思路，来简单介绍下。\n我们知道，一个搜索引擎由搜索器、索引器、检索器和用户接口四个部分组成。\n搜索器，通俗来讲就是我们常提到的爬虫（scrawler），它能在互联网上大量爬取各类网站的内容，送给索引器。索引器拿到网页和内容后，会对内容进行处理，形成索引（index），存储于内部的数据库等待检索。\n最后的用户接口很好理解，是指网页和 App 前端界面，例如百度和谷歌的搜索页面。用户通过用户接口，向搜索引擎发出询问（query），询问解析后送达检索器；检索器高效检索后，再将结果返回给用户。\n爬虫知识不是我们今天学习的重点，这里我就不做深入介绍了。我们假设搜索样本存在于本地磁盘上。\n为了方便，我们只提供五个文件的检索，内容我放在了下面这段代码中：\n# 1.txt\rI have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. I have a dream today.\r# 2.txt\rI have a dream that one day down in Alabama, with its vicious racists, . . . one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers. I have a dream today.\r# 3.txt\rI have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed, and all flesh shall see it together.\r# 4.txt\rThis is our hope. . . With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day. . . .\r# 5.txt\rAnd when this happens, and when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual: \"Free at last! Free at last! Thank God Almighty, we are free at last!\" 我们先来定义 SearchEngineBase 基类。这里我先给出了具体的代码，你不必着急操作，还是那句话，跟着节奏慢慢学，再难的东西也可以啃得下来。\n",
                content: "你好，我是景霄。这节课，我们来实现一个 Python 的搜索引擎（search engine）。\n承接上文，今天这节课的主要目的是，带你模拟敏捷开发过程中的迭代开发流程，巩固面向对象的程序设计思想。\n我们将从最简单最直接的搜索做起，一步步优化，这其中，我不会涉及到过多的超纲算法，但不可避免会介绍一些现代搜索引擎中的基础概念，例如语料（corpus）、倒序索引（inverted index）等。\n如果你对这方面本身有些了解，自然可以轻松理解；即使你之前完全没接触过搜索引擎，也不用过分担心，我会力求简洁清晰，降低学习难度。同时，我希望你把更多的精力放在面向对象的建模思路上。\n“高大上”的搜索引擎 link引擎一词尤如其名，听起来非常酷炫。搜索引擎，则是新世纪初期互联网发展最重要的入口之一，依托搜索引擎，中国和美国分别诞生了百度、谷歌等巨型公司。\n搜索引擎极大地方便了互联网生活，也成为上网必不可少的刚需工具。依托搜索引擎发展起来的互联网广告，则成了硅谷和中国巨头的核心商业模式；而搜索本身，也在持续进步着， Facebook 和微信也一直有意向在自家社交产品架设搜索平台。\n关于搜索引擎的价值我不必多说了，今天我们主要来看一下搜索引擎的核心构成。\n听Google的朋友说，他们入职培训的时候，有一门课程叫做 The life of a query，内容是讲用户在浏览器中键入一串文字，按下回车后发生了什么。今天我也按照这个思路，来简单介绍下。\n我们知道，一个搜索引擎由搜索器、索引器、检索器和用户接口四个部分组成。\n搜索器，通俗来讲就是我们常提到的爬虫（scrawler），它能在互联网上大量爬取各类网站的内容，送给索引器。索引器拿到网页和内容后，会对内容进行处理，形成索引（index），存储于内部的数据库等待检索。\n最后的用户接口很好理解，是指网页和 App 前端界面，例如百度和谷歌的搜索页面。用户通过用户接口，向搜索引擎发出询问（query），询问解析后送达检索器；检索器高效检索后，再将结果返回给用户。\n爬虫知识不是我们今天学习的重点，这里我就不做深入介绍了。我们假设搜索样本存在于本地磁盘上。\n为了方便，我们只提供五个文件的检索，内容我放在了下面这段代码中：\n# 1.txt\rI have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. I have a dream today.\r# 2.txt\rI have a dream that one day down in Alabama, with its vicious racists, . . . one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers. I have a dream today.\r# 3.txt\rI have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed, and all flesh shall see it together.\r# 4.txt\rThis is our hope. . . With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day. . . .\r# 5.txt\rAnd when this happens, and when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual: \"Free at last! Free at last! Thank God Almighty, we are free at last!\" 我们先来定义 SearchEngineBase 基类。这里我先给出了具体的代码，你不必着急操作，还是那句话，跟着节奏慢慢学，再难的东西也可以啃得下来。\nclass SearchEngineBase(object):\rdef __init__(self):\rpass\rdef add_corpus(self, file_path):\rwith open(file_path, 'r') as fin:\rtext = fin.read()\rself.process_corpus(file_path, text)\rdef process_corpus(self, id, text):\rraise Exception('process_corpus not implemented.')\rdef search(self, query):\rraise Exception('search not implemented.')\rdef main(search_engine):\rfor file_path in ['1.txt', '2.txt', '3.txt', '4.txt', '5.txt']:\rsearch_engine.add_corpus(file_path)\rwhile True:\rquery = input()\rresults = search_engine.search(query)\rprint('found {} result(s):'.format(len(results)))\rfor result in results:\rprint(result) SearchEngineBase 可以被继承，继承的类分别代表不同的算法引擎。每一个引擎都应该实现 process_corpus()和search()两个函数，对应我们刚刚提到的索引器和检索器。main()函数提供搜索器和用户接口，于是一个简单的包装界面就有了。\n具体来看这段代码，其中，\nadd_corpus() 函数负责读取文件内容，将文件路径作为 ID，连同内容一起送到 process_corpus 中。 process_corpus 需要对内容进行处理，然后文件路径为 ID ，将处理后的内容存下来。处理后的内容，就叫做索引（index）。 search 则给定一个询问，处理询问，再通过索引检索，然后返回。 好，理解这些概念后，接下来，我们实现一个最基本的可以工作的搜索引擎，代码如下：\nclass SimpleEngine(SearchEngineBase):\rdef __init__(self):\rsuper(SimpleEngine, self).__init__()\rself.__id_to_texts = {}\rdef process_corpus(self, id, text):\rself.__id_to_texts[id] = text\rdef search(self, query):\rresults = []\rfor id, text in self.__id_to_texts.items():\rif query in text:\rresults.append(id)\rreturn results\rsearch_engine = SimpleEngine()\rmain(search_engine)\r########## 输出 ##########\rsimple\rfound 0 result(s):\rlittle\rfound 2 result(s):\r1.txt\r2.txt 你可能很惊讶，只需要短短十来行代码居然就可以了吗？\n没错，正是如此，这段代码我们拆开来看一下：\nSimpleEngine 实现了一个继承 SearchEngineBase 的子类，继承并实现了 process_corpus 和 search 接口，同时，也顺手继承了 add_corpus 函数（当然你想重写也是可行的），因此我们可以在 main() 函数中直接调取。\n在我们新的构造函数中，self.__id_to_texts = {} 初始化了自己的私有变量，也就是这个用来存储文件名到文件内容的字典。\nprocess_corpus() 函数则非常直白地将文件内容插入到字典中。这里注意，ID 需要是唯一的，不然相同ID的新内容会覆盖掉旧的内容。\nsearch 直接枚举字典，从中找到要搜索的字符串。如果能够找到，则将 ID 放到结果列表中，最后返回。\n你看，是不是非常简单呢？这个过程始终贯穿着面向对象的思想，这里我为你梳理成了几个问题，你可以自己思考一下，当成是一个小复习。\n现在你对父类子类的构造函数调用顺序和方法应该更清楚了吧？ 继承的时候，函数是如何重写的？ 基类是如何充当接口作用的（你可以自行删掉子类中的重写函数，抑或是修改一下函数的参数，看一下会报什么错）？ 方法和变量之间又如何衔接起来的呢？ 好的，我们重新回到搜索引擎这个话题。\n相信你也能看得出来，这种实现方式简单，但显然是一种很低效的方式：每次索引后需要占用大量空间，因为索引函数并没有做任何事情；每次检索需要占用大量时间，因为所有索引库的文件都要被重新搜索一遍。如果把语料的信息量视为 n，那么这里的时间复杂度和空间复杂度都应该是 O(n) 级别的。\n而且，还有一个问题：这里的 query 只能是一个词，或者是连起来的几个词。如果你想要搜索多个词，它们又分散在文章的不同位置，我们的简单引擎就无能为力了。\n这时应该怎么优化呢？\n最直接的一个想法，就是把语料分词，看成一个个的词汇，这样就只需要对每篇文章存储它所有词汇的 set 即可。根据齐夫定律（Zipf’s law，https://en.wikipedia.org/wiki/Zipf%27s_law），在自然语言的语料库里，一个单词出现的频率与它在频率表里的排名成反比，呈现幂律分布。因此，语料分词的做法可以大大提升我们的存储和搜索效率。\n那具体该如何实现呢？\nBag of Words 和 Inverted Index link我们先来实现一个名叫 Bag of Words 的搜索模型。请看下面的代码：\nimport re\rclass BOWEngine(SearchEngineBase):\rdef __init__(self):\rsuper(BOWEngine, self).__init__()\rself.__id_to_words = {}\rdef process_corpus(self, id, text):\rself.__id_to_words[id] = self.parse_text_to_words(text)\rdef search(self, query):\rquery_words = self.parse_text_to_words(query)\rresults = []\rfor id, words in self.__id_to_words.items():\rif self.query_match(query_words, words):\rresults.append(id)\rreturn results\r@staticmethod\rdef query_match(query_words, words):\rfor query_word in query_words:\rif query_word not in words:\rreturn False\rreturn True\r@staticmethod\rdef parse_text_to_words(text):\r# 使用正则表达式去除标点符号和换行符\rtext = re.sub(r'[^\\w ]', ' ', text)\r# 转为小写\rtext = text.lower()\r# 生成所有单词的列表\rword_list = text.split(' ')\r# 去除空白单词\rword_list = filter(None, word_list)\r# 返回单词的 set\rreturn set(word_list)\rsearch_engine = BOWEngine()\rmain(search_engine)\r########## 输出 ##########\ri have a dream\rfound 3 result(s):\r1.txt\r2.txt\r3.txt\rfreedom children\rfound 1 result(s):\r5.txt 你应该发现，代码开始变得稍微复杂些了。\n这里我们先来理解一个概念，BOW Model，即 Bag of Words Model，中文叫做词袋模型。这是 NLP 领域最常见最简单的模型之一。\n假设一个文本，不考虑语法、句法、段落，也不考虑词汇出现的顺序，只将这个文本看成这些词汇的集合。于是相应的，我们把 id_to_texts 替换成 id_to_words，这样就只需要存这些单词，而不是全部文章，也不需要考虑顺序。\n其中，process_corpus() 函数调用类静态函数 parse_text_to_words，将文章打碎形成词袋，放入 set 之后再放到字典中。\nsearch() 函数则稍微复杂一些。这里我们假设，想得到的结果，是所有的搜索关键词都要出现在同一篇文章中。那么，我们需要同样打碎 query 得到一个 set，然后把 set 中的每一个词，和我们的索引中每一篇文章进行核对，看一下要找的词是否在其中。而这个过程由静态函数 query_match 负责。\n你可以回顾一下上节课学到的静态函数，我们看到，这两个函数都是没有状态的，它们不涉及对象的私有变量（没有 self 作为参数），相同的输入能够得到完全相同的输出结果。因此设置为静态，可以方便其他的类来使用。\n可是，即使这样做，每次查询时依然需要遍历所有ID，虽然比起 Simple 模型已经节约了大量时间，但是互联网上有上亿个页面，每次都全部遍历的代价还是太大了。到这时，又该如何优化呢？\n你可能想到了，我们每次查询的 query 的单词量不会很多，一般也就几个、最多十几个的样子。那可不可以从这里下手呢？\n再有，词袋模型并不考虑单词间的顺序，但有些人希望单词按顺序出现，或者希望搜索的单词在文中离得近一些，这种情况下词袋模型现任就无能为力了。\n针对这两点，我们还能做得更好吗？显然是可以的，请看接下来的这段代码。\nimport re\rclass BOWInvertedIndexEngine(SearchEngineBase):\rdef __init__(self):\rsuper(BOWInvertedIndexEngine, self).__init__()\rself.inverted_index = {}\rdef process_corpus(self, id, text):\rwords = self.parse_text_to_words(text)\rfor word in words:\rif word not in self.inverted_index:\rself.inverted_index[word] = []\rself.inverted_index[word].append(id)\rdef search(self, query):\rquery_words = list(self.parse_text_to_words(query))\rquery_words_index = list()\rfor query_word in query_words:\rquery_words_index.append(0)\r# 如果某一个查询单词的倒序索引为空，我们就立刻返回\rfor query_word in query_words:\rif query_word not in self.inverted_index:\rreturn []\rresult = []\rwhile True:\r# 首先，获得当前状态下所有倒序索引的 index\rcurrent_ids = []\rfor idx, query_word in enumerate(query_words):\rcurrent_index = query_words_index[idx]\rcurrent_inverted_list = self.inverted_index[query_word]\r# 已经遍历到了某一个倒序索引的末尾，结束 search\rif current_index \u003e= len(current_inverted_list):\rreturn result\rcurrent_ids.append(current_inverted_list[current_index])\r# 然后，如果 current_ids 的所有元素都一样，那么表明这个单词在这个元素对应的文档中都出现了\rif all(x == current_ids[0] for x in current_ids):\rresult.append(current_ids[0])\rquery_words_index = [x + 1 for x in query_words_index]\rcontinue\r# 如果不是，我们就把最小的元素加一\rmin_val = min(current_ids)\rmin_val_pos = current_ids.index(min_val)\rquery_words_index[min_val_pos] += 1\r@staticmethod\rdef parse_text_to_words(text):\r# 使用正则表达式去除标点符号和换行符\rtext = re.sub(r'[^\\w ]', ' ', text)\r# 转为小写\rtext = text.lower()\r# 生成所有单词的列表\rword_list = text.split(' ')\r# 去除空白单词\rword_list = filter(None, word_list)\r# 返回单词的 set\rreturn set(word_list)\rsearch_engine = BOWInvertedIndexEngine()\rmain(search_engine)\r########## 输出 ##########\rlittle\rfound 2 result(s):\r1.txt\r2.txt\rlittle vicious\rfound 1 result(s):\r2.txt 首先我要强调一下，这次的算法并不需要你完全理解，这里的实现有一些超出了本章知识点。但希望你不要因此退缩，这个例子会告诉你，面向对象编程是如何把算法复杂性隔离开来，而保留接口和其他的代码不变。\n我们接着来看这段代码。你可以看到，新模型继续使用之前的接口，仍然只在 __init__()、process_corpus()和search()三个函数进行修改。\n这其实也是大公司里团队协作的一种方式，在合理的分层设计后，每一层的逻辑只需要处理好分内的事情即可。在迭代升级我们的搜索引擎内核时， main 函数、用户接口没有任何改变。当然，如果公司招了新的前端工程师，要对用户接口部分进行修改，新人也不需要过分担心后台的事情，只要做好数据交互就可以了。\n继续看代码，你可能注意到了开头的Inverted Index。Inverted Index Model，即倒序索引，是非常有名的搜索引擎方法，接下来我简单介绍一下。\n倒序索引，一如其名，也就是说这次反过来，我们保留的是 word -\u003e id 的字典。于是情况就豁然开朗了，在 search 时，我们只需要把想要的 query_word 的几个倒序索引单独拎出来，然后从这几个列表中找共有的元素，那些共有的元素，即 ID，就是我们想要的查询结果。这样，我们就避免了将所有的 index 过一遍的尴尬。\nprocess_corpus 建立倒序索引。注意，这里的代码都是非常精简的。在工业界领域，需要一个 unique ID 生成器，来对每一篇文章标记上不同的 ID，倒序索引也应该按照这个 unique_id 来进行排序。\n至于search() 函数，你大概了解它做的事情即可。它会根据 query_words 拿到所有的倒序索引，如果拿不到，就表示有的 query word 不存在于任何文章中，直接返回空；拿到之后，运行一个“合并K个有序数组”的算法，从中拿到我们想要的 ID，并返回。\n注意，这里用到的算法并不是最优的，最优的写法需要用最小堆来存储 index。这是一道有名的 leetcode hard 题，有兴趣请参考：https://blog.csdn.net/qqxx6661/article/details/77814794）\n遍历的问题解决了，那第二个问题，如果我们想要实现搜索单词按顺序出现，或者希望搜索的单词在文中离得近一些呢？\n我们需要在 Inverted Index 上，对于每篇文章也保留单词的位置信息，这样一来，在合并操作的时候处理一下就可以了。\n倒序索引我就介绍到这里了，如果你感兴趣可以自行查阅资料。还是那句话，我们的重点是面向对象的抽象，别忘了体会这一思想。\nLRU 和多重继承 link到这一步，终于，你的搜索引擎上线了，有了越来越多的访问量（QPS）。欣喜骄傲的同时，你却发现服务器有些“不堪重负”了。经过一段时间的调研，你发现大量重复性搜索占据了 90% 以上的流量，于是，你想到了一个大杀器——给搜索引擎加一个缓存。\n所以，最后这部分，我就来讲讲缓存和多重继承的内容。\nimport pylru\rclass LRUCache(object):\rdef __init__(self, size=32):\rself.cache = pylru.lrucache(size)\rdef has(self, key):\rreturn key in self.cache\rdef get(self, key):\rreturn self.cache[key]\rdef set(self, key, value):\rself.cache[key] = value\rclass BOWInvertedIndexEngineWithCache(BOWInvertedIndexEngine, LRUCache):\rdef __init__(self):\rsuper(BOWInvertedIndexEngineWithCache, self).__init__()\rLRUCache.__init__(self)\rdef search(self, query):\rif self.has(query):\rprint('cache hit!')\rreturn self.get(query)\rresult = super(BOWInvertedIndexEngineWithCache, self).search(query)\rself.set(query, result)\rreturn result\rsearch_engine = BOWInvertedIndexEngineWithCache()\rmain(search_engine)\r########## 输出 ##########\rlittle\rfound 2 result(s):\r1.txt\r2.txt\rlittle\rcache hit!\rfound 2 result(s):\r1.txt\r2.txt 它的代码很简单，LRUCache 定义了一个缓存类，你可以通过继承这个类来调用其方法。LRU 缓存是一种很经典的缓存（同时，LRU的实现也是硅谷大厂常考的算法面试题，这里为了简单，我直接使用 pylru 这个包），它符合自然界的局部性原理，可以保留最近使用过的对象，而逐渐淘汰掉很久没有被用过的对象。\n因此，这里的缓存使用起来也很简单，调用 has() 函数判断是否在缓存中，如果在，调用 get 函数直接返回结果；如果不在，送入后台计算结果，然后再塞入缓存。\n我们可以看到，BOWInvertedIndexEngineWithCache 类，多重继承了两个类。首先，你需要注意的是构造函数（上节课的思考题，你思考了吗？）。多重继承有两种初始化方法，我们分别来看一下。\n第一种方法，用下面这行代码，直接初始化该类的第一个父类：\nsuper(BOWInvertedIndexEngineWithCache, self).__init__() 不过使用这种方法时，要求继承链的最顶层父类必须要继承 object。\n第二种方法，对于多重继承，如果有多个构造函数需要调用， 我们必须用传统的方法LRUCache.__init__(self) 。\n其次，你应该注意，search() 函数被子类 BOWInvertedIndexEngineWithCache 再次重载，但是我还需要调用 BOWInvertedIndexEngine 的 search() 函数，这时该怎么办呢？请看下面这行代码：\nsuper(BOWInvertedIndexEngineWithCache, self).search(query) 我们可以强行调用被覆盖的父类的函数。\n这样一来，我们就简洁地实现了缓存，而且还是在不影响 BOWInvertedIndexEngine 代码的情况下。这部分内容希望你多读几遍，自己揣摩清楚，通过这个例子多多体会继承的优势。\n总结 link今天这节课是面向对象的实战应用，相比起前面的理论知识，内容其实不那么友好。不过，若你能静下心来，仔细学习，理清楚整个过程的要点，对你理解面向对象必将有所裨益。比如，你可以根据下面两个问题，来检验今天这节课的收获。\n你能把这节课所有的类的属性和函数抽取出来，自己在纸上画一遍继承关系吗？ 迭代开发流程是怎样的？ 其实于我而言，通过构造搜索引擎这么一个例子来讲面向对象，也是颇费了一番功夫。这其中虽然涉及一些搜索引擎的专业知识和算法，但篇幅有限，也只能算是抛砖引玉，你若有所收获，我便欣然满足。\n思考题 link最后给你留一道思考题。私有变量能被继承吗？如果不能，你想继承应该怎么去做呢？欢迎留言与我分享、讨论，也欢迎你把这篇文章分享给你的同事、朋友，一起交流与进步。\nclass B(A): pass\nb = B() print(b._A__a)2019-06-09小侠龙旋风 👍（48） 💬（2）和面向对象无关的关键词整理： 1.一个搜索引擎由搜索器、索引器、检索器和用户接口四个部分组成。 2.Bag of Words Model，词袋模型。 3.Inverted Index Model，倒序索引。 4.语料corpus分词，齐夫定律。 5.合并 K 个有序数组。 6.LRU缓存。 难点消化：4，5，6 思考题： Python并没有真正的私有化支持，但可用下划线得到伪私有： （1）_xxx \"单下划线 \" 开始的成员变量叫做保护变量，意思是只有类对象和子类对象自己能访问到这些变量，需通过类提供的接口进行访问； （2）__xxx 类中的私有变量/方法名，只有类对象自己能访问，连子类对象也不能访问到这个数据。 （3）xxx 魔法函数，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 init() 代表类的构造函数。2019-06-08shiziwen 👍（21） 💬（5）第二种方法，对于多重继承，如果有多个构造函数需要调用， 我们必须用传统的方法LRUCache.init(self) 。\n这里的两句话没有很明白，LRUCache为什么必须使用第二种方法？\nclass B(A): def init(self): print('enter B') super().init() print('leave B')\nclass C(A): def init(self): print('enter C') super().init() print('leave C')\nclass D(B, C): def init(self): print('enter D') super(D,self).init() C.init(self) print('leave D')\nD() 输出结果： enter D enter B enter C enter A leave A leave C leave B enter C enter A leave A leave C leave D2020-03-22quanxyun 👍（4） 💬（1）Python并没有真正的私有化支持，但可用下划线得到伪私有： （1）_xxx \"单下划线 \" 开始的成员变量叫做保护变量，意思是只有类对象和子类对象自己能访问到这些变量，需通过类提供的接口进行访问； （2）__xxx 类中的私有变量/方法名，只有类对象自己能访问，连子类对象也不能访问到这个数据。 （3）xxx 魔法函数，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 init() 代表类的构造函数。2019-11-14响雨 👍（2） 💬（1）私有属性不可以被继承，但是可以创建一个普通的方法，在方法中操作私有属性。因为普通的方法是可以操作的。2019-06-25Claywoow 👍（0） 💬（1）老师可以拓展一下元类吗，它是面向对象编程中一个重要的类型吗？2019-06-08益达 👍（77） 💬（9）看不懂不睡觉2019-06-05Wing·三金 👍（65） 💬（1）思考题：子类继承父类私有变量的方法\n通过定义 get/set 函数来间接操作私有变量 通过 实例名._父类名__私有变量名 来直接调用，所以事实上 python 并不直接私有变量 主要知识点 link 搜索引擎的四个组成部分 迭代开发的流程 类的继承与父类函数的强行调用 词袋模型 + 逆序索引 + 合并有序数组 = 优化检索速度 + 考虑单词顺序与间隔 pylru 的基本用法 多重继承的初始化规则 搜索引擎 link 搜索器：相当于爬虫 索引器：为每个文件/网页建立唯一的索引 检索器：高效地检索并返回匹配的文件/网页 用户接口：输入框和结果返回界面 迭代开发的流程 link 构建一个通用的基本框架 从最简单的情况考虑起，搭建一个能运行的极简版本 按照实际需要不断对具体的实现过程进行优化：如在本讲的例子中，先考虑了单个搜索词 + 小搜索量的情况，构建了 ver 1；然后考虑了多个搜索词，构建了词袋的 ver 2；再考虑了大搜索量，构建了词袋 + 逆序索引的 ver 3（提了 搜索词排序与间隔 情况下的处理思路）；最后考虑了负载与重复性搜索问题，构建了使用 LRU 缓存策略的 ver 4 如果回过头来看最初的框架，还能发现 add_corpus 的方法并不适用于文件较大的情况，结合前面第六讲的内容可以做些改进；以及 main 函数直接用了 for 循环来找所有的文件，实际使用时用的是诸如 os.walk 的方法2019-06-05 👍（50） 💬（1）这篇文章就值回票价了。2019-06-07风居住的街 👍（23） 💬（1）Python3.x 和 Python2.x 的一个区别是: Python 3 可以使用直接使用 super().xxx 代替 super(Class, self).xxx2019-06-17chuan_chen 👍（14） 💬（0）感觉这篇好难。。。2019-09-04John Si 👍（10） 💬（0）关于思考题,子类不能继承父类私有属性，只可透过self._Parent__varname去读取该私有属性的值，或在父类创建方法返回私有属性的值，然后子类调用父类方法去取得该私有属性的值 class Animal():\ndef __init__(self, sex, height, weight):\rself.__sex = sex\rself.height = height\rself.weight = weight\rdef say_hello(self):\rraise \u0026#39;say hello not implemented\u0026#39;\rdef get_sex(self):\rprint(\u0026#39;Achieve sex information for parent method: {}\u0026#39;.format(self.__sex))\rclass Person(Animal):\ndef __init__(self,name,age):\rsuper().__init__(\u0026#39;M\u0026#39;,172,70)\rself.name = name\rself.age = age\rdef say_hello(self):\rprint(\u0026#39;Hello, {}, age: {}, weight:{}\u0026#39;.format(self.name, self.age, self.weight))\rprint(\u0026#39;Sex: {}\u0026#39;.format(self._Animal__sex))\rjohn = Person('John',35) john.say_hello() john.get_sex()\n======================== Hello, John, age: 35, weight:70 Sex: M Achieve sex information for parent method: M\n"
            }
        );
    index.add(
            {
                id:  22 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/13---%E6%90%AD%E5%BB%BA%E7%A7%AF%E6%9C%A8python-%E6%A8%A1%E5%9D%97%E5%8C%96\/",
                title: "搭建积木：Python 模块化",
                description: "你好，我是景霄。\n这是基础版块的最后一节。到目前为止，你已经掌握了 Python 这一门当代武功的基本招式和套路，走出了新手村，看到了更远的世界，有了和这个世界过过招的冲动。\n于是，你可能开始尝试写一些不那么简单的系统性工程，或者代码量较大的应用程序。这时候，简单的一个 py 文件已经过于臃肿，无法承担一个重量级软件开发的重任。\n今天这节课的主要目的，就是化繁为简，将功能模块化、文件化，从而可以像搭积木一样，将不同的功能，组件在大型工程中搭建起来。\n简单模块化 link说到最简单的模块化方式，你可以把函数、类、常量拆分到不同的文件，把它们放在同一个文件夹，然后使用 from your_file import function_name, class_name 的方式调用。之后，这些函数和类就可以在文件内直接使用了。\n# utils.py\rdef get_sum(a, b):\rreturn a + b # class_utils.py\rclass Encoder(object):\rdef encode(self, s):\rreturn s[::-1]\rclass Decoder(object):\rdef decode(self, s):\rreturn ''.join(reversed(list(s))) # main.py\rfrom utils import get_sum\rfrom class_utils import *\rprint(get_sum(1, 2))\rencoder = Encoder()\rdecoder = Decoder()\rprint(encoder.encode('abcde'))\rprint(decoder.decode('edcba'))\r########## 输出 ##########\r3\redcba\rabcde 我们来看这种方式的代码：get_sum() 函数定义在 utils.py，Encoder 和 Decoder 类则在 class_utils.py，我们在 main 函数直接调用 from import ，就可以将我们需要的东西 import 过来。\n",
                content: "你好，我是景霄。\n这是基础版块的最后一节。到目前为止，你已经掌握了 Python 这一门当代武功的基本招式和套路，走出了新手村，看到了更远的世界，有了和这个世界过过招的冲动。\n于是，你可能开始尝试写一些不那么简单的系统性工程，或者代码量较大的应用程序。这时候，简单的一个 py 文件已经过于臃肿，无法承担一个重量级软件开发的重任。\n今天这节课的主要目的，就是化繁为简，将功能模块化、文件化，从而可以像搭积木一样，将不同的功能，组件在大型工程中搭建起来。\n简单模块化 link说到最简单的模块化方式，你可以把函数、类、常量拆分到不同的文件，把它们放在同一个文件夹，然后使用 from your_file import function_name, class_name 的方式调用。之后，这些函数和类就可以在文件内直接使用了。\n# utils.py\rdef get_sum(a, b):\rreturn a + b # class_utils.py\rclass Encoder(object):\rdef encode(self, s):\rreturn s[::-1]\rclass Decoder(object):\rdef decode(self, s):\rreturn ''.join(reversed(list(s))) # main.py\rfrom utils import get_sum\rfrom class_utils import *\rprint(get_sum(1, 2))\rencoder = Encoder()\rdecoder = Decoder()\rprint(encoder.encode('abcde'))\rprint(decoder.decode('edcba'))\r########## 输出 ##########\r3\redcba\rabcde 我们来看这种方式的代码：get_sum() 函数定义在 utils.py，Encoder 和 Decoder 类则在 class_utils.py，我们在 main 函数直接调用 from import ，就可以将我们需要的东西 import 过来。\n非常简单。\n但是这就足够了吗？当然不，慢慢地，你会发现，所有文件都堆在一个文件夹下也并不是办法。\n于是，我们试着建一些子文件夹：\n# utils/utils.py\rdef get_sum(a, b):\rreturn a + b # utils/class_utils.py\rclass Encoder(object):\rdef encode(self, s):\rreturn s[::-1]\rclass Decoder(object):\rdef decode(self, s):\rreturn ''.join(reversed(list(s))) # src/sub_main.py\rimport sys\rsys.path.append(\"..\")\rfrom utils.class_utils import *\rencoder = Encoder()\rdecoder = Decoder()\rprint(encoder.encode('abcde'))\rprint(decoder.decode('edcba'))\r########## 输出 ##########\redcba\rabcde 而这一次，我们的文件结构是下面这样的：\n.\r├── utils\r│ ├── utils.py\r│ └── class_utils.py\r├── src\r│ └── sub_main.py\r└── main.py 很容易看出，main.py 调用子目录的模块时，只需要使用 . 代替 / 来表示子目录，utils.utils 表示 utils 子文件夹下的 utils.py 模块就行。\n那如果我们想调用上层目录呢？注意，sys.path.append(\"..\") 表示将当前程序所在位置向上提了一级，之后就能调用 utils 的模块了。\n同时要注意一点，import 同一个模块只会被执行一次，这样就可以防止重复导入模块出现问题。当然，良好的编程习惯应该杜绝代码多次导入的情况。在Facebook 的编程规范中，除了一些极其特殊的情况，import 必须位于程序的最前端。\n最后我想再提一下版本区别。你可能在许多教程中看到过这样的要求：我们还需要在模块所在的文件夹新建一个 __init__.py，内容可以为空，也可以用来表述包对外暴露的模块接口。不过，事实上，这是 Python 2 的规范。在 Python 3 规范中，__init__.py 并不是必须的，很多教程里没提过这一点，或者没讲明白，我希望你还是能注意到这个地方。\n整体而言，这就是最简单的模块调用方式了。在我初用 Python 时，这种方式已经足够我完成大学期间的项目了，毕竟，很多学校项目的文件数只有个位数，每个文件代码也只有几百行，这种组织方式能帮我顺利完成任务。\n但是在我来到 Facebook后，我发现，一个项目组的 workspace 可能有上千个文件，有几十万到几百万行代码。这种调用方式已经完全不够用了，学会新的组织方式迫在眉睫。\n接下来，我们就系统学习下，模块化的科学组织方式。\n项目模块化 link我们先来回顾下相对路径和绝对路径的概念。\n在 Linux 系统中，每个文件都有一个绝对路径，以 / 开头，来表示从根目录到叶子节点的路径，例如 /home/ubuntu/Desktop/my_project/test.py，这种表示方法叫作绝对路径。\n另外，对于任意两个文件，我们都有一条通路可以从一个文件走到另一个文件，例如 /home/ubuntu/Downloads/example.json。再如，我们从 test.py 访问到 example.json，需要写成 '../../Downloads/example.json'，其中 .. 表示上一层目录。这种表示方法，叫作相对路径。\n通常，一个 Python 文件在运行的时候，都会有一个运行时位置，最开始时即为这个文件所在的文件夹。当然，这个运行路径以后可以被改变。运行 sys.path.append(\"..\") ，则可以改变当前 Python 解释器的位置。不过，一般而言我并不推荐，固定一个确定路径对大型工程来说是非常必要的。\n理清楚这些概念后，我们就很容易搞懂，项目中如何设置模块的路径。\n首先，你会发现，相对位置是一种很不好的选择。因为代码可能会迁移，相对位置会使得重构既不雅观，也易出错。因此，在大型工程中尽可能使用绝对位置是第一要义。对于一个独立的项目，所有的模块的追寻方式，最好从项目的根目录开始追溯，这叫做相对的绝对路径。\n事实上，在 Facebook 和 Google，整个公司都只有一个代码仓库，全公司的代码都放在这个库里。我刚加入 Facebook 时对此感到很困惑，也很新奇，难免会有些担心：\n这样做似乎会增大项目管理的复杂度吧？ 是不是也会有不同组代码隐私泄露的风险呢？ 后来，随着工作的深入，我才发现了这种代码仓库独有的几个优点。\n第一个优点，简化依赖管理。整个公司的代码模块，都可以被你写的任何程序所调用，而你写的库和模块也会被其他人调用。调用的方式，都是从代码的根目录开始索引，也就是前面提到过的相对的绝对路径。这样极大地提高了代码的分享共用能力，你不需要重复造轮子，只需要在写之前，去搜一下有没有已经实现好的包或者框架就可以了。\n第二个优点，版本统一。不存在使用了一个新模块，却导致一系列函数崩溃的情况；并且所有的升级都需要通过单元测试才可以继续。\n第三个优点，代码追溯。你可以很容易追溯，一个 API 是从哪里被调用的，它的历史版本是怎样迭代开发，产生变化的。\n如果你有兴趣，可以参考这篇论文：https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext\n在做项目的时候，虽然你不可能把全世界的代码都放到一个文件夹下，但是类似模块化的思想还是要有的——那就是以项目的根目录作为最基本的目录，所有的模块调用，都要通过根目录一层层向下索引的方式来 import。\n明白了这一点后，这次我们使用 PyCharm 来创建一个项目。这个项目结构如下所示：\n.\r├── proto\r│ ├── mat.py\r├── utils\r│ └── mat_mul.py\r└── src\r└── main.py # proto/mat.py\rclass Matrix(object):\rdef __init__(self, data):\rself.data = data\rself.n = len(data)\rself.m = len(data[0]) # utils/mat_mul.py\rfrom proto.mat import Matrix\rdef mat_mul(matrix_1: Matrix, matrix_2: Matrix):\rassert matrix_1.m == matrix_2.n\rn, m, s = matrix_1.n, matrix_1.m, matrix_2.m\rresult = [[0 for _ in range(n)] for _ in range(s)]\rfor i in range(n):\rfor j in range(s):\rfor k in range(m):\rresult[i][k] += matrix_1.data[i][j] * matrix_2.data[j][k]\rreturn Matrix(result) # src/main.py\rfrom proto.mat import Matrix\rfrom utils.mat_mul import mat_mul\ra = Matrix([[1, 2], [3, 4]])\rb = Matrix([[5, 6], [7, 8]])\rprint(mat_mul(a, b).data)\r########## 输出 ##########\r[[19, 22], [43, 50]] 这个例子和前面的例子长得很像，但请注意 utils/mat_mul.py，你会发现，它 import Matrix 的方式是from proto.mat。这种做法，直接从项目根目录中导入，并依次向下导入模块 mat.py 中的 Matrix，而不是使用 .. 导入上一级文件夹。\n是不是很简单呢？对于接下来的所有项目，你都能直接使用 Pycharm 来构建。把不同模块放在不同子文件夹里，跨模块调用则是从顶层直接索引，一步到位，非常方便。\n我猜，这时你的好奇心来了。你尝试使用命令行进入 src 文件夹，直接输入 Python main.py，报错，找不到 proto。你不甘心，退回到上一级目录，输入Python src/main.py，继续报错，找不到 proto。\nPycharm 用了什么黑魔法呢？\n实际上，Python 解释器在遇到 import 的时候，它会在一个特定的列表中寻找模块。这个特定的列表，可以用下面的方式拿到：\nimport sys print(sys.path)\r########## 输出 ##########\r['', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages'] 请注意，它的第一项为空。其实，Pycharm 做的一件事，就是将第一项设置为项目根目录的绝对地址。这样，每次你无论怎么运行 main.py，import 函数在执行的时候，都会去项目根目录中找相应的包。\n你说，你想修改下，使得普通的 Python 运行环境也能做到？这里有两种方法可以做到：\nimport sys\rsys.path[0] = '/home/ubuntu/workspace/your_projects' 第一种方法，“大力出奇迹”，我们可以强行修改这个位置，这样，你的 import 接下来肯定就畅通无阻了。但这显然不是最佳解决方案，把绝对路径写到代码里，是我非常不推荐的方式（你可以写到配置文件中，但找配置文件也需要路径寻找，于是就会进入无解的死循环）。\n第二种方法，是修改 PYTHONHOME。这里我稍微提一下 Python 的 Virtual Environment（虚拟运行环境）。Python 可以通过 Virtualenv 工具，非常方便地创建一个全新的 Python 运行环境。\n事实上，我们提倡，对于每一个项目来说，最好要有一个独立的运行环境来保持包和模块的纯净性。更深的内容超出了今天的范围，你可以自己查资料了解。\n回到第二种修改方法上。在一个 Virtual Environment 里，你能找到一个文件叫 activate，在这个文件的末尾，填上下面的内容：\nexport PYTHONPATH=\"/home/ubuntu/workspace/your_projects\" 这样，每次你通过 activate 激活这个运行时环境的时候，它就会自动将项目的根目录添加到搜索路径中去。\n神奇的 if __name__ == '__main__' link最后一部分，我们再来讲讲 if __name__ == '__main__' ，这个我们经常看到的写法。\nPython 是脚本语言，和 C++、Java 最大的不同在于，不需要显式提供 main() 函数入口。如果你有 C++、Java 等语言经验，应该对 main() {} 这样的结构很熟悉吧？\n不过，既然 Python 可以直接写代码，if __name__ == '__main__' 这样的写法，除了能让 Python 代码更好看（更像 C++ ）外，还有什么好处吗？\n项目结构如下：\n.\r├── utils.py\r├── utils_with_main.py\r├── main.py\r└── main_2.py # utils.py\rdef get_sum(a, b):\rreturn a + b\rprint('testing')\rprint('{} + {} = {}'.format(1, 2, get_sum(1, 2))) # utils_with_main.py\rdef get_sum(a, b):\rreturn a + b\rif __name__ == '__main__':\rprint('testing')\rprint('{} + {} = {}'.format(1, 2, get_sum(1, 2))) # main.py\rfrom utils import get_sum\rprint('get_sum: ', get_sum(1, 2))\r########## 输出 ##########\rtesting\r1 + 2 = 3\rget_sum: 3 # main_2.py\rfrom utils_with_main import get_sum\rprint('get_sum: ', get_sum(1, 2))\r########## 输出 ##########\rget_sum_2: 3 看到这个项目结构，你就很清晰了吧。\nimport 在导入文件的时候，会自动把所有暴露在外面的代码全都执行一遍。因此，如果你要把一个东西封装成模块，又想让它可以执行的话，你必须将要执行的代码放在 if __name__ == '__main__'下面。\n为什么呢？其实，__name__ 作为 Python 的魔术内置参数，本质上是模块对象的一个属性。我们使用 import 语句时，__name__ 就会被赋值为该模块的名字，自然就不等于 __main__了。更深的原理我就不做过多介绍了，你只需要明白这个知识点即可。\n总结 link今天这节课，我为你讲述了如何使用 Python 来构建模块化和大型工程。这里需要强调几点：\n通过绝对路径和相对路径，我们可以 import 模块； 在大型工程中模块化非常重要，模块的索引要通过绝对路径来做，而绝对路径从程序的根目录开始； 记着巧用if __name__ == '__main__'来避开 import 时执行。 思考题 link最后，我想为你留一道思考题。from module_name import *和import module_name有什么区别呢？欢迎留言和我分享，也欢迎你把这篇文章分享给你的同事、朋友。\n假如现在有main.py和foo.py两个文件， foo.py中内容如下： def bar(): print('bar') print('hello')\nmain.py中内容如下： from foo import bar import foo bar() foo.bar() 执行python main.py后的结果是： hello bar bar2019-12-30萧潇风 👍（10） 💬（2）export PYTHONPATH=\"/home/ubuntu/workspace/your_projects\"\n在windows系统 中 亲测无效 T_T2019-06-07Paul Shan 👍（7） 💬（1）思考题 两者的前缀不同。第一种，把目录下的文件都倒入了，每个文件有各自前缀。第二种，只是倒入了一个前缀，所有文件都通过这个相同前缀。第一种类似于拷贝一个目录下所有文件。第二种类似于拷贝整个目录。2019-11-15enjoylearning 👍（7） 💬（1）作者写的都是原来疑惑的地方，如有时候要新建一个模块总是纠结于是添加文件夹还是包，怀疑加文件夹是不是不如加包规范，有时面对每个文件夹一个空的__init__.py，觉得真是不够优雅，现在好了，原来是2和3的区别，以后可以大胆的用文件夹来组织模块了。另外就是觉得python 命名模块名不能像java和.net那样以公司名.application.web.api格式，觉得还是有点别扭。2019-06-08小侠龙旋风 👍（3） 💬（1）在pycharm里，我会使用“Mark Directory as -\u003e Sources Root”来设置当前文件夹为根目录。 思考题： 1.from module_name import * 能够导入模块下所有的类/函数等内容，使用时不需要包含模块名。容易出现重名现象，发生错误； 2.import module_name 只是将模块名导入，调用时必须模块名.xxx。 3.from module_name import class_name 需要用模块中的哪个类就导入哪个类，比较推荐。2019-06-08Kevin 👍（2） 💬（1）“import 在导入文件的时候，会自动把所有暴露在外面的代码全都执行一遍。因此，如果你要把一个东西封装成模块，又想让它可以执行的话，你必须将要执行的代码放在 if name == 'main'下面。” 导入的模块if name == 'main'下面的语句没有被执行。2020-06-22Paul Shan 👍（2） 💬（1）树状结构是大多数项目的组织方式，树状结构本身不复杂，从根节点到每个节点有唯一路径，这条路径可以用一致的方式来引用文件。树状结构可以表达的文件上限是层数的指数，对于大型项目也没问题。如果目录是线性结构，文件一多，查找就费力。文件直接的调用如果用相对路径，这就相当于在树状的结构中引入了中间节点的边，几乎让树成图，复杂度大大增加。2019-11-15大象 👍（2） 💬（1）请教老师一个问题：如果我们所有的项目（项目A，项目B，项目C）都在一个文件夹底下，每个项目都有自己的虚拟运行环境。如果我项目A是公共库，项目B要引用项目A，那么我需要怎么做？谢谢2019-10-25Geek_59f23e 👍（2） 💬（1）class_utils.py那儿应该是reversed吧，而不是reverse。2019-06-08Hy 👍（1） 💬（1）老师您好，请问这个函数后面的参数是什么意思，没见过这种写法，中间加一个冒号\ndef mat_mul(matrix_1: Matrix, matrix_2: Matrix)2020-06-11吴小智 👍（1） 💬（1）老师的基础模块，帮助自己扫清了一下知识盲区，期待老师接下来的进阶篇，up,up,up。老师端午节快乐。2019-06-07ShmilyVidian 👍（0） 💬（1）from module_name import * 是导入module_name 中的所有内容，可以直接调用内部方法容易引入冲突；import module_name，则是导入module_name，在代码中调用必须写成module_name.function的，减少引起冲突，通过module_name做了一层桥接隔离。2020-05-23徐旭 👍（0） 💬（1）赞赞，老师讲得不错2020-03-29大象 👍（0） 💬（1）“事实上，在 Facebook 和 Google，整个公司都只有一个代码仓库，全公司的代码都放在这个库里。”不太理解这里的意思是啥？是类似于在git的同一个组底下么？还是说所有的项目在同一个文件夹底下？2019-10-25\n"
            }
        );
    index.add(
            {
                id:  23 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/14---%E7%AD%94%E7%96%91%E4%B8%80%E5%88%97%E8%A1%A8%E5%92%8C%E5%85%83%E7%BB%84%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84\/",
                title: "答疑（一）：列表和元组的内部实现是怎样的？",
                description: "你好，我是景霄。\n转眼间，专栏上线已经一个月了，而我们也在不知不觉中完成了第一大章基础篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：列表和元组的内部实现 link第一个问题，是胡峣同学提出的，有关列表（list）和元组（tuple）的内部实现，想知道里边是linked list 或array，还是把array linked一下这样的方式？\n关于这个问题，我们可以分别从源码来看。\n先来看 Python 3.7 的list源码。你可以先自己阅读下面两个链接里的内容。\nlistobject.h：https://github.com/python/cpython/blob/949fe976d5c62ae63ed505ecf729f815d0baccfc/Include/listobject.h#L23\nlistobject.c: https://github.com/python/cpython/blob/3d75bd15ac82575967db367c517d7e6e703a6de3/Objects/listobject.c#L33\n",
                content: "你好，我是景霄。\n转眼间，专栏上线已经一个月了，而我们也在不知不觉中完成了第一大章基础篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：列表和元组的内部实现 link第一个问题，是胡峣同学提出的，有关列表（list）和元组（tuple）的内部实现，想知道里边是linked list 或array，还是把array linked一下这样的方式？\n关于这个问题，我们可以分别从源码来看。\n先来看 Python 3.7 的list源码。你可以先自己阅读下面两个链接里的内容。\nlistobject.h：https://github.com/python/cpython/blob/949fe976d5c62ae63ed505ecf729f815d0baccfc/Include/listobject.h#L23\nlistobject.c: https://github.com/python/cpython/blob/3d75bd15ac82575967db367c517d7e6e703a6de3/Objects/listobject.c#L33\n我把 list的具体结构放在了下面：\n可以看到，list本质上是一个over-allocate的array。其中，ob_item是一个指针列表，里面的每一个指针都指向列表的元素。而 allocated则存储了这个列表已经被分配的空间大小。\n需要注意的是，allocated 与列表实际空间大小的区别。列表实际空间大小，是指len(list)返回的结果，即上述代码注释中的ob_size，表示这个列表总共存储了多少个元素。实际情况下，为了优化存储结构，避免每次增加元素都要重新分配内存，列表预分配的空间allocated往往会大于ob_size（详见正文中的例子）。\n所以，它们的关系为：allocated \u003e= len(list) = ob_size。\n如果当前列表分配的空间已满（即allocated == len(list)），则会向系统请求更大的内存空间，并把原来的元素全部拷贝过去。列表每次分配空间的大小，遵循下面的模式：\n0, 4, 8, 16, 25, 35, 46, 58, 72, 88, ... 我们再来分析元组。下面是Python 3.7 的tuple源码，同样的，你可以先自己阅读一下。\ntupleobject.h： https://github.com/python/cpython/blob/3d75bd15ac82575967db367c517d7e6e703a6de3/Include/tupleobject.h#L25\ntupleobject.c：https://github.com/python/cpython/blob/3d75bd15ac82575967db367c517d7e6e703a6de3/Objects/tupleobject.c#L16\n同样的，下面为tuple的具体结构：\n你可以看到，它和list相似，本质也是一个array，但是空间大小固定。不同于一般array，Python的tuple做了许多优化，来提升在程序中的效率。\n举个例子，当tuple的大小不超过20时，Python就会把它缓存在内部的一个free list中。这样，如果你以后需要再去创建同样的tuple，Python就可以直接从缓存中载入，提高了程序运行效率。\n问题二：为什么在旧哈希表中，元素会越来越稀疏？ link第二个问题，是Hoo同学提出的，为什么在旧哈希表中，元素会越来越稀疏？\n我们可以先来看旧哈希表的示意图：\n--+-------------------------------+\r| 哈希值 (hash) 键 (key) 值 (value)\r--+-------------------------------+\r0 | hash0 key0 value0\r--+-------------------------------+\r1 | hash1 key1 value1\r--+-------------------------------+\r2 | hash2 key2 value2\r--+-------------------------------+\r. | ...\r__+_______________________________+ 你会发现，它是一个over-allocate的array，根据元素键（key）的哈希值，来计算其应该被插入位置的索引。\n因此，假设我有下面这样一个字典：\n{'name': 'mike', 'dob': '1999-01-01', 'gender': 'male'} 那么这个字典便会存储为类似下面的形式：\nentries = [\r['--', '--', '--']\r[-230273521, 'dob', '1999-01-01'],\r['--', '--', '--'],\r['--', '--', '--'],\r[1231236123, 'name', 'mike'],\r['--', '--', '--'],\r[9371539127, 'gender', 'male']\r] 这里的’---‘，表示这个位置没有元素，但是已经分配了内存。\n我们知道，当哈希表剩余空间小于1/3时，为了保证相关操作的高效性并避免哈希冲突，就会重新分配更大的内存。所以，当哈希表中的元素越来越多时，分配了内存但里面没有元素的位置，也会变得越来越多。这样一来，哈希表便会越来越稀疏。\n而新哈希表的结构，改变了这一点，也大大提高了空间的利用率。新哈希表的结构如下所示：\nIndices\r----------------------------------------------------\rNone | index | None | None | index | None | index ...\r----------------------------------------------------\rEntries\r--------------------\rhash0 key0 value0\r---------------------\rhash1 key1 value1\r---------------------\rhash2 key2 value2\r---------------------\r...\r--------------------- 你可以看到，它把存储结构分成了Indices和Entries这两个array，而’None‘代表这个位置分配了内存但没有元素。\n我们同样还用上面这个例子，它在新哈希表中的存储模式，就会变为下面这样：\nindices = [None, 1, None, None, 0, None, 2]\rentries = [\r[1231236123, 'name', 'mike'],\r[-230273521, 'dob', '1999-01-01'],\r[9371539127, 'gender', 'male']\r] 其中，Indices中元素的值，对应entries中相应的索引。比如indices中的1，就对应着entries[1]，即’'dob': '1999-01-01'‘。\n对比之下，我们会清晰感受到，新哈希表中的空间利用率，相比于旧哈希表有大大的提升。\n问题三：有关异常的困扰 link第三个问题，是“不瘦到140不改名”同学提出的，对“NameError”异常的困惑。这是很常见的一个错误，我在这里也解释一下。\n这个问题其实有点tricky，如果你查阅官方文档，会看到这么一句话”When an exception has been assigned using as target, it is cleared at the end of the except clause. ”\n这句话意思是，如果你在异常处理的except block中，把异常赋予了一个变量，那么这个变量会在except block执行结束时被删除，相当于下面这样的表示：\ne = 1\rtry:\r1 / 0\rexcept ZeroDivisionError as e:\rtry:\rpass\rfinally:\rdel e 这里的e一开始指向整数1，但是在except block结束时被删除了（del e），所以程序执行就会抛出“NameError”的异常。\n因此，这里提醒我们，在平时写代码时，一定要保证except中异常赋予的变量，在之后的语句中不再被用到。\n问题四：关于多态和全局变量的修改 link最后的问题来自于farFlight同学，他提了两个问题：\nPython自己判断类型的多态和子类继承的多态Polymorphism是否相同？ 函数内部不能直接用+=等修改全局变量，但是对于list全局变量，却可以使用append、extend之类修改，这是为什么呢? 我们分别来看这两个问题。对于第一个问题，要搞清楚多态的概念，多态是指有多种不同的形式。因此，判断类型的多态和子类继承的多态，在本质上都是一样的，只不过你可以把它们理解为多态的两种不同表现。\n再来看第二个问题。当全局变量指向的对象不可变时，比如是整型、字符串等等，如果你尝试在函数内部改变它的值，却不加关键字global，就会抛出异常：\nx = 1\rdef func():\rx += 1\rfunc()\rx\r## 输出\rUnboundLocalError: local variable 'x' referenced before assignment 这是因为，程序默认函数内部的x是局部变量，而你没有为其赋值就直接引用，显然是不可行。\n不过，如果全局变量指向的对象是可变的，比如是列表、字典等等，你就可以在函数内部修改它了：\nx = [1]\rdef func():\rx.append(2)\rfunc()\rx\r## 输出\r[1, 2] 当然，需要注意的是，这里的x.append(2)，并没有改变变量x，x依然指向原来的列表。事实上，这句话的意思是，访问x指向的列表，并在这个列表的末尾增加2。\n今天主要回答这些问题，同时也欢迎你继续在留言区写下疑问和感想，我会持续不断地解答。希望每一次的留言和答疑，都能给你带来新的收获和价值。\n以上，思维比较发散，说得不对还望指出。2019-06-1318646333118 👍（5） 💬（0）辛苦老师，希望能用更通俗的语言或者例子来帮助我们这帮菜鸟理解哈哈，有的时候感觉老师明白，但是编辑成文字总是差一点 哈2019-06-11xavier 👍（3） 💬（0）对于我这种野生程序员来说，收获颇多。每一篇都是从基础开始，然后循序渐进。感谢老师！2019-07-11Geek_d848f7 👍（3） 💬（0） 老师，原谅我还是不太理解这2点吧\n列表分配大小时，遵循下面模式：0、4、8…，我看源代码的确这样，但是怎么算都对不上，求指导； 哈希的存储怎么知道是如图形式呢？尤其是无元素位置，这个位置为啥要分配呢？2019-06-10隰有荷 👍（2） 💬（2）不太明白为什么新哈希表的结构是 Indices None | index | None | None | index | None | Entries 这种形式?\nNone和index的排列有什么规则吗？为什么会有None? 2019-08-23瞳梦 👍（2） 💬（0）list的append()并不是一个赋值操作，不会去定义新的变量。而是会根据LEGB规则去寻找list这个变量。2019-07-08me 👍（1） 💬（0）x = 1 def func(): x += 1 func() 报错,分析原因: (从两个角度分析) 1\u003e 从右往左 先要明白赋值操作的一个概念, 被赋值=被引用； 再来看函数体内的 x += 1, 本质上就是x = x + 1 (扩展一下,若x是列表 x+=[1] 等同于 x.extend() 原地改变, 但放在此处依旧会报错, 报错原因于 x+=1同理) 继续分析, x = x + 1，右边的x变量在函数体里没有找到(在函数体里没有定义此变量),就去全局作用域里找, 找到啦, 右边的值最终为2.. 重点来了, 记住python在作用域里对变量的赋值操作规则, 在函数体内,若对某一变量未定义,对其赋值视为在函数体里定义了该变量; 在函数体内,若对某一变量已经定义,对其赋值视为修改该变量的值; 这里左边的x变量在函数体里未定义,那么按照规则会定义一个局部变量x,但右边的x是全局变量… 冲突了. 2\u003e 从左往右 根据报错的角度分析 是因为函数体里无x变量,赋值操作是定义该x变量,而赋值语句中又有还没有定义好的x变量)2022-09-13catshitfive 👍（1） 💬（0）有几个地方不是很懂请老师能否说明一下： (1)python中的list数据结构本质上是array,但是list多用来进行增删改的操作，岂不是没有链表结构时间复杂度低？还是说有什么优化？(2)list中存储的是指针(存储每个不可变元素对象的地址)，我用id()查看了每个指针内存储的地址，发现是连续的，但是地址都相差32，如何理解32个这个数字，是32bytes? list除了存储的是指针，那么它的空间内还存储了指针指向的那些元素吗？(3)指针本身是一块内存，那么指针对应自己本身的地址如何知晓？2019-06-11KaitoShy 👍（1） 💬（0）怎么得上面的存储方式的？和hash存储有关么？还是python实现的造成的？2019-06-10程序员人生 👍（1） 💬（0）想问一下Mr King，问题3我在pycharm中执行了一下没报错啊？2019-06-10Geek_145846 👍（0） 💬（0）想学学Python 没想到还要重新拾起 C ++，学海无涯苦作舟的感觉 哭2022-04-25\n"
            }
        );
    index.add(
            {
                id:  24 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/15---python%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%AF%94%E8%BE%83%E6%8B%B7%E8%B4%9D\/",
                title: "Python对象的比较、拷贝",
                description: "你好，我是景霄。\n在前面的学习中，我们其实已经接触到了很多 Python对象比较和复制的例子，比如下面这个，判断a和b是否相等的if语句：\nif a == b:\r... 再比如第二个例子，这里l2就是l1的拷贝。\nl1 = [1, 2, 3]\rl2 = list(l1) 但你可能并不清楚，这些语句的背后发生了什么。比如，\nl2是l1的浅拷贝（shallow copy）还是深度拷贝（deep copy）呢？ a == b是比较两个对象的值相等，还是两个对象完全相等呢？ 关于这些的种种知识，我希望通过这节课的学习，让你有个全面的了解。\n'==' VS 'is' link等于（==）和is是Python中对象比较常用的两种方式。简单来说，'=='操作符比较对象之间的值是否相等，比如下面的例子，表示比较变量a和b所指向的值是否相等。\na == b 而'is'操作符比较的是对象的身份标识是否相等，即它们是否是同一个对象，是否指向同一个内存地址。\n在Python中，每个对象的身份标识，都能通过函数id(object)获得。因此，'is'操作符，相当于比较对象之间的ID是否相等，我们来看下面的例子：\na = 10\rb = 10\ra == b\rTrue\rid(a)\r4427562448\rid(b)\r4427562448\ra is b\rTrue 这里，首先Python会为10这个值开辟一块内存，然后变量a和b同时指向这块内存区域，即a和b都是指向10这个变量，因此a和b的值相等，id也相等，a == b和a is b都返回True。\n不过，需要注意，对于整型数字来说，以上a is b为True的结论，只适用于-5到256范围内的数字。比如下面这个例子：\na = 257\rb = 257\ra == b\rTrue\rid(a)\r4473417552\rid(b)\r4473417584\ra is b\rFalse 这里我们把257同时赋值给了a和b，可以看到a == b仍然返回True，因为a和b指向的值相等。但奇怪的是，a is b返回了false，并且我们发现，a和b的ID不一样了，这是为什么呢？\n",
                content: "你好，我是景霄。\n在前面的学习中，我们其实已经接触到了很多 Python对象比较和复制的例子，比如下面这个，判断a和b是否相等的if语句：\nif a == b:\r... 再比如第二个例子，这里l2就是l1的拷贝。\nl1 = [1, 2, 3]\rl2 = list(l1) 但你可能并不清楚，这些语句的背后发生了什么。比如，\nl2是l1的浅拷贝（shallow copy）还是深度拷贝（deep copy）呢？ a == b是比较两个对象的值相等，还是两个对象完全相等呢？ 关于这些的种种知识，我希望通过这节课的学习，让你有个全面的了解。\n'==' VS 'is' link等于（==）和is是Python中对象比较常用的两种方式。简单来说，'=='操作符比较对象之间的值是否相等，比如下面的例子，表示比较变量a和b所指向的值是否相等。\na == b 而'is'操作符比较的是对象的身份标识是否相等，即它们是否是同一个对象，是否指向同一个内存地址。\n在Python中，每个对象的身份标识，都能通过函数id(object)获得。因此，'is'操作符，相当于比较对象之间的ID是否相等，我们来看下面的例子：\na = 10\rb = 10\ra == b\rTrue\rid(a)\r4427562448\rid(b)\r4427562448\ra is b\rTrue 这里，首先Python会为10这个值开辟一块内存，然后变量a和b同时指向这块内存区域，即a和b都是指向10这个变量，因此a和b的值相等，id也相等，a == b和a is b都返回True。\n不过，需要注意，对于整型数字来说，以上a is b为True的结论，只适用于-5到256范围内的数字。比如下面这个例子：\na = 257\rb = 257\ra == b\rTrue\rid(a)\r4473417552\rid(b)\r4473417584\ra is b\rFalse 这里我们把257同时赋值给了a和b，可以看到a == b仍然返回True，因为a和b指向的值相等。但奇怪的是，a is b返回了false，并且我们发现，a和b的ID不一样了，这是为什么呢？\n事实上，出于对性能优化的考虑，Python内部会对-5到256的整型维持一个数组，起到一个缓存的作用。这样，每次你试图创建一个-5到256范围内的整型数字时，Python都会从这个数组中返回相对应的引用，而不是重新开辟一块新的内存空间。\n但是，如果整型数字超过了这个范围，比如上述例子中的257，Python则会为两个257开辟两块内存区域，因此a和b的ID不一样，a is b就会返回False了。\n通常来说，在实际工作中，当我们比较变量时，使用'=='的次数会比'is'多得多，因为我们一般更关心两个变量的值，而不是它们内部的存储地址。但是，当我们比较一个变量与一个单例（singleton）时，通常会使用'is'。一个典型的例子，就是检查一个变量是否为None：\nif a is None:\r...\rif a is not None:\r... 这里注意，比较操作符'is'的速度效率，通常要优于'=='。因为'is'操作符不能被重载，这样，Python就不需要去寻找，程序中是否有其他地方重载了比较操作符，并去调用。执行比较操作符'is'，就仅仅是比较两个变量的ID而已。\n但是'=='操作符却不同，执行a == b相当于是去执行a.__eq__(b)，而Python大部分的数据类型都会去重载__eq__这个函数，其内部的处理通常会复杂一些。比如，对于列表，__eq__函数会去遍历列表中的元素，比较它们的顺序和值是否相等。\n不过，对于不可变（immutable）的变量，如果我们之前用'=='或者'is'比较过，结果是不是就一直不变了呢？\n答案自然是否定的。我们来看下面一个例子：\nt1 = (1, 2, [3, 4])\rt2 = (1, 2, [3, 4])\rt1 == t2\rTrue\rt1[-1].append(5)\rt1 == t2\rFalse 我们知道元组是不可变的，但元组可以嵌套，它里面的元素可以是列表类型，列表是可变的，所以如果我们修改了元组中的某个可变元素，那么元组本身也就改变了，之前用'is'或者'=='操作符取得的结果，可能就不适用了。\n这一点，你在日常写程序时一定要注意，在必要的地方请不要省略条件检查。\n浅拷贝和深度拷贝 link接下来，我们一起来看看Python中的浅拷贝（shallow copy）和深度拷贝（deep copy）。\n对于这两个熟悉的操作，我并不想一上来先抛概念让你死记硬背来区分，我们不妨先从它们的操作方法说起，通过代码来理解两者的不同。\n先来看浅拷贝。常见的浅拷贝的方法，是使用数据类型本身的构造器，比如下面两个例子：\nl1 = [1, 2, 3]\rl2 = list(l1)\rl2\r[1, 2, 3]\rl1 == l2\rTrue\rl1 is l2\rFalse\rs1 = set([1, 2, 3])\rs2 = set(s1)\rs2\r{1, 2, 3}\rs1 == s2\rTrue\rs1 is s2\rFalse 这里，l2就是l1的浅拷贝，s2是s1的浅拷贝。当然，对于可变的序列，我们还可以通过切片操作符':'完成浅拷贝，比如下面这个列表的例子：\nl1 = [1, 2, 3]\rl2 = l1[:]\rl1 == l2\rTrue\rl1 is l2\rFalse 当然，Python中也提供了相对应的函数copy.copy()，适用于任何数据类型：\nimport copy\rl1 = [1, 2, 3]\rl2 = copy.copy(l1) 不过，需要注意的是，对于元组，使用tuple()或者切片操作符':'不会创建一份浅拷贝，相反，它会返回一个指向相同元组的引用：\nt1 = (1, 2, 3)\rt2 = tuple(t1)\rt1 == t2\rTrue\rt1 is t2\rTrue 这里，元组(1, 2, 3)只被创建一次，t1和t2同时指向这个元组。\n到这里，对于浅拷贝你应该很清楚了。浅拷贝，是指重新分配一块内存，创建一个新的对象，里面的元素是原对象中子对象的引用。因此，如果原对象中的元素不可变，那倒无所谓；但如果元素可变，浅拷贝通常会带来一些副作用，尤其需要注意。我们来看下面的例子：\nl1 = [[1, 2], (30, 40)]\rl2 = list(l1)\rl1.append(100)\rl1[0].append(3)\rl1\r[[1, 2, 3], (30, 40), 100]\rl2\r[[1, 2, 3], (30, 40)]\rl1[1] += (50, 60)\rl1\r[[1, 2, 3], (30, 40, 50, 60), 100]\rl2\r[[1, 2, 3], (30, 40)] 这个例子中，我们首先初始化了一个列表l1，里面的元素是一个列表和一个元组；然后对l1执行浅拷贝，赋予l2。因为浅拷贝里的元素是对原对象元素的引用，因此l2中的元素和l1指向同一个列表和元组对象。\n接着往下看。l1.append(100)，表示对l1的列表新增元素100。这个操作不会对l2产生任何影响，因为l2和l1作为整体是两个不同的对象，并不共享内存地址。操作过后l2不变，l1会发生改变：\n[[1, 2, 3], (30, 40), 100] 再来看，l1[0].append(3)，这里表示对l1中的第一个列表新增元素3。因为l2是l1的浅拷贝，l2中的第一个元素和l1中的第一个元素，共同指向同一个列表，因此l2中的第一个列表也会相对应的新增元素3。操作后l1和l2都会改变：\nl1: [[1, 2, 3], (30, 40), 100]\rl2: [[1, 2, 3], (30, 40)] 最后是l1[1] += (50, 60)，因为元组是不可变的，这里表示对l1中的第二个元组拼接，然后重新创建了一个新元组作为l1中的第二个元素，而l2中没有引用新元组，因此l2并不受影响。操作后l2不变，l1发生改变：\nl1: [[1, 2, 3], (30, 40, 50, 60), 100] 通过这个例子，你可以很清楚地看到使用浅拷贝可能带来的副作用。因此，如果我们想避免这种副作用，完整地拷贝一个对象，你就得使用深度拷贝。\n所谓深度拷贝，是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。\nPython中以copy.deepcopy()来实现对象的深度拷贝。比如上述例子写成下面的形式，就是深度拷贝：\nimport copy\rl1 = [[1, 2], (30, 40)]\rl2 = copy.deepcopy(l1)\rl1.append(100)\rl1[0].append(3)\rl1\r[[1, 2, 3], (30, 40), 100]\rl2 [[1, 2], (30, 40)] 我们可以看到，无论l1如何变化，l2都不变。因为此时的l1和l2完全独立，没有任何联系。\n不过，深度拷贝也不是完美的，往往也会带来一系列问题。如果被拷贝对象中存在指向自身的引用，那么程序很容易陷入无限循环：\nimport copy\rx = [1]\rx.append(x)\rx\r[1, [...]]\ry = copy.deepcopy(x)\ry\r[1, [...]] 上面这个例子，列表x中有指向自身的引用，因此x是一个无限嵌套的列表。但是我们发现深度拷贝x到y后，程序并没有出现stack overflow的现象。这是为什么呢？\n其实，这是因为深度拷贝函数deepcopy中会维护一个字典，记录已经拷贝的对象与其ID。拷贝过程中，如果字典里已经存储了将要拷贝的对象，则会从字典直接返回，我们来看相对应的源码就能明白：\ndef deepcopy(x, memo=None, _nil=[]):\r\"\"\"Deep copy operation on arbitrary Python objects.\rSee the module's __doc__ string for more info.\r\"\"\"\rif memo is None:\rmemo = {}\rd = id(x) # 查询被拷贝对象x的id\ry = memo.get(d, _nil) # 查询字典里是否已经存储了该对象\rif y is not _nil:\rreturn y # 如果字典里已经存储了将要拷贝的对象，则直接返回\r... 总结 link今天这节课，我们一起学习了Python中对象的比较和拷贝，主要有下面几个重点内容。\n比较操作符'=='表示比较对象间的值是否相等，而'is'表示比较对象的标识是否相等，即它们是否指向同一个内存地址。 比较操作符'is'效率优于'=='，因为'is'操作符无法被重载，执行'is'操作只是简单的获取对象的ID，并进行比较；而'=='操作符则会递归地遍历对象的所有值，并逐一比较。 浅拷贝中的元素，是原对象中子对象的引用，因此，如果原对象中的元素是可变的，改变其也会影响拷贝后的对象，存在一定的副作用。 深度拷贝则会递归地拷贝原对象中的每一个子对象，因此拷贝后的对象和原对象互不相关。另外，深度拷贝中会维护一个字典，记录已经拷贝的对象及其ID，来提高效率并防止无限递归的发生。 思考题 link最后，我为你留下一道思考题。这节课我曾用深度拷贝，拷贝过一个无限嵌套的列表。那么。当我们用等于操作符'=='进行比较时，输出会是什么呢？是True或者False还是其他？为什么呢？建议你先自己动脑想一想，然后再实际跑一下代码，来检验你的猜想。\nimport copy\rx = [1]\rx.append(x)\ry = copy.deepcopy(x)\r# 以下命令的输出是？\rx == y 欢迎在留言区写下你的答案和学习感想，也欢迎你把这篇文章分享给你的同事、朋友。我们一起交流，一起进步。\n对与整数型，范围在（-5 ~ 256 ）之间的整形数，‘==’ 与 ‘is’ 结果相同，原因在于python建立了一个数组缓存，创建对象时直接引用缓存\n浅拷贝：定义：重新分配一片内存，生成新的对象，里面的元素是原对象中子对象的引用。 生成方法： 可以通过数据构造器（list、set）完成浅拷贝，对于可变序列可以使用切片完成浅拷贝，对于元组而言，tupletuple()和切片不创建浅拷贝，指向相同元组的引用，还可以使用import copy, 使用copy.copy()来进行浅拷贝。 浅拷贝是对元素的引用，所以对于子对象，如果子对象是不可变，没有影响，如果是可变的序列，会带来一些影响\n深拷贝，重新分配一块内存，创建一个新的对象，将原对象中的元素以递归的方式全部拷贝。深拷贝中会维持一个字典，记录已经拷贝的对象以及对象的ID，防止出现无限递归。2019-06-20酸葡萄 👍（0） 💬（3）老师 你好 浅拷贝指向的应该也不是同一块内存吧，如果是的话为什么 is 在浅拷贝中会返回False呢？ is比较的不是地址吗？比如下面的例子\nl1 = [1, 2, 3] l2 = l1[:]\nl1 == l2 True\nl1 is l2 False2019-12-16SCAR 👍（171） 💬（4）应该会出错，因为x是一个无限嵌套的列表，y深拷贝于x，按道理来讲 x == y应该是True的，但进行比较操作符“==”的时候，'=='操作符则会递归地遍历对象的所有值，并逐一比较。而python为了防止栈崩溃，递归的层数是要限定的，不会无休下去，所以到了限定的层数，python解释器会跳出错误。执行了一下代码，也的确是跳出了 RecursionError: maximum recursion depth exceeded in comparison。 之前课中做阶乘的例子，如果大于一定的整数，也是会出现递归错误，究其原因也是python的递归层数是有限定的。 def factorial(n): return 1 if n \u003c=1 else n*factorial(n-1) factorial(5000) RecursionError: maximum recursion depth exceeded in comparison 在sys模块中有个方法可以得到递归的层数: import sys sys.getrecursionlimit() 3000 当然你也可以重新设定递归的层数： sys.setrecursionlimit(10000) 那是不是可以设定无穷大呢？理论上可以，但你的程序崩溃也是一定的，我的mac内存是16G，如果把递归层数设定到1百万，大概跑到35000层左右，我的服务就挂了。\n在 Python 中，对象的赋值就是简单的对象引用，这点和 C++不同\n二、浅拷贝(shallow copy):\n浅拷贝会创建新对象，其内容非原对象本身的引用，而是原对象内第一层对象的引用。浅拷贝有三种形式:切片操作、工厂函数、copy 模块中的 copy 函数。\n三、深拷贝(deep copy):\n深拷贝只有一种形式，copy 模块中的 deepcopy()函数。深拷贝和浅拷贝对应，深拷贝拷贝了对象的所有元素，包括多层嵌套的元素。因此，它的时间和空间开销要高。\n四、拷贝的注意点:\n1、对于非容器类型，如数字、字符，以及其他的“原子”类型，没有拷贝一说，产生的都是原对象的引用。 2、如果元组变量值包含原子类型对象，即使采用了深拷贝，也只能得到浅拷贝。2019-07-08yshan 👍（71） 💬（0）浅拷贝，不可变的不可变，可变的依旧可变 深拷贝，都不可变2019-06-12Jason 👍（18） 💬（3）x.append(x)为什么会产生无限嵌套的列表呢？2019-06-12张丽娜 👍（12） 💬（4）a = 257 b = 257 print(id(a)) print(id(b)) 在pycharm中运行结果中一致2019-06-12hlz-123 👍（12） 💬（1）# 以下命令的输出是？ x == y\n出现如下错误信息，推测原因是x与y的列表进行一项一项比较，因无限嵌套，导致递归深度失败。 RecursionError: maximum recursion depth exceeded in comparison 两个问题，需要老师解答 既然是无限嵌套，为什么x.append(x)没有报错？ 运行len(x),结果为2,更是不可理解 x = 1 y = copy.deepcopy(x) x is y # failed True\nx = '1' y = copy.deepcopy(x) x is y # failed True\nx = (1) y = copy.deepcopy(x) x is y # failed True\nx = (1,[]) y = copy.deepcopy(x) x is y # succeed False\n当对数值、字符串、仅包含数值/字符串的元组进行浅/深拷贝会失效。 也就是文中所提到的, 会返回一个指向相同数值、字符串、元组的引用~2019-06-12明月 👍（4） 💬（1）我的x超过256的还是is或者==为true 不知道是不是版本和机器的原因 我的是python3.5.32019-06-12Dynasterran 👍（3） 💬（0）没看源码，猜的：\n为什么 len(x) 是 2。 \u003e\u003e x = [1] \u003e\u003e id(x) 4378931848 \u003e\u003e x.append(x) \u003e\u003e id(x) 4378931848 \u003e\u003e id(x[0]) 4304870656 \u003e\u003e id(x[1]) 4378931848 \u003e\u003e x[1] is x True \u003e\u003e len(x) 2\n为什么 x == y 会报错。 ‘==’ 搜到 x[1] 时发现 x[1] 指向一个列表 x'，又去遍历这个列表 x' 的每个值，然后发现这个列表里的 x'[1] 又指向一个列表 x'', … 实际上 x, x', x'' 都是同一个，无限循环。2019-06-18Jon徐 👍（3） 💬（1）a = 258 b = 258 在python解释器中使用id查看确实内存地址不同，但是使用vs code同样也是python解释器，内存地址是相同的。\n思考题中 x 是循环嵌套的列表，比较时超过了递归限制报错\n"
            }
        );
    index.add(
            {
                id:  25 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/16---%E5%80%BC%E4%BC%A0%E9%80%92%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92or%E5%85%B6%E4%BB%96python%E9%87%8C%E5%8F%82%E6%95%B0%E6%98%AF%E5%A6%82%E4%BD%95%E4%BC%A0%E9%80%92%E7%9A%84\/",
                title: "值传递，引用传递or其他，Python里参数是如何传递的？",
                description: "你好，我是景霄。\n在前面的第一大章节中，我们一起学习了Python的函数基础及其应用。我们大致明白了，所谓的传参，就是把一些参数从一个函数传递到另一个函数，从而使其执行相应的任务。但是你有没有想过，参数传递的底层是如何工作的，原理又是怎样的呢？\n实际工作中，很多人会遇到这样的场景：写完了代码，一测试，发现结果和自己期望的不一样，于是开始一层层地debug。花了很多时间，可到最后才发现，是传参过程中数据结构的改变，导致了程序的“出错”。\n比如，我将一个列表作为参数传入另一个函数，期望列表在函数运行结束后不变，但是往往“事与愿违”，由于某些操作，它的值改变了，那就很有可能带来后续程序一系列的错误。\n因此，了解Python中参数的传递机制，具有十分重要的意义，这往往能让我们写代码时少犯错误，提高效率。今天我们就一起来学习一下，Python中参数是如何传递的。\n什么是值传递和引用传递 link如果你接触过其他的编程语言，比如C/C++，很容易想到，常见的参数传递有2种：值传递和引用传递。所谓值传递，通常就是拷贝参数的值，然后传递给函数里的新变量。这样，原变量和新变量之间互相独立，互不影响。\n比如，我们来看下面的一段C++代码：\n#include using namespace std;\r// 交换2个变量的值\rvoid swap(int x, int y) {\rint temp;\rtemp = x; // 交换x和y的值\rx = y;\ry = temp;\rreturn;\r}\rint main () {\rint a = 1;\rint b = 2;\rcout \u003c\u003c \"Before swap, value of a :\" \u003c\u003c a \u003c\u003c endl;\rcout \u003c\u003c \"Before swap, value of b :\" \u003c\u003c b \u003c\u003c endl;\rswap(a, b); cout \u003c\u003c \"After swap, value of a :\" \u003c\u003c a \u003c\u003c endl;\rcout \u003c\u003c \"After swap, value of b :\" \u003c\u003c b \u003c\u003c endl;\rreturn 0;\r}\rBefore swap, value of a :1\rBefore swap, value of b :2\rAfter swap, value of a :1\rAfter swap, value of b :2 这里的swap()函数，把a和b的值拷贝给了x和y，然后再交换x和y的值。这样一来，x和y的值发生了改变，但是a和b不受其影响，所以值不变。这种方式，就是我们所说的值传递。\n",
                content: "你好，我是景霄。\n在前面的第一大章节中，我们一起学习了Python的函数基础及其应用。我们大致明白了，所谓的传参，就是把一些参数从一个函数传递到另一个函数，从而使其执行相应的任务。但是你有没有想过，参数传递的底层是如何工作的，原理又是怎样的呢？\n实际工作中，很多人会遇到这样的场景：写完了代码，一测试，发现结果和自己期望的不一样，于是开始一层层地debug。花了很多时间，可到最后才发现，是传参过程中数据结构的改变，导致了程序的“出错”。\n比如，我将一个列表作为参数传入另一个函数，期望列表在函数运行结束后不变，但是往往“事与愿违”，由于某些操作，它的值改变了，那就很有可能带来后续程序一系列的错误。\n因此，了解Python中参数的传递机制，具有十分重要的意义，这往往能让我们写代码时少犯错误，提高效率。今天我们就一起来学习一下，Python中参数是如何传递的。\n什么是值传递和引用传递 link如果你接触过其他的编程语言，比如C/C++，很容易想到，常见的参数传递有2种：值传递和引用传递。所谓值传递，通常就是拷贝参数的值，然后传递给函数里的新变量。这样，原变量和新变量之间互相独立，互不影响。\n比如，我们来看下面的一段C++代码：\n#include using namespace std;\r// 交换2个变量的值\rvoid swap(int x, int y) {\rint temp;\rtemp = x; // 交换x和y的值\rx = y;\ry = temp;\rreturn;\r}\rint main () {\rint a = 1;\rint b = 2;\rcout \u003c\u003c \"Before swap, value of a :\" \u003c\u003c a \u003c\u003c endl;\rcout \u003c\u003c \"Before swap, value of b :\" \u003c\u003c b \u003c\u003c endl;\rswap(a, b); cout \u003c\u003c \"After swap, value of a :\" \u003c\u003c a \u003c\u003c endl;\rcout \u003c\u003c \"After swap, value of b :\" \u003c\u003c b \u003c\u003c endl;\rreturn 0;\r}\rBefore swap, value of a :1\rBefore swap, value of b :2\rAfter swap, value of a :1\rAfter swap, value of b :2 这里的swap()函数，把a和b的值拷贝给了x和y，然后再交换x和y的值。这样一来，x和y的值发生了改变，但是a和b不受其影响，所以值不变。这种方式，就是我们所说的值传递。\n所谓引用传递，通常是指把参数的引用传给新的变量，这样，原变量和新变量就会指向同一块内存地址。如果改变了其中任何一个变量的值，那么另外一个变量也会相应地随之改变。\n还是拿我们刚刚讲到的C++代码为例，上述例子中的swap()函数，如果改成下面的形式，声明引用类型的参数变量：\nvoid swap(int\u0026 x, int\u0026 y) {\rint temp;\rtemp = x; // 交换x和y的值\rx = y;\ry = temp;\rreturn;\r} 那么输出的便是另一个结果：\nBefore swap, value of a :1\rBefore swap, value of b :2\rAfter swap, value of a :2\rAfter swap, value of b :1 原变量a和b的值被交换了，因为引用传递使得a和x，b和y一模一样，对x和y的任何改变必然导致了a和b的相应改变。\n不过，这是C/C++语言中的特点。那么Python中，参数传递到底是如何进行的呢？它们到底属于值传递、引用传递，还是其他呢？\n在回答这个问题之前，让我们先来了解一下，Python变量和赋值的基本原理。\nPython变量及其赋值 link我们首先来看，下面的Python代码示例：\na = 1\rb = a\ra = a + 1 这里首先将1赋值于a，即a指向了1这个对象，如下面的流程图所示：\n接着b = a则表示，让变量b也同时指向1这个对象。这里要注意，Python里的对象可以被多个变量所指向或引用。\n最后执行a = a + 1。需要注意的是，Python的数据类型，例如整型（int）、字符串（string）等等，是不可变的。所以，a = a + 1，并不是让a的值增加1，而是表示重新创建了一个新的值为2的对象，并让a指向它。但是b仍然不变，仍然指向1这个对象。\n因此，最后的结果是，a的值变成了2，而b的值不变仍然是1。\n通过这个例子你可以看到，这里的a和b，开始只是两个指向同一个对象的变量而已，或者你也可以把它们想象成同一个对象的两个名字。简单的赋值b = a，并不表示重新创建了新对象，只是让同一个对象被多个变量指向或引用。\n同时，指向同一个对象，也并不意味着两个变量就被绑定到了一起。如果你给其中一个变量重新赋值，并不会影响其他变量的值。\n明白了这个基本的变量赋值例子，我们再来看一个列表的例子：\nl1 = [1, 2, 3]\rl2 = l1\rl1.append(4)\rl1\r[1, 2, 3, 4]\rl2\r[1, 2, 3, 4] 同样的，我们首先让列表l1和l2同时指向了[1, 2, 3]这个对象。\n由于列表是可变的，所以l1.append(4)不会创建新的列表，只是在原列表的末尾插入了元素4，变成[1, 2, 3, 4]。由于l1和l2同时指向这个列表，所以列表的变化会同时反映在l1和l2这两个变量上，那么，l1和l2的值就同时变为了[1, 2, 3, 4]。\n另外，需要注意的是，Python里的变量可以被删除，但是对象无法被删除。比如下面的代码：\nl = [1, 2, 3]\rdel l del l 删除了l这个变量，从此以后你无法访问l，但是对象[1, 2, 3]仍然存在。Python程序运行时，其自带的垃圾回收系统会跟踪每个对象的引用。如果[1, 2, 3]除了l外，还在其他地方被引用，那就不会被回收，反之则会被回收。\n由此可见，在Python中：\n变量的赋值，只是表示让变量指向了某个对象，并不表示拷贝对象给变量；而一个对象，可以被多个变量所指向。 可变对象（列表，字典，集合等等）的改变，会影响所有指向该对象的变量。 对于不可变对象（字符串、整型、元组等等），所有指向该对象的变量的值总是一样的，也不会改变。但是通过某些操作（+=等等）更新不可变对象的值时，会返回一个新的对象。 变量可以被删除，但是对象无法被删除。 Python函数的参数传递 link从上述Python变量的命名与赋值的原理讲解中，相信你能举一反三，大概猜出Python函数中参数是如何传递了吧？\n这里首先引用Python官方文档中的一段说明：\n“Remember that arguments are passed by assignment in Python. Since assignment just creates references to objects, there’s no alias between an argument name in the caller and callee, and so no call-by-reference per Se.”\n准确地说，Python的参数传递是赋值传递 （pass by assignment），或者叫作对象的引用传递（pass by object reference）。Python里所有的数据类型都是对象，所以参数传递时，只是让新变量与原变量指向相同的对象而已，并不存在值传递或是引用传递一说。\n比如，我们来看下面这个例子：\ndef my_func1(b):\rb = 2\ra = 1\rmy_func1(a)\ra\r1 这里的参数传递，使变量a和b同时指向了1这个对象。但当我们执行到b = 2时，系统会重新创建一个值为2的新对象，并让b指向它；而a仍然指向1这个对象。所以，a的值不变，仍然为1。\n那么对于上述例子的情况，是不是就没有办法改变a的值了呢？\n答案当然是否定的，我们只需稍作改变，让函数返回新变量，赋给a。这样，a就指向了一个新的值为2的对象，a的值也因此变为2。\ndef my_func2(b):\rb = 2\rreturn b\ra = 1\ra = my_func2(a)\ra\r2 不过，当可变对象当作参数传入函数里的时候，改变可变对象的值，就会影响所有指向它的变量。比如下面的例子：\ndef my_func3(l2):\rl2.append(4)\rl1 = [1, 2, 3]\rmy_func3(l1)\rl1\r[1, 2, 3, 4] 这里l1和l2先是同时指向值为[1, 2, 3]的列表。不过，由于列表可变，执行append()函数，对其末尾加入新元素4时，变量l1和l2的值也都随之改变了。\n但是，下面这个例子，看似都是给列表增加了一个新元素，却得到了明显不同的结果。\ndef my_func4(l2):\rl2 = l2 + [4]\rl1 = [1, 2, 3]\rmy_func4(l1)\rl1\r[1, 2, 3] 为什么l1仍然是[1, 2, 3]，而不是[1, 2, 3, 4]呢？\n要注意，这里l2 = l2 + [4]，表示创建了一个“末尾加入元素4“的新列表，并让l2指向这个新的对象。这个过程与l1无关，因此l1的值不变。当然，同样的，如果要改变l1的值，我们就得让上述函数返回一个新列表，再赋予l1即可：\ndef my_func5(l2):\rl2 = l2 + [4]\rreturn l2\rl1 = [1, 2, 3]\rl1 = my_func5(l1)\rl1\r[1, 2, 3, 4] 这里你尤其要记住的是，改变变量和重新赋值的区别：\nmy_func3()中单纯地改变了对象的值，因此函数返回后，所有指向该对象的变量都会被改变； 但my_func4()中则创建了新的对象，并赋值给一个本地变量，因此原变量仍然不变。 至于my_func3()和my_func5()的用法，两者虽然写法不同，但实现的功能一致。不过，在实际工作应用中，我们往往倾向于类似my_func5()的写法，添加返回语句。这样更简洁明了，不易出错。\n总结 link今天，我们一起学习了Python的变量及其赋值的基本原理，并且解释了Python中参数是如何传递的。和其他语言不同的是，Python中参数的传递既不是值传递，也不是引用传递，而是赋值传递，或者是叫对象的引用传递。\n需要注意的是，这里的赋值或对象的引用传递，不是指向一个具体的内存地址，而是指向一个具体的对象。\n如果对象是可变的，当其改变时，所有指向这个对象的变量都会改变。 如果对象不可变，简单的赋值只能改变其中一个变量的值，其余变量则不受影响。 清楚了这一点，如果你想通过一个函数来改变某个变量的值，通常有两种方法。一种是直接将可变数据类型（比如列表，字典，集合）当作参数传入，直接在其上修改；第二种则是创建一个新变量，来保存修改后的值，然后将其返回给原变量。在实际工作中，我们更倾向于使用后者，因为其表达清晰明了，不易出错。\n思考题 link最后，我为你留下了两道思考题。\n第一个问题，下面的代码中, l1、l2和l3都指向同一个对象吗？\nl1 = [1, 2, 3]\rl2 = [1, 2, 3]\rl3 = l2 第二个问题，下面的代码中，打印d最后的输出是什么呢？\ndef func(d):\rd['a'] = 10\rd['b'] = 20\rd = {'a': 1, 'b': 2}\rfunc(d)\rprint(d) 欢迎留言和我分享，也欢迎你把这篇文章分享给你的同事、朋友，一起在交流中进步。\n第二题： 输出的是{'a': 10, 'b': 20}，字典是可变的，传入函数后，函数里的d和外部的d实际上都指向同一个对象 d[idx] = value语句改变了字典对应key所指向的值\n"
            }
        );
    index.add(
            {
                id:  26 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/17---%E5%BC%BA%E5%A4%A7%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8\/",
                title: "强大的装饰器",
                description: "你好，我是景霄。这节课，我们一起来学习装饰器。\n装饰器一直以来都是Python中很有用、很经典的一个feature，在工程中的应用也十分广泛，比如日志、缓存等等的任务都会用到。然而，在平常工作生活中，我发现不少人，尤其是初学者，常常因为其相对复杂的表示，对装饰器望而生畏，认为它“too fancy to learn”，实际并不如此。\n今天这节课，我会以前面所讲的函数、闭包为切入点，引出装饰器的概念、表达和基本用法，最后，再通过实际工程中的例子，让你再次加深理解。\n接下来，让我们进入正文一起学习吧！\n函数-\u003e装饰器 link函数核心回顾 link引入装饰器之前，我们首先一起来复习一下，必须掌握的函数的几个核心概念。\n第一点，我们要知道，在Python中，函数是一等公民（first-class citizen），函数也是对象。我们可以把函数赋予变量，比如下面这段代码：\ndef func(message):\rprint('Got a message: {}'.format(message))\rsend_message = func\rsend_message('hello world')\r# 输出\rGot a message: hello world 这个例子中，我们把函数func赋予了变量send_message，这样之后你调用send_message，就相当于是调用函数func()。\n第二点，我们可以把函数当作参数，传入另一个函数中，比如下面这段代码：\ndef get_message(message):\rreturn 'Got a message: ' + message\rdef root_call(func, message):\rprint(func(message))\rroot_call(get_message, 'hello world')\r# 输出\rGot a message: hello world 这个例子中，我们就把函数get_message以参数的形式，传入了函数root_call()中然后调用它。\n第三点，我们可以在函数里定义函数，也就是函数的嵌套。这里我同样举了一个例子：\ndef func(message):\rdef get_message(message):\rprint('Got a message: {}'.format(message))\rreturn get_message(message)\rfunc('hello world')\r# 输出\rGot a message: hello world 这段代码中，我们在函数func()里又定义了新的函数get_message()，调用后作为func()的返回值返回。\n",
                content: "你好，我是景霄。这节课，我们一起来学习装饰器。\n装饰器一直以来都是Python中很有用、很经典的一个feature，在工程中的应用也十分广泛，比如日志、缓存等等的任务都会用到。然而，在平常工作生活中，我发现不少人，尤其是初学者，常常因为其相对复杂的表示，对装饰器望而生畏，认为它“too fancy to learn”，实际并不如此。\n今天这节课，我会以前面所讲的函数、闭包为切入点，引出装饰器的概念、表达和基本用法，最后，再通过实际工程中的例子，让你再次加深理解。\n接下来，让我们进入正文一起学习吧！\n函数-\u003e装饰器 link函数核心回顾 link引入装饰器之前，我们首先一起来复习一下，必须掌握的函数的几个核心概念。\n第一点，我们要知道，在Python中，函数是一等公民（first-class citizen），函数也是对象。我们可以把函数赋予变量，比如下面这段代码：\ndef func(message):\rprint('Got a message: {}'.format(message))\rsend_message = func\rsend_message('hello world')\r# 输出\rGot a message: hello world 这个例子中，我们把函数func赋予了变量send_message，这样之后你调用send_message，就相当于是调用函数func()。\n第二点，我们可以把函数当作参数，传入另一个函数中，比如下面这段代码：\ndef get_message(message):\rreturn 'Got a message: ' + message\rdef root_call(func, message):\rprint(func(message))\rroot_call(get_message, 'hello world')\r# 输出\rGot a message: hello world 这个例子中，我们就把函数get_message以参数的形式，传入了函数root_call()中然后调用它。\n第三点，我们可以在函数里定义函数，也就是函数的嵌套。这里我同样举了一个例子：\ndef func(message):\rdef get_message(message):\rprint('Got a message: {}'.format(message))\rreturn get_message(message)\rfunc('hello world')\r# 输出\rGot a message: hello world 这段代码中，我们在函数func()里又定义了新的函数get_message()，调用后作为func()的返回值返回。\n第四点，要知道，函数的返回值也可以是函数对象（闭包），比如下面这个例子：\ndef func_closure():\rdef get_message(message):\rprint('Got a message: {}'.format(message))\rreturn get_message\rsend_message = func_closure()\rsend_message('hello world')\r# 输出\rGot a message: hello world 这里，函数func_closure()的返回值是函数对象get_message本身，之后，我们将其赋予变量send_message，再调用send_message(‘hello world’)，最后输出了'Got a message: hello world'。\n简单的装饰器 link简单的复习之后，我们接下来学习今天的新知识——装饰器。按照习惯，我们可以先来看一个装饰器的简单例子：\ndef my_decorator(func):\rdef wrapper():\rprint('wrapper of decorator')\rfunc()\rreturn wrapper\rdef greet():\rprint('hello world')\rgreet = my_decorator(greet)\rgreet()\r# 输出\rwrapper of decorator\rhello world 这段代码中，变量greet指向了内部函数wrapper()，而内部函数wrapper()中又会调用原函数greet()，因此，最后调用greet()时，就会先打印'wrapper of decorator'，然后输出'hello world'。\n这里的函数my_decorator()就是一个装饰器，它把真正需要执行的函数greet()包裹在其中，并且改变了它的行为，但是原函数greet()不变。\n事实上，上述代码在Python中有更简单、更优雅的表示：\ndef my_decorator(func):\rdef wrapper():\rprint('wrapper of decorator')\rfunc()\rreturn wrapper\r@my_decorator\rdef greet():\rprint('hello world')\rgreet() 这里的@，我们称之为语法糖，@my_decorator就相当于前面的greet=my_decorator(greet)语句，只不过更加简洁。因此，如果你的程序中有其它函数需要做类似的装饰，你只需在它们的上方加上@decorator就可以了，这样就大大提高了函数的重复利用和程序的可读性。\n带有参数的装饰器 link你或许会想到，如果原函数greet()中，有参数需要传递给装饰器怎么办？\n一个简单的办法，是可以在对应的装饰器函数wrapper()上，加上相应的参数，比如：\ndef my_decorator(func):\rdef wrapper(message):\rprint('wrapper of decorator')\rfunc(message)\rreturn wrapper\r@my_decorator\rdef greet(message):\rprint(message)\rgreet('hello world')\r# 输出\rwrapper of decorator\rhello world 不过，新的问题来了。如果我另外还有一个函数，也需要使用my_decorator()装饰器，但是这个新的函数有两个参数，又该怎么办呢？比如：\n@my_decorator\rdef celebrate(name, message):\r... 事实上，通常情况下，我们会把*args和**kwargs，作为装饰器内部函数wrapper()的参数。*args和**kwargs，表示接受任意数量和类型的参数，因此装饰器就可以写成下面的形式：\ndef my_decorator(func):\rdef wrapper(*args, **kwargs):\rprint('wrapper of decorator')\rfunc(*args, **kwargs)\rreturn wrapper 带有自定义参数的装饰器 link其实，装饰器还有更大程度的灵活性。刚刚说了，装饰器可以接受原函数任意类型和数量的参数，除此之外，它还可以接受自己定义的参数。\n举个例子，比如我想要定义一个参数，来表示装饰器内部函数被执行的次数，那么就可以写成下面这种形式：\ndef repeat(num):\rdef my_decorator(func):\rdef wrapper(*args, **kwargs):\rfor i in range(num):\rprint('wrapper of decorator')\rfunc(*args, **kwargs)\rreturn wrapper\rreturn my_decorator\r@repeat(4)\rdef greet(message):\rprint(message)\rgreet('hello world')\r# 输出：\rwrapper of decorator\rhello world\rwrapper of decorator\rhello world\rwrapper of decorator\rhello world\rwrapper of decorator\rhello world 原函数还是原函数吗？ link现在，我们再来看个有趣的现象。还是之前的例子，我们试着打印出greet()函数的一些元信息：\ngreet.__name__\r## 输出\r'wrapper'\rhelp(greet)\r# 输出\rHelp on function wrapper in module __main__:\rwrapper(*args, **kwargs) 你会发现，greet()函数被装饰以后，它的元信息变了。元信息告诉我们“它不再是以前的那个greet()函数，而是被wrapper()函数取代了”。\n为了解决这个问题，我们通常使用内置的装饰器@functools.wrap，它会帮助保留原函数的元信息（也就是将原函数的元信息，拷贝到对应的装饰器函数里）。\nimport functools\rdef my_decorator(func):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rprint('wrapper of decorator')\rfunc(*args, **kwargs)\rreturn wrapper\r@my_decorator\rdef greet(message):\rprint(message)\rgreet.__name__\r# 输出\r'greet' 类装饰器 link前面我们主要讲了函数作为装饰器的用法，实际上，类也可以作为装饰器。类装饰器主要依赖于函数__call__()，每当你调用一个类的示例时，函数__call__()就会被执行一次。\n我们来看下面这段代码：\nclass Count:\rdef __init__(self, func):\rself.func = func\rself.num_calls = 0\rdef __call__(self, *args, **kwargs):\rself.num_calls += 1\rprint('num of calls is: {}'.format(self.num_calls))\rreturn self.func(*args, **kwargs)\r@Count\rdef example():\rprint(\"hello world\")\rexample()\r# 输出\rnum of calls is: 1\rhello world\rexample()\r# 输出\rnum of calls is: 2\rhello world\r... 这里，我们定义了类Count，初始化时传入原函数func()，而__call__()函数表示让变量num_calls自增1，然后打印，并且调用原函数。因此，在我们第一次调用函数example()时，num_calls的值是1，而在第二次调用时，它的值变成了2。\n装饰器的嵌套 link回顾刚刚讲的例子，基本都是一个装饰器的情况，但实际上，Python也支持多个装饰器，比如写成下面这样的形式：\n@decorator1\r@decorator2\r@decorator3\rdef func():\r... 它的执行顺序从里到外，所以上面的语句也等效于下面这行代码：\ndecorator1(decorator2(decorator3(func))) 这样，'hello world'这个例子，就可以改写成下面这样：\nimport functools\rdef my_decorator1(func):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rprint('execute decorator1')\rfunc(*args, **kwargs)\rreturn wrapper\rdef my_decorator2(func):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rprint('execute decorator2')\rfunc(*args, **kwargs)\rreturn wrapper\r@my_decorator1\r@my_decorator2\rdef greet(message):\rprint(message)\rgreet('hello world')\r# 输出\rexecute decorator1\rexecute decorator2\rhello world 装饰器用法实例 link到此，装饰器的基本概念及用法我就讲完了，接下来，我将结合实际工作中的几个例子，带你加深对它的理解。\n身份认证 link首先是最常见的身份认证的应用。这个很容易理解，举个最常见的例子，你登录微信，需要输入用户名密码，然后点击确认，这样，服务器端便会查询你的用户名是否存在、是否和密码匹配等等。如果认证通过，你就可以顺利登录；如果不通过，就抛出异常并提示你登录失败。\n再比如一些网站，你不登录也可以浏览内容，但如果你想要发布文章或留言，在点击发布时，服务器端便会查询你是否登录。如果没有登录，就不允许这项操作等等。\n我们来看一个大概的代码示例：\nimport functools\rdef authenticate(func):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rrequest = args[0]\rif check_user_logged_in(request): # 如果用户处于登录状态\rreturn func(*args, **kwargs) # 执行函数post_comment() else:\rraise Exception('Authentication failed')\rreturn wrapper\r@authenticate\rdef post_comment(request, ...)\r...\r这段代码中，我们定义了装饰器authenticate；而函数post_comment()，则表示发表用户对某篇文章的评论。每次调用这个函数前，都会先检查用户是否处于登录状态，如果是登录状态，则允许这项操作；如果没有登录，则不允许。\n日志记录 link日志记录同样是很常见的一个案例。在实际工作中，如果你怀疑某些函数的耗时过长，导致整个系统的latency（延迟）增加，所以想在线上测试某些函数的执行时间，那么，装饰器就是一种很常用的手段。\n我们通常用下面的方法来表示：\nimport time\rimport functools\rdef log_execution_time(func):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rstart = time.perf_counter()\rres = func(*args, **kwargs)\rend = time.perf_counter()\rprint('{} took {} ms'.format(func.__name__, (end - start) * 1000))\rreturn res\rreturn wrapper\r@log_execution_time\rdef calculate_similarity(items):\r... 这里，装饰器log_execution_time记录某个函数的运行时间，并返回其执行结果。如果你想计算任何函数的执行时间，在这个函数上方加上@log_execution_time即可。\n输入合理性检查 link再来看今天要讲的第三个应用，输入合理性检查。\n在大型公司的机器学习框架中，我们调用机器集群进行模型训练前，往往会用装饰器对其输入（往往是很长的JSON文件）进行合理性检查。这样就可以大大避免，输入不正确对机器造成的巨大开销。\n它的写法往往是下面的格式：\nimport functools\rdef validation_check(input):\r@functools.wraps(func)\rdef wrapper(*args, **kwargs): ... # 检查输入是否合法\r@validation_check\rdef neural_network_training(param1, param2, ...):\r... 其实在工作中，很多情况下都会出现输入不合理的现象。因为我们调用的训练模型往往很复杂，输入的文件有成千上万行，很多时候确实也很难发现。\n试想一下，如果没有输入的合理性检查，很容易出现“模型训练了好几个小时后，系统却报错说输入的一个参数不对，成果付之一炬”的现象。这样的“惨案”，大大减缓了开发效率，也对机器资源造成了巨大浪费。\n缓存 link最后，我们来看缓存方面的应用。关于缓存装饰器的用法，其实十分常见，这里我以Python内置的LRU cache为例来说明（如果你不了解 LRU cache，可以点击链接自行查阅）。\nLRU cache，在Python中的表示形式是@lru_cache。@lru_cache会缓存进程中的函数参数和结果，当缓存满了以后，会删除least recenly used 的数据。\n正确使用缓存装饰器，往往能极大地提高程序运行效率。为什么呢？我举一个常见的例子来说明。\n大型公司服务器端的代码中往往存在很多关于设备的检查，比如你使用的设备是安卓还是iPhone，版本号是多少。这其中的一个原因，就是一些新的feature，往往只在某些特定的手机系统或版本上才有（比如Android v200+）。\n这样一来，我们通常使用缓存装饰器，来包裹这些检查函数，避免其被反复调用，进而提高程序运行效率，比如写成下面这样：\n@lru_cache\rdef check(param1, param2, ...) # 检查用户设备类型，版本号等等\r... 总结 link这节课，我们一起学习了装饰器的概念及用法。所谓的装饰器，其实就是通过装饰器函数，来修改原函数的一些功能，使得原函数不需要修改。\nDecorators is to modify the behavior of the function through a wrapper so we don’t have to actually modify the function.\n而实际工作中，装饰器通常运用在身份认证、日志记录、输入合理性检查以及缓存等多个领域中。合理使用装饰器，往往能极大地提高程序的可读性以及运行效率。\n思考题 link那么，你平时工作中，通常会在哪些情况下使用装饰器呢？欢迎留言和我讨论，也欢迎你把这篇文章分享给你的同事、朋友，一起在交流中进步。\n我尝试如下会报错： 第1点：send_message = func() 第4点：send_message = func_closure\n想知道这是哪一个知识点，谢谢2019-06-17吴星 👍（12） 💬（12）请教下，为什么count那儿是单例模式吗？为什么二次执行会加1？2019-06-17被炸的油条 👍（9） 💬（1）工作当中，如果是二次开发，在原来的需求基础之上做优化，原逻辑不需要修改的情况下，只需增加新的业务场景的时候，感觉用装饰器挺好的。不动原来的逻辑，增加程序的健壮性。2019-09-22farFlight 👍（8） 💬（4）请问一下，lru cache不是应该删除最久没有访问的内容吗。2019-06-17🇨🇳 👍（7） 💬（2）1、总结中，倒数第二行发现错别字（程序）不是程度。 2、类装饰器在实际中有哪些应用场景呢2019-06-17geraltlaush 👍（6） 💬（1）我之前开发过微服务脚手架，跟装饰器模式很像，就是rpc调用之前，把限流，上报，统计耗时统计在前面，每个功能还可以自由选择执行的时机，跟业务功能分离，开发关注于业务研发就行了2019-11-07enjoylearning 👍（6） 💬（1）还有类装饰器，又长见识了，最近正愁参数校验放哪里，参照本文终于开窍了2019-06-17向南 👍（5） 💬（1）装饰器本质上是一个 Python 函数或类，它可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能，装饰器的返回值也是一个函数/类对象。 它经常用于有特定需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景，装饰器是解决这类问题的绝佳设计。 有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码到装饰器中并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 装饰器并没有修改原函数，或者说装饰器并没有修改原函数的功能，而为其新增其他功能。2020-03-08Hoo-Ah 👍（5） 💬（1）目前工作中使用的是tornado框架，里面依赖tornado.gen.coroutine这个装饰器用来将被装饰的函数变为协程，这样就可以将代码的执行变为异步非阻塞，提高程序的并发量。2019-06-17Jadm 👍（1） 💬（1）老师能不能多出点课程，讲的太好了🤠🤠2020-06-14Ray 👍（0） 💬（1）老师，类装饰器的那个代码中，example是不是变成了Count类一个对象？ 我通过type(example)，返回的是class 'main.Count'2020-02-22大懒虫 👍（0） 💬（1）终于彻底理解了装饰器，感谢老师😄2020-01-11舍予 👍（0） 💬（1）老师，装饰器的作用是不是也可以用函数封装来实现？2019-12-11Defensor 👍（0） 💬（1）老师 能讲解下warpper函数里的return么 我看前面的案例没有return 但是后面有返回func的有返回func结果的 就有点乱了 如果原函数本身需要返回值呢？2019-12-05\n"
            }
        );
    index.add(
            {
                id:  27 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/18---metaclass%E6%98%AF%E6%BD%98%E5%A4%9A%E6%8B%89%E9%AD%94%E7%9B%92%E8%BF%98%E6%98%AF%E9%98%BF%E6%8B%89%E4%B8%81%E7%A5%9E%E7%81%AF\/",
                title: "metaclass，是潘多拉魔盒还是阿拉丁神灯？",
                description: "你好，我是蔡元楠，极客时间《大规模数据处理实战》专栏的作者。今天我想和你分享的主题是：metaclass，是潘多拉魔盒还是阿拉丁神灯？\nPython中有很多黑魔法，比如今天我将分享的metaclass。我认识许多人，对于这些语言特性有两种极端的观点。\n一种人觉得这些语言特性太牛逼了，简直是无所不能的阿拉丁神灯，必须找机会用上才能显示自己的Python实力。 另一种观点则是认为这些语言特性太危险了，会蛊惑人心去滥用，一旦打开就会释放“恶魔”，让整个代码库变得难以维护。 其实这两种看法都有道理，却又都浅尝辄止。今天，我就带你来看看，metaclass到底是潘多拉魔盒还是阿拉丁神灯？\n市面上的很多中文书，都把metaclass译为“元类”。我一直认为这个翻译很糟糕，所以也不想在这里称metaclass为元类。因为如果仅从字面理解，“元”是“本源”“基本”的意思，“元类”会让人以为是“基本类”。难道Python的metaclass，指的是Python 2的Object吗？这就让人一头雾水了。\n事实上，meta-class的meta这个词根，起源于希腊语词汇meta，包含下面两种意思：\n“Beyond”，例如技术词汇metadata，意思是描述数据的超越数据； “Change”，例如技术词汇metamorphosis，意思是改变的形态。 metaclass，一如其名，实际上同时包含了“超越类”和“变形类”的含义，完全不是“基本类”的意思。所以，要深入理解metaclass，我们就要围绕它的超越变形特性。接下来，我将为你展开metaclass的超越变形能力，讲清楚metaclass究竟有什么用？怎么应用？Python语言设计层面是如何实现metaclass的 ？以及使用metaclass的风险。\nmetaclass的超越变形特性有什么用？ linkYAML是一个家喻户晓的Python工具，可以方便地序列化/逆序列化结构数据。YAMLObject的一个超越变形能力，就是它的任意子类支持序列化和反序列化（serialization \u0026 deserialization）。比如说下面这段代码：\nclass Monster(yaml.YAMLObject):\ryaml_tag = u'!Monster'\rdef __init__(self, name, hp, ac, attacks):\rself.name = name\rself.hp = hp\rself.ac = ac\rself.attacks = attacks\rdef __repr__(self):\rreturn \"%s(name=%r, hp=%r, ac=%r, attacks=%r)\" % (\rself.__class__.__name__, self.name, self.hp, self.ac, self.attacks)\ryaml.load(\"\"\"\r--- !Monster\rname: Cave spider\rhp: [2,6] # 2d6\rac: 16\rattacks: [BITE, HURT]\r\"\"\")\rMonster(name='Cave spider', hp=[2, 6], ac=16, attacks=['BITE', 'HURT'])\rprint yaml.dump(Monster(\rname='Cave lizard', hp=[3,6], ac=16, attacks=['BITE','HURT']))\r# 输出\r!Monster\rac: 16\rattacks: [BITE, HURT]\rhp: [3, 6]\rname: Cave lizard 这里YAMLObject的特异功能体现在哪里呢？\n",
                content: "你好，我是蔡元楠，极客时间《大规模数据处理实战》专栏的作者。今天我想和你分享的主题是：metaclass，是潘多拉魔盒还是阿拉丁神灯？\nPython中有很多黑魔法，比如今天我将分享的metaclass。我认识许多人，对于这些语言特性有两种极端的观点。\n一种人觉得这些语言特性太牛逼了，简直是无所不能的阿拉丁神灯，必须找机会用上才能显示自己的Python实力。 另一种观点则是认为这些语言特性太危险了，会蛊惑人心去滥用，一旦打开就会释放“恶魔”，让整个代码库变得难以维护。 其实这两种看法都有道理，却又都浅尝辄止。今天，我就带你来看看，metaclass到底是潘多拉魔盒还是阿拉丁神灯？\n市面上的很多中文书，都把metaclass译为“元类”。我一直认为这个翻译很糟糕，所以也不想在这里称metaclass为元类。因为如果仅从字面理解，“元”是“本源”“基本”的意思，“元类”会让人以为是“基本类”。难道Python的metaclass，指的是Python 2的Object吗？这就让人一头雾水了。\n事实上，meta-class的meta这个词根，起源于希腊语词汇meta，包含下面两种意思：\n“Beyond”，例如技术词汇metadata，意思是描述数据的超越数据； “Change”，例如技术词汇metamorphosis，意思是改变的形态。 metaclass，一如其名，实际上同时包含了“超越类”和“变形类”的含义，完全不是“基本类”的意思。所以，要深入理解metaclass，我们就要围绕它的超越变形特性。接下来，我将为你展开metaclass的超越变形能力，讲清楚metaclass究竟有什么用？怎么应用？Python语言设计层面是如何实现metaclass的 ？以及使用metaclass的风险。\nmetaclass的超越变形特性有什么用？ linkYAML是一个家喻户晓的Python工具，可以方便地序列化/逆序列化结构数据。YAMLObject的一个超越变形能力，就是它的任意子类支持序列化和反序列化（serialization \u0026 deserialization）。比如说下面这段代码：\nclass Monster(yaml.YAMLObject):\ryaml_tag = u'!Monster'\rdef __init__(self, name, hp, ac, attacks):\rself.name = name\rself.hp = hp\rself.ac = ac\rself.attacks = attacks\rdef __repr__(self):\rreturn \"%s(name=%r, hp=%r, ac=%r, attacks=%r)\" % (\rself.__class__.__name__, self.name, self.hp, self.ac, self.attacks)\ryaml.load(\"\"\"\r--- !Monster\rname: Cave spider\rhp: [2,6] # 2d6\rac: 16\rattacks: [BITE, HURT]\r\"\"\")\rMonster(name='Cave spider', hp=[2, 6], ac=16, attacks=['BITE', 'HURT'])\rprint yaml.dump(Monster(\rname='Cave lizard', hp=[3,6], ac=16, attacks=['BITE','HURT']))\r# 输出\r!Monster\rac: 16\rattacks: [BITE, HURT]\rhp: [3, 6]\rname: Cave lizard 这里YAMLObject的特异功能体现在哪里呢？\n你看，调用统一的yaml.load()，就能把任意一个yaml序列载入成一个Python Object；而调用统一的yaml.dump()，就能把一个YAMLObject子类序列化。对于load()和dump()的使用者来说，他们完全不需要提前知道任何类型信息，这让超动态配置编程成了可能。在我的实战经验中，许多大型项目都需要应用这种超动态配置的理念。\n比方说，在一个智能语音助手的大型项目中，我们有1万个语音对话场景，每一个场景都是不同团队开发的。作为智能语音助手的核心团队成员，我不可能去了解每个子场景的实现细节。\n在动态配置实验不同场景时，经常是今天我要实验场景A和B的配置，明天实验B和C的配置，光配置文件就有几万行量级，工作量真是不小。而应用这样的动态配置理念，我就可以让引擎根据我的文本配置文件，动态加载所需要的Python类。\n对于YAML的使用者，这一点也很方便，你只要简单地继承yaml.YAMLObject，就能让你的Python Object具有序列化和逆序列化能力。是不是相比普通Python类，有一点“变态”，有一点“超越”？\n事实上，我在Google见过很多Python开发者，发现能深入解释YAML这种设计模式优点的人，大概只有10%。而能知道类似YAML的这种动态序列化/逆序列化功能正是用metaclass实现的人，更是凤毛麟角，可能只有1%了。\nmetaclass的超越变形特性怎么用？ link刚刚提到，估计只有1%的Python开发者，知道YAML的动态序列化/逆序列化是由metaclass实现的。如果你追问，YAML怎样用metaclass实现动态序列化/逆序列化功能，可能只有0.1%的人能说得出一二了。\n因为篇幅原因，我们这里只看YAMLObject的load()功能。简单来说，我们需要一个全局的注册器，让YAML知道，序列化文本中的 !Monster 需要载入成 Monster这个Python类型。\n一个很自然的想法就是，那我们建立一个全局变量叫 registry，把所有需要逆序列化的YAMLObject，都注册进去。比如下面这样：\nregistry = {}\rdef add_constructor(target_class):\rregistry[target_class.yaml_tag] = target_class 然后，在Monster 类定义后面加上下面这行代码：\nadd_constructor(Monster) 但这样的缺点也很明显，对于YAML的使用者来说，每一个YAML的可逆序列化的类Foo定义后，都需要加上一句话，add_constructor(Foo)。这无疑给开发者增加了麻烦，也更容易出错，毕竟开发者很容易忘了这一点。\n那么，更优的实现方式是什么样呢？如果你看过YAML的源码，就会发现，正是metaclass解决了这个问题。\n# Python 2/3 相同部分\rclass YAMLObjectMetaclass(type):\rdef __init__(cls, name, bases, kwds):\rsuper(YAMLObjectMetaclass, cls).__init__(name, bases, kwds)\rif 'yaml_tag' in kwds and kwds['yaml_tag'] is not None:\rcls.yaml_loader.add_constructor(cls.yaml_tag, cls.from_yaml)\r# 省略其余定义\r# Python 3\rclass YAMLObject(metaclass=YAMLObjectMetaclass):\ryaml_loader = Loader\r# 省略其余定义\r# Python 2\rclass YAMLObject(object):\r__metaclass__ = YAMLObjectMetaclass\ryaml_loader = Loader\r# 省略其余定义 你可以发现，YAMLObject把metaclass都声明成了YAMLObjectMetaclass，尽管声明方式在Python 2 和3中略有不同。在YAMLObjectMetaclass中， 下面这行代码就是魔法发生的地方：\ncls.yaml_loader.add_constructor(cls.yaml_tag, cls.from_yaml) YAML应用metaclass，拦截了所有YAMLObject子类的定义。也就说说，在你定义任何YAMLObject子类时，Python会强行插入运行下面这段代码，把我们之前想要的add_constructor(Foo)给自动加上。\ncls.yaml_loader.add_constructor(cls.yaml_tag, cls.from_yaml) 所以YAML的使用者，无需自己去手写add_constructor(Foo) 。怎么样，是不是其实并不复杂？\n看到这里，我们已经掌握了metaclass的使用方法，超越了世界上99.9%的Python开发者。更进一步，如果你能够深入理解，Python的语言设计层面是怎样实现metaclass的，你就是世间罕见的“Python大师”了。\nPython底层语言设计层面是如何实现metaclass的？ link刚才我们提到，metaclass能够拦截Python类的定义。它是怎么做到的？\n要理解metaclass的底层原理，你需要深入理解Python类型模型。下面，我将分三点来说明。\n第一，所有的Python的用户定义类，都是type这个类的实例。 link可能会让你惊讶，事实上，类本身不过是一个名为 type 类的实例。在Python的类型世界里，type这个类就是造物的上帝。这可以在代码中验证：\n# Python 3和Python 2类似\rclass MyClass:\rpass\rinstance = MyClass()\rtype(instance)\r# 输出\r"
            }
        );
    index.add(
            {
                id:  28 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/19---%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8\/",
                title: "深入理解迭代器和生成器",
                description: "你好，我是景霄。\n在第一次接触 Python 的时候，你可能写过类似 for i in [2, 3, 5, 7, 11, 13]: print(i) 这样的语句。for in 语句理解起来很直观形象，比起 C++ 和 java 早期的 for (int i = 0; i \u003c n; i ++) printf(\"%d\\n\", a[i]) 这样的语句，不知道简洁清晰到哪里去了。\n但是，你想过 Python 在处理 for in 语句的时候，具体发生了什么吗？什么样的对象可以被 for in 来枚举呢？\n这一节课，我们深入到 Python 的容器类型实现底层去走走，了解一种叫做迭代器和生成器的东西。\n你肯定用过的容器、可迭代对象和迭代器 link容器这个概念非常好理解。我们说过，在Python 中一切皆对象，对象的抽象就是类，而对象的集合就是容器。\n列表（list: [0, 1, 2]），元组（tuple: (0, 1, 2)），字典（dict: {0:0, 1:1, 2:2}），集合（set: set([0, 1, 2])）都是容器。对于容器，你可以很直观地想象成多个元素在一起的单元；而不同容器的区别，正是在于内部数据结构的实现方法。然后，你就可以针对不同场景，选择不同时间和空间复杂度的容器。\n所有的容器都是可迭代的（iterable）。这里的迭代，和枚举不完全一样。迭代可以想象成是你去买苹果，卖家并不告诉你他有多少库存。这样，每次你都需要告诉卖家，你要一个苹果，然后卖家采取行为：要么给你拿一个苹果；要么告诉你，苹果已经卖完了。你并不需要知道，卖家在仓库是怎么摆放苹果的。\n严谨地说，迭代器（iterator）提供了一个 next 的方法。调用这个方法后，你要么得到这个容器的下一个对象，要么得到一个 StopIteration 的错误（苹果卖完了）。你不需要像列表一样指定元素的索引，因为字典和集合这样的容器并没有索引一说。比如，字典采用哈希表实现，那么你就只需要知道，next 函数可以不重复不遗漏地一个一个拿到所有元素即可。\n",
                content: "你好，我是景霄。\n在第一次接触 Python 的时候，你可能写过类似 for i in [2, 3, 5, 7, 11, 13]: print(i) 这样的语句。for in 语句理解起来很直观形象，比起 C++ 和 java 早期的 for (int i = 0; i \u003c n; i ++) printf(\"%d\\n\", a[i]) 这样的语句，不知道简洁清晰到哪里去了。\n但是，你想过 Python 在处理 for in 语句的时候，具体发生了什么吗？什么样的对象可以被 for in 来枚举呢？\n这一节课，我们深入到 Python 的容器类型实现底层去走走，了解一种叫做迭代器和生成器的东西。\n你肯定用过的容器、可迭代对象和迭代器 link容器这个概念非常好理解。我们说过，在Python 中一切皆对象，对象的抽象就是类，而对象的集合就是容器。\n列表（list: [0, 1, 2]），元组（tuple: (0, 1, 2)），字典（dict: {0:0, 1:1, 2:2}），集合（set: set([0, 1, 2])）都是容器。对于容器，你可以很直观地想象成多个元素在一起的单元；而不同容器的区别，正是在于内部数据结构的实现方法。然后，你就可以针对不同场景，选择不同时间和空间复杂度的容器。\n所有的容器都是可迭代的（iterable）。这里的迭代，和枚举不完全一样。迭代可以想象成是你去买苹果，卖家并不告诉你他有多少库存。这样，每次你都需要告诉卖家，你要一个苹果，然后卖家采取行为：要么给你拿一个苹果；要么告诉你，苹果已经卖完了。你并不需要知道，卖家在仓库是怎么摆放苹果的。\n严谨地说，迭代器（iterator）提供了一个 next 的方法。调用这个方法后，你要么得到这个容器的下一个对象，要么得到一个 StopIteration 的错误（苹果卖完了）。你不需要像列表一样指定元素的索引，因为字典和集合这样的容器并没有索引一说。比如，字典采用哈希表实现，那么你就只需要知道，next 函数可以不重复不遗漏地一个一个拿到所有元素即可。\n而可迭代对象，通过 iter() 函数返回一个迭代器，再通过 next() 函数就可以实现遍历。for in 语句将这个过程隐式化，所以，你只需要知道它大概做了什么就行了。\n我们来看下面这段代码，主要向你展示怎么判断一个对象是否可迭代。当然，这还有另一种做法，是 isinstance(obj, Iterable)。\ndef is_iterable(param):\rtry: iter(param) return True\rexcept TypeError:\rreturn False\rparams = [\r1234,\r'1234',\r[1, 2, 3, 4],\rset([1, 2, 3, 4]),\r{1:1, 2:2, 3:3, 4:4},\r(1, 2, 3, 4)\r]\rfor param in params:\rprint('{} is iterable? {}'.format(param, is_iterable(param)))\r########## 输出 ##########\r1234 is iterable? False\r1234 is iterable? True\r[1, 2, 3, 4] is iterable? True\r{1, 2, 3, 4} is iterable? True\r{1: 1, 2: 2, 3: 3, 4: 4} is iterable? True\r(1, 2, 3, 4) is iterable? True 通过这段代码，你就可以知道，给出的类型中，除了数字 1234 之外，其它的数据类型都是可迭代的。\n生成器，又是什么？ link据我所知，很多人对生成器这个概念会比较陌生，因为生成器在很多常用语言中，并没有相对应的模型。\n这里，你只需要记着一点：生成器是懒人版本的迭代器。\n我们知道，在迭代器中，如果我们想要枚举它的元素，这些元素需要事先生成。这里，我们先来看下面这个简单的样例。\nimport os\rimport psutil\r# 显示当前 python 程序占用的内存大小\rdef show_memory_info(hint):\rpid = os.getpid()\rp = psutil.Process(pid)\rinfo = p.memory_full_info()\rmemory = info.uss / 1024. / 1024\rprint('{} memory used: {} MB'.format(hint, memory)) def test_iterator():\rshow_memory_info('initing iterator')\rlist_1 = [i for i in range(100000000)]\rshow_memory_info('after iterator initiated')\rprint(sum(list_1))\rshow_memory_info('after sum called')\rdef test_generator():\rshow_memory_info('initing generator')\rlist_2 = (i for i in range(100000000))\rshow_memory_info('after generator initiated')\rprint(sum(list_2))\rshow_memory_info('after sum called')\r%time test_iterator()\r%time test_generator()\r########## 输出 ##########\riniting iterator memory used: 48.9765625 MB\rafter iterator initiated memory used: 3920.30078125 MB\r4999999950000000\rafter sum called memory used: 3920.3046875 MB\rWall time: 17 s\riniting generator memory used: 50.359375 MB\rafter generator initiated memory used: 50.359375 MB\r4999999950000000\rafter sum called memory used: 50.109375 MB\rWall time: 12.5 s 声明一个迭代器很简单，[i for i in range(100000000)]就可以生成一个包含一亿元素的列表。每个元素在生成后都会保存到内存中，你通过代码可以看到，它们占用了巨量的内存，内存不够的话就会出现 OOM 错误。\n不过，我们并不需要在内存中同时保存这么多东西，比如对元素求和，我们只需要知道每个元素在相加的那一刻是多少就行了，用完就可以扔掉了。\n于是，生成器的概念应运而生，在你调用 next() 函数的时候，才会生成下一个变量。生成器在 Python 的写法是用小括号括起来，(i for i in range(100000000))，即初始化了一个生成器。\n这样一来，你可以清晰地看到，生成器并不会像迭代器一样占用大量内存，只有在被使用的时候才会调用。而且生成器在初始化的时候，并不需要运行一次生成操作，相比于 test_iterator() ，test_generator() 函数节省了一次生成一亿个元素的过程，因此耗时明显比迭代器短。\n到这里，你可能说，生成器不过如此嘛，我有的是钱，不就是多占一些内存和计算资源嘛，我多出点钱就是了呗。\n哪怕你是土豪，请坐下先喝点茶，再听我继续讲完，这次，我们来实现一个自定义的生成器。\n生成器，还能玩什么花样？ link数学中有一个恒等式，(1 + 2 + 3 + ... + n)^2 = 1^3 + 2^3 + 3^3 + ... + n^3，想必你高中就应该学过它。现在，我们来验证一下这个公式的正确性。老规矩，先放代码，你先自己阅读一下，看不懂的也不要紧，接下来我再来详细讲解。\ndef generator(k):\ri = 1\rwhile True:\ryield i ** k\ri += 1\rgen_1 = generator(1)\rgen_3 = generator(3)\rprint(gen_1)\rprint(gen_3)\rdef get_sum(n):\rsum_1, sum_3 = 0, 0\rfor i in range(n):\rnext_1 = next(gen_1)\rnext_3 = next(gen_3)\rprint('next_1 = {}, next_3 = {}'.format(next_1, next_3))\rsum_1 += next_1\rsum_3 += next_3\rprint(sum_1 * sum_1, sum_3)\rget_sum(8)\r########## 输出 ##########\rnext_1 = 1, next_3 = 1\rnext_1 = 2, next_3 = 8\rnext_1 = 3, next_3 = 27\rnext_1 = 4, next_3 = 64\rnext_1 = 5, next_3 = 125\rnext_1 = 6, next_3 = 216\rnext_1 = 7, next_3 = 343\rnext_1 = 8, next_3 = 512\r1296 1296 这段代码中，你首先注意一下 generator() 这个函数，它返回了一个生成器。\n接下来的yield 是魔术的关键。对于初学者来说，你可以理解为，函数运行到这一行的时候，程序会从这里暂停，然后跳出，不过跳到哪里呢？答案是 next() 函数。那么 i ** k 是干什么的呢？它其实成了 next() 函数的返回值。\n这样，每次 next(gen) 函数被调用的时候，暂停的程序就又复活了，从 yield 这里向下继续执行；同时注意，局部变量 i 并没有被清除掉，而是会继续累加。我们可以看到 next_1 从 1 变到 8，next_3 从 1 变到 512。\n聪明的你应该注意到了，这个生成器居然可以一直进行下去！没错，事实上，迭代器是一个有限集合，生成器则可以成为一个无限集。我只管调用 next()，生成器根据运算会自动生成新的元素，然后返回给你，非常便捷。\n到这里，土豪同志应该也坐不住了吧，那么，还能再给力一点吗？\n别急，我们再来看一个问题：给定一个 list 和一个指定数字，求这个数字在 list 中的位置。\n下面这段代码你应该不陌生，也就是常规做法，枚举每个元素和它的 index，判断后加入 result，最后返回。\ndef index_normal(L, target):\rresult = []\rfor i, num in enumerate(L):\rif num == target:\rresult.append(i)\rreturn result\rprint(index_normal([1, 6, 2, 4, 5, 2, 8, 6, 3, 2], 2))\r########## 输出 ##########\r[2, 5, 9] 那么使用迭代器可以怎么做呢？二话不说，先看代码。\ndef index_generator(L, target):\rfor i, num in enumerate(L):\rif num == target:\ryield i\rprint(list(index_generator([1, 6, 2, 4, 5, 2, 8, 6, 3, 2], 2)))\r########## 输出 ##########\r[2, 5, 9] 聪明的你应该看到了明显的区别，我就不做过多解释了。唯一需要强调的是， index_generator 会返回一个 Generator 对象，需要使用 list 转换为列表后，才能用 print 输出。\n这里我再多说两句。在Python 语言规范中，用更少、更清晰的代码实现相同功能，一直是被推崇的做法，因为这样能够很有效提高代码的可读性，减少出错概率，也方便别人快速准确理解你的意图。当然，要注意，这里“更少”的前提是清晰，而不是使用更多的魔术操作，虽说减少了代码却反而增加了阅读的难度。\n回归正题。接下来我们再来看一个问题：给定两个序列，判定第一个是不是第二个的子序列。（LeetCode 链接如下：https://leetcode.com/problems/is-subsequence/ ）\n先来解读一下这个问题本身。序列就是列表，子序列则指的是，一个列表的元素在第二个列表中都按顺序出现，但是并不必挨在一起。举个例子，[1, 3, 5] 是 [1, 2, 3, 4, 5] 的子序列，[1, 4, 3] 则不是。\n要解决这个问题，常规算法是贪心算法。我们维护两个指针指向两个列表的最开始，然后对第二个序列一路扫过去，如果某个数字和第一个指针指的一样，那么就把第一个指针前进一步。第一个指针移出第一个序列最后一个元素的时候，返回 True，否则返回 False。\n不过，这个算法正常写的话，写下来怎么也得十行左右。\n那么如果我们用迭代器和生成器呢？\ndef is_subsequence(a, b):\rb = iter(b)\rreturn all(i in b for i in a)\rprint(is_subsequence([1, 3, 5], [1, 2, 3, 4, 5]))\rprint(is_subsequence([1, 4, 3], [1, 2, 3, 4, 5]))\r########## 输出 ##########\rTrue\rFalse 这简短的几行代码，你是不是看得一头雾水，不知道发生了什么？\n来，我们先把这段代码复杂化，然后一步步看。\ndef is_subsequence(a, b):\rb = iter(b)\rprint(b)\rgen = (i for i in a)\rprint(gen)\rfor i in gen:\rprint(i)\rgen = ((i in b) for i in a)\rprint(gen)\rfor i in gen:\rprint(i)\rreturn all(((i in b) for i in a))\rprint(is_subsequence([1, 3, 5], [1, 2, 3, 4, 5]))\rprint(is_subsequence([1, 4, 3], [1, 2, 3, 4, 5]))\r########## 输出 ##########\r"
            }
        );
    index.add(
            {
                id:  29 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/20---%E6%8F%AD%E7%A7%98-python-%E5%8D%8F%E7%A8%8B\/",
                title: "揭秘 Python 协程",
                description: "你好，我是景霄。\n上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。\n那么首先你要明白，什么是协程？\n协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到举足轻重的作用。\n随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。\n如果将多进程/多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。\n再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）\n回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。\n我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。\n从一个爬虫说起 link爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。\n话不多说，我们先看一个简单的爬虫例子：\nimport time\rdef crawl_page(url):\rprint('crawling {}'.format(url))\rsleep_time = int(url.split('_')[-1])\rtime.sleep(sleep_time)\rprint('OK {}'.format(url))\rdef main(urls):\rfor url in urls:\rcrawl_page(url)\r%time main(['url_1', 'url_2', 'url_3', 'url_4'])\r########## 输出 ##########\rcrawling url_1\rOK url_1\rcrawling url_2\rOK url_2\rcrawling url_3\rOK url_3\rcrawling url_4\rOK url_4\rWall time: 10 s （注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）\n",
                content: "你好，我是景霄。\n上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。\n那么首先你要明白，什么是协程？\n协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到举足轻重的作用。\n随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。\n如果将多进程/多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。\n再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）\n回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。\n我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。\n从一个爬虫说起 link爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。\n话不多说，我们先看一个简单的爬虫例子：\nimport time\rdef crawl_page(url):\rprint('crawling {}'.format(url))\rsleep_time = int(url.split('_')[-1])\rtime.sleep(sleep_time)\rprint('OK {}'.format(url))\rdef main(urls):\rfor url in urls:\rcrawl_page(url)\r%time main(['url_1', 'url_2', 'url_3', 'url_4'])\r########## 输出 ##########\rcrawling url_1\rOK url_1\rcrawling url_2\rOK url_2\rcrawling url_3\rOK url_3\rcrawling url_4\rOK url_4\rWall time: 10 s （注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）\n这是一个很简单的爬虫，main() 函数执行时，调取 crawl_page() 函数进行网络通信，经过若干秒等待后收到结果，然后执行下一个。\n看起来很简单，但你仔细一算，它也占用了不少时间，五个页面分别用了 1 秒到 4 秒的时间，加起来一共用了 10 秒。这显然效率低下，该怎么优化呢？\n于是，一个很简单的思路出现了——我们这种爬取操作，完全可以并发化。我们就来看看使用协程怎么写。\nimport asyncio\rasync def crawl_page(url):\rprint('crawling {}'.format(url))\rsleep_time = int(url.split('_')[-1])\rawait asyncio.sleep(sleep_time)\rprint('OK {}'.format(url))\rasync def main(urls):\rfor url in urls:\rawait crawl_page(url)\r%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\r########## 输出 ##########\rcrawling url_1\rOK url_1\rcrawling url_2\rOK url_2\rcrawling url_3\rOK url_3\rcrawling url_4\rOK url_4\rWall time: 10 s 看到这段代码，你应该发现了，在 Python 3.7 以上版本中，使用协程写异步程序非常简单。\n首先来看 import asyncio，这个库包含了大部分我们实现协程所需的魔法工具。\nasync 修饰词声明异步函数，于是，这里的 crawl_page 和 main 都变成了异步函数。而调用异步函数，我们便可得到一个协程对象（coroutine object）。\n举个例子，如果你 print(crawl_page(''))，便会输出，提示你这是一个 Python 的协程对象，而并不会真正执行这个函数。\n再来说说协程的执行。执行协程有多种方法，这里我介绍一下常用的三种。\n首先，我们可以通过 await 来调用。await 执行的效果，和 Python 正常执行是一样的，也就是说程序会阻塞在这里，进入被调用的协程函数，执行完毕返回后再继续，而这也是 await 的字面意思。代码中 await asyncio.sleep(sleep_time) 会在这里休息若干秒，await crawl_page(url) 则会执行 crawl_page() 函数。\n其次，我们可以通过 asyncio.create_task() 来创建任务，这个我们下节课会详细讲一下，你先简单知道即可。\n最后，我们需要 asyncio.run 来触发运行。asyncio.run 这个函数是 Python 3.7 之后才有的特性，可以让 Python 的协程接口变得非常简单，你不用去理会事件循环怎么定义和怎么使用的问题（我们会在下面讲）。一个非常好的编程规范是，asyncio.run(main()) 作为主程序的入口函数，在程序运行周期内，只调用一次 asyncio.run。\n这样，你就大概看懂了协程是怎么用的吧。不妨试着跑一下代码，欸，怎么还是 10 秒？\n10 秒就对了，还记得上面所说的，await 是同步调用，因此， crawl_page(url) 在当前的调用结束之前，是不会触发下一次调用的。于是，这个代码效果就和上面完全一样了，相当于我们用异步接口写了个同步代码。\n现在又该怎么办呢？\n其实很简单，也正是我接下来要讲的协程中的一个重要概念，任务（Task）。老规矩，先看代码。\nimport asyncio\rasync def crawl_page(url):\rprint('crawling {}'.format(url))\rsleep_time = int(url.split('_')[-1])\rawait asyncio.sleep(sleep_time)\rprint('OK {}'.format(url))\rasync def main(urls):\rtasks = [asyncio.create_task(crawl_page(url)) for url in urls]\rfor task in tasks:\rawait task\r%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\r########## 输出 ##########\rcrawling url_1\rcrawling url_2\rcrawling url_3\rcrawling url_4\rOK url_1\rOK url_2\rOK url_3\rOK url_4\rWall time: 3.99 s 你可以看到，我们有了协程对象后，便可以通过 asyncio.create_task 来创建任务。任务创建后很快就会被调度执行，这样，我们的代码也不会阻塞在任务这里。所以，我们要等所有任务都结束才行，用for task in tasks: await task 即可。\n这次，你就看到效果了吧，结果显示，运行总时长等于运行时间最长的爬虫。\n当然，你也可以想一想，这里用多线程应该怎么写？而如果需要爬取的页面有上万个又该怎么办呢？再对比下协程的写法，谁更清晰自是一目了然。\n其实，对于执行 tasks，还有另一种做法：\nimport asyncio\rasync def crawl_page(url):\rprint('crawling {}'.format(url))\rsleep_time = int(url.split('_')[-1])\rawait asyncio.sleep(sleep_time)\rprint('OK {}'.format(url))\rasync def main(urls):\rtasks = [asyncio.create_task(crawl_page(url)) for url in urls]\rawait asyncio.gather(*tasks)\r%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\r########## 输出 ##########\rcrawling url_1\rcrawling url_2\rcrawling url_3\rcrawling url_4\rOK url_1\rOK url_2\rOK url_3\rOK url_4\rWall time: 4.01 s 这里的代码也很好理解。唯一要注意的是，*tasks 解包列表，将列表变成了函数的参数；与之对应的是， ** dict 将字典变成了函数的参数。\n另外，asyncio.create_task，asyncio.run 这些函数都是 Python 3.7 以上的版本才提供的，自然，相比于旧接口它们也更容易理解和阅读。\n解密协程运行时 link说了这么多，现在，我们不妨来深入代码底层看看。有了前面的知识做基础，你应该很容易理解这两段代码。\nimport asyncio\rasync def worker_1():\rprint('worker_1 start')\rawait asyncio.sleep(1)\rprint('worker_1 done')\rasync def worker_2():\rprint('worker_2 start')\rawait asyncio.sleep(2)\rprint('worker_2 done')\rasync def main():\rprint('before await')\rawait worker_1()\rprint('awaited worker_1')\rawait worker_2()\rprint('awaited worker_2')\r%time asyncio.run(main())\r########## 输出 ##########\rbefore await\rworker_1 start\rworker_1 done\rawaited worker_1\rworker_2 start\rworker_2 done\rawaited worker_2\rWall time: 3 s import asyncio\rasync def worker_1():\rprint('worker_1 start')\rawait asyncio.sleep(1)\rprint('worker_1 done')\rasync def worker_2():\rprint('worker_2 start')\rawait asyncio.sleep(2)\rprint('worker_2 done')\rasync def main():\rtask1 = asyncio.create_task(worker_1())\rtask2 = asyncio.create_task(worker_2())\rprint('before await')\rawait task1\rprint('awaited worker_1')\rawait task2\rprint('awaited worker_2')\r%time asyncio.run(main())\r########## 输出 ##########\rbefore await\rworker_1 start\rworker_2 start\rworker_1 done\rawaited worker_1\rworker_2 done\rawaited worker_2\rWall time: 2.01 s 不过，第二个代码，到底发生了什么呢？为了让你更详细了解到协程和线程的具体区别，这里我详细地分析了整个过程。步骤有点多，别着急，我们慢慢来看。\nasyncio.run(main())，程序进入 main() 函数，事件循环开启； task1 和 task2 任务被创建，并进入事件循环等待运行；运行到 print，输出 'before await'； await task1 执行，用户选择从当前的主任务中切出，事件调度器开始调度 worker_1； worker_1 开始运行，运行 print 输出'worker_1 start'，然后运行到 await asyncio.sleep(1)， 从当前任务切出，事件调度器开始调度 worker_2； worker_2 开始运行，运行 print 输出 'worker_2 start'，然后运行 await asyncio.sleep(2) 从当前任务切出； 以上所有事件的运行时间，都应该在 1ms 到 10ms 之间，甚至可能更短，事件调度器从这个时候开始暂停调度； 一秒钟后，worker_1 的 sleep 完成，事件调度器将控制权重新传给 task_1，输出 'worker_1 done'，task_1 完成任务，从事件循环中退出； await task1 完成，事件调度器将控制器传给主任务，输出 'awaited worker_1'，·然后在 await task2 处继续等待； 两秒钟后，worker_2 的 sleep 完成，事件调度器将控制权重新传给 task_2，输出 'worker_2 done'，task_2 完成任务，从事件循环中退出； 主任务输出 'awaited worker_2'，协程全任务结束，事件循环结束。 接下来，我们进阶一下。如果我们想给某些协程任务限定运行时间，一旦超时就取消，又该怎么做呢？再进一步，如果某些协程运行时出现错误，又该怎么处理呢？同样的，来看代码。\nimport asyncio\rasync def worker_1():\rawait asyncio.sleep(1)\rreturn 1\rasync def worker_2():\rawait asyncio.sleep(2)\rreturn 2 / 0\rasync def worker_3():\rawait asyncio.sleep(3)\rreturn 3\rasync def main():\rtask_1 = asyncio.create_task(worker_1())\rtask_2 = asyncio.create_task(worker_2())\rtask_3 = asyncio.create_task(worker_3())\rawait asyncio.sleep(2)\rtask_3.cancel()\rres = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)\rprint(res)\r%time asyncio.run(main())\r########## 输出 ##########\r[1, ZeroDivisionError('division by zero'), CancelledError()]\rWall time: 2 s 你可以看到，worker_1 正常运行，worker_2 运行中出现错误，worker_3 执行时间过长被我们 cancel 掉了，这些信息会全部体现在最终的返回结果 res 中。\n不过要注意return_exceptions=True这行代码。如果不设置这个参数，错误就会完整地 throw 到我们这个执行层，从而需要 try except 来捕捉，这也就意味着其他还没被执行的任务会被全部取消掉。为了避免这个局面，我们将 return_exceptions 设置为 True 即可。\n到这里，发现了没，线程能实现的，协程都能做到。那就让我们温习一下这些知识点，用协程来实现一个经典的生产者消费者模型吧。\nimport asyncio\rimport random\rasync def consumer(queue, id):\rwhile True:\rval = await queue.get()\rprint('{} get a val: {}'.format(id, val))\rawait asyncio.sleep(1)\rasync def producer(queue, id):\rfor i in range(5):\rval = random.randint(1, 10)\rawait queue.put(val)\rprint('{} put a val: {}'.format(id, val))\rawait asyncio.sleep(1)\rasync def main():\rqueue = asyncio.Queue()\rconsumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))\rconsumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))\rproducer_1 = asyncio.create_task(producer(queue, 'producer_1'))\rproducer_2 = asyncio.create_task(producer(queue, 'producer_2'))\rawait asyncio.sleep(10)\rconsumer_1.cancel()\rconsumer_2.cancel()\rawait asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)\r%time asyncio.run(main())\r########## 输出 ##########\rproducer_1 put a val: 5\rproducer_2 put a val: 3\rconsumer_1 get a val: 5\rconsumer_2 get a val: 3\rproducer_1 put a val: 1\rproducer_2 put a val: 3\rconsumer_2 get a val: 1\rconsumer_1 get a val: 3\rproducer_1 put a val: 6\rproducer_2 put a val: 10\rconsumer_1 get a val: 6\rconsumer_2 get a val: 10\rproducer_1 put a val: 4\rproducer_2 put a val: 5\rconsumer_2 get a val: 4\rconsumer_1 get a val: 5\rproducer_1 put a val: 2\rproducer_2 put a val: 8\rconsumer_1 get a val: 2\rconsumer_2 get a val: 8\rWall time: 10 s 实战：豆瓣近日推荐电影爬虫 link最后，进入今天的实战环节——实现一个完整的协程爬虫。\n任务描述：https://movie.douban.com/cinema/later/beijing/ 这个页面描述了北京最近上映的电影，你能否通过 Python 得到这些电影的名称、上映时间和海报呢？这个页面的海报是缩小版的，我希望你能从具体的电影描述页面中抓取到海报。\n听起来难度不是很大吧？我在下面给出了同步版本的代码和协程版本的代码，通过运行时间和代码写法的对比，希望你能对协程有更深的了解。（注意：为了突出重点、简化代码，这里我省略了异常处理。）\n不过，在参考我给出的代码之前，你是不是可以自己先动手写一下、跑一下呢？\nimport requests\rfrom bs4 import BeautifulSoup\rdef main():\rurl = \"https://movie.douban.com/cinema/later/beijing/\"\rinit_page = requests.get(url).content\rinit_soup = BeautifulSoup(init_page, 'lxml')\rall_movies = init_soup.find('div', id=\"showing-soon\")\rfor each_movie in all_movies.find_all('div', class_=\"item\"):\rall_a_tag = each_movie.find_all('a')\rall_li_tag = each_movie.find_all('li')\rmovie_name = all_a_tag[1].text\rurl_to_fetch = all_a_tag[1]['href']\rmovie_date = all_li_tag[0].text\rresponse_item = requests.get(url_to_fetch).content\rsoup_item = BeautifulSoup(response_item, 'lxml')\rimg_tag = soup_item.find('img')\rprint('{} {} {}'.format(movie_name, movie_date, img_tag['src']))\r%time main()\r########## 输出 ##########\r阿拉丁 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg\r龙珠超：布罗利 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg\r五月天人生无限公司 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg\r... ...\r直播攻略 06月04日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg\rWall time: 56.6 s import asyncio\rimport aiohttp\rfrom bs4 import BeautifulSoup\rasync def fetch_content(url):\rasync with aiohttp.ClientSession(\rheaders=header, connector=aiohttp.TCPConnector(ssl=False)\r) as session:\rasync with session.get(url) as response:\rreturn await response.text()\rasync def main():\rurl = \"https://movie.douban.com/cinema/later/beijing/\"\rinit_page = await fetch_content(url)\rinit_soup = BeautifulSoup(init_page, 'lxml')\rmovie_names, urls_to_fetch, movie_dates = [], [], []\rall_movies = init_soup.find('div', id=\"showing-soon\")\rfor each_movie in all_movies.find_all('div', class_=\"item\"):\rall_a_tag = each_movie.find_all('a')\rall_li_tag = each_movie.find_all('li')\rmovie_names.append(all_a_tag[1].text)\rurls_to_fetch.append(all_a_tag[1]['href'])\rmovie_dates.append(all_li_tag[0].text)\rtasks = [fetch_content(url) for url in urls_to_fetch]\rpages = await asyncio.gather(*tasks)\rfor movie_name, movie_date, page in zip(movie_names, movie_dates, pages):\rsoup_item = BeautifulSoup(page, 'lxml')\rimg_tag = soup_item.find('img')\rprint('{} {} {}'.format(movie_name, movie_date, img_tag['src']))\r%time asyncio.run(main())\r########## 输出 ##########\r阿拉丁 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg\r龙珠超：布罗利 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg\r五月天人生无限公司 05月24日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg\r... ...\r直播攻略 06月04日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg\rWall time: 4.98 s 总结 link到这里，今天的主要内容就讲完了。今天我用了较长的篇幅，从一个简单的爬虫开始，到一个真正的爬虫结束，在中间穿插讲解了 Python 协程最新的基本概念和用法。这里带你简单复习一下。\n协程和多线程的区别，主要在于两点，一是协程为单线程；二是协程由用户决定，在哪些地方交出控制权，切换到下一个任务。 协程的写法更加简洁清晰，把async / await 语法和 create_task 结合来用，对于中小级别的并发需求已经毫无压力。 写协程程序的时候，你的脑海中要有清晰的事件循环概念，知道程序在什么时候需要暂停、等待 I/O，什么时候需要一并执行到底。 最后的最后，请一定不要轻易炫技。多线程模型也一定有其优点，一个真正牛逼的程序员，应该懂得，在什么时候用什么模型能达到工程上的最优，而不是自觉某个技术非常牛逼，所有项目创造条件也要上。技术是工程，而工程则是时间、资源、人力等纷繁复杂的事情的折衷。\n思考题 link最后给你留一个思考题。协程怎么实现回调函数呢？欢迎留言和我讨论，也欢迎你把这篇文章分享给你的同事朋友，我们一起交流，一起进步。\n在 python 3.7 及以上的版本中，我们对 task 对象调用 add_done_callback() 函数，即可绑定特定回调函数。回调函数接受一个 future 对象，可以通过 future.result() 来获取协程函数的返回值。\n示例如下：\nimport asyncio\nasync def crawl_page(url): print('crawling {}'.format(url)) sleep_time = int(url.split('_')[-1]) await asyncio.sleep(sleep_time) return 'OK {}'.format(url)\nasync def main(urls): tasks = [asyncio.create_task(crawl_page(url)) for url in urls] for task in tasks: task.add_done_callback(lambda future: print('result: ', future.result())) await asyncio.gather(*tasks)\n%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\n输出：\ncrawling url_1 crawling url_2 crawling url_3 crawling url_4 result: OK url_1 result: OK url_2 result: OK url_3 result: OK url_4 Wall time: 4 s2019-07-01Jingxiao 👍（77） 💬（10）发现评论区好多朋友说无法运行，在这里统一解释下：\n%time 是 jupyter notebook 自带的语法糖，用来统计一行命令的运行时间；如果你的运行时是纯粹的命令行 python，或者 pycharm，那么请把 %time 删掉，自己用传统的时间戳方法来记录时间也可以；或者使用 jupyter notebook 我的本地解释器是 Anaconda Python 3.7.3，亲测 windows / ubuntu 均可正常运行，如无法执行可以试试 pip install nest-asyncio，依然无法解决请尝试安装 Anaconda Python 这次代码因为使用了较新的 API，所以需要较新的版本号，但是朋友们依然出现了一些运行时问题，这里先表示下歉意；同时也想说明的是，在提问之前自己经过充分搜索，尝试后解决问题，带来的快感，和能力的提升，相应也是很大的，一门工程最需要的是 hands on dirty work（动手做脏活），才能让自己的能力得到本质的提升，加油！2019-06-25Airnm.毁 👍（8） 💬（3）豆瓣那个发现requests.get(url).content/text返回都为空，然后打了下status_code发现是418，网上找418的解释，一般是网站反爬虫基础机制，需要加请求头模仿浏览器就可跳过，改为下面的样子就可通过：url = \"https://movie.douban.com/cinema/later/beijing/\" head={ 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36', 'Referer':'https://time.geekbang.org/column/article/101855', 'Connection':'keep-alive'} res = requests.get(url,headers=head)2020-04-18jackstraw 👍（4） 💬（2）有点没明白，前面说任务创建后立马就开始执行了么？怎么后面在解密底层运行过程的时候，说任务创建后等待执行？到底是哪一个呀？2020-01-14长期规划 👍（2） 💬（1）老师，在最后那个协程例子中为何没用requests库呢？是因为它不支持协程吗2019-12-20一凡 👍（1） 💬（1）协程是单线程怎么理解？所有的协程都是吗2020-06-18苹果 👍（1） 💬（1）asyncio.run() cannot be called from a running event loop 这个问题是如何解决， 其中的await asyncio.sleep(2)是否可以理解为在切出当前程序，2秒后再继续执行print('worker_2 done')代码？ 那么如果我有个耗时任务 def xxx(): …，那么该如何用await asyncio来让这个xxx函数运行并切出当前程序呢？2019-11-28扶幽 👍（1） 💬（1）请问下有木有相关的书籍，来进行这块的学习呢！有些原理性的东西还是没办法深入理解，谢谢。2019-10-12cotter 👍（1） 💬（3）受教了，第一次听说这个高级功能！ 我在工作中遇到一个需要并发的问题，用python在后台并发执行shell ,并发数量用时间范围控制，要不停的改时间分多次串行，方法比较笨拙。协程可以简化我的代码。 老师，并发很多事件应该也是需要消耗很多资源，协程改如何控制并发数量？2019-06-24SUN 👍（0） 💬（2）Jupyter 中运行 %time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4'])) 会报错： RuntimeError: asyncio.run() cannot be called from a running event loop Python、Anaconda、Jupyter都安装了。 话说：Jupyter不就是为了消除个人本地开发环境差异性而诞生的吗？这个结果有点反讽。 各位学员的留言都看了，没人解决了此问题……\n综合下前面的留言和个人的学习，总结下 py 3.6 版本下 asyncio 的主要不同： 1、没有 run(), create_task()，可以用 asyncio.get_even_loop().run_until_complete() 来代替 run()，用 ensure_future() 来代替 create_task()； 2、可能会出现 RuntimeError: This event loop is already running，解决方案一：pip install nest_asyncio; import nest_asyncio; nest_asyncio.apply()；解决方案二：有些友人说是 tornado 5.x 起的版本才有此问题，可考虑将其版本降至 4.x（不推荐）； 3、%time 与 %%time 的主要区别：%time func()（必须是同一行）；%%time 必须放在单元格的开头，强烈建议单独一行 + 不要与 import、def 相关的语句放在同个单元格； 4、爬虫中的 aiohttp.ClientSession(headers=header, connector=aiohttp.TCPConnector(ssl=False)) 提及未声明的 header，要么将 headers=header 部分去掉使用默认参数，要么用诸如 header={\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\"} 来显式声明； 5、tasks = [asyncio.create_task(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks); 约等于 tasks = [crawl_page(url) for url in urls]; asyncio.get_even_loop().run_until_complete(asyncio.wait(tasks)); 或 tasks = [asyncio.ensure_future(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks);2019-06-27\n"
            }
        );
    index.add(
            {
                id:  30 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/21---python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bfutures\/",
                title: "Python并发编程之Futures",
                description: "你好，我是景霄。\n无论对于哪门语言，并发编程都是一项很常用很重要的技巧。比如我们上节课所讲的很常见的爬虫，就被广泛应用在工业界的各个领域。我们每天在各个网站、各个App上获取的新闻信息，很大一部分便是通过并发编程版的爬虫获得。\n正确合理地使用并发编程，无疑会给我们的程序带来极大的性能提升。今天这节课，我就带你一起来学习理解、运用Python中的并发编程——Futures。\n区分并发和并行 link在我们学习并发编程时，常常同时听到并发（Concurrency）和并行（Parallelism）这两个术语，这两者经常一起使用，导致很多人以为它们是一个意思，其实不然。\n首先你要辨别一个误区，在Python中，并发并不是指同一时刻有多个操作（thread、task）同时进行。相反，某个特定的时刻，它只允许有一个操作发生，只不过线程/任务之间会互相切换，直到完成。我们来看下面这张图：\n图中出现了thread和task两种切换顺序的不同方式，分别对应Python中并发的两种形式——threading和asyncio。\n对于threading，操作系统知道每个线程的所有信息，因此它会做主在适当的时候做线程切换。很显然，这样的好处是代码容易书写，因为程序员不需要做任何切换操作的处理；但是切换线程的操作，也有可能出现在一个语句执行的过程中（比如 x += 1），这样就容易出现race condition的情况。\n而对于asyncio，主程序想要切换任务时，必须得到此任务可以被切换的通知，这样一来也就可以避免刚刚提到的 race condition的情况。\n至于所谓的并行，指的才是同一时刻、同时发生。Python中的multi-processing便是这个意思，对于multi-processing，你可以简单地这么理解：比如你的电脑是6核处理器，那么在运行程序时，就可以强制Python开6个进程，同时执行，以加快运行速度，它的原理示意图如下：\n对比来看，\n并发通常应用于I/O操作频繁的场景，比如你要从网站上下载多个文件，I/O操作的时间可能会比CPU运行处理的时间长得多。 而并行则更多应用于CPU heavy的场景，比如MapReduce中的并行计算，为了加快运行速度，一般会用多台机器、多个处理器来完成。 并发编程之Futures link单线程与多线程性能比较 link接下来，我们一起通过具体的实例，从代码的角度来理解并发编程中的Futures，并进一步来比较其与单线程的性能区别。\n假设我们有一个任务，是下载一些网站的内容并打印。如果用单线程的方式，它的代码实现如下所示（为了简化代码，突出主题，此处我忽略了异常处理）：\nimport requests\rimport time\rdef download_one(url):\rresp = requests.get(url)\rprint('Read {} from {}'.format(len(resp.content), url))\rdef download_all(sites):\rfor site in sites:\rdownload_one(site)\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rdownload_all(sites)\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r# 输出\rRead 129886 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 184343 from https://en.wikipedia.org/wiki/Portal:History\rRead 224118 from https://en.wikipedia.org/wiki/Portal:Society\rRead 107637 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 151021 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 157811 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 167923 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 93347 from https://en.wikipedia.org/wiki/Portal:Science\rRead 321352 from https://en.wikipedia.org/wiki/Computer_science\rRead 391905 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 321417 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 468461 from https://en.wikipedia.org/wiki/PHP\rRead 180298 from https://en.wikipedia.org/wiki/Node.js\rRead 56765 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 324039 from https://en.wikipedia.org/wiki/Go_(programming_language)\rDownload 15 sites in 2.464231112999869 seconds 这种方式应该是最直接也最简单的：\n",
                content: "你好，我是景霄。\n无论对于哪门语言，并发编程都是一项很常用很重要的技巧。比如我们上节课所讲的很常见的爬虫，就被广泛应用在工业界的各个领域。我们每天在各个网站、各个App上获取的新闻信息，很大一部分便是通过并发编程版的爬虫获得。\n正确合理地使用并发编程，无疑会给我们的程序带来极大的性能提升。今天这节课，我就带你一起来学习理解、运用Python中的并发编程——Futures。\n区分并发和并行 link在我们学习并发编程时，常常同时听到并发（Concurrency）和并行（Parallelism）这两个术语，这两者经常一起使用，导致很多人以为它们是一个意思，其实不然。\n首先你要辨别一个误区，在Python中，并发并不是指同一时刻有多个操作（thread、task）同时进行。相反，某个特定的时刻，它只允许有一个操作发生，只不过线程/任务之间会互相切换，直到完成。我们来看下面这张图：\n图中出现了thread和task两种切换顺序的不同方式，分别对应Python中并发的两种形式——threading和asyncio。\n对于threading，操作系统知道每个线程的所有信息，因此它会做主在适当的时候做线程切换。很显然，这样的好处是代码容易书写，因为程序员不需要做任何切换操作的处理；但是切换线程的操作，也有可能出现在一个语句执行的过程中（比如 x += 1），这样就容易出现race condition的情况。\n而对于asyncio，主程序想要切换任务时，必须得到此任务可以被切换的通知，这样一来也就可以避免刚刚提到的 race condition的情况。\n至于所谓的并行，指的才是同一时刻、同时发生。Python中的multi-processing便是这个意思，对于multi-processing，你可以简单地这么理解：比如你的电脑是6核处理器，那么在运行程序时，就可以强制Python开6个进程，同时执行，以加快运行速度，它的原理示意图如下：\n对比来看，\n并发通常应用于I/O操作频繁的场景，比如你要从网站上下载多个文件，I/O操作的时间可能会比CPU运行处理的时间长得多。 而并行则更多应用于CPU heavy的场景，比如MapReduce中的并行计算，为了加快运行速度，一般会用多台机器、多个处理器来完成。 并发编程之Futures link单线程与多线程性能比较 link接下来，我们一起通过具体的实例，从代码的角度来理解并发编程中的Futures，并进一步来比较其与单线程的性能区别。\n假设我们有一个任务，是下载一些网站的内容并打印。如果用单线程的方式，它的代码实现如下所示（为了简化代码，突出主题，此处我忽略了异常处理）：\nimport requests\rimport time\rdef download_one(url):\rresp = requests.get(url)\rprint('Read {} from {}'.format(len(resp.content), url))\rdef download_all(sites):\rfor site in sites:\rdownload_one(site)\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rdownload_all(sites)\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r# 输出\rRead 129886 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 184343 from https://en.wikipedia.org/wiki/Portal:History\rRead 224118 from https://en.wikipedia.org/wiki/Portal:Society\rRead 107637 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 151021 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 157811 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 167923 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 93347 from https://en.wikipedia.org/wiki/Portal:Science\rRead 321352 from https://en.wikipedia.org/wiki/Computer_science\rRead 391905 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 321417 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 468461 from https://en.wikipedia.org/wiki/PHP\rRead 180298 from https://en.wikipedia.org/wiki/Node.js\rRead 56765 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 324039 from https://en.wikipedia.org/wiki/Go_(programming_language)\rDownload 15 sites in 2.464231112999869 seconds 这种方式应该是最直接也最简单的：\n先是遍历存储网站的列表； 然后对当前网站执行下载操作； 等到当前操作完成后，再对下一个网站进行同样的操作，一直到结束。 我们可以看到总共耗时约2.4s。单线程的优点是简单明了，但是明显效率低下，因为上述程序的绝大多数时间，都浪费在了I/O等待上。程序每次对一个网站执行下载操作，都必须等到前一个网站下载完成后才能开始。如果放在实际生产环境中，我们需要下载的网站数量至少是以万为单位的，不难想象，这种方案根本行不通。\n接着我们再来看，多线程版本的代码实现：\nimport concurrent.futures\rimport requests\rimport threading\rimport time\rdef download_one(url):\rresp = requests.get(url)\rprint('Read {} from {}'.format(len(resp.content), url))\rdef download_all(sites):\rwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\rexecutor.map(download_one, sites)\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rdownload_all(sites)\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r## 输出\rRead 151021 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 129886 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 107637 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 224118 from https://en.wikipedia.org/wiki/Portal:Society\rRead 184343 from https://en.wikipedia.org/wiki/Portal:History\rRead 167923 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 157811 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 91533 from https://en.wikipedia.org/wiki/Portal:Science\rRead 321352 from https://en.wikipedia.org/wiki/Computer_science\rRead 391905 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 180298 from https://en.wikipedia.org/wiki/Node.js\rRead 56765 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 468461 from https://en.wikipedia.org/wiki/PHP\rRead 321417 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 324039 from https://en.wikipedia.org/wiki/Go_(programming_language)\rDownload 15 sites in 0.19936635800002023 seconds 非常明显，总耗时是0.2s左右，效率一下子提升了10倍多。\n我们具体来看这段代码，它是多线程版本和单线程版的主要区别所在：\nwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\rexecutor.map(download_one, sites) 这里我们创建了一个线程池，总共有5个线程可以分配使用。executer.map()与前面所讲的Python内置的map()函数类似，表示对sites中的每一个元素，并发地调用函数download_one()。\n顺便提一下，在download_one()函数中，我们使用的requests.get()方法是线程安全的（thread-safe），因此在多线程的环境下，它也可以安全使用，并不会出现race condition的情况。\n另外，虽然线程的数量可以自己定义，但是线程数并不是越多越好，因为线程的创建、维护和删除也会有一定的开销。所以如果你设置的很大，反而可能会导致速度变慢。我们往往需要根据实际的需求做一些测试，来寻找最优的线程数量。\n当然，我们也可以用并行的方式去提高程序运行效率。你只需要在download_all()函数中，做出下面的变化即可：\nwith futures.ThreadPoolExecutor(workers) as executor\r=\u003e\rwith futures.ProcessPoolExecutor() as executor: 在需要修改的这部分代码中，函数ProcessPoolExecutor()表示创建进程池，使用多个进程并行的执行程序。不过，这里我们通常省略参数workers，因为系统会自动返回CPU的数量作为可以调用的进程数。\n我刚刚提到过，并行的方式一般用在CPU heavy的场景中，因为对于I/O heavy的操作，多数时间都会用于等待，相比于多线程，使用多进程并不会提升效率。反而很多时候，因为CPU数量的限制，会导致其执行效率不如多线程版本。\n到底什么是 Futures ？ linkPython中的Futures模块，位于concurrent.futures和asyncio中，它们都表示带有延迟的操作。Futures会将处于等待状态的操作包裹起来放到队列中，这些操作的状态随时可以查询，当然，它们的结果或是异常，也能够在操作完成后被获取。\n通常来说，作为用户，我们不用考虑如何去创建Futures，这些Futures底层都会帮我们处理好。我们要做的，实际上是去schedule这些Futures的执行。\n比如，Futures中的Executor类，当我们执行executor.submit(func)时，它便会安排里面的func()函数执行，并返回创建好的future实例，以便你之后查询调用。\n这里再介绍一些常用的函数。Futures中的方法done()，表示相对应的操作是否完成——True表示完成，False表示没有完成。不过，要注意，done()是non-blocking的，会立即返回结果。相对应的add_done_callback(fn)，则表示Futures完成后，相对应的参数函数fn，会被通知并执行调用。\nFutures中还有一个重要的函数result()，它表示当future完成后，返回其对应的结果或异常。而as_completed(fs)，则是针对给定的future迭代器fs，在其完成后，返回完成后的迭代器。\n所以，上述例子也可以写成下面的形式：\nimport concurrent.futures\rimport requests\rimport time\rdef download_one(url):\rresp = requests.get(url)\rprint('Read {} from {}'.format(len(resp.content), url))\rdef download_all(sites):\rwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\rto_do = []\rfor site in sites:\rfuture = executor.submit(download_one, site)\rto_do.append(future)\rfor future in concurrent.futures.as_completed(to_do):\rfuture.result()\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rdownload_all(sites)\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r# 输出\rRead 129886 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 107634 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 224118 from https://en.wikipedia.org/wiki/Portal:Society\rRead 158984 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 184343 from https://en.wikipedia.org/wiki/Portal:History\rRead 157949 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 167923 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 94228 from https://en.wikipedia.org/wiki/Portal:Science\rRead 391905 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 321352 from https://en.wikipedia.org/wiki/Computer_science\rRead 180298 from https://en.wikipedia.org/wiki/Node.js\rRead 321417 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 468421 from https://en.wikipedia.org/wiki/PHP\rRead 56765 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 324039 from https://en.wikipedia.org/wiki/Go_(programming_language)\rDownload 15 sites in 0.21698231499976828 seconds 这里，我们首先调用executor.submit()，将下载每一个网站的内容都放进future队列to_do，等待执行。然后是as_completed()函数，在future完成后，便输出结果。\n不过，这里要注意，future列表中每个future完成的顺序，和它在列表中的顺序并不一定完全一致。到底哪个先完成、哪个后完成，取决于系统的调度和每个future的执行时间。\n为什么多线程每次只能有一个线程执行？ link前面我说过，同一时刻，Python主程序只允许有一个线程执行，所以Python的并发，是通过多线程的切换完成的。你可能会疑惑这到底是为什么呢？\n这里我简单提一下全局解释器锁的概念，具体内容后面会讲到。\n事实上，Python的解释器并不是线程安全的，为了解决由此带来的race condition等问题，Python便引入了全局解释器锁，也就是同一时刻，只允许一个线程执行。当然，在执行I/O操作时，如果一个线程被block了，全局解释器锁便会被释放，从而让另一个线程能够继续执行。\n总结 link这节课，我们首先学习了Python中并发和并行的概念与区别。\n并发，通过线程和任务之间互相切换的方式实现，但同一时刻，只允许有一个线程或任务执行。 而并行，则是指多个进程同时执行。 并发通常用于I/O操作频繁的场景，而并行则适用于CPU heavy的场景。\n随后，我们通过下载网站内容的例子，比较了单线程和运用Futures的多线程版本的性能差异。显而易见，合理地运用多线程，能够极大地提高程序运行效率。\n我们还一起学习了Futures的具体原理，介绍了一些常用函数比如done()、result()、as_completed()等的用法，并辅以实例加以理解。\n要注意，Python中之所以同一时刻只允许一个线程运行，其实是由于全局解释器锁的存在。但是对I/O操作而言，当其被block的时候，全局解释器锁便会被释放，使其他线程继续执行。\n思考题 link最后给你留一道思考题。你能否通过查阅相关文档，为今天所讲的这个下载网站内容的例子，加上合理的异常处理，让程序更加稳定健壮呢？欢迎在留言区写下你的思考和答案，也欢迎你把今天的内容分享给你的同事朋友，我们一起交流、一起进步。\n并发，是指遇到I/O阻塞时（一般是网络I/O或磁盘I/O），通过多个线程之间切换执行多个任务（多线程）或单线程内多个任务之间切换执行的方式来最大化利用CPU时间，但同一时刻，只允许有一个线程或任务执行。适合I/O阻塞频繁的业务场景。\n并行，是指多个进程完全同步同时的执行。适合CPU密集型业务场景。2019-06-26LJK 👍（3） 💬（4）老师好，请问一下在python存在GIL的情况下，多进程是不是还是无法并发运行？谢谢老师2019-06-26_stuView 👍（2） 💬（1）老师，请问什么是线程安全，什么是race condition呢？2019-06-26MarDino 👍（1） 💬（1）想问下老师，该怎么向executor.map中的函数，传入多个参数？2020-02-11BotterZhang 👍（47） 💬（4）关于concurrent写过一篇学习笔记： https://www.zhangqibot.com/post/python-concurrent-futures/ Python实现多线程/多进程，大家常常会用到标准库中的threading和multiprocessing模块。 但从Python3.2开始，标准库为我们提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，实现了对threading和multiprocessing的进一步抽象，使得开发者只需编写少量代码即可让程序实现并行计算。2019-06-26SCAR 👍（30） 💬（0）future之与中文理解起来其实挺微妙，不过这与生活中大家熟知的期物在底层逻辑上是一致的，future英文词义中就有期货的意思，都是封存一个东西，平常你该干嘛就干嘛，可以不用去理会，在未来的某个时候去看结果就行，只是python中那个物是对象而已。而关键词是延迟，异步。 思考题：添加异常处理 def download_all(sites): with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: to_do = {} for site in sites: future = executor.submit(download_one, site) to_do[future]=site\nfor future in concurrent.futures.as_completed(to_do):\rtry：\rres=future.result()\rexcept request.exceptions.HTTPError as e:\re_msg=‘HTTP erro’\rexcept request.exceptions.ConnectionError as e:\re_msg=‘Connection erro’\relse:\re_msg=\u0026#39;\u0026#39;\rif e_msg:\rsite=to_do[future]\rPrint(‘Error is {} from {}’.format(e_msg,site))\r-- encoding -- link''' py 3.6 sulime ''' import concurrent.futures import threading import requests import time\nnow = lambda: time.perf_counter()\ndef download_one(url): try: req = requests.get(url) req.raise_for_status() print('Read {} from {}'.format(len(req.content), url)) except: print('404')\ndef download_all(sites): with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: executor.map(download_one, sites)\ndef main(): sites = [ 'https://www.baidu.com/', 'https://pypi.org/', 'https://www.sina.com.cn/', 'https://www.163.com/', 'https://news.qq.com/', 'http://www.ifeng.com/', 'http://www.ce.cn/', 'https://news.baidu.com/', 'http://www.people.com.cn/', 'http://www.ce.cn/', 'https://news.163.com/', 'http://news.sohu.com/' ] start = now() download_all(sites) print('Download {} sites in {} s'.format(len(sites), now() - start))\nif name == 'main': main()\nRead 2443 from https://www.baidu.com/ linkRead 6216 from https://news.qq.com/ linkRead 699004 from https://www.163.com/ linkRead 250164 from http://www.ifeng.com/ linkRead 579572 from https://www.sina.com.cn/ linkRead 107530 from http://www.ce.cn/ linkRead 165901 from http://www.people.com.cn/ linkRead 107530 from http://www.ce.cn/ linkRead 210816 from https://news.163.com/ linkRead 74060 from https://news.baidu.com/ linkRead 174553 from http://news.sohu.com/ linkRead 19492 from https://pypi.org/ linkDownload 12 sites in 2.8500169346527673 s link[Finished in 3.6s]2019-06-30somenzz 👍（4） 💬（1）from multiprocessing.dummy import Pool as ThreadPool linkwith ThreadPool(processes=100) as executor: executor.map(func, iterable)\n请问老师，Futures 和这种方式哪一种好呢？ 我在实际的网终请求中发现 Futures 请求成功的次数更少。 都是 100 个线程，处理 3000 个相同的请求。\n"
            }
        );
    index.add(
            {
                id:  31 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/22---%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Basyncio\/",
                title: "并发编程之Asyncio",
                description: "你好，我是景霄。\n上节课，我们一起学习了Python并发编程的一种实现——多线程。今天这节课，我们继续学习Python并发编程的另一种实现方式——Asyncio。不同于协程那章，这节课我们更注重原理的理解。\n通过上节课的学习，我们知道，在处理I/O操作时，使用多线程与普通的单线程相比，效率得到了极大的提高。你可能会想，既然这样，为什么还需要Asyncio？\n诚然，多线程有诸多优点且应用广泛，但也存在一定的局限性：\n比如，多线程运行过程容易被打断，因此有可能出现race condition的情况； 再如，线程切换本身存在一定的损耗，线程数不能无限增加，因此，如果你的 I/O操作非常heavy，多线程很有可能满足不了高效率、高质量的需求。 正是为了解决这些问题，Asyncio应运而生。\n什么是Asyncio linkSync VS Async link我们首先来区分一下Sync（同步）和Async（异步）的概念。\n所谓Sync，是指操作一个接一个地执行，下一个操作必须等上一个操作完成后才能执行。 而Async是指不同操作间可以相互交替执行，如果其中的某个操作被block了，程序并不会等待，而是会找出可执行的操作继续执行。 举个简单的例子，你的老板让你做一份这个季度的报表，并且邮件发给他。\n如果按照Sync的方式，你会先向软件输入这个季度的各项数据，接下来等待5min，等报表明细生成后，再写邮件发给他。 但如果按照Async的方式，再你输完这个季度的各项数据后，便会开始写邮件。等报表明细生成后，你会暂停邮件，先去查看报表，确认后继续写邮件直到发送完毕。 Asyncio工作原理 link明白了Sync 和Async，回到我们今天的主题，到底什么是Asyncio呢？\n事实上，Asyncio和其他Python程序一样，是单线程的，它只有一个主线程，但是可以进行多个不同的任务（task），这里的任务，就是特殊的future对象。这些不同的任务，被一个叫做event loop的对象所控制。你可以把这里的任务，类比成多线程版本里的多个线程。\n为了简化讲解这个问题，我们可以假设任务只有两个状态：一是预备状态；二是等待状态。所谓的预备状态，是指任务目前空闲，但随时待命准备运行。而等待状态，是指任务已经运行，但正在等待外部的操作完成，比如I/O操作。\n在这种情况下，event loop会维护两个任务列表，分别对应这两种状态；并且选取预备状态的一个任务（具体选取哪个任务，和其等待的时间长短、占用的资源等等相关），使其运行，一直到这个任务把控制权交还给event loop为止。\n当任务把控制权交还给event loop时，event loop会根据其是否完成，把任务放到预备或等待状态的列表，然后遍历等待状态列表的任务，查看他们是否完成。\n如果完成，则将其放到预备状态的列表； 如果未完成，则继续放在等待状态的列表。 而原先在预备状态列表的任务位置仍旧不变，因为它们还未运行。\n这样，当所有任务被重新放置在合适的列表后，新一轮的循环又开始了：event loop继续从预备状态的列表中选取一个任务使其执行…如此周而复始，直到所有任务完成。\n值得一提的是，对于Asyncio来说，它的任务在运行时不会被外部的一些因素打断，因此Asyncio内的操作不会出现race condition的情况，这样你就不需要担心线程安全的问题了。\nAsyncio用法 link讲完了Asyncio的原理，我们结合具体的代码来看一下它的用法。还是以上节课下载网站内容为例，用Asyncio的写法我放在了下面代码中（省略了异常处理的一些操作），接下来我们一起来看：\nimport asyncio\rimport aiohttp\rimport time\rasync def download_one(url):\rasync with aiohttp.ClientSession() as session:\rasync with session.get(url) as resp:\rprint('Read {} from {}'.format(resp.content_length, url))\rasync def download_all(sites):\rtasks = [asyncio.create_task(download_one(site)) for site in sites]\rawait asyncio.gather(*tasks)\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rasyncio.run(download_all(sites))\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r## 输出\rRead 63153 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 31461 from https://en.wikipedia.org/wiki/Portal:Society\rRead 23965 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 36312 from https://en.wikipedia.org/wiki/Portal:History\rRead 25203 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 15160 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 28749 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 29587 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 79318 from https://en.wikipedia.org/wiki/PHP\rRead 30298 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 73914 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 62218 from https://en.wikipedia.org/wiki/Go_(programming_language)\rRead 22318 from https://en.wikipedia.org/wiki/Portal:Science\rRead 36800 from https://en.wikipedia.org/wiki/Node.js\rRead 67028 from https://en.wikipedia.org/wiki/Computer_science\rDownload 15 sites in 0.062144195078872144 seconds 这里的Async和await关键字是Asyncio的最新写法，表示这个语句/函数是non-block的，正好对应前面所讲的event loop的概念。如果任务执行的过程需要等待，则将其放入等待状态的列表中，然后继续执行预备状态列表里的任务。\n",
                content: "你好，我是景霄。\n上节课，我们一起学习了Python并发编程的一种实现——多线程。今天这节课，我们继续学习Python并发编程的另一种实现方式——Asyncio。不同于协程那章，这节课我们更注重原理的理解。\n通过上节课的学习，我们知道，在处理I/O操作时，使用多线程与普通的单线程相比，效率得到了极大的提高。你可能会想，既然这样，为什么还需要Asyncio？\n诚然，多线程有诸多优点且应用广泛，但也存在一定的局限性：\n比如，多线程运行过程容易被打断，因此有可能出现race condition的情况； 再如，线程切换本身存在一定的损耗，线程数不能无限增加，因此，如果你的 I/O操作非常heavy，多线程很有可能满足不了高效率、高质量的需求。 正是为了解决这些问题，Asyncio应运而生。\n什么是Asyncio linkSync VS Async link我们首先来区分一下Sync（同步）和Async（异步）的概念。\n所谓Sync，是指操作一个接一个地执行，下一个操作必须等上一个操作完成后才能执行。 而Async是指不同操作间可以相互交替执行，如果其中的某个操作被block了，程序并不会等待，而是会找出可执行的操作继续执行。 举个简单的例子，你的老板让你做一份这个季度的报表，并且邮件发给他。\n如果按照Sync的方式，你会先向软件输入这个季度的各项数据，接下来等待5min，等报表明细生成后，再写邮件发给他。 但如果按照Async的方式，再你输完这个季度的各项数据后，便会开始写邮件。等报表明细生成后，你会暂停邮件，先去查看报表，确认后继续写邮件直到发送完毕。 Asyncio工作原理 link明白了Sync 和Async，回到我们今天的主题，到底什么是Asyncio呢？\n事实上，Asyncio和其他Python程序一样，是单线程的，它只有一个主线程，但是可以进行多个不同的任务（task），这里的任务，就是特殊的future对象。这些不同的任务，被一个叫做event loop的对象所控制。你可以把这里的任务，类比成多线程版本里的多个线程。\n为了简化讲解这个问题，我们可以假设任务只有两个状态：一是预备状态；二是等待状态。所谓的预备状态，是指任务目前空闲，但随时待命准备运行。而等待状态，是指任务已经运行，但正在等待外部的操作完成，比如I/O操作。\n在这种情况下，event loop会维护两个任务列表，分别对应这两种状态；并且选取预备状态的一个任务（具体选取哪个任务，和其等待的时间长短、占用的资源等等相关），使其运行，一直到这个任务把控制权交还给event loop为止。\n当任务把控制权交还给event loop时，event loop会根据其是否完成，把任务放到预备或等待状态的列表，然后遍历等待状态列表的任务，查看他们是否完成。\n如果完成，则将其放到预备状态的列表； 如果未完成，则继续放在等待状态的列表。 而原先在预备状态列表的任务位置仍旧不变，因为它们还未运行。\n这样，当所有任务被重新放置在合适的列表后，新一轮的循环又开始了：event loop继续从预备状态的列表中选取一个任务使其执行…如此周而复始，直到所有任务完成。\n值得一提的是，对于Asyncio来说，它的任务在运行时不会被外部的一些因素打断，因此Asyncio内的操作不会出现race condition的情况，这样你就不需要担心线程安全的问题了。\nAsyncio用法 link讲完了Asyncio的原理，我们结合具体的代码来看一下它的用法。还是以上节课下载网站内容为例，用Asyncio的写法我放在了下面代码中（省略了异常处理的一些操作），接下来我们一起来看：\nimport asyncio\rimport aiohttp\rimport time\rasync def download_one(url):\rasync with aiohttp.ClientSession() as session:\rasync with session.get(url) as resp:\rprint('Read {} from {}'.format(resp.content_length, url))\rasync def download_all(sites):\rtasks = [asyncio.create_task(download_one(site)) for site in sites]\rawait asyncio.gather(*tasks)\rdef main():\rsites = [\r'https://en.wikipedia.org/wiki/Portal:Arts',\r'https://en.wikipedia.org/wiki/Portal:History',\r'https://en.wikipedia.org/wiki/Portal:Society',\r'https://en.wikipedia.org/wiki/Portal:Biography',\r'https://en.wikipedia.org/wiki/Portal:Mathematics',\r'https://en.wikipedia.org/wiki/Portal:Technology',\r'https://en.wikipedia.org/wiki/Portal:Geography',\r'https://en.wikipedia.org/wiki/Portal:Science',\r'https://en.wikipedia.org/wiki/Computer_science',\r'https://en.wikipedia.org/wiki/Python_(programming_language)',\r'https://en.wikipedia.org/wiki/Java_(programming_language)',\r'https://en.wikipedia.org/wiki/PHP',\r'https://en.wikipedia.org/wiki/Node.js',\r'https://en.wikipedia.org/wiki/The_C_Programming_Language',\r'https://en.wikipedia.org/wiki/Go_(programming_language)'\r]\rstart_time = time.perf_counter()\rasyncio.run(download_all(sites))\rend_time = time.perf_counter()\rprint('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\rif __name__ == '__main__':\rmain()\r## 输出\rRead 63153 from https://en.wikipedia.org/wiki/Java_(programming_language)\rRead 31461 from https://en.wikipedia.org/wiki/Portal:Society\rRead 23965 from https://en.wikipedia.org/wiki/Portal:Biography\rRead 36312 from https://en.wikipedia.org/wiki/Portal:History\rRead 25203 from https://en.wikipedia.org/wiki/Portal:Arts\rRead 15160 from https://en.wikipedia.org/wiki/The_C_Programming_Language\rRead 28749 from https://en.wikipedia.org/wiki/Portal:Mathematics\rRead 29587 from https://en.wikipedia.org/wiki/Portal:Technology\rRead 79318 from https://en.wikipedia.org/wiki/PHP\rRead 30298 from https://en.wikipedia.org/wiki/Portal:Geography\rRead 73914 from https://en.wikipedia.org/wiki/Python_(programming_language)\rRead 62218 from https://en.wikipedia.org/wiki/Go_(programming_language)\rRead 22318 from https://en.wikipedia.org/wiki/Portal:Science\rRead 36800 from https://en.wikipedia.org/wiki/Node.js\rRead 67028 from https://en.wikipedia.org/wiki/Computer_science\rDownload 15 sites in 0.062144195078872144 seconds 这里的Async和await关键字是Asyncio的最新写法，表示这个语句/函数是non-block的，正好对应前面所讲的event loop的概念。如果任务执行的过程需要等待，则将其放入等待状态的列表中，然后继续执行预备状态列表里的任务。\n主函数里的asyncio.run(coro)是Asyncio的root call，表示拿到event loop，运行输入的coro，直到它结束，最后关闭这个event loop。事实上，asyncio.run()是Python3.7+才引入的，相当于老版本的以下语句：\nloop = asyncio.get_event_loop()\rtry:\rloop.run_until_complete(coro)\rfinally:\rloop.close() 至于Asyncio版本的函数download_all()，和之前多线程版本有很大的区别：\ntasks = [asyncio.create_task(download_one(site)) for site in sites]\rawait asyncio.gather(*task) 这里的asyncio.create_task(coro)，表示对输入的协程coro创建一个任务，安排它的执行，并返回此任务对象。这个函数也是Python 3.7+新增的，如果是之前的版本，你可以用asyncio.ensure_future(coro)等效替代。可以看到，这里我们对每一个网站的下载，都创建了一个对应的任务。\n再往下看，asyncio.gather(*aws, loop=None, return_exception=False)，则表示在event loop中运行aws序列的所有任务。当然，除了例子中用到的这几个函数，Asyncio还提供了很多其他的用法，你可以查看 相应文档 进行了解。\n最后，我们再来看一下最后的输出结果——用时只有0.06s，效率比起之前的多线程版本，可以说是更上一层楼，充分体现其优势。\nAsyncio有缺陷吗？ link学了这么多内容，我们认识到了Asyncio的强大，但你要清楚，任何一种方案都不是完美的，都存在一定的局限性，Asyncio同样如此。\n实际工作中，想用好Asyncio，特别是发挥其强大的功能，很多情况下必须得有相应的Python库支持。你可能注意到了，上节课的多线程编程中，我们使用的是requests库，但今天我们并没有使用，而是用了aiohttp库，原因就是requests库并不兼容Asyncio，但是aiohttp库兼容。\nAsyncio软件库的兼容性问题，在Python3的早期一直是个大问题，但是随着技术的发展，这个问题正逐步得到解决。\n另外，使用Asyncio时，因为你在任务的调度方面有了更大的自主权，写代码时就得更加注意，不然很容易出错。\n举个例子，如果你需要await一系列的操作，就得使用asyncio.gather()；如果只是单个的future，或许只用asyncio.wait()就可以了。那么，对于你的future，你是想要让它run_until_complete()还是run_forever()呢？诸如此类，都是你在面对具体问题时需要考虑的。\n多线程还是Asyncio link不知不觉，我们已经把并发编程的两种方式都给学习完了。不过，遇到实际问题时，多线程和Asyncio到底如何选择呢？\n总的来说，你可以遵循以下伪代码的规范：\nif io_bound:\rif io_slow:\rprint('Use Asyncio')\relse:\rprint('Use multi-threading')\relse if cpu_bound:\rprint('Use multi-processing') 如果是I/O bound，并且I/O操作很慢，需要很多任务/线程协同实现，那么使用Asyncio更合适。 如果是I/O bound，但是I/O操作很快，只需要有限数量的任务/线程，那么使用多线程就可以了。 如果是CPU bound，则需要使用多进程来提高程序运行效率。 总结 link今天这节课，我们一起学习了Asyncio的原理和用法，并比较了Asyncio和多线程各自的优缺点。\n不同于多线程，Asyncio是单线程的，但其内部event loop的机制，可以让它并发地运行多个不同的任务，并且比多线程享有更大的自主控制权。\nAsyncio中的任务，在运行过程中不会被打断，因此不会出现race condition的情况。尤其是在I/O操作heavy的场景下，Asyncio比多线程的运行效率更高。因为Asyncio内部任务切换的损耗，远比线程切换的损耗要小；并且Asyncio可以开启的任务数量，也比多线程中的线程数量多得多。\n但需要注意的是，很多情况下，使用Asyncio需要特定第三方库的支持，比如前面示例中的aiohttp。而如果I/O操作很快，并不heavy，那么运用多线程，也能很有效地解决问题。\n思考题 link这两节课，我们学习了并发编程的两种实现方式，也多次提到了并行编程（multi-processing），其适用于CPU heavy的场景。\n现在有这么一个需求：输入一个列表，对于列表中的每个元素，我想计算0到这个元素的所有整数的平方和。\n我把常规版本的写法放在了下面，你能通过查阅资料，写出它的多进程版本，并且比较程序的耗时吗？\nimport time\rdef cpu_bound(number):\rprint(sum(i * i for i in range(number)))\rdef calculate_sums(numbers):\rfor number in numbers:\rcpu_bound(number)\rdef main():\rstart_time = time.perf_counter() numbers = [10000000 + x for x in range(20)]\rcalculate_sums(numbers)\rend_time = time.perf_counter()\rprint('Calculation takes {} seconds'.format(end_time - start_time))\rif __name__ == '__main__':\rmain() 欢迎在留言区写下你的思考和答案，也欢迎你把今天的内容分享给你的同事朋友，我们一起交流、一起进步。\ndef cpu_bound(number): return sum(i * i for i in range(number))\ndef find_sums(numbers): with multiprocessing.Pool() as pool: pool.map(cpu_bound, numbers)\nif name == \"main\": numbers = [10000000 + x for x in range(20)]\nstart_time = time.time()\rfind_sums(numbers)\rduration = time.time() - start_time\rprint(f\u0026quot;Duration {duration} seconds\u0026quot;)\n2019-07-02建强 👍（6） 💬（2）上网查询资料后，初步了解了多进程的一些知识，按照资料中的方法简单改写了一下程序，由于多进程方式时，不知什么原因，cpu_bound函数不能实时输出，所以就把cpu_bound改为返回字符串形式的结果，等所有的数计算完成后，再一并输出结果 ，程序中常规执行和多进程两种方式都有，并作了对比后发现，常规执行用时约23秒，多进程用时约6秒，两者相差4倍，程序如下，不足处请老师指正：\r#多进程演示 import multiprocessing import time\ndef cpu_bound(number): return 'sum({}^2)={}'.format(number,sum(i * i for i in range(number)))\ndef calculate_sums(numbers):\nresults = []\rprint(\u0026#39;-\u0026#39;*10+\u0026#39;串行执行开始：\u0026#39;+\u0026#39;-\u0026#39;*10)\rfor number in numbers:\rresults.append(cpu_bound(number))\rprint(\u0026#39;-\u0026#39;*10+\u0026#39;串行执行结束，结果如下：\u0026#39;+\u0026#39;-\u0026#39;*10)\rfor res in results:\rprint(res)\rdef multicalculate_sums(numbers):\n#创建有4个进程的进程池\rpool = multiprocessing.Pool(processes=4)\rresults = []\rprint(\u0026#39;-\u0026#39;*10+\u0026#39;多进程执行开始：\u0026#39;+\u0026#39;-\u0026#39;*10)\r#为每一个需要计算的元素创建一个进程\rfor number in numbers:\rresults.append(pool.apply_async(cpu_bound, (number,)))\rpool.close() #关闭进程池，不能往进程池添加进程\rpool.join() #等待进程池中的所有进程执行完毕\rprint(\u0026#39;-\u0026#39;*10+\u0026#39;多进程执行结束，结果如下：\u0026#39;+\u0026#39;-\u0026#39;*10)\rfor res in results:\rprint(res.get())\rdef main():\nnumbers = [10000000 + x for x in range(20)]\r#串行执行方式\rstart_time = time.perf_counter() calculate_sums(numbers)\rend_time = time.perf_counter()\rprint(\u0026#39;串行执行用时：Calculation takes {} seconds\u0026#39;.format(end_time - start_time))\r#多进程执行方式\rstart_time = time.perf_counter() multicalculate_sums(numbers)\rend_time = time.perf_counter()\rprint(\u0026#39;多进程执行用时：Calculation takes {} seconds\u0026#39;.format(end_time - start_time))\rif name == 'main': main()\ndef cpu_bound(number): return sum(i * i for i in range(number))\ndef calculate_sums(numbers): for number in numbers: print(cpu_bound(number))\ndef main(): start_time = time.perf_counter() numbers = [10000000 + x for x in range(20)] calculate_sums(numbers) end_time = time.perf_counter() print('Calculation takes {} seconds'.format(end_time - start_time))\ndef main_process(): start_time = time.perf_counter() numbers = [10000000 + x for x in range(20)] with futures.ProcessPoolExecutor() as pe: result = pe.map(cpu_bound, numbers) print(f\"result: {list(result)}\") end_time = time.perf_counter() print('multiprocessing Calculation takes {} seconds'.format(end_time - start_time))\nif name == 'main': main() main_process() ———————— 输出： 333333283333335000000 333333383333335000000 333333483333355000001 333333583333395000005 333333683333455000014 333333783333535000030 333333883333635000055 333333983333755000091 333334083333895000140 333334183334055000204 333334283334235000285 333334383334435000385 333334483334655000506 333334583334895000650 333334683335155000819 333334783335435001015 333334883335735001240 333334983336055001496 333335083336395001785 333335183336755002109 Calculation takes 15.771127400000001 seconds result: [333333283333335000000, 333333383333335000000, 333333483333355000001, 333333583333395000005, 333333683333455000014, 333333783333535000030, 333333883333635000055, 333333983333755000091, 333334083333895000140, 333334183334055000204, 333334283334235000285, 333334383334435000385, 333334483334655000506, 333334583334895000650, 333334683335155000819, 333334783335435001015, 333334883335735001240, 333334983336055001496, 333335083336395001785, 333335183336755002109] multiprocessing Calculation takes 4.7333084 seconds\n具体到关键字 async 是表示函数是异步的，也就是来回穿插的起点（进入预备队列），await是表示调用需要IO，也就是进入等待队列的入口（函数开始调用）和出口（函数调用结束，重新进入预备队列）。2019-11-21唐哥 👍（3） 💬（2）老师好，对于 Asyncio 来说，它的任务在运行时不会被外部的一些因素打断。不被打断是如何保证的？还有event loop是每次取出一个任务运行，当这个任务运行期间它就是只等待任务结束吗？不干其他事了吗？2019-07-01Geek_59f23e 👍（3） 💬（0）import time from multiprocessing import Pool\ndef square(number): return sum(i * i for i in range(number))\ndef single_process(numbers): res = [] for number in numbers: res.append(square(number)) return res\ndef multi_process(numbers): with Pool() as pool: res = pool.map(square, numbers) return res\nif name == 'main': numbers = [10000000 + x for x in range(20)] start1 = time.perf_counter() single_process(numbers) print('单进程用时：%f 秒' % (time.perf_counter() - start1)) start2 = time.perf_counter() multi_process(numbers) print('多进程用时：%f 秒' % (time.perf_counter() - start2))\n———————— 输出： 单进程用时：29.382878 秒 多进程用时：10.354565 秒\n[333333283333335000000, 333333383333335000000, 333333483333355000001, 333333583333395000005, 333333683333455000014, 333333783333535000030, 333333883333635000055, 333333983333755000091, 333334083333895000140, 333334183334055000204, 333334283334235000285, 333334383334435000385, 333334483334655000506, 333334583334895000650, 333334683335155000819, 333334783335435001015, 333334883335735001240, 333334983336055001496, 333335083336395001785, 333335183336755002109]\ndef calculate_sums(numbers): with concurrent.futures.ProcessPoolExecutor() as executor: executor.map(cpu_bound, numbers)\ndef main(): start_time = time.perf_counter()\nnumbers = [10000000 + x for x in range(20)] calculate_sums(numbers) end_time = time.perf_counter() print('Calculation takes {} seconds'.format(end_time - start_time))\nif name == 'main': main()2020-10-04\n"
            }
        );
    index.add(
            {
                id:  32 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/23---%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82python-gil%E5%85%A8%E5%B1%80%E8%A7%A3%E9%87%8A%E5%99%A8%E9%94%81%E5%90%97\/",
                title: "你真的懂Python GIL（全局解释器锁）吗？",
                description: "你好，我是景霄。\n前面几节课，我们学习了Python的并发编程特性，也了解了多线程编程。事实上，Python多线程另一个很重要的话题——GIL（Global Interpreter Lock，即全局解释器锁）却鲜有人知，甚至连很多Python“老司机”都觉得GIL就是一个谜。今天我就来为你解谜，带你一起来看GIL。\n一个不解之谜 link耳听为虚，眼见为实。我们不妨先来看一个例子，让你感受下GIL为什么会让人不明所以。\n比如下面这段很简单的cpu-bound代码：\ndef CountDown(n):\rwhile n \u003e 0:\rn -= 1 现在，假设一个很大的数字n = 100000000，我们先来试试单线程的情况下执行CountDown(n)。在我手上这台号称8核的MacBook上执行后，我发现它的耗时为5.4s。\n这时，我们想要用多线程来加速，比如下面这几行操作：\nfrom threading import Thread\rn = 100000000\rt1 = Thread(target=CountDown, args=[n // 2])\rt2 = Thread(target=CountDown, args=[n // 2])\rt1.start()\rt2.start()\rt1.join()\rt2.join() 我又在同一台机器上跑了一下，结果发现，这不仅没有得到速度的提升，反而让运行变慢，总共花了9.6s。\n我还是不死心，决定使用四个线程再试一次，结果发现运行时间还是9.8s，和2个线程的结果几乎一样。\n这是怎么回事呢？难道是我买了假的MacBook吗？你可以先自己思考一下这个问题，也可以在自己电脑上测试一下。我当然也要自我反思一下，并且提出了下面两个猜想。\n第一个怀疑：我的机器出问题了吗？\n这不得不说也是一个合理的猜想。因此我又找了一个单核CPU的台式机，跑了一下上面的实验。这次我发现，在单核CPU电脑上，单线程运行需要11s时间，2个线程运行也是11s时间。虽然不像第一台机器那样，多线程反而比单线程更慢，但是这两次整体效果几乎一样呀！\n看起来，这不像是电脑的问题，而是Python的线程失效了，没有起到并行计算的作用。\n顺理成章，我又有了第二个怀疑：Python的线程是不是假的线程？\nPython的线程，的的确确封装了底层的操作系统线程，在Linux系统里是Pthread（全称为POSIX Thread），而在Windows系统里是Windows Thread。另外，Python的线程，也完全受操作系统管理，比如协调何时执行、管理内存资源、管理中断等等。\n所以，虽然Python的线程和C++的线程本质上是不同的抽象，但它们的底层并没有什么不同。\n为什么有GIL？ link看来我的两个猜想，都不能解释开头的这个未解之谜。那究竟谁才是“罪魁祸首”呢？事实上，正是我们今天的主角，也就是GIL，导致了Python线程的性能并不像我们期望的那样。\nGIL，是最流行的Python解释器CPython中的一个技术术语。它的意思是全局解释器锁，本质上是类似操作系统的Mutex。每一个Python线程，在CPython解释器中执行时，都会先锁住自己的线程，阻止别的线程执行。\n当然，CPython会做一些小把戏，轮流执行Python线程。这样一来，用户看到的就是“伪并行”——Python线程在交错执行，来模拟真正并行的线程。\n那么，为什么CPython需要GIL呢？这其实和CPython的实现有关。下一节我们会讲Python的内存管理机制，今天先稍微提一下。\nCPython使用引用计数来管理内存，所有Python脚本中创建的实例，都会有一个引用计数，来记录有多少个指针指向它。当引用计数只有0时，则会自动释放内存。\n什么意思呢？我们来看下面这个例子：\n\u003e\u003e\u003e import sys\r\u003e\u003e\u003e a = []\r\u003e\u003e\u003e b = a\r\u003e\u003e\u003e sys.getrefcount(a)\r3 这个例子中，a的引用计数是3，因为有a、b和作为参数传递的getrefcount这三个地方，都引用了一个空列表。\n",
                content: "你好，我是景霄。\n前面几节课，我们学习了Python的并发编程特性，也了解了多线程编程。事实上，Python多线程另一个很重要的话题——GIL（Global Interpreter Lock，即全局解释器锁）却鲜有人知，甚至连很多Python“老司机”都觉得GIL就是一个谜。今天我就来为你解谜，带你一起来看GIL。\n一个不解之谜 link耳听为虚，眼见为实。我们不妨先来看一个例子，让你感受下GIL为什么会让人不明所以。\n比如下面这段很简单的cpu-bound代码：\ndef CountDown(n):\rwhile n \u003e 0:\rn -= 1 现在，假设一个很大的数字n = 100000000，我们先来试试单线程的情况下执行CountDown(n)。在我手上这台号称8核的MacBook上执行后，我发现它的耗时为5.4s。\n这时，我们想要用多线程来加速，比如下面这几行操作：\nfrom threading import Thread\rn = 100000000\rt1 = Thread(target=CountDown, args=[n // 2])\rt2 = Thread(target=CountDown, args=[n // 2])\rt1.start()\rt2.start()\rt1.join()\rt2.join() 我又在同一台机器上跑了一下，结果发现，这不仅没有得到速度的提升，反而让运行变慢，总共花了9.6s。\n我还是不死心，决定使用四个线程再试一次，结果发现运行时间还是9.8s，和2个线程的结果几乎一样。\n这是怎么回事呢？难道是我买了假的MacBook吗？你可以先自己思考一下这个问题，也可以在自己电脑上测试一下。我当然也要自我反思一下，并且提出了下面两个猜想。\n第一个怀疑：我的机器出问题了吗？\n这不得不说也是一个合理的猜想。因此我又找了一个单核CPU的台式机，跑了一下上面的实验。这次我发现，在单核CPU电脑上，单线程运行需要11s时间，2个线程运行也是11s时间。虽然不像第一台机器那样，多线程反而比单线程更慢，但是这两次整体效果几乎一样呀！\n看起来，这不像是电脑的问题，而是Python的线程失效了，没有起到并行计算的作用。\n顺理成章，我又有了第二个怀疑：Python的线程是不是假的线程？\nPython的线程，的的确确封装了底层的操作系统线程，在Linux系统里是Pthread（全称为POSIX Thread），而在Windows系统里是Windows Thread。另外，Python的线程，也完全受操作系统管理，比如协调何时执行、管理内存资源、管理中断等等。\n所以，虽然Python的线程和C++的线程本质上是不同的抽象，但它们的底层并没有什么不同。\n为什么有GIL？ link看来我的两个猜想，都不能解释开头的这个未解之谜。那究竟谁才是“罪魁祸首”呢？事实上，正是我们今天的主角，也就是GIL，导致了Python线程的性能并不像我们期望的那样。\nGIL，是最流行的Python解释器CPython中的一个技术术语。它的意思是全局解释器锁，本质上是类似操作系统的Mutex。每一个Python线程，在CPython解释器中执行时，都会先锁住自己的线程，阻止别的线程执行。\n当然，CPython会做一些小把戏，轮流执行Python线程。这样一来，用户看到的就是“伪并行”——Python线程在交错执行，来模拟真正并行的线程。\n那么，为什么CPython需要GIL呢？这其实和CPython的实现有关。下一节我们会讲Python的内存管理机制，今天先稍微提一下。\nCPython使用引用计数来管理内存，所有Python脚本中创建的实例，都会有一个引用计数，来记录有多少个指针指向它。当引用计数只有0时，则会自动释放内存。\n什么意思呢？我们来看下面这个例子：\n\u003e\u003e\u003e import sys\r\u003e\u003e\u003e a = []\r\u003e\u003e\u003e b = a\r\u003e\u003e\u003e sys.getrefcount(a)\r3 这个例子中，a的引用计数是3，因为有a、b和作为参数传递的getrefcount这三个地方，都引用了一个空列表。\n这样一来，如果有两个Python线程同时引用了a，就会造成引用计数的race condition，引用计数可能最终只增加1，这样就会造成内存被污染。因为第一个线程结束时，会把引用计数减少1，这时可能达到条件释放内存，当第二个线程再试图访问a时，就找不到有效的内存了。\n所以说，CPython 引进 GIL 其实主要就是这么两个原因：\n一是设计者为了规避类似于内存管理这样的复杂的竞争风险问题（race condition）； 二是因为CPython大量使用C语言库，但大部分C语言库都不是原生线程安全的（线程安全会降低性能和增加复杂度）。 GIL是如何工作的？ link下面这张图，就是一个GIL在Python程序的工作示例。其中，Thread 1、2、3轮流执行，每一个线程在开始执行时，都会锁住GIL，以阻止别的线程执行；同样的，每一个线程执行完一段后，会释放GIL，以允许别的线程开始利用资源。\n细心的你可能会发现一个问题：为什么Python线程会去主动释放GIL呢？毕竟，如果仅仅是要求Python线程在开始执行时锁住GIL，而永远不去释放GIL，那别的线程就都没有了运行的机会。\n没错，CPython中还有另一个机制，叫做check_interval，意思是CPython解释器会去轮询检查线程GIL的锁住情况。每隔一段时间，Python解释器就会强制当前线程去释放GIL，这样别的线程才能有执行的机会。\n不同版本的Python中，check interval的实现方式并不一样。早期的Python是100个ticks，大致对应了1000个bytecodes；而 Python 3以后，interval是15毫秒。当然，我们不必细究具体多久会强制释放GIL，这不应该成为我们程序设计的依赖条件，我们只需明白，CPython解释器会在一个“合理”的时间范围内释放GIL就可以了。\n整体来说，每一个Python线程都是类似这样循环的封装，我们来看下面这段代码：\nfor (;;) {\rif (--ticker \u003c 0) {\rticker = check_interval;\r/* Give another thread a chance */\rPyThread_release_lock(interpreter_lock);\r/* Other threads may run now */\rPyThread_acquire_lock(interpreter_lock, 1);\r}\rbytecode = *next_instr++;\rswitch (bytecode) {\r/* execute the next instruction ... */ }\r} 从这段代码中，我们可以看到，每个Python线程都会先检查ticker计数。只有在ticker大于0的情况下，线程才会去执行自己的bytecode。\nPython的线程安全 link不过，有了GIL，并不意味着我们Python编程者就不用去考虑线程安全了。即使我们知道，GIL仅允许一个Python线程执行，但前面我也讲到了，Python还有check interval这样的抢占机制。我们来考虑这样一段代码：\nimport threading\rn = 0\rdef foo():\rglobal n\rn += 1\rthreads = []\rfor i in range(100):\rt = threading.Thread(target=foo)\rthreads.append(t)\rfor t in threads:\rt.start()\rfor t in threads:\rt.join()\rprint(n) 如果你执行的话，就会发现，尽管大部分时候它能够打印100，但有时侯也会打印99或者98。\n这其实就是因为，n+=1这一句代码让线程并不安全。如果你去翻译foo这个函数的bytecode，就会发现，它实际上由下面四行bytecode组成：\n\u003e\u003e\u003e import dis\r\u003e\u003e\u003e dis.dis(foo)\rLOAD_GLOBAL 0 (n)\rLOAD_CONST 1 (1)\rINPLACE_ADD\rSTORE_GLOBAL 0 (n) 而这四行bytecode中间都是有可能被打断的！\n所以，千万别想着，有了GIL你的程序就可以高枕无忧了，我们仍然需要去注意线程安全。正如我开头所说，GIL的设计，主要是为了方便CPython解释器层面的编写者，而不是Python应用层面的程序员。作为Python的使用者，我们还是需要lock等工具，来确保线程安全。比如我下面的这个例子：\nn = 0\rlock = threading.Lock()\rdef foo():\rglobal n\rwith lock:\rn += 1 如何绕过GIL？ link学到这里，估计有的Python使用者感觉自己像被废了武功一样，觉得降龙十八掌只剩下了一掌。其实大可不必，你并不需要太沮丧。Python的GIL，是通过CPython的解释器加的限制。如果你的代码并不需要CPython解释器来执行，就不再受GIL的限制。\n事实上，很多高性能应用场景都已经有大量的C实现的Python库，例如NumPy的矩阵运算，就都是通过C来实现的，并不受GIL影响。\n所以，大部分应用情况下，你并不需要过多考虑GIL。因为如果多线程计算成为性能瓶颈，往往已经有Python库来解决这个问题了。\n换句话说，如果你的应用真的对性能有超级严格的要求，比如100us就对你的应用有很大影响，那我必须要说，Python可能不是你的最优选择。\n当然，可以理解的是，我们难以避免的有时候就是想临时给自己松松绑，摆脱GIL，比如在深度学习应用里，大部分代码就都是Python的。在实际工作中，如果我们想实现一个自定义的微分算子，或者是一个特定硬件的加速器，那我们就不得不把这些关键性能（performance-critical）代码在C++中实现（不再受GIL所限），然后再提供Python的调用接口。\n总的来说，你只需要重点记住，绕过GIL的大致思路有这么两种就够了：\n绕过CPython，使用JPython（Java实现的Python解释器）等别的实现； 把关键性能代码，放到别的语言（一般是C++）中实现。 总结 link今天这节课，我们先通过一个实际的例子，了解了GIL对于应用的影响；之后我们适度剖析了GIL的实现原理，你不必深究一些原理的细节，明白其主要机制和存在的隐患即可。\n自然，我也为你提供了绕过GIL的两种思路。不过还是那句话，很多时候，我们并不需要过多纠结GIL的影响。\n思考题 link最后，我给你留下两道思考题。\n第一问，在我们处理cpu-bound的任务（文中第一个例子）时，为什么有时候使用多线程会比单线程还要慢些？\n第二问，你觉得GIL是一个好的设计吗？事实上，在Python 3之后，确实有很多关于GIL改进甚至是取消的讨论，你的看法是什么呢？你在平常工作中有被GIL困扰过的场景吗？\n欢迎在留言区写下你的想法，也欢迎你把今天的内容分享给你的同事朋友，我们一起交流、一起进步。\n思考题2： 个人觉得GIL仍然是一种好的设计，虽然损失了一些性能，但在保证资源不发生冲突，预防死锁方面还是有一定作用的。\n以上是个人的一点肤浅理解，请老师指正。2019-10-25jackstraw 👍（9） 💬（1）关于绕过GIL的第二个方式：将关键的性能代码放到别的语言中（通常C++）实现；这种解决方式指的是在别的语言中使用多线程的方式处理任务么？就是不用python的多线程，而是在别的语言中使用多线程？2020-01-15小侠龙旋风 👍（145） 💬（2）先mark一下学到的知识点： 一、查看引用计数的方法：sys.getrefcount(a) 二、CPython引进GIL的主要原因是：\n设计者为了规避类似内存管理这样的复杂竞争风险问题（race condition）； CPython大量使用C语言库，但大部分C语言库都不是线程安全的（线程安全会降低性能和增加复杂度）。 三、绕过GIL的两种思路： 绕过CPython，使用JPython等别的实现； 把关键性能代码放到其他语言中实现，比如C++。 问答老师的问题：\ncpu-bound属于计算密集型程序，用多线程运行时，每个线程在开始执行时都会锁住GIL、执行完会释放GIL，这两个步骤比较费时。相比单线程就没有切换线程的问题，所以更快。 相反，在处理多阻塞高延迟的IO密集型程序时，因为多线程有check interval机制，若遇阻塞，CPython会强制当前线程让出（释放）GIL，给其他线程执行的机会。所以能提高程序的执行效率。 第二个问题摘抄了知乎上的讨论： 在python3中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后interval=15毫秒，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低。 经常会听到老手说：“python下想要充分利用多核CPU，就用多进程”，原因是什么呢？原因是：每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。所以我们能够得出结论：多核下，想做并行提升效率，比较通用的方法是使用多进程，能够有效提高执行效率。2019-07-06leixin 👍（41） 💬（3）有重要的一点没讲，GIL会在遇到io的时候自动释放，给其他线程执行的机会，这样Python多线程在io阻塞的多任务中有效。2019-07-01leixin 👍（34） 💬（1）老师，我曾经去某大厂面试。人家问了我几个问题，比说说，你知道元类吗？Python是如何解决循环引用的？换句话说，Python的垃圾回收机制是如何？我后来自己找了些资料看了，还是，不是理解的特别明白。老师后面的课程能帮我们讲解下吗？2019-07-01helloworld 👍（10） 💬（0）python的单线程和多线程同时都只能利用一颗cpu核心，对于纯cpu heavy任务场景，不涉及到io耗时环节，cpu都是充分利用的，多线程和单线程相比反倒是多了线程切换的成本，所以性能反而不如单线程。2019-07-01SCAR 👍（8） 💬（1）1.cpu-bound任务的多线程相比单线程，时间的增加在于锁添加的获取和释放的开销结果。 2.返回到python诞生的年代，GIL相对来说是合理而且有效率的，它易于实现，很容易就添加到python中，而且它为单线程程序提供了性能提升。以至于Guido在“It isn't Easy to Remove the GIL”里面说“ I'd welcome a set of patches into Py3k only if the performance for a single-threaded program (and for a multi-threaded but I/O-bound program) does not decrease”。而到现在为止，任何尝试都没有达到这一条件。 2你觉得 GIL 是一个好的设计吗？事实上，在 Python 3 之后，确实有很多关于 GIL 改进甚至是取消的讨论，你的看法是什么呢？你在平常工作中有被 GIL 困扰过的场景吗？ 答：不是一个好的设计，仅仅是简化了解释器的设计，且并没有解决线程安全的问题。\n总结：CPU密集型任务用多进程并行处理（CPU需多核），I/O密集型任务用协程，理论上协程比多线程的效率还要高。2020-05-26程序员人生 👍（2） 💬（8）t1 = Thread(target=CountDown, args=[n // 2]) 老师，这段代码里面n//2是什么意思？2019-07-01自由民 👍（1） 💬（0）思考题 1.线程切换有开销成本，另外最主要是由于GIL的存在使python的并行为伪并行。 2.我觉得不是好设计，像戴着镣铐跳舞，好处仅仅是简化了解释器的设计。而且它并不能完全解决线程安全问题。但我平时很少用多线程编程，所以还没有实际体会。而像解释器这样的基础设施应该是把脏活留给自己，尽量减少用户的复杂性。类似还有从python2到python3的大变动。2019-10-15程序员人生 👍（1） 💬（0）通过老师的讲解，我觉得GIL有点像java的Synchronized 监视器锁，同一时刻只有一个线程获得监视器锁。所以线程的频繁切换，会增加CPU开销，导致多线程反而速度变慢。2019-07-01张申傲 👍（0） 💬（0）第23讲打卡~2024-06-20A君 👍（0） 💬（0）如果是通过Threading创建多线程，多线程跑python API封装的C++程序，这样是受限GIL的。而把创建多线程的工作放到C++程序里，就不被GIL所累了。2022-05-27\n"
            }
        );
    index.add(
            {
                id:  33 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/24---%E5%B8%A6%E4%BD%A0%E8%A7%A3%E6%9E%90-python-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6\/",
                title: "带你解析 Python 垃圾回收机制",
                description: "你好，我是景霄。\n众所周知，我们当代的计算机都是图灵机架构。图灵机架构的本质，就是一条无限长的纸带，对应着我们今天的存储器。在工程学的演化中，逐渐出现了寄存器、易失性存储器（内存）和永久性存储器（硬盘）等产品。其实，这本身来自一个矛盾：速度越快的存储器，单位价格也越昂贵。因此，妥善利用好每一寸高速存储器的空间，永远是系统设计的一个核心。\n回到 Python 应用层。\n我们知道，Python 程序在运行的时候，需要在内存中开辟出一块空间，用于存放运行时产生的临时变量；计算完成后，再将结果输出到永久性存储器中。如果数据量过大，内存空间管理不善就很容易出现 OOM（out of memory），俗称爆内存，程序可能被操作系统中止。\n而对于服务器，这种设计为永不中断的系统来说，内存管理则显得更为重要，不然很容易引发内存泄漏。什么是内存泄漏呢？\n这里的泄漏，并不是说你的内存出现了信息安全问题，被恶意程序利用了，而是指程序本身没有设计好，导致程序未能释放已不再使用的内存。 内存泄漏也不是指你的内存在物理上消失了，而是意味着代码在分配了某段内存后，因为设计错误，失去了对这段内存的控制，从而造成了内存的浪费。 那么，Python 又是怎么解决这些问题的？换句话说，对于不会再用到的内存空间，Python 是通过什么机制来回收这些空间的呢？\n计数引用 link我们反复提过好几次， Python 中一切皆对象。因此，你所看到的一切变量，本质上都是对象的一个指针。\n那么，怎么知道一个对象，是否永远都不能被调用了呢？\n我们上节课提到过的，也是非常直观的一个想法，就是当这个对象的引用计数（指针数）为 0 的时候，说明这个对象永不可达，自然它也就成为了垃圾，需要被回收。\n我们来看一个例子：\nimport os\rimport psutil\r# 显示当前 python 程序占用的内存大小\rdef show_memory_info(hint):\rpid = os.getpid()\rp = psutil.Process(pid)\rinfo = p.memory_full_info()\rmemory = info.uss / 1024. / 1024\rprint('{} memory used: {} MB'.format(hint, memory)) def func():\rshow_memory_info('initial')\ra = [i for i in range(10000000)]\rshow_memory_info('after a created')\rfunc()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 47.19140625 MB\rafter a created memory used: 433.91015625 MB\rfinished memory used: 48.109375 MB 通过这个示例，你可以看到，调用函数 func()，在列表 a 被创建之后，内存占用迅速增加到了 433 MB：而在函数调用结束后，内存则返回正常。\n",
                content: "你好，我是景霄。\n众所周知，我们当代的计算机都是图灵机架构。图灵机架构的本质，就是一条无限长的纸带，对应着我们今天的存储器。在工程学的演化中，逐渐出现了寄存器、易失性存储器（内存）和永久性存储器（硬盘）等产品。其实，这本身来自一个矛盾：速度越快的存储器，单位价格也越昂贵。因此，妥善利用好每一寸高速存储器的空间，永远是系统设计的一个核心。\n回到 Python 应用层。\n我们知道，Python 程序在运行的时候，需要在内存中开辟出一块空间，用于存放运行时产生的临时变量；计算完成后，再将结果输出到永久性存储器中。如果数据量过大，内存空间管理不善就很容易出现 OOM（out of memory），俗称爆内存，程序可能被操作系统中止。\n而对于服务器，这种设计为永不中断的系统来说，内存管理则显得更为重要，不然很容易引发内存泄漏。什么是内存泄漏呢？\n这里的泄漏，并不是说你的内存出现了信息安全问题，被恶意程序利用了，而是指程序本身没有设计好，导致程序未能释放已不再使用的内存。 内存泄漏也不是指你的内存在物理上消失了，而是意味着代码在分配了某段内存后，因为设计错误，失去了对这段内存的控制，从而造成了内存的浪费。 那么，Python 又是怎么解决这些问题的？换句话说，对于不会再用到的内存空间，Python 是通过什么机制来回收这些空间的呢？\n计数引用 link我们反复提过好几次， Python 中一切皆对象。因此，你所看到的一切变量，本质上都是对象的一个指针。\n那么，怎么知道一个对象，是否永远都不能被调用了呢？\n我们上节课提到过的，也是非常直观的一个想法，就是当这个对象的引用计数（指针数）为 0 的时候，说明这个对象永不可达，自然它也就成为了垃圾，需要被回收。\n我们来看一个例子：\nimport os\rimport psutil\r# 显示当前 python 程序占用的内存大小\rdef show_memory_info(hint):\rpid = os.getpid()\rp = psutil.Process(pid)\rinfo = p.memory_full_info()\rmemory = info.uss / 1024. / 1024\rprint('{} memory used: {} MB'.format(hint, memory)) def func():\rshow_memory_info('initial')\ra = [i for i in range(10000000)]\rshow_memory_info('after a created')\rfunc()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 47.19140625 MB\rafter a created memory used: 433.91015625 MB\rfinished memory used: 48.109375 MB 通过这个示例，你可以看到，调用函数 func()，在列表 a 被创建之后，内存占用迅速增加到了 433 MB：而在函数调用结束后，内存则返回正常。\n这是因为，函数内部声明的列表 a 是局部变量，在函数返回后，局部变量的引用会注销掉；此时，列表 a 所指代对象的引用数为 0，Python 便会执行垃圾回收，因此之前占用的大量内存就又回来了。\n明白了这个原理后，我们稍微修改一下代码：\ndef func():\rshow_memory_info('initial')\rglobal a\ra = [i for i in range(10000000)]\rshow_memory_info('after a created')\rfunc()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 48.88671875 MB\rafter a created memory used: 433.94921875 MB\rfinished memory used: 433.94921875 MB 新的这段代码中，global a 表示将 a 声明为全局变量。那么，即使函数返回后，列表的引用依然存在，于是对象就不会被垃圾回收掉，依然占用大量内存。\n同样，如果我们把生成的列表返回，然后在主程序中接收，那么引用依然存在，垃圾回收就不会被触发，大量内存仍然被占用着：\ndef func():\rshow_memory_info('initial')\ra = [i for i in derange(10000000)]\rshow_memory_info('after a created')\rreturn a\ra = func()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 47.96484375 MB\rafter a created memory used: 434.515625 MB\rfinished memory used: 434.515625 MB 这是最常见的几种情况。由表及里，下面，我们深入看一下 Python 内部的引用计数机制。老规矩，先来看代码：\nimport sys\ra = []\r# 两次引用，一次来自 a，一次来自 getrefcount\rprint(sys.getrefcount(a))\rdef func(a):\r# 四次引用，a，python 的函数调用栈，函数参数，和 getrefcount\rprint(sys.getrefcount(a))\rfunc(a)\r# 两次引用，一次来自 a，一次来自 getrefcount，函数 func 调用已经不存在\rprint(sys.getrefcount(a))\r########## 输出 ##########\r2\r4\r2 简单介绍一下，sys.getrefcount() 这个函数，可以查看一个变量的引用次数。这段代码本身应该很好理解，不过别忘了，getrefcount 本身也会引入一次计数。\n另一个要注意的是，在函数调用发生的时候，会产生额外的两次引用，一次来自函数栈，另一个是函数参数。\nimport sys\ra = []\rprint(sys.getrefcount(a)) # 两次\rb = a\rprint(sys.getrefcount(a)) # 三次\rc = b\rd = b\re = c\rf = e\rg = d\rprint(sys.getrefcount(a)) # 八次\r########## 输出 ##########\r2\r3\r8 看到这段代码，需要你稍微注意一下，a、b、c、d、e、f、g 这些变量全部指代的是同一个对象，而sys.getrefcount() 函数并不是统计一个指针，而是要统计一个对象被引用的次数，所以最后一共会有八次引用。\n理解引用这个概念后，引用释放是一种非常自然和清晰的思想。相比 C 语言里，你需要使用 free 去手动释放内存，Python 的垃圾回收在这里可以说是省心省力了。\n不过，我想还是会有人问，如果我偏偏想手动释放内存，应该怎么做呢？\n方法同样很简单。你只需要先调用 del a 来删除对象的引用；然后强制调用 gc.collect()，清除没有引用的对象，即可手动启动垃圾回收。\nimport gc\rshow_memory_info('initial')\ra = [i for i in range(10000000)]\rshow_memory_info('after a created')\rdel a\rgc.collect()\rshow_memory_info('finish')\rprint(a)\r########## 输出 ##########\rinitial memory used: 48.1015625 MB\rafter a created memory used: 434.3828125 MB\rfinish memory used: 48.33203125 MB\r---------------------------------------------------------------------------\rNameError Traceback (most recent call last)\rin 11 12 show_memory_info('finish')\r---\u003e 13 print(a)\rNameError: name 'a' is not defined 到这里，是不是觉得垃圾回收非常简单呀？\n我想，肯定有人觉得自己都懂了，那么，如果此时有面试官问：引用次数为 0 是垃圾回收启动的充要条件吗？还有没有其他可能性呢？\n这个问题，你能回答的上来吗？\n循环引用 link如果你也被困住了，别急。我们不妨小步设问，先来思考这么一个问题：如果有两个对象，它们互相引用，并且不再被别的对象所引用，那么它们应该被垃圾回收吗？\n请仔细观察下面这段代码：\ndef func():\rshow_memory_info('initial')\ra = [i for i in range(10000000)]\rb = [i for i in range(10000000)]\rshow_memory_info('after a, b created')\ra.append(b)\rb.append(a)\rfunc()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 47.984375 MB\rafter a, b created memory used: 822.73828125 MB\rfinished memory used: 821.73046875 MB 这里，a 和 b 互相引用，并且，作为局部变量，在函数 func 调用结束后，a 和 b 这两个指针从程序意义上已经不存在了。但是，很明显，依然有内存占用！为什么呢？因为互相引用，导致它们的引用数都不为 0。\n试想一下，如果这段代码出现在生产环境中，哪怕 a 和 b 一开始占用的空间不是很大，但经过长时间运行后，Python 所占用的内存一定会变得越来越大，最终撑爆服务器，后果不堪设想。\n当然，有人可能会说，互相引用还是很容易被发现的呀，问题不大。可是，更隐蔽的情况是出现一个引用环，在工程代码比较复杂的情况下，引用环还真不一定能被轻易发现。\n那么，我们应该怎么做呢？\n事实上，Python 本身能够处理这种情况，我们刚刚讲过的，可以显式调用 gc.collect() ，来启动垃圾回收。\nimport gc\rdef func():\rshow_memory_info('initial')\ra = [i for i in range(10000000)]\rb = [i for i in range(10000000)]\rshow_memory_info('after a, b created')\ra.append(b)\rb.append(a)\rfunc()\rgc.collect()\rshow_memory_info('finished')\r########## 输出 ##########\rinitial memory used: 49.51171875 MB\rafter a, b created memory used: 824.1328125 MB\rfinished memory used: 49.98046875 MB 所以你看，Python 的垃圾回收机制并没有那么弱。\nPython 使用标记清除（mark-sweep）算法和分代收集（generational），来启用针对循环引用的自动垃圾回收。你可能不太熟悉这两个词，这里我简单介绍一下。\n先来看标记清除算法。我们先用图论来理解不可达的概念。对于一个有向图，如果从一个节点出发进行遍历，并标记其经过的所有节点；那么，在遍历结束后，所有没有被标记的节点，我们就称之为不可达节点。显而易见，这些节点的存在是没有任何意义的，自然的，我们就需要对它们进行垃圾回收。\n当然，每次都遍历全图，对于 Python 而言是一种巨大的性能浪费。所以，在 Python 的垃圾回收实现中，mark-sweep 使用双向链表维护了一个数据结构，并且只考虑容器类的对象（只有容器类对象才有可能产生循环引用）。具体算法这里我就不再多讲了，毕竟我们的重点是关注应用。\n而分代收集算法，则是另一个优化手段。\nPython 将所有对象分为三代。刚刚创立的对象是第 0 代；经过一次垃圾回收后，依然存在的对象，便会依次从上一代挪到下一代。而每一代启动自动垃圾回收的阈值，则是可以单独指定的。当垃圾回收器中新增对象减去删除对象达到相应的阈值时，就会对这一代对象启动垃圾回收。\n事实上，分代收集基于的思想是，新生的对象更有可能被垃圾回收，而存活更久的对象也有更高的概率继续存活。因此，通过这种做法，可以节约不少计算量，从而提高 Python 的性能。\n学了这么多，刚刚面试官的问题，你应该能回答得上来了吧！没错，引用计数是其中最简单的实现，不过切记，引用计数并非充要条件，它只能算作充分非必要条件；至于其他的可能性，我们所讲的循环引用正是其中一种。\n调试内存泄漏 link不过，虽然有了自动回收机制，但这也不是万能的，难免还是会有漏网之鱼。内存泄漏是我们不想见到的，而且还会严重影响性能。有没有什么好的调试手段呢？\n答案当然是肯定的，接下来我就为你介绍一个“得力助手”。\n它就是objgraph，一个非常好用的可视化引用关系的包。在这个包中，我主要推荐两个函数，第一个是show_refs()，它可以生成清晰的引用关系图。\n通过下面这段代码和生成的引用调用图，你能非常直观地发现，有两个 list 互相引用，说明这里极有可能引起内存泄露。这样一来，再去代码层排查就容易多了。\nimport objgraph\ra = [1, 2, 3]\rb = [4, 5, 6]\ra.append(b)\rb.append(a)\robjgraph.show_refs([a]) 而另一个非常有用的函数，是 show_backrefs()。下面同样为示例代码和生成图，你可以自己先阅读一下：\nimport objgraph\ra = [1, 2, 3]\rb = [4, 5, 6]\ra.append(b)\rb.append(a)\robjgraph.show_backrefs([a]) 相比刚才的引用调用图，这张图显得稍微复杂一些。不过，我仍旧推荐你掌握它，因为这个 API 有很多有用的参数，比如层数限制（max_depth）、宽度限制（too_many）、输出格式控制（filename output）、节点过滤（filter, extra_ignore）等。所以，建议你使用之前，先认真看一下文档。\n总结 link最后，带你来总结一下。今天这节课，我们深入了解了Python 的垃圾回收机制，我主要强调下面这几点：\n垃圾回收是 Python 自带的机制，用于自动释放不会再用到的内存空间； 引用计数是其中最简单的实现，不过切记，这只是充分非必要条件，因为循环引用需要通过不可达判定，来确定是否可以回收； Python 的自动回收算法包括标记清除和分代收集，主要针对的是循环引用的垃圾收集； 调试内存泄漏方面， objgraph 是很好的可视化分析工具。 思考题 link最后给你留一道思考题。你能否自己实现一个垃圾回收判定算法呢？我的要求很简单，输入是一个有向图，给定起点，表示程序入口点；给定有向边，输出不可达节点。\n希望你可以认真思考这个问题，并且在留言区写下你的答案与我讨论。也欢迎你把这篇文章分享出去，我们一起交流，一起进步。\n事实上算法可以写的很简单，这是个很经典的 dfs （深度优先搜索）遍历，从起点开始遍历，对遍历到的节点做个记号。遍历完成后，再对所有节点扫一遍，没有被做记号的，就是需要垃圾回收的。2019-07-06陈迪 👍（24） 💬（4）1. 循环引用情况下Python不立即回收内存，如果放任不管，即不显式调用gc.collect的话，Python的垃圾回收器自己会什么时候处理？ 2. 最后介绍了内存泄露排查工具，哪种算内存泄露呢？接问题1，不立即回收算内存泄露吗？还是有其他场景2019-07-03天凉好个秋 👍（10） 💬（3）本文讲的垃圾回收算法在Java中也都有，当初在设计的时候是不是参考了Java？而且，Java中还有标记整理算法，可以解决回收内存不连续的问题，这个在Python中有没有考虑呢？2019-07-03　星豪 👍（5） 💬（1）1. 在读文章的时候找了一个可能是错别字的地方，在循环引用那一节中，第四段试想一下，如果这段代码出现在生产环境中…但经过长时间运行“候”…。这一侯应该是后来的后吧？ 2. 当垃圾回收器中新增对象减去删除对象达到相应的阈值时，就会对这一代对象启动垃圾回收。这一句话不是很明白，新增对象我理解的是新创建的对象或者是从上一代挪过来的对象，那么删除对象指的是哪些呢？或者说是如何进行指定哪些是应该被删除的对象呢？2019-07-04MirkoWei 👍（3） 💬（1）windows下使用objgraph遇到个问题： failed to execute [\u0026#39;dot\u0026#39;, \u0026#39;-Tpdf\u0026#39;], make sure the Graphviz executables are on your systems\u0026#39; path\n安装objgraph的时候，需要的前置条件graphviz、xdot都安装了，系统环境变量也添加了，仍然找不到路径\n之后通过stackoverflow得到解决办法，就是每次使用的时候，需要在代码前面手动添加环境变量\nimport os\ros.environ[\u0026quot;PATH\u0026quot;] += os.pathsep + \u0026#39;xxx\u0026#47;Graphviz2.38\u0026#47;bin\u0026#47;\u0026#39; 问题是解决了，但是每次都需要手动添加环境变量也太麻烦了，不知道是否有更好的解决办法2020-05-19wangkx 👍（1） 💬（1）课程越往后越有意思，发现了很多知识点盲区，这门课很值！2020-07-02Switch 👍（23） 💬（1）思考题： from typing import Set\nclass Graph: def init(self, value, nodes=None): self._value = value self._nodes: list = [] if nodes is None else nodes\n@property\rdef value(self):\rreturn self._value\r@property\rdef nodes(self):\rreturn self._nodes\rdef node_add(self, node):\rself._nodes.append(node)\rdef node_adds(self, nodes):\rself._nodes.extend(nodes)\rdef node_del(self, node):\rself._nodes.remove(node)\rdef __str__(self):\rreturn \u0026quot;Graph {} nodes {}\u0026quot;.format(self._value, [node.value for node in self.nodes])\rdef __repr__(self):\rreturn self.__str__()\rdef dfs(start: Graph, includes: Set[Graph] = None) -\u003e Set[Graph]: if includes is None: includes = set() if start in includes: return includes includes.add(start) for s in start.nodes: includes.update(dfs(s, includes)) return includes\nif name == 'main': A = Graph('A') B = Graph('B') C = Graph('C') D = Graph('D') E = Graph('E') F = Graph('F') has_nodes = {A, B, C, D, E, F}\n# A-\u0026gt;B-\u0026gt;E\r# -\u0026gt;C-\u0026gt;E\r# B-\u0026gt;A\r# D-\u0026gt;F\r# F-\u0026gt;D\rA.node_adds([B, C])\rB.node_adds([A, E])\rC.node_adds([E])\rD.node_adds([F])\rF.node_adds([D])\rgraph_nodes = dfs(A, set())\r# OUT: {Graph B nodes [\u0026#39;A\u0026#39;, \u0026#39;E\u0026#39;], Graph E nodes [], Graph C nodes [\u0026#39;E\u0026#39;], Graph A nodes [\u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;]}\rprint(graph_nodes)\r# OUT: {Graph F nodes [\u0026#39;D\u0026#39;], Graph D nodes [\u0026#39;F\u0026#39;]}\rprint(has_nodes - graph_nodes)\rwhile stack:\rnode = stack.pop()\rif node not in visited:\rvisited.add(node)\rstack.extend(graph[node] - visited)\rreturn visited\rdef unreachable_nodes(graph: dict, start: str): reachable_nodes = dfs(graph, start) all_nodes = set(node for nodes in graph.values() for node in nodes).union(graph.keys()) return all_nodes - reachable_nodes\n示例图结构 linkgraph = { \"A\": {\"B\", \"C\"}, \"B\": {\"A\", \"D\", \"E\"}, \"C\": {\"A\", \"F\"}, \"D\": {\"B\"}, \"E\": {\"B\", \"F\"}, \"F\": {\"C\", \"E\"}, \"G\": {\"H\"}, \"H\": {\"G\"} }\nprint(unreachable_nodes(graph, 'A'))\n输出 link{'G', 'H'}2023-05-16瞌睡的咸鱼 👍（1） 💬（0）思考题——通过有向图的拓扑排序可以求出（可以参考《算法导论》去理解）2019-07-03\n"
            }
        );
    index.add(
            {
                id:  34 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/25---%E7%AD%94%E7%96%91%E4%BA%8Cgil%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%98%AF%E4%BB%80%E4%B9%88%E5%85%B3%E7%B3%BB%E5%91%A2\/",
                title: "答疑（二）：GIL与多线程是什么关系呢？",
                description: "你好，我是景霄。\n不知不觉中，我们又一起完成了第二大章进阶篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：列表self append无限嵌套的原理 link 先来回答第一个问题，两个同学都问到了，下面这段代码中的x，为什么是无限嵌套的列表？\nx = [1]\rx.append(x)\rx\r[1, [...]] 我们可以将上述操作画一个图，便于你更直观地理解：\n这里，x指向一个列表，列表的第一个元素为1；执行了append操作后，第二个元素又反过来指向x，即指向了x所指向的列表，因此形成了一个无限嵌套的循环：[1, [1, [1, [1, …]]]]。\n不过，虽然x是无限嵌套的列表，但x.append(x)的操作，并不会递归遍历其中的每一个元素。它只是扩充了原列表的第二个元素，并将其指向x，因此不会出现stack overflow的问题，自然不会报错。\n至于第二点，为什么len(x)返回的是2？我们还是来看x，虽然它是无限嵌套的列表，但x的top level只有2个元素组成，第一个元素为1，第二个元素为指向自身的列表，因此len(x)返回2。\n问题二：装饰器的宏观理解 link 再来看第二个问题，胡峣同学对装饰器的疑问。事实上，装饰器的作用与意义，在于其可以通过自定义的函数或类，在不改变原函数的基础上，改变原函数的一些功能。\nDecorators is to modify the behavior of the function through a wrapper so we don't have to actually modify the function. 装饰器将额外增加的功能，封装在自己的装饰器函数或类中；如果你想要调用它，只需要在原函数的顶部，加上@decorator即可。显然，这样做可以让你的代码得到高度的抽象、分离与简化。\n光说概念可能还是有点抽象，我们可以想象下面这样一个场景，从真实例子来感受装饰器的魅力。在一些社交网站的后台，有无数的操作在调用之前，都需要先检查用户是否登录，比如在一些帖子里发表评论、发表状态等等。\n如果你不知道装饰器，用常规的方法来编程，写出来的代码大概是下面这样的：\n# 发表评论\rdef post_comment(request, ...):\rif not authenticate(request):\rraise Exception('U must log in first')\r...\r# 发表状态\rdef post_moment(request, ...):\rif not authenticate(request):\rraise Exception('U must log in first')\r... 显然，这样重复调用认证函数authenticate()的步骤，就显得非常冗余了。更好的解决办法，就是将认证函数authenticate()单独分离出来，写成一个装饰器，就像我们下面这样的写法。这样一来，代码便得到了高度的优化：\n",
                content: "你好，我是景霄。\n不知不觉中，我们又一起完成了第二大章进阶篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：列表self append无限嵌套的原理 link 先来回答第一个问题，两个同学都问到了，下面这段代码中的x，为什么是无限嵌套的列表？\nx = [1]\rx.append(x)\rx\r[1, [...]] 我们可以将上述操作画一个图，便于你更直观地理解：\n这里，x指向一个列表，列表的第一个元素为1；执行了append操作后，第二个元素又反过来指向x，即指向了x所指向的列表，因此形成了一个无限嵌套的循环：[1, [1, [1, [1, …]]]]。\n不过，虽然x是无限嵌套的列表，但x.append(x)的操作，并不会递归遍历其中的每一个元素。它只是扩充了原列表的第二个元素，并将其指向x，因此不会出现stack overflow的问题，自然不会报错。\n至于第二点，为什么len(x)返回的是2？我们还是来看x，虽然它是无限嵌套的列表，但x的top level只有2个元素组成，第一个元素为1，第二个元素为指向自身的列表，因此len(x)返回2。\n问题二：装饰器的宏观理解 link 再来看第二个问题，胡峣同学对装饰器的疑问。事实上，装饰器的作用与意义，在于其可以通过自定义的函数或类，在不改变原函数的基础上，改变原函数的一些功能。\nDecorators is to modify the behavior of the function through a wrapper so we don't have to actually modify the function. 装饰器将额外增加的功能，封装在自己的装饰器函数或类中；如果你想要调用它，只需要在原函数的顶部，加上@decorator即可。显然，这样做可以让你的代码得到高度的抽象、分离与简化。\n光说概念可能还是有点抽象，我们可以想象下面这样一个场景，从真实例子来感受装饰器的魅力。在一些社交网站的后台，有无数的操作在调用之前，都需要先检查用户是否登录，比如在一些帖子里发表评论、发表状态等等。\n如果你不知道装饰器，用常规的方法来编程，写出来的代码大概是下面这样的：\n# 发表评论\rdef post_comment(request, ...):\rif not authenticate(request):\rraise Exception('U must log in first')\r...\r# 发表状态\rdef post_moment(request, ...):\rif not authenticate(request):\rraise Exception('U must log in first')\r... 显然，这样重复调用认证函数authenticate()的步骤，就显得非常冗余了。更好的解决办法，就是将认证函数authenticate()单独分离出来，写成一个装饰器，就像我们下面这样的写法。这样一来，代码便得到了高度的优化：\n# 发表评论\r@authenticate\rdef post_comment(request, ...):\r# 发表状态\r@authenticate\rdef post_moment(request, ...): 不过也要注意，很多情况下，装饰器并不是唯一的方法。而我这里强调的，主要是使用装饰器带来的好处：\n代码更加简洁； 逻辑更加清晰； 程序的层次化、分离化更加明显。 而这也是我们应该遵循和优先选择的开发模式。\n问题三：GIL与多线程的关系 link 第三个问题，new同学疑惑的是，GIL只支持单线程，而Python支持多线程，这两者之间究竟是什么关系呢？\n其实，GIL的存在与Python支持多线程并不矛盾。前面我们讲过，GIL是指同一时刻，程序只能有一个线程运行；而Python中的多线程，是指多个线程交替执行，造成一个“伪并行”的结果，但是具体到某一时刻，仍然只有1个线程在运行，并不是真正的多线程并行。这个机制，我画了下面这张图来表示：\n举个例子来理解。比如，我用10个线程来爬取50个网站的内容。线程1在爬取第1个网站时，被I/O block住了，处于等待状态；这时，GIL就会释放，而线程2就会开始执行，去爬取第2个网站，依次类推。等到线程1的I/O操作完成时，主程序便又会切回线程1，让其完成剩下的操作。这样一来，从用户角度看到的，便是我们所说的多线程。\n问题四：多进程与多线程的应用场景 link 第四个问题，这个在文章中多次提到，不过，我还是想在这里再次强调一下。\n如果你想对CPU密集型任务加速，使用多线程是无效的，请使用多进程。这里所谓的CPU密集型任务，是指会消耗大量CPU资源的任务，比如求1到100000000的乘积，或者是把一段很长的文字编码后又解码等等。\n使用多线程之所以无效，原因正是我们前面刚讲过的，Python多线程的本质是多个线程互相切换，但同一时刻仍然只允许一个线程运行。因此，你使用多线程，和使用一个主线程，本质上来说并没有什么差别；反而在很多情况下，因为线程切换带来额外损耗，还会降低程序的效率。\n而如果使用多进程，就可以允许多个进程之间in parallel地执行任务，所以能够有效提高程序的运行效率。\n至于 I/O密集型任务，如果想要加速，请优先使用多线程或Asyncio。当然，使用多进程也可以达到目的，但是完全没有这个必要。因为对I/O密集型任务来说，大多数时间都浪费在了I/O等待上。因此，在一个线程/任务等待I/O时，我们只需要切换线程/任务去执行其他 I/O操作就可以了。\n不过，如果I/O操作非常多、非常heavy，需要建立的连接也比较多时，我们一般会选择Asyncio。因为Asyncio的任务切换更加轻量化，并且它能启动的任务数也远比多线程启动的线程数要多。当然，如果I/O的操作不是那么的heavy，那么使用多线程也就足够了。\n今天主要回答这几个问题，同时也欢迎你继续在留言区写下疑问和感想，我会持续不断地解答。希望每一次的留言和答疑，都能给你带来新的收获和价值。\n"
            }
        );
    index.add(
            {
                id:  35 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/26---%E6%B4%BB%E9%83%BD%E6%9D%A5%E4%B8%8D%E5%8F%8A%E5%B9%B2%E4%BA%86%E8%BF%98%E6%9C%89%E7%A9%BA%E6%B3%A8%E6%84%8F%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC\/",
                title: "活都来不及干了，还有空注意代码风格？！",
                description: "你好，我是蔡元楠，是极客时间《大规模数据处理实战》的作者。今天是我第二次受邀来我们专栏分享了，很高兴再次见到你。今天我分享的主题是：活都来不及干了，还有空注意代码风格吗？！\n许多来Google参观的人，用完洗手间后，都会惊奇而略带羞涩地问：“你们马桶前面的门上，贴着的Python编程规范，是用来搞笑的吗？”\n这事儿还真不是搞笑，Google对编码规范的要求极其严格。今天，我们就来聊聊编程规范这件事儿。\n对于编程规范（style guide） 的认知，很多人可能只停留在第一阶段：知道编程规范有用，整个公司都要求使用驼峰式命名。而后面的阶段，比如为什么和怎么做，就并不了解了。\n但在Google，对于编程规范的信仰，可能超出很多人的想象，我给你简单介绍几点。\n每一个语言都有专门的委员会（Style Committee）制定全公司强制的编程规范，和负责在编程风格争议时的仲裁人（Style Arbiters）。 在每个语言相应的编程规范群里，每天都有大量的讨论和辩论。新达成的共识会被写出“大字报”张贴在厕所里，以至于每个人甚至来访者都能用坐着的时候那零碎的5分钟阅读。 每一个代码提交，类似于Git里diff的概念，都需要至少两次代码评审（code review），一次针对业务逻辑，一次针对可读性（readability review）。所谓的可读性评审，着重在代码风格规范上。只有通过考核的人，才能够成为可读性评审人（readability reviewer）。 有大量的开发自动化工具，确保以上的准则得到强制实施。例如，代码提交前会有linter做静态规则检查，不通过是无法提交代码的。 看到这里，不知道你有怎样的感受？我自己十分认同这样的工程师文化，所以今天，我会给你介绍清楚两点：\nPython的编程规范为什么重要，这对于业务开发来说，究竟有没有帮助？ 有哪些流程和工具，可以整合到已有的开发流程中，让你的编程规范强制自动执行呢？ 在讲解过程中，我会适时引用两个条例来举例，分别是：\n《8号Python增强规范》（Python Enhacement Proposal #8），以下简称PEP8； 《Google Python 风格规范》（Google Python Style Guide），以下简称Google Style，这是源自Google内部的风格规范。公开发布的社区版本，是为了让Google旗下所有Python开源项目的编程风格统一。（http://google.github.io/styleguide/pyguide.html） 相对来说，Google Style是比PEP8更严格的一个编程规范。因为PEP8的受众是个人和小团队开发者，而Google Style能够胜任大团队，企业级，百万行级别代码库。他们的内容，后面我也会简单说明。\n",
                content: "你好，我是蔡元楠，是极客时间《大规模数据处理实战》的作者。今天是我第二次受邀来我们专栏分享了，很高兴再次见到你。今天我分享的主题是：活都来不及干了，还有空注意代码风格吗？！\n许多来Google参观的人，用完洗手间后，都会惊奇而略带羞涩地问：“你们马桶前面的门上，贴着的Python编程规范，是用来搞笑的吗？”\n这事儿还真不是搞笑，Google对编码规范的要求极其严格。今天，我们就来聊聊编程规范这件事儿。\n对于编程规范（style guide） 的认知，很多人可能只停留在第一阶段：知道编程规范有用，整个公司都要求使用驼峰式命名。而后面的阶段，比如为什么和怎么做，就并不了解了。\n但在Google，对于编程规范的信仰，可能超出很多人的想象，我给你简单介绍几点。\n每一个语言都有专门的委员会（Style Committee）制定全公司强制的编程规范，和负责在编程风格争议时的仲裁人（Style Arbiters）。 在每个语言相应的编程规范群里，每天都有大量的讨论和辩论。新达成的共识会被写出“大字报”张贴在厕所里，以至于每个人甚至来访者都能用坐着的时候那零碎的5分钟阅读。 每一个代码提交，类似于Git里diff的概念，都需要至少两次代码评审（code review），一次针对业务逻辑，一次针对可读性（readability review）。所谓的可读性评审，着重在代码风格规范上。只有通过考核的人，才能够成为可读性评审人（readability reviewer）。 有大量的开发自动化工具，确保以上的准则得到强制实施。例如，代码提交前会有linter做静态规则检查，不通过是无法提交代码的。 看到这里，不知道你有怎样的感受？我自己十分认同这样的工程师文化，所以今天，我会给你介绍清楚两点：\nPython的编程规范为什么重要，这对于业务开发来说，究竟有没有帮助？ 有哪些流程和工具，可以整合到已有的开发流程中，让你的编程规范强制自动执行呢？ 在讲解过程中，我会适时引用两个条例来举例，分别是：\n《8号Python增强规范》（Python Enhacement Proposal #8），以下简称PEP8； 《Google Python 风格规范》（Google Python Style Guide），以下简称Google Style，这是源自Google内部的风格规范。公开发布的社区版本，是为了让Google旗下所有Python开源项目的编程风格统一。（http://google.github.io/styleguide/pyguide.html） 相对来说，Google Style是比PEP8更严格的一个编程规范。因为PEP8的受众是个人和小团队开发者，而Google Style能够胜任大团队，企业级，百万行级别代码库。他们的内容，后面我也会简单说明。\n统一的编程规范为什么重要？ link用一句话来概括，统一的编程规范能提高开发效率。而开发效率，关乎三类对象，也就是阅读者、编程者和机器。他们的优先级是阅读者的体验 \u003e\u003e 编程者的体验 \u003e\u003e 机器的体验。\n阅读者的体验\u003e\u003e编程者的体验 link写过代码的人可能都有体会，在我们的实际工作中，真正在打字的时间，远比阅读或者debug的时间要少。事实正是如此，研究表明，软件工程中80%的时间都在阅读代码。所以，为了提高开发效率，我们要优化的，不是你的打字时间，而是团队阅读的体验。\n其实，不少的编程规范，本来就是为了优化读者体验而存在的。举个例子，对于命名原则，我想很多人应该都有所理解，PEP8第38条规定命名必须有意义，不能是无意义的单字母。\n有些人可能会说，啊，编程规范好烦哟，变量名一定要我写完整，打起来好累。但是当你作为阅读者时，一定能分辨下面两种代码的可读性不同：\n# 错误示例\rif (a \u003c= 0):\rreturn\relif (a \u003e b):\rreturn\relse:\rb -= a\r# 正确示例\rif (transfer_amount \u003c= 0):\rraise Exception('...')\relif (transfer_amount \u003e balance):\rraise Exception('...')\relse:\rbalance -= transfer_amount 再举一个例子，Google Style 2.2条规定，Python代码中的import对象，只能是package或者module。\n# 错误示例\rfrom mypkg import Obj\rfrom mypkg import my_func\rmy_func([1, 2, 3])\r# 正确示例\rimport numpy as np\rimport mypkg\rnp.array([6, 7, 8]) 以上错误示例在语法上完全合法（因为没有符号冲突name collisions），但是对于读者来讲，它们的可读性太差了。因为my_func这样的名字，如果没有一个package name提供上下文语境，读者很难单独通过my_func这个名字来推测它的可能功能，也很难在debug时根据package name找到可能的问题。\n反观正确示例，虽然array是如此大众脸的名字，但因为有了numpy这个package的暗示，读者可以一下子反应过来，哦，这是一个numpy array。不过这里要注意区别，这个例子和符号冲突（name collisions）是正交（orthogonal）的两个概念，即使没有符号冲突，我们也要遵循这样的import规范。\n编程者的体验 \u003e\u003e 机器的体验 link说完了阅读者的体验，再来聊聊编程者的体验。我常常见到的一个错误倾向，是过度简化自己的代码，包括我自己也有这样的问题。一个典型的例子，就是盲目地使用Python的list comprehension。\n# 错误示例\rresult = [(x, y) for x in range(10) for y in range(5) if x * y \u003e 10] 我敢打赌，一定很少有人能一口气写出来这么复杂的list comprehension。这不仅容易累着自己，也让阅读者看得很累。其实，如果你用一个简单的for loop，会让这段代码更加简洁明了，自己也更为轻松。\n# 正确示例\rresult = []\rfor x in range(10):\rfor y in range(5):\rif x * y \u003e 10:\rresult.append((x, y)) 机器的体验也很重要 link讲完了编程者和阅读者的重要性，我们不能忽视了机器的体验。我们最终希望代码能正确、高效地在电脑上执行。但是，一些危险的编程风格，不仅会影响程序正确性，也容易成为代码效率的瓶颈。\n我们先来看看 is 和 == 的使用区别。你能看出下面的代码的运行结果吗？\n# 错误示例\rx = 27\ry = 27\rprint(x is y)\rx = 721\ry = 721\rprint(x is y) 看起来is是比较内存地址，那么两个结果应该都是一样的，可是实际上打印出来的，却分别是True和False！\n原因是在CPython（Python的C实现）的实现中，把-5到256的整数做成了singleton，也就是说，这个区间里的数字都会引用同一块内存区域，所以上面的27和下面的27会指向同一个地址，运行结果为True。\n但是-5到256之外的数字，会因为你的重新定义而被重新分配内存，所以两个721会指向不同的内存地址，结果也就是False了。\n所以，即使你已经清楚，is比较对象的内存地址，你也应该在代码风格中，避免去用is比较两个Python整数的地址。\n# 正确示例\rx = 27\ry = 27\rprint(x == y)\rx = 721\ry = 721\rprint(x == y) 看完这个例子，我们再看==在比较值的时候，是否总能如你所愿呢？同样的，你可以自己先判断一下运行结果。\n# 错误示例\rx = MyObject()\rprint(x == None) 打印结果是False吗？不一定。因为对于类来说，==的结果，取决于它的__eq__()方法的具体实现。MyObject的作者完全可能这样实现：\nclass MyObject(object):\rdef __eq__(self, other):\rif other:\rreturn self.field == other.field\rreturn True 正确的是在代码风格中，当你和None比较时候永远使用 is:\n# 正确示例\rx = MyObject()\rprint(x is None) 上面两个例子，我简单介绍了通过编程风格的限制，让is 和 == 的使用更安全。不过，光注意这两点就可以了吗？不要忘记，Python中还有隐式布尔转换。比如：\n# 错误示例\rdef pay(name, salary=None):\rif not salary:\rsalary = 11\rprint(name, \"is compensated\", salary, \"dollars\") 如果有人调用 pay(“Andrew”, 0) ，会打印什么呢？“Andrew is compensated 11 dollars”。当你明确想要比较对象是否是None时，一定要显式地用 is None。\n# 正确示例\rdef pay(name, salary=None):\rif salary is not None:\rsalary = 11\rprint(name, \"is compensated\", salary, \"dollars\") 这就是为什么，PEP8和Google Style都特别强调了，何时使用is， 何时使用 ==，何时使用隐式布尔转换。\n不规范的编程习惯也会导致程序效率问题，我们看下面的代码有什么问题：\n# 错误示例\radict = {i: i * 2 for i in xrange(10000000)}\rfor key in adict.keys():\rprint(\"{0} = {1}\".format(key, adict[key])) keys()方法会在遍历前生成一个临时的列表，导致上面的代码消耗大量内存并且运行缓慢。正确的方式，是使用默认的iterator。默认的iterator不会分配新内存，也就不会造成上面的性能问题:\n# 正确示例\rfor key in adict: 这也就是为什么Google Style 2.8对于遍历方式的选择作出了限制。\n相信读到这里，对于代码风格规范的重要性，你已经有了进一步的理解。如果能够做到下一步，会让你和你的团队脱胎换骨，那就是和开发流程的完全整合。\n整合进开发流程的自动化工具 link前面我们已经提到了，编程规范的终极目标是提高开发效率。显然，如果每次写代码，都需要你在代码规范上额外花很多时间的话，就达不到我们的初衷了。\n首先，你需要根据你的具体工作环境，选择或者制定适合自己公司/团队的规范。市面上可以参考的规范，也就是我在开头提到的那两个，PEP8和Google Style。\n没有放之四海而皆准的规范，你需要因地制宜。例如在Google，因为历史原因C++不使用异常，引入异常对整个代码库带来的风险已经远大于它的益处，所以在它的C++代码规范中，禁止使用异常。\n其次，一旦确定了整个团队同意的代码规范，就一定要强制执行。停留在口头和大脑的共识，只是水中月镜中花。如何执行呢？靠强制代码评审和强制静态或者动态linter。\n当然，需要注意的是，我这里“强制”的意思，不是说如果不做就罚款。那就太low了，完全没有极客精神。我指的“强制”，是把共识写进代码里，让机器来自动化这些流程。比如：\n在代码评审工具里，添加必须的编程规范环节； 把团队确定的代码规范写进Pylint里（https://www.pylint.org/），能够在每份代码提交前自动检查，不通过的代码无法提交。 整合之后，你的团队工作流程就会变成这样：\n总结 link学到这里，相信你对代码风格的重要性有了全新的认识。代码风格之所以重要，是因为它关乎阅读者的体验、编程者的体验和执行代码的机器体验。\n当然，仅仅意识到代码风格重要，是远远不够的。我还具体分享了一些自动化代码风格检查的切实方法，比如强制代码评审和强制静态或者动态linter。总之还是那句话，我们强调编程规范，最终一定是为了提高开发效率，而不是做额外功。\n思考题 link在你个人或者团队的项目经验中，是否也因为编程规范的问题，踩过坑或者吵过架呢？欢迎留言和我分享，也欢迎你把这篇文章分享出去。\n1.码代码的时候写注释 2.接手别人代码没注释2019-07-08一期一会 👍（69） 💬（0）写代码不写注释。过了半年以上有事再去读代码，自己也不知道是怎么回事的人举个手2019-08-11小侠龙旋风 👍（37） 💬（0）心中默念三遍：当和 None 比较时候永远使用 is。2019-07-10一叶知秋 👍（22） 💬（1）个人没经历过，但是听说过： “因代码不规范、使用git push -f，码农枪击4名同事，一人情况危急”2019-07-08奥特虾不会写代码 👍（20） 💬（0）接手了离职同事留下来的代码，很多变量的命名都是无意义的单词+数字，例如data1、data2这种，看得我十分痛苦2019-07-08Lonely绿豆蛙 👍（9） 💬（0）代码其实归根结底是写给人看的，是程序员之间沟通交流的语言，因此写作风格需要统一规范而不提倡个性化，就像提倡工作中使用普通话而非方言。2020-02-07吴月月鸟 👍（5） 💬（1）https://blog.csdn.net/FU250/article/details/95633286 git+pylint实现python提交代码格式校验2019-07-12Breathless 👍（3） 💬（2） if not salary: if salary is not None: 怎么怪怪的？2019-09-12Z_ying 👍（3） 💬（0）dict.items()推荐使用吗 它是使用默认的iter还是另外使用临时内存吗 2019-08-02贺宇 👍（3） 💬（1）原来在java的时候比较都用=，后来被主管骂了一顿后就再也不用=做比较了，全部用Objects.equals2019-07-17yanger2004 👍（2） 💬（0）我们一般是linter通过没问题，才会开始代码评审，所以最后那张图我们是倒过来的2023-01-29geraltlaush 👍（2） 💬（0）我是遇到过工作十年的人制定的probuf协议文件像万国博览会，java风格，C风格，微软匈牙利命名法，生成的代码的结构体有成员产量是ooxxxxdddd，像甜甜圈和万花筒，测试环境直接把自己的英文名打进日志，并发编程直接一把锁锁住七八个map，那代码，分分钟灼烧着我的视网膜2019-11-10三毛大叔 👍（2） 💬（2）评审者是专门评审员吗，一天到晚评审，不写代码?2019-07-08年轻人的瞎折腾^. 👍（1） 💬（1）最痛苦的还是给代码取名字，不能随便取，但是又想不到更好的名字~很愁2021-04-22\n"
            }
        );
    index.add(
            {
                id:  36 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/27---%E5%AD%A6%E4%BC%9A%E5%90%88%E7%90%86%E5%88%86%E8%A7%A3%E4%BB%A3%E7%A0%81%E6%8F%90%E9%AB%98%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%AF%BB%E6%80%A7\/",
                title: "学会合理分解代码，提高代码可读性",
                description: "你好，我是景霄。今天我们不讲任何技术知识点，继续来一起聊聊代码哲学。\n有句话说得好，好的代码本身就是一份文档。同样功能的一份程序，一个组件，一套系统，让不同的人来写，写出来的代码却是千差万别。\n有些人的设计风格和代码风格犹如热刀切黄油，从顶层到底层的代码看下来酣畅淋漓，注释详尽而又精简；深入到细节代码，无需注释也能理解清清楚楚。\n而有些人，代码勉勉强强能跑起来，遇到稍微复杂的情况可能就会出 bug；深入到代码中 debug，则发现处处都是魔术数、函数堆在一起。一个文件上千行，设计模式又是混淆不堪，让人实在很难阅读，更别提修改和迭代开发。\nGuido van Rossum（吉多·范罗苏姆，Python创始人 ）说过，代码的阅读频率远高于编写代码的频率。毕竟，即使是在编写代码的时候，你也需要对代码进行反复阅读和调试，来确认代码能够按照期望运行。\n话不多说，进入正题。\nPEP 8 规范 link上节课我们简单提起过 PEP 8 ，今天我们继续来详细解读。\nPEP是 Python Enhancement Proposal 的缩写，翻译过来叫“Python 增强规范”。正如我们写文章，会有句式、标点、段落格式、开头缩进等标准的规范一样，Python 书写自然也有一套较为官方的规范。PEP 8 就是这样一种规范，它存在的意义，就是让 Python 更易阅读，换句话，增强代码可读性。\n事实上，Pycharm 已经内置了 PEP 8 规范检测器，它会自动对编码不规范的地方进行检查，然后指出错误，并推荐修改方式。下面这张图就是其界面。\n因此，在学习今天的内容时，我推荐你使用 Pycharm IDE 进行代码检查，看一下自己的代码格式哪里有问题。尤其对于初学者，从某些程度来说，代码规范甚至是比代码准确更重要的事情，因为实际工作中，代码可读性的重要性一定比你想象的多得多。\n缩进规范 link首先，我们来看代码块内的缩进。\nPython 和 C++ / Java 最大的不同在于，后者完全使用大括号来区分代码块，而前者依靠不同行和不同的缩进来进行分块。有一个很有名的比赛，叫作 C 语言混乱代码大赛，其中有很多非常精彩的作品，你能看到书写的代码排成各种形状，有的是一幅画，或者一个卡通头像，但是能执行出惊人的结果。\n",
                content: "你好，我是景霄。今天我们不讲任何技术知识点，继续来一起聊聊代码哲学。\n有句话说得好，好的代码本身就是一份文档。同样功能的一份程序，一个组件，一套系统，让不同的人来写，写出来的代码却是千差万别。\n有些人的设计风格和代码风格犹如热刀切黄油，从顶层到底层的代码看下来酣畅淋漓，注释详尽而又精简；深入到细节代码，无需注释也能理解清清楚楚。\n而有些人，代码勉勉强强能跑起来，遇到稍微复杂的情况可能就会出 bug；深入到代码中 debug，则发现处处都是魔术数、函数堆在一起。一个文件上千行，设计模式又是混淆不堪，让人实在很难阅读，更别提修改和迭代开发。\nGuido van Rossum（吉多·范罗苏姆，Python创始人 ）说过，代码的阅读频率远高于编写代码的频率。毕竟，即使是在编写代码的时候，你也需要对代码进行反复阅读和调试，来确认代码能够按照期望运行。\n话不多说，进入正题。\nPEP 8 规范 link上节课我们简单提起过 PEP 8 ，今天我们继续来详细解读。\nPEP是 Python Enhancement Proposal 的缩写，翻译过来叫“Python 增强规范”。正如我们写文章，会有句式、标点、段落格式、开头缩进等标准的规范一样，Python 书写自然也有一套较为官方的规范。PEP 8 就是这样一种规范，它存在的意义，就是让 Python 更易阅读，换句话，增强代码可读性。\n事实上，Pycharm 已经内置了 PEP 8 规范检测器，它会自动对编码不规范的地方进行检查，然后指出错误，并推荐修改方式。下面这张图就是其界面。\n因此，在学习今天的内容时，我推荐你使用 Pycharm IDE 进行代码检查，看一下自己的代码格式哪里有问题。尤其对于初学者，从某些程度来说，代码规范甚至是比代码准确更重要的事情，因为实际工作中，代码可读性的重要性一定比你想象的多得多。\n缩进规范 link首先，我们来看代码块内的缩进。\nPython 和 C++ / Java 最大的不同在于，后者完全使用大括号来区分代码块，而前者依靠不同行和不同的缩进来进行分块。有一个很有名的比赛，叫作 C 语言混乱代码大赛，其中有很多非常精彩的作品，你能看到书写的代码排成各种形状，有的是一幅画，或者一个卡通头像，但是能执行出惊人的结果。\n而放到 Python ，显然就不能实现同样的技巧了。不过，以小换大，我们有了“像阅读英语”一样清晰的 Python 代码，也还是可以接受的。\n话说回来，Python 的缩进其实可以写成很多种，Tab、双空格、四空格、空格和 Tab 混合等。而PEP 8 规范告诉我们，请选择四个空格的缩进，不要使用 Tab，更不要 Tab 和空格混着用。\n第二个要注意的是，每行最大长度请限制在 79 个字符。\n这个原则主要有两个优点，第一个优点比较好理解。很多工程师在编程的时候，习惯一个屏幕并列竖排展示多个源代码。如果某个源代码的某些行过长，你就需要拖动横向滚动条来阅读，或者需要软回车将本行内容放入下一行，这就极大地影响了编码和阅读效率。\n至于第二个优点，需要有一定经验的编程经验后更容易理解：因为当代码的嵌套层数过高，比如超过三层之后，一行的内容就很容易超过 79 个字符了。所以，这条规定另一方面也在制约着程序员，不要写迭代过深的代码，而是要思考继续把代码分解成其他函数或逻辑块，来优化自己的代码结构。\n空行规范 link接着我们来看代码块之间的空行。\n我们知道，Python 中的空行对 Python 解释器的执行没有影响，但对阅读体验有很深刻的影响。\nPEP 8 规定，全局的类和函数的上方需要空两个空行，而类的函数之间需要空一个空行。当然，函数内部也可以使用空行，和英语的段落一样，用来区分不同意群之间的代码块。但是记住最多空一行，千万不要滥用。\n另外，Python 本身允许把多行合并为一行，使用分号隔开，但这是 PEP 8 不推荐的做法。所以，即使是使用控制语句 if / while / for，你的执行语句哪怕只有一行命令，也请另起一行，这样可以更大程度提升阅读效率。\n至于代码的尾部，每个代码文件的最后一行为空行，并且只有这一个空行。\n空格规范 link我们再来看一下，代码块中，每行语句中空格的使用。\n函数的参数列表中，调用函数的参数列表中会出现逗号，请注意逗号后要跟一个空格，这是英语的使用习惯，也能让每个参数独立阅读，更清晰。\n同理，冒号经常被用来初始化字典，冒号后面也要跟一个空格。\n另外，Python 中我们可以使用#进行单独注释，请记得要在#后、注释前加一个空格。\n对于操作符，例如+，-，*，/，\u0026，|，=，==，!=，请在两边都保留空格。不过与此对应，括号内的两端并不需要空格。\n换行规范 link现在再回到缩进规范，注意我们提到的第二点，控制每行的最大长度不超过 79 个字符，但是有时候，函数调用逻辑过长而不得不超过这个数字时，该怎么办呢？\n请看下面这段代码，建议你先自己阅读并总结其特点：\ndef solve1(this_is_the_first_parameter, this_is_the_second_parameter, this_is_the_third_parameter,\rthis_is_the_forth_parameter, this_is_the_fifth_parameter, this_is_the_sixth_parameter):\rreturn (this_is_the_first_parameter + this_is_the_second_parameter + this_is_the_third_parameter +\rthis_is_the_forth_parameter + this_is_the_fifth_parameter + this_is_the_sixth_parameter)\rdef solve2(this_is_the_first_parameter, this_is_the_second_parameter, this_is_the_third_parameter,\rthis_is_the_forth_parameter, this_is_the_fifth_parameter, this_is_the_sixth_parameter):\rreturn this_is_the_first_parameter + this_is_the_second_parameter + this_is_the_third_parameter + \\\rthis_is_the_forth_parameter + this_is_the_fifth_parameter + this_is_the_sixth_parameter\r(top_secret_func(param1=12345678, param2=12345678, param3=12345678, param4=12345678, param5=12345678).check()\r.launch_nuclear_missile().wait())\rtop_secret_func(param1=12345678, param2=12345678, param3=12345678, param4=12345678, param5=12345678).check() \\\r.launch_nuclear_missile().wait() 事实上，这里有两种经典做法。\n第一种，通过括号来将过长的运算进行封装，此时虽然跨行，但是仍处于一个逻辑引用之下。solve1 函数的参数过多，直接换行，不过请注意，要考虑第二行参数和第一行第一个参数对齐，这样可以让函数变得非常美观的同时，更易于阅读。当然，函数调用也可以使用类似的方式，只需要用一对括号将其包裹起来。\n第二种，则是通过换行符来实现。这个方法更为直接，你可以从 solve2 和第二个函数调用看出来。\n关于代码细节方面的规范，我主要强调这四个方面。习惯不是一天养成的，但一定需要你特别留心和刻意练习。我能做的，便是告诉你这些需要留心的地方，并带你感受实际项目的代码风格。\n下面的代码选自开源库 Google TensorFlow Keras，为了更加直观突出重点，我删去了注释和大部分代码，你意会即可。我希望，通过阅读这段代码，你能更真实地了解到，前沿的项目是怎么在增强阅读性上下功夫的。\nclass Model(network.Network):\rdef fit(self,\rx=None,\ry=None,\rbatch_size=None,\repochs=1,\rverbose=1,\rcallbacks=None,\rvalidation_split=0.,\rvalidation_data=None,\rshuffle=True,\rclass_weight=None,\rsample_weight=None,\rinitial_epoch=0,\rsteps_per_epoch=None,\rvalidation_steps=None,\rvalidation_freq=1,\rmax_queue_size=10,\rworkers=1,\ruse_multiprocessing=False,\r**kwargs):\r# Legacy support\rif 'nb_epoch' in kwargs:\rlogging.warning(\r'The `nb_epoch` argument in `fit` has been renamed `epochs`.')\repochs = kwargs.pop('nb_epoch')\rif kwargs:\rraise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\rself._assert_compile_was_called()\rfunc = self._select_training_loop(x)\rreturn func.fit(\rself,\rx=x,\ry=y,\rbatch_size=batch_size,\repochs=epochs,\rverbose=verbose,\rcallbacks=callbacks,\rvalidation_split=validation_split,\rvalidation_data=validation_data,\rshuffle=shuffle,\rclass_weight=class_weight,\rsample_weight=sample_weight,\rinitial_epoch=initial_epoch,\rsteps_per_epoch=steps_per_epoch,\rvalidation_steps=validation_steps,\rvalidation_freq=validation_freq,\rmax_queue_size=max_queue_size,\rworkers=workers,\ruse_multiprocessing=use_multiprocessing) 文档规范 link接下来我们说说文档规范。先来看看最常用的 import 函数。\n首先，所有 import 尽量放在开头，这个没什么说的，毕竟到处 import 会让人很难看清楚文件之间的依赖关系，运行时 import 也可能会导致潜在的效率问题和其他风险。\n其次，不要使用 import 一次导入多个模块。虽然我们可以在一行中 import 多个模块，并用逗号分隔，但请不要这么做。import time, os 是 PEP 8 不推荐的做法。\n如果你采用 from module import func 这样的语句，请确保 func 在本文件中不会出现命名冲突。不过，你其实可以通过 from module import func as new_func 来进行重命名，从而避免冲突。\n注释规范 link有句话这么说：错误的注释，不如没有注释。所以，当你改动代码的时候，一定要注意检查周围的注释是否需要更新。\n对于大的逻辑块，我们可以在最开始相同的缩进处以 # 开始写注释。即使是注释，你也应该把它当成完整的文章来书写。如果英文注释，请注意开头大写及结尾标点，注意避免语法错误和逻辑错误，同时精简要表达的意思。中文注释也是同样的要求。一份优秀的代码，离不开优秀的注释。\n至于行注释，如空格规范中所讲，我们可以在一行后面跟两个空格，然后以 # 开头加入注释。不过，请注意，行注释并不是很推荐的方式。\n# This is an example to demonstrate how to comment.\r# Please note this function must be used carefully.\rdef solve(x):\rif x == 1: # This is only one exception.\rreturn False\rreturn True 文档描述 link再来说说文档描述，我们继续以 TensorFlow 的代码为例。\nclass SpatialDropout2D(Dropout):\r\"\"\"Spatial 2D version of Dropout.\rThis version performs the same function as Dropout, however it drops\rentire 2D feature maps instead of individual elements. If adjacent pixels\rwithin feature maps are strongly correlated (as is normally the case in\rearly convolution layers) then regular dropout will not regularize the\ractivations and will otherwise just result in an effective learning rate\rdecrease. In this case, SpatialDropout2D will help promote independence\rbetween feature maps and should be used instead.\rArguments:\rrate: float between 0 and 1. Fraction of the input units to drop.\rdata_format: 'channels_first' or 'channels_last'.\rIn 'channels_first' mode, the channels dimension\r(the depth) is at index 1,\rin 'channels_last' mode is it at index 3.\rIt defaults to the `image_data_format` value found in your\rKeras config file at `~/.keras/keras.json`.\rIf you never set it, then it will be \"channels_last\".\rInput shape:\r4D tensor with shape:\r`(samples, channels, rows, cols)` if data_format='channels_first'\ror 4D tensor with shape:\r`(samples, rows, cols, channels)` if data_format='channels_last'.\rOutput shape:\rSame as input\rReferences:\r- [Efficient Object Localization Using Convolutional\rNetworks](https://arxiv.org/abs/1411.4280)\r\"\"\"\rdef __init__(self, rate, data_format=None, **kwargs):\rsuper(SpatialDropout2D, self).__init__(rate, **kwargs)\rif data_format is None:\rdata_format = K.image_data_format()\rif data_format not in {'channels_last', 'channels_first'}:\rraise ValueError('data_format must be in '\r'{\"channels_last\", \"channels_first\"}')\rself.data_format = data_format\rself.input_spec = InputSpec(ndim=4) 你应该可以发现，类和函数的注释，为的是让读者快速理解这个函数做了什么，它输入的参数和格式，输出的返回值和格式，以及其他需要注意的地方。\n至于docstring 的写法，它是用三个双引号开始、三个双引号结尾。我们首先用一句话简单说明这个函数做什么，然后跟一段话来详细解释；再往后是参数列表、参数格式、返回值格式。\n命名规范 link接下来，我来讲一讲命名。你应该听过这么一句话，“计算机科学的两件难事：缓存失效和命名。”命名对程序员来说，是一个不算省心的事。一个具有误导性的名字，极有可能在项目中埋下潜在的 bug。这里我就不从命名分类方法来给你划分了，我们只讲一些最实用的规范。\n先来看变量命名。变量名请拒绝使用 a b c d 这样毫无意义的单字符，我们应该使用能够代表其意思的变量名。一般来说，变量使用小写，通过下划线串联起来，例如：data_format、input_spec、image_data_set。唯一可以使用单字符的地方是迭代，比如 for i in range(n) 这种，为了精简可以使用。如果是类的私有变量，请记得前面增加两个下划线。\n对于常量，最好的做法是全部大写，并通过下划线连接，例如：WAIT_TIME、SERVER_ADDRESS、PORT_NUMBER。\n对于函数名，同样也请使用小写的方式，通过下划线连接起来，例如：launch_nuclear_missile()、check_input_validation()。\n对于类名，则应该首字母大写，然后合并起来，例如：class SpatialDropout2D()、class FeatureSet()。\n总之，还是那句话，不要过于吝啬一个变量名的长度。当然，在合理描述这个变量背后代表的对象后，一定的精简能力也是必要的。\n代码分解技巧 link最后，我们再讲一些很实用的代码优化技巧。\n编程中一个核心思想是，不写重复代码。重复代码大概率可以通过使用条件、循环、构造函数和类来解决。而另一个核心思想则是，减少迭代层数，尽可能让 Python 代码扁平化，毕竟，人的大脑无法处理过多的栈操作。\n所以，在很多业务逻辑比较复杂的地方，就需要我们加入大量的判断和循环。不过，这些一旦没写好，程序看起来就是地狱了。\n我们来看下面几个示例，来说说写好判断、循环的细节问题。先来看第一段代码：\nif i_am_rich:\rmoney = 100\rsend(money)\relse:\rmoney = 10\rsend(money) 这段代码中，同样的send语句出现了两次，所以我们完全可以合并一下，把代码改造成下面这样：\nif i_am_rich:\rmoney = 100\relse:\rmoney = 10\rsend(money) 再来看一个例子：\ndef send(money):\rif is_server_dead:\rLOG('server dead')\rreturn\relse:\rif is_server_timed_out:\rLOG('server timed out')\rreturn\relse:\rresult = get_result_from_server()\rif result == MONEY_IS_NOT_ENOUGH:\rLOG('you do not have enough money')\rreturn\relse:\rif result == TRANSACTION_SUCCEED:\rLOG('OK')\rreturn\relse:\rLOG('something wrong')\rreturn 这段代码层层缩进，显而易见的难看。我们来改一下：\ndef send(money):\rif is_server_dead:\rLOG('server dead')\rreturn\rif is_server_timed_out:\rLOG('server timed out')\rreturn\rresult = get_result_from_server()\rif result == MONET_IS_NOT_ENOUGH:\rLOG('you do not have enough money')\rreturn\rif result == TRANSACTION_SUCCEED:\rLOG('OK')\rreturn\rLOG('something wrong') 新的代码是不是就清晰多了？\n另外，我们知道，一个函数的粒度应该尽可能细，不要让一个函数做太多的事情。所以，对待一个复杂的函数，我们需要尽可能地把它拆分成几个功能简单的函数，然后合并起来。那么，应该如何拆分函数呢？\n这里，我以一个简单的二分搜索来举例说明。我给定一个非递减整数数组，和一个 target，要求你找到数组中最小的一个数 x，可以满足 x*x \u003e target。一旦不存在，则返回 -1。\n这个功能应该不难写吧。你不妨先自己写一下，写完后再对照着来看下面的代码，找出自己的问题。\ndef solve(arr, target):\rl, r = 0, len(arr) - 1\rret = -1\rwhile l \u003c= r:\rm = (l + r) // 2\rif arr[m] * arr[m] \u003e target:\rret = m\rr = m - 1\relse:\rl = m + 1\rif ret == -1:\rreturn -1\relse:\rreturn arr[ret]\rprint(solve([1, 2, 3, 4, 5, 6], 8))\rprint(solve([1, 2, 3, 4, 5, 6], 9))\rprint(solve([1, 2, 3, 4, 5, 6], 0))\rprint(solve([1, 2, 3, 4, 5, 6], 40)) 我给出的第一段代码这样的写法，在算法比赛和面试中已经 OK 了。不过，从工程角度来说，我们还能继续优化一下：\ndef comp(x, target):\rreturn x * x \u003e target\rdef binary_search(arr, target):\rl, r = 0, len(arr) - 1\rret = -1\rwhile l \u003c= r:\rm = (l + r) // 2\rif comp(arr[m], target):\rret = m\rr = m - 1\relse:\rl = m + 1\rreturn ret\rdef solve(arr, target):\rid = binary_search(arr, target)\rif id != -1:\rreturn arr[id]\rreturn -1\rprint(solve([1, 2, 3, 4, 5, 6], 8))\rprint(solve([1, 2, 3, 4, 5, 6], 9))\rprint(solve([1, 2, 3, 4, 5, 6], 0))\rprint(solve([1, 2, 3, 4, 5, 6], 40)) 你可以看出，第二段代码中，我把不同功能的代码拿了出来。其中，comp() 函数作为核心判断，拿出来后可以让整个程序更清晰；同时，我也把二分搜索的主程序拿了出来，只负责二分搜索；最后的 solve() 函数拿到结果，决定返回不存在，还是返回值。这样一来，每个函数各司其职，阅读性也能得到一定提高。\n最后，我们再来看一下如何拆分类。老规矩，先看代码：\nclass Person:\rdef __init__(self, name, sex, age, job_title, job_description, company_name):\rself.name = name\rself.sex = sex\rself.age = age\rself.job_title = job_title\rself.job_description = description\rself.company_name = company_name 你应该能看得出来，job 在其中出现了很多次，而且它们表达的是一个意义实体，这种情况下，我们可以考虑将这部分分解出来，作为单独的类。\nclass Person:\rdef __init__(self, name, sex, age, job_title, job_description, company_name):\rself.name = name\rself.sex = sex\rself.age = age\rself.job = Job(job_title, job_description, company_name)\rclass Job:\rdef __init__(self, job_title, job_description, company_name):\rself.job_title = job_title\rself.job_description = description\rself.company_name = company_name 你看，改造后的代码，瞬间就清晰了很多。\n总结 link今天这节课，我们简单讲述了如何提高 Python 代码的可读性，主要介绍了PEP 8 规范，并通过实例的说明和改造，让你清楚如何对 Python 程序进行可读性优化。\n思考题 link最后，我想留一个思考题。这次的思考题开放一些，希望你在评论区讲一讲，你自己在初学编程时，不注意规范问题而犯下的错误，和这些错误会导致什么样的后果，比如对后来读代码的人有严重的误导，或是埋下了潜在的 bug 等等。\n希望你在留言区分享你的经历，你也可以把这篇文章分享出去，让更多的人互相交流心得体会，留下真实的经历，并在经历中进步成长。\n缩进规范：\n使用四空格缩进 每行最大长度79个字符 空行规范：\n全局的(文件级别的)类和全局的函数上方要有两个空行 类中的函数上方要有一个空行 函数内部不同意群的代码块之前要有一个空行 不要把多行语句合并为一行(即不要使用分号分隔多条语句) 当使用控制语句if/while/for时，即使执行语句只有一行命令，也需要另起一行 代码文件尾部有且只有一个空行 空格规范：\n函数的参数之间要有一个空格 列表、元组、字典的元素之间要有一个空格 字典的冒号之后要有一个空格 使用#注释的话，#后要有一个空格 操作符(例如+，-，*，/，\u0026，|，=，==，!=)两边都要有一个空格，不过括号(包括小括号、中括号和大括号)内的两端不需要空格 换行规范：\n一般我们通过代码逻辑拆分等手段来控制每行的最大长度不超过79个字符，但有些时候单行代码还是不可避免的会超过这个限制，这个时候就需要通过换行来解决问题了。 两种实现换行的方法： 第一种，通过小括号进行封装，此时虽然跨行，但是仍处于一个逻辑引用之下。比如函数参数列表的场景、过长的运算语句场景 第二种，直接通过换行符()实现 文档规范：\n所有import尽量放在代码文件的头部位置 每行import只导入一个对象 当我们使用from xxx import xxx时，import后面跟着的对象要是一个package(包对应代码目录)或者module(模块对应代码文件)，不要是一个类或者一个函数 注释规范：\n代码块注释，在代码块上一行的相同缩进处以 # 开始书写注释 代码行注释，在代码行的尾部跟2个空格，然后以 # 开始书写注释，行注释尽量少写 英文注释开头要大写，结尾要写标点符号，避免语法错误和逻辑错误，中文注释也是相同要求 改动代码逻辑时，一定要及时更新相关的注释 文档描述规范： 三个双引号开始、三个双引号结尾； 首先用一句话简单说明这个函数做什么，然后跟一段话来详细解释； 再往后是参数列表、参数格式、返回值格式的描述。\n命名规范：\n变量名，要全部小写，多个词通过下划线连接，可以使用单字符变量名的场景，比如for i in range(n)这种变量没有实际意义的情况 类的私有变量名，变量名前需要加2个下划线 常量名，要全部大写，多个词通过下划线连接 函数名，要全部小写，多个词通过下划线连接 类名，要求驼峰形式，即单词首字母大写，多个词的话，每个词首字母大写然后直接拼接 命名需要做到名如其意，不要吝啬名字的长度 代码分解技巧：\n不写重复代码，重复代码可以通过使用条件、循环、函数和类来解决 减少迭代层数，让代码扁平化 函数拆分，函数的粒度尽可能细，也就是一个函数不要做太多事情 类的拆分，如果一个类中有多个属性描述的是同一类事物，就可以把这些属性拆分出来新建一个单独的类 模块化，若项目偏大，要为不同功能模块创建独立的目录或文件，通过import互相关联2019-07-11lipan 👍（33） 💬（1）还记得刚开始写第一个iOS项目的时候，一个文件几千行代码。 业务和逻辑没有分层设计的思想，全部混合在一个文件里，虽然勉强实现了功能，但是后期代码没法改，连我自已都看不懂了，遑论接盘者。\n后来在做新浪微博登录授权的时候，看了一下微博oAuth的授权流程，顿时大开眼界。后来又看了一些苹果给的开发例子，才开始有了代码的分层设计和想法，然后才开始学习iOS的MVC和MVVM的设计架构，代码算是勉强看得下去。\n所以我觉得如果要提高代码水平，除了动手实战以外，还要多观摹和学习大神的项目代码。\n看到老师能够把Python知识给我们讲解深入浅出，举重若轻，完全符合我心目中的大神风范。\n因此，希望老师可以给我们分享一些Python的小、中型的项目或Demo(关于爬虫、机器学习、深度学习、自动运营、量化分析或是其它有趣的Python做的小工具都可以)。以供我们观摹学习。谢谢。2019-07-11夜路破晓 👍（12） 💬（2）听很多程序员讲过，开始他们的关注点大多数是先写出能跑起来的代码，后期当优化成为他们的瓶颈和需求时再来关注代码规范之类的问题。 对于初学者而言，想要实现弯道超车，就需要下大力气把基础夯实，而代码规范正是其中重要的一项。\n不可否认，担心学了半天能写漂亮但跑不起来代码的大有人在。如何权衡呢？ 分享一个认知：写漂亮代码与写能跑起来的代码之间不存在因果关系，两者都是你需要花费时间精力学习的内容。 越早认识到这一点，越能合理而高效地安排自己的学习计划。2019-07-10new 👍（8） 💬（2）如果代码逻辑清晰，加上注释是锦上添花的事，相对写代码和读代码，程序员更愿意自己写代码，而在项目中又必须要读代码，因此代码注释真的很重要，特别是那些逻辑复杂还掺杂部分业务的代码逻辑，如果不加注释几乎不可能有人理解，但是问题来了，如果后来的程序员把最初编写代码的人的代码修改了，但是注释却不更新就会对公司其他人产生重大影响相当于埋了雷，比如你用128个标识位分别表示128个探头启停信号，而在硬件升级过程中探头数量减少了4个探头，原始注释可能是描述128个探头信号启停等信息，而第二个程序员在升级修改时直接修改了循环计数变量为124，常量128未修改，注释也没有改，后又新来的程序员以为程序存在bug，把循环次数重新改回了常量定义128，导致4个探头怎么也读取不到信号，测试n长时间，最后查到硬件才明白是根本没有那4个探头2019-07-10geraltlaush 👍（3） 💬（0）大量if else嵌套我接盘过这类代码，我觉得有两个原因造成的，第一就是开发者自己逻辑不清晰，想到哪写到哪 第二 就是懒，赶紧把泥巴墙糊完去结工钱的感觉，这是对项目的极度不负责任，也是对自己的不负责任，坏的习惯养成了就很难改掉了2019-11-12Geek.S. 👍（2） 💬（0）python 代码规范中，实践中最难的是变量命名，每次起变量名都花比较长时间，待完成代码编写后，经常需要修改变量名或函数名，使得变量名能够见名知意; 又或者过了一段时间后，发现函数名还是不够精确，于是改了，为了使得使用的代码不会保存，又将旧名字指向新名字。\n使用 pycharm 编写代码，我很少会按 ctrl + alt + L，而是根据页面波浪线的提示，手动调整，长年累月，不仅知道了代码规范的具体规则，还可以在脱离 IDE 环境下写出符合代码规范的代码，比如在服务器 vim 里写代码，现在看来这个习惯很受益。\n不止对代码规范，连码子都要遵循中文写作规范，哈哈，感觉有点强迫症。2020-03-30Geek_d848f7 👍（2） 💬（0）出现过命名和内置模块一样的情况，结果调用内置模块时，报错或者不起作用2019-07-15吴月月鸟 👍（1） 💬（0）写的代码没写注释，当初自己一行一行码的代码，过段时间自己都不认识了。2019-07-11JackLee 👍（1） 💬（0）老师，我看之前的文章有个疑问，就是说列表在扩容的时候如果遇上空间被占用，需要重新复制到一块新的地址时。它的id会变么？2019-07-10张申傲 👍（0） 💬（0）第27讲打卡~2024-06-25T_Mer 👍（0） 💬（0）文本跟着语音滑动，多好\n"
            }
        );
    index.add(
            {
                id:  37 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/28---%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E5%88%A9%E7%94%A8assert\/",
                title: "如何合理利用assert？",
                description: "你好，我是景霄。\n相信你平时在写代码时，肯定或多或少看到过assert的存在。我也曾在日常的code review中，被一些同事要求增加assert语句，让代码更加健壮。\n不过，尽管如此，我发现在很多情况下，assert还是很容易被忽略，人们似乎对这么一个“不起眼”的东西并不关心。但事实上，这个看似“不起眼”的东西，如果能用好，对我们的程序大有裨益。\n说了这么多，那么究竟什么是assert，我们又该如何合理地使用assert呢？今天这节课，我就带你一起来学习它的用法。\n什么是assert？ linkPython的assert语句，可以说是一个debug的好工具，主要用于测试一个条件是否满足。如果测试的条件满足，则什么也不做，相当于执行了pass语句；如果测试条件不满足，便会抛出异常AssertionError，并返回具体的错误信息（optional）。\n它的具体语法是下面这样的：\nassert_stmt ::= \"assert\" expression [\",\" expression] 我们先来看一个简单形式的assert expression，比如下面这个例子：\nassert 1 == 2 它就相当于下面这两行代码：\nif __debug__:\rif not expression: raise AssertionError 再来看assert expression1, expression2的形式，比如下面这个例子：\nassert 1 == 2, 'assertion is wrong' 它就相当于下面这两行代码：\nif __debug__:\rif not expression1: raise AssertionError(expression2) 这里的__debug__是一个常数。如果Python程序执行时附带了-O这个选项，比如Python test.py -O，那么程序中所有的assert语句都会失效，常数__debug__便为False；反之__debug__则为True。\n不过，需要注意的是，直接对常数__debug__赋值是非法的，因为它的值在解释器开始运行时就已经决定了，中途无法改变。\n此外，一定记住，不要在使用assert时加入括号，比如下面这个例子：\nassert(1 == 2, 'This should fail')\r# 输出\r:1: SyntaxWarning: assertion is always true, perhaps remove parentheses?\rassert(1 == 2, 'This should fail') 如果你按照这样来写，无论表达式对与错（比如这里的1 == 2显然是错误的），assert检查永远不会fail，程序只会给你SyntaxWarning。\n",
                content: "你好，我是景霄。\n相信你平时在写代码时，肯定或多或少看到过assert的存在。我也曾在日常的code review中，被一些同事要求增加assert语句，让代码更加健壮。\n不过，尽管如此，我发现在很多情况下，assert还是很容易被忽略，人们似乎对这么一个“不起眼”的东西并不关心。但事实上，这个看似“不起眼”的东西，如果能用好，对我们的程序大有裨益。\n说了这么多，那么究竟什么是assert，我们又该如何合理地使用assert呢？今天这节课，我就带你一起来学习它的用法。\n什么是assert？ linkPython的assert语句，可以说是一个debug的好工具，主要用于测试一个条件是否满足。如果测试的条件满足，则什么也不做，相当于执行了pass语句；如果测试条件不满足，便会抛出异常AssertionError，并返回具体的错误信息（optional）。\n它的具体语法是下面这样的：\nassert_stmt ::= \"assert\" expression [\",\" expression] 我们先来看一个简单形式的assert expression，比如下面这个例子：\nassert 1 == 2 它就相当于下面这两行代码：\nif __debug__:\rif not expression: raise AssertionError 再来看assert expression1, expression2的形式，比如下面这个例子：\nassert 1 == 2, 'assertion is wrong' 它就相当于下面这两行代码：\nif __debug__:\rif not expression1: raise AssertionError(expression2) 这里的__debug__是一个常数。如果Python程序执行时附带了-O这个选项，比如Python test.py -O，那么程序中所有的assert语句都会失效，常数__debug__便为False；反之__debug__则为True。\n不过，需要注意的是，直接对常数__debug__赋值是非法的，因为它的值在解释器开始运行时就已经决定了，中途无法改变。\n此外，一定记住，不要在使用assert时加入括号，比如下面这个例子：\nassert(1 == 2, 'This should fail')\r# 输出\r:1: SyntaxWarning: assertion is always true, perhaps remove parentheses?\rassert(1 == 2, 'This should fail') 如果你按照这样来写，无论表达式对与错（比如这里的1 == 2显然是错误的），assert检查永远不会fail，程序只会给你SyntaxWarning。\n正确的写法，应该是下面这种不带括号的写法：\nassert 1 == 2, 'This should fail'\r# 输出\rAssertionError: This should fail 总的来说，assert在程序中的作用，是对代码做一些internal的self-check。使用assert，就表示你很确定。这个条件一定会发生或者一定不会发生。\n举个例子，比如你有一个函数，其中一个参数是人的性别，因为性别只有男女之分（这里只指生理性别），你便可以使用assert，以防止程序的非法输入。如果你的程序没有bug，那么assert永远不会抛出异常；而它一旦抛出了异常，你就知道程序存在问题了，并且可以根据错误信息，很容易定位出错误的源头。\nassert 的用法 link讲完了assert的基本语法与概念，我们接下来通过一些实际应用的例子，来看看assert在Python中的用法，并弄清楚 assert 的使用场景。\n第一个例子，假设你现在使用的极客时间正在做专栏促销活动，准备对一些专栏进行打折，所以后台需要写一个apply_discount()函数，要求输入为原来的价格和折扣，输出是折后的价格。那么，我们可以大致写成下面这样：\ndef apply_discount(price, discount):\rupdated_price = price * (1 - discount)\rassert 0 \u003c= updated_price \u003c= price, 'price should be greater or equal to 0 and less or equal to original price'\rreturn updated_price 可以看到，在计算新价格的后面，我们还写了一个assert语句，用来检查折后价格，这个值必须大于等于0、小于等于原来的价格，否则就抛出异常。\n我们可以试着输入几组数，来验证一下这个功能：\napply_discount(100, 0.2)\r80.0\rapply_discount(100, 2)\rAssertionError: price should be greater or equal to 0 and less or equal to original price 显然，当discount是0.2时，输出80，没有问题。但是当discount为2时，程序便抛出下面这个异常：\nAssertionError：price should be greater or equal to 0 and less or equal to original price 这样一来，如果开发人员修改相关的代码，或者是加入新的功能，导致discount数值的异常时，我们运行测试时就可以很容易发现问题。正如我开头所说，assert的加入，可以有效预防bug的发生，提高程序的健壮性。\n再来看一个例子，最常见的除法操作，这在任何领域的计算中都经常会遇到。同样还是以极客时间为例，假如极客时间后台想知道每个专栏的平均销售价格，那么就需要给定销售总额和销售数目，这样平均销售价格便很容易计算出来：\ndef calculate_average_price(total_sales, num_sales):\rassert num_sales \u003e 0, 'number of sales should be greater than 0'\rreturn total_sales / num_sales 同样的，我们也加入了assert语句，规定销售数目必须大于0，这样就可以防止后台计算那些还未开卖的专栏的价格。\n除了这两个例子，在实际工作中，assert还有一些很常见的用法，比如下面的场景：\ndef func(input):\rassert isinstance(input, list), 'input must be type of list'\r# 下面的操作都是基于前提：input必须是list\rif len(input) == 1:\r...\relif len(input) == 2:\r...\relse:\r... 这里函数func()里的所有操作，都是基于输入必须是list 这个前提。是不是很熟悉的需求呢？那我们就很有必要在开头加一句assert的检查，防止程序出错。\n当然，我们也要根据具体情况具体分析。比如上面这个例子，之所以能加assert，是因为我们很确定输入必须是list，不能是其他数据类型。\n如果你的程序中，允许input是其他数据类型，并且对不同的数据类型都有不同的处理方式，那你就应该写成if else的条件语句了：\ndef func(input):\rif isinstance(input, list):\r...\relse:\r... assert错误示例 link前面我们讲了这么多 assert的使用场景，可能给你一种错觉，也可能会让你有些迷茫：很多地方都可以使用assert， 那么，很多if条件语句是不是都可以换成assert呢？这么想可就不准确了，接下来，我们就一起来看几个典型的错误用法，避免一些想当然的用法。\n还是以极客时间为例，我们假设下面这样的场景：后台有时候需要删除一些上线时间较长的专栏，于是，相关的开发人员便设计出了下面这个专栏删除函数。\ndef delete_course(user, course_id):\rassert user_is_admin(user), 'user must be admin'\rassert course_exist(course_id), 'course id must exist'\rdelete(course_id) 极客时间规定，必须是admin才能删除专栏，并且这个专栏课程必须存在。有的同学一看，很熟悉的需求啊，所以在前面加了相应的assert检查。那么我想让你思考一下，这样写到底对不对呢？\n答案显然是否定的。你可能觉得，从代码功能角度来说，这没错啊。但是在实际工程中，基本上没人会这么写。为什么呢？\n要注意，前面我说过，assert的检查是可以被关闭的，比如在运行Python程序时，加入-O这个选项就会让assert失效。因此，一旦assert的检查被关闭，user_is_admin()和course_exist()这两个函数便不会被执行。这就会导致：\n任何用户都有权限删除专栏课程； 并且，不管这个课程是否存在，他们都可以强行执行删除操作。 这显然会给程序带来巨大的安全漏洞。所以，正确的做法，是使用条件语句进行相应的检查，并合理抛出异常：\ndef delete_course(user, course_id):\rif not user_is_admin(user):\rraise Exception('user must be admin')\rif not course_exist(course_id):\rraise Exception('coursde id must exist')\rdelete(course_id) 再来看一个例子，如果你想打开一个文件，进行数据读取、处理等一系列操作，那么下面这样的写法，显然也是不正确的：\ndef read_and_process(path):\rassert file_exist(path), 'file must exist'\rwith open(path) as f:\r... 因为assert的使用，表明你强行指定了文件必须存在，但事实上在很多情况下，这个假设并不成立。另外，打开文件操作，也有可能触发其他的异常。所以，正确的做法是进行异常处理，用try和except来解决：\ndef read_and_process(path):\rtry:\rwith open(path) as f:\r...\rexcept Exception as e:\r... 总的来说，assert并不适用run-time error 的检查。比如你试图打开一个文件，但文件不存在；再或者是你试图从网上下载一个东西，但中途断网了了等等，这些情况下，还是应该参照我们前面所讲的错误与异常的内容，进行正确处理。\n总结 link今天这节课，我们一起学习了assert的用法。assert通常用来对代码进行必要的self check，表明你很确定这种情况一定发生，或者一定不会发生。需要注意的是，使用assert时，一定不要加上括号，否则无论表达式对与错，assert检查永远不会fail。另外，程序中的assert语句，可以通过-O等选项被全局disable。\n通过这节课的几个使用场景，你能看到，assert的合理使用，可以增加代码的健壮度，同时也方便了程序出错时开发人员的定位排查。\n不过，我们也不能滥用assert。很多情况下，程序中出现的不同情况都是意料之中的，需要我们用不同的方案去处理，这时候用条件语句进行判断更为合适。而对于程序中的一些run-time error，请记得使用异常处理。\n思考题 link最后，给你留一个思考题。在平时的工作学习中，你用过assert吗？如果用过的话，是在什么情况下使用的？有遇到过什么问题吗？\n欢迎在留言区写下你的经历，还有今天学习的心得和疑惑，与我一起分享。也欢迎你把这篇文章分享给你的同事、朋友，我们一起交流，一起进步。\n检查值在某一确定的范围： assert a\u003e0, “a must \u003e 0”\n检查值的数据类型： assert isinstance(a, list), “a should be list”\n注：\nassert 是可以使用-O关闭的； run-time error需要使用try-except异常处理；2019-07-17丁丁历险记 👍（3） 💬（0）个人理解，assert 主要是做健壮性处理。2019-10-07倾 👍（3） 💬（0）一般不怎么用，全部使用异常处理的。2019-07-15Ray 👍（2） 💬（0）之前在一个C++程序中用过assert语句，记得好像是在一个FTP下载模块中。后来很长时间没啥问题后也忘了，然后有一阵程序偶尔异常退出，查了半天发现是assert条件原因，最后发现原来是交换机出问题了时好时坏。2020-03-17自由民 👍（2） 💬（2）在c++里用过，用得不多。Python里没用过。2019-10-20Eski 👍（2） 💬（0）经常在 try except 当中用 assert，比较方便在一些不需要程序继续执行下去的地方跳出来，比if else好用2019-07-16D.mc 👍（0） 💬（0）读下来认为是这样： 1.try-except, 用于处理可能有多种异常的情况 2.if-else, 用于处理多种情况，但不同情况都可能合理的情况 3.assert, 则只能用于处理一种特定的情况，当要特定地确认某个情况是否发生时；或者说，一般只用于增强健壮性2025-01-22 "
            }
        );
    index.add(
            {
                id:  38 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/29---%E5%B7%A7%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8%E5%92%8Cwith%E8%AF%AD%E5%8F%A5%E7%B2%BE%E7%AE%80%E4%BB%A3%E7%A0%81\/",
                title: "巧用上下文管理器和With语句精简代码",
                description: "你好，我是景霄。\n我想你对Python中的with语句一定不陌生，在专栏里它也曾多次出现，尤其是在文件的输入输出操作中，不过我想，大部分人可能习惯了它的使用，却并不知道隐藏在其背后的“秘密”。\n那么，究竟with语句要怎么用，与之相关的上下文管理器（context manager）是什么，它们之间又有着怎样的联系呢？这节课，我就带你一起揭开它们的神秘面纱。\n什么是上下文管理器？ link在任何一门编程语言中，文件的输入输出、数据库的连接断开等，都是很常见的资源管理操作。但资源都是有限的，在写程序时，我们必须保证这些资源在使用过后得到释放，不然就容易造成资源泄露，轻者使得系统处理缓慢，重则会使系统崩溃。\n光说这些概念，你可能体会不到这一点，我们可以看看下面的例子：\nfor x in range(10000000): f = open('test.txt', 'w')\rf.write('hello') 这里我们一共打开了10000000个文件，但是用完以后都没有关闭它们，如果你运行该段代码，便会报错：\nOSError: [Errno 23] Too many open files in system: 'test.txt' 这就是一个典型的资源泄露的例子。因为程序中同时打开了太多的文件，占据了太多的资源，造成系统崩溃。\n为了解决这个问题，不同的编程语言都引入了不同的机制。而在Python中，对应的解决方式便是上下文管理器（context manager）。上下文管理器，能够帮助你自动分配并且释放资源，其中最典型的应用便是with语句。所以，上面代码的正确写法应该如下所示：\nfor x in range(10000000):\rwith open('test.txt', 'w') as f:\rf.write('hello') 这样，我们每次打开文件“test.txt”，并写入‘hello’之后，这个文件便会自动关闭，相应的资源也可以得到释放，防止资源泄露。当然，with语句的代码，也可以用下面的形式表示：\nf = open('test.txt', 'w')\rtry:\rf.write('hello')\rfinally:\rf.close() 要注意的是，最后的finally block尤其重要，哪怕在写入文件时发生错误异常，它也可以保证该文件最终被关闭。不过与with语句相比，这样的代码就显得冗余了，并且还容易漏写，因此我们一般更倾向于使用with语句。\n另外一个典型的例子，是Python中的threading.lock类。举个例子，比如我想要获取一个锁，执行相应的操作，完成后再释放，那么代码就可以写成下面这样：\nsome_lock = threading.Lock()\rsome_lock.acquire()\rtry:\r...\rfinally:\rsome_lock.release() 而对应的with语句，同样非常简洁：\n",
                content: "你好，我是景霄。\n我想你对Python中的with语句一定不陌生，在专栏里它也曾多次出现，尤其是在文件的输入输出操作中，不过我想，大部分人可能习惯了它的使用，却并不知道隐藏在其背后的“秘密”。\n那么，究竟with语句要怎么用，与之相关的上下文管理器（context manager）是什么，它们之间又有着怎样的联系呢？这节课，我就带你一起揭开它们的神秘面纱。\n什么是上下文管理器？ link在任何一门编程语言中，文件的输入输出、数据库的连接断开等，都是很常见的资源管理操作。但资源都是有限的，在写程序时，我们必须保证这些资源在使用过后得到释放，不然就容易造成资源泄露，轻者使得系统处理缓慢，重则会使系统崩溃。\n光说这些概念，你可能体会不到这一点，我们可以看看下面的例子：\nfor x in range(10000000): f = open('test.txt', 'w')\rf.write('hello') 这里我们一共打开了10000000个文件，但是用完以后都没有关闭它们，如果你运行该段代码，便会报错：\nOSError: [Errno 23] Too many open files in system: 'test.txt' 这就是一个典型的资源泄露的例子。因为程序中同时打开了太多的文件，占据了太多的资源，造成系统崩溃。\n为了解决这个问题，不同的编程语言都引入了不同的机制。而在Python中，对应的解决方式便是上下文管理器（context manager）。上下文管理器，能够帮助你自动分配并且释放资源，其中最典型的应用便是with语句。所以，上面代码的正确写法应该如下所示：\nfor x in range(10000000):\rwith open('test.txt', 'w') as f:\rf.write('hello') 这样，我们每次打开文件“test.txt”，并写入‘hello’之后，这个文件便会自动关闭，相应的资源也可以得到释放，防止资源泄露。当然，with语句的代码，也可以用下面的形式表示：\nf = open('test.txt', 'w')\rtry:\rf.write('hello')\rfinally:\rf.close() 要注意的是，最后的finally block尤其重要，哪怕在写入文件时发生错误异常，它也可以保证该文件最终被关闭。不过与with语句相比，这样的代码就显得冗余了，并且还容易漏写，因此我们一般更倾向于使用with语句。\n另外一个典型的例子，是Python中的threading.lock类。举个例子，比如我想要获取一个锁，执行相应的操作，完成后再释放，那么代码就可以写成下面这样：\nsome_lock = threading.Lock()\rsome_lock.acquire()\rtry:\r...\rfinally:\rsome_lock.release() 而对应的with语句，同样非常简洁：\nsome_lock = threading.Lock()\rwith somelock:\r... 我们可以从这两个例子中看到，with语句的使用，可以简化了代码，有效避免资源泄露的发生。\n上下文管理器的实现 link基于类的上下文管理器 link了解了上下文管理的概念和优点后，下面我们就通过具体的例子，一起来看看上下文管理器的原理，搞清楚它的内部实现。这里，我自定义了一个上下文管理类FileManager，模拟Python的打开、关闭文件操作：\nclass FileManager:\rdef __init__(self, name, mode):\rprint('calling __init__ method')\rself.name = name\rself.mode = mode self.file = None\rdef __enter__(self):\rprint('calling __enter__ method')\rself.file = open(self.name, self.mode)\rreturn self.file\rdef __exit__(self, exc_type, exc_val, exc_tb):\rprint('calling __exit__ method')\rif self.file:\rself.file.close()\rwith FileManager('test.txt', 'w') as f:\rprint('ready to write to file')\rf.write('hello world')\r## 输出\rcalling __init__ method\rcalling __enter__ method\rready to write to file\rcalling __exit__ method 需要注意的是，当我们用类来创建上下文管理器时，必须保证这个类包括方法”__enter__()”和方法“__exit__()”。其中，方法“__enter__()”返回需要被管理的资源，方法“__exit__()”里通常会存在一些释放、清理资源的操作，比如这个例子中的关闭文件等等。\n而当我们用with语句，执行这个上下文管理器时：\nwith FileManager('test.txt', 'w') as f:\rf.write('hello world') 下面这四步操作会依次发生：\n方法“__init__()”被调用，程序初始化对象FileManager，使得文件名（name）是\"test.txt\"，文件模式(mode)是'w'； 方法“__enter__()”被调用，文件“test.txt”以写入的模式被打开，并且返回FileManager对象赋予变量f； 字符串“hello world”被写入文件“test.txt”； 方法“__exit__()”被调用，负责关闭之前打开的文件流。 因此，这个程序的输出是：\ncalling __init__ method\rcalling __enter__ method\rready to write to file\rcalling __exit__ meth 另外，值得一提的是，方法“__exit__()”中的参数“exc_type, exc_val, exc_tb”，分别表示exception_type、exception_value和traceback。当我们执行含有上下文管理器的with语句时，如果有异常抛出，异常的信息就会包含在这三个变量中，传入方法“__exit__()”。\n因此，如果你需要处理可能发生的异常，可以在“__exit__()”添加相应的代码，比如下面这样来写：\nclass Foo:\rdef __init__(self):\rprint('__init__ called') def __enter__(self):\rprint('__enter__ called')\rreturn self\rdef __exit__(self, exc_type, exc_value, exc_tb):\rprint('__exit__ called')\rif exc_type:\rprint(f'exc_type: {exc_type}')\rprint(f'exc_value: {exc_value}')\rprint(f'exc_traceback: {exc_tb}')\rprint('exception handled')\rreturn True\rwith Foo() as obj:\rraise Exception('exception raised').with_traceback(None)\r# 输出\r__init__ called\r__enter__ called\r__exit__ called\rexc_type: "
            }
        );
    index.add(
            {
                id:  39 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/30---%E7%9C%9F%E7%9A%84%E6%9C%89%E5%BF%85%E8%A6%81%E5%86%99%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%90%97\/",
                title: "真的有必要写单元测试吗？",
                description: "你好，我是景霄。\n说到unit test（即单元测试，下文统一用中文称呼），大部分人的反应估计有这么两种：要么就是，单元测试啊，挺简单的呀，做不做无所谓吧；要么就是，哎呀，项目进度太赶，单元测试拖一拖之后再来吧。\n显然，这两种人，都没有正确认识到单元测试的价值，也没能掌握正确的单元测试方法。你是不是觉得自己只要了解Python的各个feature，能够编写出符合规定功能的程序就可以了呢？\n其实不然，完成产品的功能需求只是很基础的一部分，如何保证所写代码的稳定、高效、无误，才是我们工作的关键。而学会合理地使用单元测试，正是帮助你实现这一目标的重要路径。\n我们总说，测试驱动开发（TDD）。今天我就以Python为例，教你设计编写Python的单元测试代码，带你熟悉并掌握这一重要技能。\n什么是单元测试？ link单元测试，通俗易懂地讲，就是编写测试来验证某一个模块的功能正确性，一般会指定输入，验证输出是否符合预期。\n实际生产环境中，我们会对每一个模块的所有可能输入值进行测试。这样虽然显得繁琐，增加了额外的工作量，但是能够大大提高代码质量，减小bug发生的可能性，也更方便系统的维护。\n说起单元测试，就不得不提 Python unittest库，它提供了我们需要的大多数工具。我们来看下面这个简单的测试，从代码中了解其使用方法：\nimport unittest\r# 将要被测试的排序函数\rdef sort(arr):\rl = len(arr)\rfor i in range(0, l):\rfor j in range(i + 1, l):\rif arr[i] \u003e= arr[j]:\rtmp = arr[i]\rarr[i] = arr[j]\rarr[j] = tmp\r# 编写子类继承unittest.TestCase\rclass TestSort(unittest.TestCase):\r# 以test开头的函数将会被测试\rdef test_sort(self):\rarr = [3, 4, 1, 5, 6]\rsort(arr)\r# assert 结果跟我们期待的一样\rself.assertEqual(arr, [1, 3, 4, 5, 6])\rif __name__ == '__main__':\r## 如果在Jupyter下，请用如下方式运行单元测试\runittest.main(argv=['first-arg-is-ignored'], exit=False)\r## 如果是命令行下运行，则：\r## unittest.main()\r## 输出\r..\r----------------------------------------------------------------------\rRan 2 tests in 0.002s\rOK 这里，我们创建了一个排序函数的单元测试，来验证排序函数的功能是否正确。代码里我做了非常详细的注释，相信你能够大致读懂，我再来介绍一些细节。\n",
                content: "你好，我是景霄。\n说到unit test（即单元测试，下文统一用中文称呼），大部分人的反应估计有这么两种：要么就是，单元测试啊，挺简单的呀，做不做无所谓吧；要么就是，哎呀，项目进度太赶，单元测试拖一拖之后再来吧。\n显然，这两种人，都没有正确认识到单元测试的价值，也没能掌握正确的单元测试方法。你是不是觉得自己只要了解Python的各个feature，能够编写出符合规定功能的程序就可以了呢？\n其实不然，完成产品的功能需求只是很基础的一部分，如何保证所写代码的稳定、高效、无误，才是我们工作的关键。而学会合理地使用单元测试，正是帮助你实现这一目标的重要路径。\n我们总说，测试驱动开发（TDD）。今天我就以Python为例，教你设计编写Python的单元测试代码，带你熟悉并掌握这一重要技能。\n什么是单元测试？ link单元测试，通俗易懂地讲，就是编写测试来验证某一个模块的功能正确性，一般会指定输入，验证输出是否符合预期。\n实际生产环境中，我们会对每一个模块的所有可能输入值进行测试。这样虽然显得繁琐，增加了额外的工作量，但是能够大大提高代码质量，减小bug发生的可能性，也更方便系统的维护。\n说起单元测试，就不得不提 Python unittest库，它提供了我们需要的大多数工具。我们来看下面这个简单的测试，从代码中了解其使用方法：\nimport unittest\r# 将要被测试的排序函数\rdef sort(arr):\rl = len(arr)\rfor i in range(0, l):\rfor j in range(i + 1, l):\rif arr[i] \u003e= arr[j]:\rtmp = arr[i]\rarr[i] = arr[j]\rarr[j] = tmp\r# 编写子类继承unittest.TestCase\rclass TestSort(unittest.TestCase):\r# 以test开头的函数将会被测试\rdef test_sort(self):\rarr = [3, 4, 1, 5, 6]\rsort(arr)\r# assert 结果跟我们期待的一样\rself.assertEqual(arr, [1, 3, 4, 5, 6])\rif __name__ == '__main__':\r## 如果在Jupyter下，请用如下方式运行单元测试\runittest.main(argv=['first-arg-is-ignored'], exit=False)\r## 如果是命令行下运行，则：\r## unittest.main()\r## 输出\r..\r----------------------------------------------------------------------\rRan 2 tests in 0.002s\rOK 这里，我们创建了一个排序函数的单元测试，来验证排序函数的功能是否正确。代码里我做了非常详细的注释，相信你能够大致读懂，我再来介绍一些细节。\n首先，我们需要创建一个类TestSort，继承类‘unittest.TestCase’；然后，在这个类中定义相应的测试函数test_sort()，进行测试。注意，测试函数要以‘test’开头，而测试函数的内部，通常使用assertEqual()、assertTrue()、assertFalse()和assertRaise()等assert语句对结果进行验证。\n最后运行时，如果你是在IPython或者Jupyter环境下，请使用下面这行代码：\nunittest.main(argv=['first-arg-is-ignored'], exit=False) 而如果你用的是命令行，直接使用unittest.main()就可以了。你可以看到，运行结果输出’OK‘，这就表示我们的测试通过了。\n当然，这个例子中的被测函数相对简单一些，所以写起对应的单元测试来也非常自然，并不需要很多单元测试的技巧。但实战中的函数往往还是比较复杂的，遇到复杂问题，高手和新手的最大差别，便是单元测试技巧的使用。\n单元测试的几个技巧 link接下来，我将会介绍Python单元测试的几个技巧，分别是mock、side_effect和patch。这三者用法不一样，但都是一个核心思想，即用虚假的实现，来替换掉被测试函数的一些依赖项，让我们能把更多的精力放在需要被测试的功能上。\nmock linkmock是单元测试中最核心重要的一环。mock的意思，便是通过一个虚假对象，来代替被测试函数或模块需要的对象。\n举个例子，比如你要测一个后端API逻辑的功能性，但一般后端API都依赖于数据库、文件系统、网络等。这样，你就需要通过mock，来创建一些虚假的数据库层、文件系统层、网络层对象，以便可以简单地对核心后端逻辑单元进行测试。\nPython mock则主要使用mock或者MagicMock对象，这里我也举了一个代码示例。这个例子看上去比较简单，但是里面的思想很重要。下面我们一起来看下：\nimport unittest\rfrom unittest.mock import MagicMock\rclass A(unittest.TestCase):\rdef m1(self):\rval = self.m2()\rself.m3(val)\rdef m2(self):\rpass\rdef m3(self, val):\rpass\rdef test_m1(self):\ra = A()\ra.m2 = MagicMock(return_value=\"custom_val\")\ra.m3 = MagicMock()\ra.m1()\rself.assertTrue(a.m2.called) #验证m2被call过\ra.m3.assert_called_with(\"custom_val\") #验证m3被指定参数call过\rif __name__ == '__main__':\runittest.main(argv=['first-arg-is-ignored'], exit=False)\r## 输出\r..\r----------------------------------------------------------------------\rRan 2 tests in 0.002s\rOK 这段代码中，我们定义了一个类的三个方法m1()、m2()、m3()。我们需要对m1()进行单元测试，但是m1()取决于m2()和m3()。如果m2()和m3()的内部比较复杂, 你就不能只是简单地调用m1()函数来进行测试，可能需要解决很多依赖项的问题。\n这一听就让人头大了吧？但是，有了mock其实就很好办了。我们可以把m2()替换为一个返回具体数值的value，把m3()替换为另一个mock（空函数）。这样，测试m1()就很容易了，我们可以测试m1()调用m2()，并且用m2()的返回值调用m3()。\n可能你会疑惑，这样测试m1()不是基本上毫无意义吗？看起来只是象征性地测了一下逻辑呀？\n其实不然，真正工业化的代码，都是很多层模块相互逻辑调用的一个树形结构。单元测试需要测的是某个节点的逻辑功能，mock掉相关的依赖项是非常重要的。这也是为什么会被叫做单元测试unit test，而不是其他的integration test、end to end test这类。\nMock Side Effect link第二个我们来看Mock Side Effect，这个概念很好理解，就是 mock的函数，属性是可以根据不同的输入，返回不同的数值，而不只是一个return_value。\n比如下面这个示例，例子很简单，测试的是输入参数是否为负数，输入小于0则输出为1 ，否则输出为2。代码很简短，你一定可以看懂，这便是Mock Side Effect的用法。\nfrom unittest.mock import MagicMock\rdef side_effect(arg):\rif arg \u003c 0:\rreturn 1\relse:\rreturn 2\rmock = MagicMock()\rmock.side_effect = side_effect\rmock(-1)\r1\rmock(1)\r2 patch link至于patch，给开发者提供了非常便利的函数mock方法。它可以应用Python的decoration模式或是context manager概念，快速自然地mock所需的函数。它的用法也不难，我们来看代码：\nfrom unittest.mock import patch\r@patch('sort')\rdef test_sort(self, mock_sort):\r...\r... 在这个test里面，mock_sort 替代sort函数本身的存在，所以，我们可以像开始提到的mock object一样，设置return_value和side_effect。\n另一种patch的常见用法，是mock类的成员函数，这个技巧我们在工作中也经常会用到，比如说一个类的构造函数非常复杂，而测试其中一个成员函数并不依赖所有初始化的object。它的用法如下：\nwith patch.object(A, '__init__', lambda x: None):\r… 代码应该也比较好懂。在with语句里面，我们通过patch，将A类的构造函数mock为一个do nothing的函数，这样就可以很方便地避免一些复杂的初始化（initialization）。\n其实，综合前面讲的这几点来看，你应该感受到了，单元测试的核心还是mock，mock掉依赖项，测试相应的逻辑或算法的准确性。在我看来，虽然Python unittest库还有很多层出不穷的方法，但只要你能掌握了MagicMock和patch，编写绝大部分工作场景的单元测试就不成问题了。\n高质量单元测试的关键 link这节课的最后，我想谈一谈高质量的单元测试。我很理解，单元测试这个东西，哪怕是正在使用的人也是“百般讨厌”的，不少人很多时候只是敷衍了事。我也嫌麻烦，但从来不敢松懈，因为在大公司里，如果你写一个很重要的模块功能，不写单元测试是无法通过code review的。\n低质量的单元测试，可能真的就是摆设，根本不能帮我们验证代码的正确性，还浪费时间。那么，既然要做单元测试，与其浪费时间糊弄自己，不如追求高质量的单元测试，切实提高代码品质。\n那该怎么做呢？结合工作经验，我认为一个高质量的单元测试，应该特别关注下面两点。\nTest Coverage link首先我们要关注Test Coverage，它是衡量代码中语句被cover的百分比。可以说，提高代码模块的Test Coverage，基本等同于提高代码的正确性。\n为什么呢？\n要知道，大多数公司代码库的模块都非常复杂。尽管它们遵从模块化设计的理念，但因为有复杂的业务逻辑在，还是会产生逻辑越来越复杂的模块。所以，编写高质量的单元测试，需要我们cover模块的每条语句，提高Test Coverage。\n我们可以用Python的coverage tool 来衡量Test Coverage，并且显示每个模块为被coverage的语句。如果你想了解更多更详细的使用，可以点击这个链接来学习：https://coverage.readthedocs.io/en/v4.5.x/ 。\n模块化 link高质量单元测试，不仅要求我们提高Test Coverage，尽量让所写的测试能够cover每个模块中的每条语句；还要求我们从测试的角度审视codebase，去思考怎么模块化代码，以便写出高质量的单元测试。\n光讲这段话可能有些抽象，我们来看这样的场景。比如，我写了一个下面这个函数，对一个数组进行处理，并返回新的数组：\ndef work(arr):\r# pre process\r...\r...\r# sort\rl = len(arr)\rfor i in range(0, l):\rfor j in range(i + 1, j):\rif arr[i] \u003e= arr[j]:\rtmp = arr[i]\rarr[i] = arr[j]\rarr[j] = tmp\r# post process\r...\r...\rReturn arr 这段代码的大概意思是，先有个预处理，再排序，最后再处理一下然后返回。如果现在要求你，给这个函数写个单元测试，你是不是会一筹莫展呢？\n毕竟，这个函数确实有点儿复杂，以至于你都不知道应该是怎样的输入，并要期望怎样的输出。这种代码写单元测试是非常痛苦的，更别谈cover每条语句的要求了。\n所以，正确的测试方法，应该是先模块化代码，写成下面的形式：\ndef preprocess(arr):\r...\r...\rreturn arr\rdef sort(arr):\r...\r...\rreturn arr\rdef postprocess(arr):\r...\rreturn arr\rdef work(self):\rarr = preprocess(arr)\rarr = sort(arr)\rarr = postprocess(arr)\rreturn arr 接着再进行相应的测试，测试三个子函数的功能正确性；然后通过mock子函数，调用work()函数，来验证三个子函数被call过。\nfrom unittest.mock import patch\rdef test_preprocess(self):\r...\rdef test_sort(self):\r...\rdef test_postprocess(self):\r...\r@patch('%s.preprocess')\r@patch('%s.sort')\r@patch('%s.postprocess')\rdef test_work(self,mock_post_process, mock_sort, mock_preprocess):\rwork()\rself.assertTrue(mock_post_process.called)\rself.assertTrue(mock_sort.called)\rself.assertTrue(mock_preprocess.called) 你看，这样一来，通过重构代码就可以使单元测试更加全面、精确，并且让整体架构、函数设计都美观了不少。\n总结 link回顾下这节课，整体来看，单元测试的理念是先模块化代码设计，然后针对每个作用单元，编写单独的测试去验证其准确性。更好的模块化设计和更多的Test Coverage，是提高代码质量的核心。而单元测试的本质就是通过mock，去除掉不影响测试的依赖项，把重点放在需要测试的代码核心逻辑上。\n讲了这么多，还是想告诉你，单元测试是个非常非常重要的技能，在实际工作中是保证代码质量和准确性必不可少的一环。同时，单元测试的设计技能，不只是适用于Python，而是适用于任何语言。所以，单元测试必不可少。\n思考题 link那么，你在平时的学习工作中，曾经写过单元测试吗？在编写单元测试时，用到过哪些技巧或者遇到过哪些问题吗？欢迎留言与我交流，也欢迎你把这篇文章分享出去。\n在写UT的时候，编写对平台的mock即可。2019-08-07KaitoShy 👍（7） 💬（4）后面有几个代码没怎么看懂，希望老师详细说明一下： 1） from unittest.mock import patch\n@patch('sort') def test_sort(self, mock_sort): … 文档上说这个是个patch()里面是个类,但老师这里表达的是函数？ 2） @patch('%s.preprocess') 这个又是表达的什么的，运行后ModuleNotFoundError: No module named '%s'。 所以烦请老师把这块详细说明一下，不然感觉还是不怎么会使用2019-07-17hello,everyone 👍（5） 💬（0）从来没写过单元测试，在jupyter notebook 做数据分析，每步都会有结果出来，根据结果做修改，请问这样的数据分析，有必要写单元测试吗？或者数据分析过程有什么好的测试方法，感觉有时候花好长时间完成一个特征的处理，发现结果与预期不一致，很是头疼。2019-07-28magician 👍（5） 💬（0）requests 测试api2019-07-25zengyunda 👍（4） 💬（0）从来没有写过单元测试的人表示很忧伤2019-07-25武瑞霞 👍（3） 💬（0）mock下的side effect和patch，这两个完全茫然啊，希望老师能详细介绍并示范下实践运用！2020-04-14夜路破晓 👍（3） 💬（0）认知层次决定了效率高低。 虽然作为小白代码部分看得一脸懵逼，但完全get到了测试单元属于高级思维运用的高级方法与技能，因为它不仅要求代码设计拥有模块化理念的底层逻辑，还提倡代码不只是满足产品功能需求更要求持续稳定高效。 这就是码农与非码农的认知差距。2019-07-17\n"
            }
        );
    index.add(
            {
                id:  40 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/31---pdb--cprofile%E8%B0%83%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E7%9A%84%E6%B3%95%E5%AE%9D\/",
                title: "pdb \u0026 cProfile：调试和性能分析的法宝",
                description: "你好，我是景霄。\n在实际生产环境中，对代码进行调试和性能分析，是一个永远都逃不开的话题。调试和性能分析的主要场景，通常有这么三个：\n一是代码本身有问题，需要我们找到root cause并修复； 二是代码效率有问题，比如过度浪费资源，增加latency，因此需要我们debug； 三是在开发新的feature时，一般都需要测试。 在遇到这些场景时，究竟应该使用哪些工具，如何正确的使用这些工具，应该遵循什么样的步骤等等，就是这节课我们要讨论的话题。\n用pdb进行代码调试 linkpdb的必要性 link首先，我们来看代码的调试。也许不少人会有疑问：代码调试？说白了不就是在程序中使用print()语句吗？\n没错，在程序中相应的地方打印，的确是调试程序的一个常用手段，但这只适用于小型程序。因为你每次都得重新运行整个程序，或是一个完整的功能模块，才能看到打印出来的变量值。如果程序不大，每次运行都非常快，那么使用print()，的确是很方便的。\n但是，如果我们面对的是大型程序，运行一次的调试成本很高。特别是对于一些tricky的例子来说，它们通常需要反复运行调试、追溯上下文代码，才能找到错误根源。这种情况下，仅仅依赖打印的效率自然就很低了。\n我们可以想象下面这个场景。比如你最常使用的极客时间App，最近出现了一个bug，部分用户无法登陆。于是，后端工程师们开始debug。\n他们怀疑错误的代码逻辑在某几个函数中，如果使用print()语句debug，很可能出现的场景是，工程师们在他们认为的10个最可能出现bug的地方，都使用print()语句，然后运行整个功能块代码（从启动到运行花了5min），看打印出来的结果值，是不是和预期相符。\n如果结果值和预期相符，并能直接找到错误根源，显然是最好的。但实际情况往往是，\n要么与预期并不相符，需要重复以上步骤，继续debug； 要么虽说与预期相符，但前面的操作只是缩小了错误代码的范围，所以仍得继续添加print()语句，再一次运行相应的代码模块（又要5min），进行debug。 你可以看到，这样的效率就很低下了。哪怕只是遇到稍微复杂一点的case，两、三个工程师一下午的时间可能就没了。\n可能又有人会说，现在很多的IDE不都有内置的debug工具吗？\n这话说的也没错。比如我们常用的Pycharm，可以很方便地在程序中设置断点。这样程序只要运行到断点处，便会自动停下，你就可以轻松查看环境中各个变量的值，并且可以执行相应的语句，大大提高了调试的效率。\n看到这里，你不禁会问，既然问题都解决了，那为什么还要学习pdb呢？其实在很多大公司，产品的创造与迭代，往往需要很多编程语言的支持；并且，公司内部也会开发很多自己的接口，尝试把尽可能多的语言给结合起来。\n这就使得，很多情况下，单一语言的IDE，对混合代码并不支持UI形式的断点调试功能，或是只对某些功能模块支持。另外，考虑到不少代码已经挪到了类似Jupyter的Notebook中，往往就要求开发者使用命令行的形式，来对代码进行调试。\n而Python的pdb，正是其自带的一个调试库。它为Python程序提供了交互式的源代码调试功能，是命令行版本的IDE断点调试器，完美地解决了我们刚刚讨论的这个问题。\n如何使用pdb link了解了pdb的重要性与必要性后，接下来，我们就一起来看看，pdb在Python中到底应该如何使用。\n首先，要启动pdb调试，我们只需要在程序中，加入“import pdb”和“pdb.set_trace()”这两行代码就行了，比如下面这个简单的例子：\na = 1\rb = 2\rimport pdb\rpdb.set_trace()\rc = 3\rprint(a + b + c) 当我们运行这个程序时时，它的输出界面是下面这样的，表示程序已经运行到了“pdb.set_trace()”这行，并且暂停了下来，等待用户输入。\n\u003e /Users/jingxiao/test.py(5)()\r-\u003e c = 3 这时，我们就可以执行，在IDE断点调试器中可以执行的一切操作，比如打印，语法是\"p \"：\n(pdb) p a\r1\r(pdb) p b\r2 你可以看到，我打印的是a和b的值，分别为1和2，与预期相符。为什么不打印c呢？显然，打印c会抛出异常，因为程序目前只运行了前面几行，此时的变量c还没有被定义：\n",
                content: "你好，我是景霄。\n在实际生产环境中，对代码进行调试和性能分析，是一个永远都逃不开的话题。调试和性能分析的主要场景，通常有这么三个：\n一是代码本身有问题，需要我们找到root cause并修复； 二是代码效率有问题，比如过度浪费资源，增加latency，因此需要我们debug； 三是在开发新的feature时，一般都需要测试。 在遇到这些场景时，究竟应该使用哪些工具，如何正确的使用这些工具，应该遵循什么样的步骤等等，就是这节课我们要讨论的话题。\n用pdb进行代码调试 linkpdb的必要性 link首先，我们来看代码的调试。也许不少人会有疑问：代码调试？说白了不就是在程序中使用print()语句吗？\n没错，在程序中相应的地方打印，的确是调试程序的一个常用手段，但这只适用于小型程序。因为你每次都得重新运行整个程序，或是一个完整的功能模块，才能看到打印出来的变量值。如果程序不大，每次运行都非常快，那么使用print()，的确是很方便的。\n但是，如果我们面对的是大型程序，运行一次的调试成本很高。特别是对于一些tricky的例子来说，它们通常需要反复运行调试、追溯上下文代码，才能找到错误根源。这种情况下，仅仅依赖打印的效率自然就很低了。\n我们可以想象下面这个场景。比如你最常使用的极客时间App，最近出现了一个bug，部分用户无法登陆。于是，后端工程师们开始debug。\n他们怀疑错误的代码逻辑在某几个函数中，如果使用print()语句debug，很可能出现的场景是，工程师们在他们认为的10个最可能出现bug的地方，都使用print()语句，然后运行整个功能块代码（从启动到运行花了5min），看打印出来的结果值，是不是和预期相符。\n如果结果值和预期相符，并能直接找到错误根源，显然是最好的。但实际情况往往是，\n要么与预期并不相符，需要重复以上步骤，继续debug； 要么虽说与预期相符，但前面的操作只是缩小了错误代码的范围，所以仍得继续添加print()语句，再一次运行相应的代码模块（又要5min），进行debug。 你可以看到，这样的效率就很低下了。哪怕只是遇到稍微复杂一点的case，两、三个工程师一下午的时间可能就没了。\n可能又有人会说，现在很多的IDE不都有内置的debug工具吗？\n这话说的也没错。比如我们常用的Pycharm，可以很方便地在程序中设置断点。这样程序只要运行到断点处，便会自动停下，你就可以轻松查看环境中各个变量的值，并且可以执行相应的语句，大大提高了调试的效率。\n看到这里，你不禁会问，既然问题都解决了，那为什么还要学习pdb呢？其实在很多大公司，产品的创造与迭代，往往需要很多编程语言的支持；并且，公司内部也会开发很多自己的接口，尝试把尽可能多的语言给结合起来。\n这就使得，很多情况下，单一语言的IDE，对混合代码并不支持UI形式的断点调试功能，或是只对某些功能模块支持。另外，考虑到不少代码已经挪到了类似Jupyter的Notebook中，往往就要求开发者使用命令行的形式，来对代码进行调试。\n而Python的pdb，正是其自带的一个调试库。它为Python程序提供了交互式的源代码调试功能，是命令行版本的IDE断点调试器，完美地解决了我们刚刚讨论的这个问题。\n如何使用pdb link了解了pdb的重要性与必要性后，接下来，我们就一起来看看，pdb在Python中到底应该如何使用。\n首先，要启动pdb调试，我们只需要在程序中，加入“import pdb”和“pdb.set_trace()”这两行代码就行了，比如下面这个简单的例子：\na = 1\rb = 2\rimport pdb\rpdb.set_trace()\rc = 3\rprint(a + b + c) 当我们运行这个程序时时，它的输出界面是下面这样的，表示程序已经运行到了“pdb.set_trace()”这行，并且暂停了下来，等待用户输入。\n\u003e /Users/jingxiao/test.py(5)()\r-\u003e c = 3 这时，我们就可以执行，在IDE断点调试器中可以执行的一切操作，比如打印，语法是\"p \"：\n(pdb) p a\r1\r(pdb) p b\r2 你可以看到，我打印的是a和b的值，分别为1和2，与预期相符。为什么不打印c呢？显然，打印c会抛出异常，因为程序目前只运行了前面几行，此时的变量c还没有被定义：\n(pdb) p c\r*** NameError: name 'c' is not defined 除了打印，常见的操作还有“n”，表示继续执行代码到下一行，用法如下：\n(pdb) n\r-\u003e print(a + b + c) 而命令”l“，则表示列举出当前代码行上下的11行源代码，方便开发者熟悉当前断点周围的代码状态：\n(pdb) l\r1 a = 1\r2 b = 2\r3 import pdb\r4 pdb.set_trace()\r5 -\u003e\tc = 3\r6 print(a + b + c) 命令“s“，就是 step into 的意思，即进入相对应的代码内部。这时，命令行中会显示”--Call--“的字样，当你执行完内部的代码块后，命令行中则会出现”--Return--“的字样。\n我们来看下面这个例子：\ndef func():\rprint('enter func()')\ra = 1\rb = 2\rimport pdb\rpdb.set_trace()\rfunc()\rc = 3\rprint(a + b + c)\r# pdb\r\u003e /Users/jingxiao/test.py(9)()\r-\u003e func()\r(pdb) s\r--Call--\r\u003e /Users/jingxiao/test.py(1)func()\r-\u003e def func():\r(Pdb) l\r1 -\u003e\tdef func():\r2 print('enter func()')\r3\r4\r5 a = 1\r6 b = 2\r7 import pdb\r8 pdb.set_trace()\r9 func()\r10 c = 3\r11 print(a + b + c)\r(Pdb) n\r\u003e /Users/jingxiao/test.py(2)func()\r-\u003e print('enter func()')\r(Pdb) n\renter func()\r--Return--\r\u003e /Users/jingxiao/test.py(2)func()-\u003eNone\r-\u003e print('enter func()')\r(Pdb) n\r\u003e /Users/jingxiao/test.py(10)()\r-\u003e c = 3 这里，我们使用命令”s“进入了函数func()的内部，显示”--Call--“；而当我们执行完函数func()内部语句并跳出后，显示”--Return--“。\n另外，\n与之相对应的命令”r“，表示step out，即继续执行，直到当前的函数完成返回。 命令”b [ ([filename:]lineno | function) [, condition] ]“可以用来设置断点。比方说，我想要在代码中的第10行，再加一个断点，那么在pdb模式下输入”b 11“即可。 而”c“则表示一直执行程序，直到遇到下一个断点。 当然，除了这些常用命令，还有许多其他的命令可以使用，这里我就不在一一赘述了。你可以参考对应的官方文档（https://docs.python.org/3/library/pdb.html#module-pdb），来熟悉这些用法。\n用cProfile进行性能分析 link关于调试的内容，我主要先讲这么多。事实上，除了要对程序进行调试，性能分析也是每个开发者的必备技能。\n日常工作中，我们常常会遇到这样的问题：在线上，我发现产品的某个功能模块效率低下，延迟（latency）高，占用的资源多，但却不知道是哪里出了问题。\n这时，对代码进行profile就显得异常重要了。\n这里所谓的profile，是指对代码的每个部分进行动态的分析，比如准确计算出每个模块消耗的时间等。这样你就可以知道程序的瓶颈所在，从而对其进行修正或优化。当然，这并不需要你花费特别大的力气，在Python中，这些需求用cProfile就可以实现。\n举个例子，比如我想计算斐波拉契数列，运用递归思想，我们很容易就能写出下面这样的代码：\ndef fib(n):\rif n == 0:\rreturn 0\relif n == 1:\rreturn 1\relse:\rreturn fib(n-1) + fib(n-2)\rdef fib_seq(n):\rres = []\rif n \u003e 0:\rres.extend(fib_seq(n-1))\rres.append(fib(n))\rreturn res\rfib_seq(30) 接下来，我想要测试一下这段代码总的效率以及各个部分的效率。那么，我就只需在开头导入cProfile这个模块，并且在最后运行cProfile.run()就可以了：\nimport cProfile\r# def fib(n)\r# def fib_seq(n):\rcProfile.run('fib_seq(30)') 或者更简单一些，直接在运行脚本的命令中，加入选项“-m cProfile”也很方便：\npython3 -m cProfile xxx.py 运行完毕后，我们可以看到下面这个输出界面：\n这里有一些参数你可能比较陌生，我来简单介绍一下：\nncalls，是指相应代码/函数被调用的次数； tottime，是指对应代码/函数总共执行所需要的时间（注意，并不包括它调用的其他代码/函数的执行时间）； tottime percall，就是上述两者相除的结果，也就是tottime / ncalls； cumtime，则是指对应代码/函数总共执行所需要的时间，这里包括了它调用的其他代码/函数的执行时间； cumtime percall，则是cumtime和ncalls相除的平均结果。 了解这些参数后，再来看这张图。我们可以清晰地看到，这段程序执行效率的瓶颈，在于第二行的函数fib()，它被调用了700多万次。\n有没有什么办法可以提高改进呢？答案是肯定的。通过观察，我们发现，程序中有很多对fib()的调用，其实是重复的，那我们就可以用字典来保存计算过的结果，防止重复。改进后的代码如下所示：\ndef memoize(f):\rmemo = {}\rdef helper(x):\rif x not in memo: memo[x] = f(x)\rreturn memo[x]\rreturn helper\r@memoize\rdef fib(n):\rif n == 0:\rreturn 0\relif n == 1:\rreturn 1\relse:\rreturn fib(n-1) + fib(n-2)\rdef fib_seq(n):\rres = []\rif n \u003e 0:\rres.extend(fib_seq(n-1))\rres.append(fib(n))\rreturn res\rfib_seq(30) 这时，我们再对其进行profile，你就会得到新的输出结果，很明显，效率得到了极大的提高。\n这个简单的例子，便是cProfile的基本用法，也是我今天想讲的重点。当然，cProfile还有很多其他功能，还可以结合stats类来使用，你可以阅读相应的 官方文档 来了解。\n总结 link这节课，我们一起学习了Python中常用的调试工具pdb，和经典的性能分析工具cProfile。pdb为Python程序提供了一种通用的、交互式的高效率调试方案；而cProfile则是为开发者提供了每个代码块执行效率的详细分析，有助于我们对程序的优化与提高。\n关于它们的更多用法，你可以通过它们的官方文档进行实践，都不太难，熟能生巧。\n思考题 link最后，留一个开放性的交流问题。你在平时的工作中，常用的调试和性能分析工具是什么呢？有发现什么独到的使用技巧吗？你曾用到过pdb、cProfile或是其他相似的工具吗？\n欢迎在下方留言与我讨论，也欢迎你把这篇文章分享出去。我们一起交流，一起进步。\ndef all_fib(n): global dict1 res =[] for i in range(n + 1): req = fibl(i) dict1[i] = req res.append(req) print(res) all_fib(100000)\n老师用的装饰器很高大上(看了好几遍才搞明白), 但是当数字大于995后会有超过递归深度报错, 所以过来皮一下/狗头2019-08-14JackLee 👍（7） 💬（0）还有一个ipdb是pdb的加强版，用法比较相近，不过需要pip安装一下2019-07-19new 👍（6） 💬（0）老师应该在这里回顾一下装饰器的用法2019-07-22泥土  👍（5） 💬（3）看到memoize装饰器，想起装饰器那节中的LRU_CACHE，发现比memoize性能更高 import functools\n@memoize\n@functools.lru_cache(None) linkdef fib(n): …2020-03-24lipan 👍（5） 💬（1）最近在用js撸小程序，一个console.log()搞定所有调试。2019-07-19未来已来 👍（4） 💬（1）被最后那个装饰器惊艳到了，以前只知道用循环，没想到 Python 还可以这么玩2019-07-19向南 👍（3） 💬（0）有时候会用装饰器试一下 def timeit_wrapper(func): @wraps(func) def wrapper(*args, **kwargs): start_time = time.perf_counter() func_return_value = func(*args, **kwargs) end_time = time.perf_counter() print('{0:\u003c10}.{1:\u003c8} : {2:\u003c8}'.format(func.module, func.name, end_time - start_time)) return func_return_value return wrapper\n@timeit_wrapper def some_func(): ….2020-03-11一一 👍（3） 💬（0）cProfile真的太好用了2020-01-31\n"
            }
        );
    index.add(
            {
                id:  41 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/32---%E7%AD%94%E7%96%91%E4%B8%89%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F\/",
                title: "答疑（三）：如何选择合适的异常处理方式？",
                description: "你好，我是景霄。\n不知不觉中，我们又一起完成了第三大章规范篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：应该使用哪种异常处理方式？ link 第一个问题是code2同学的疑惑。下面这两种处理的风格，哪一种风格更有效、更优雅？\n第一种，在代码中对数据进行检测，并直接处理与抛出异常。 第二种，在异常处理代码中进行处理。 其实，第一种方法，可以翻译成下面的“if…elif…”语句：\nif [condition1]:\rraise Exception1('exception 1')\relif [condition2]:\rraise Exception2('exception 2')\r... 而第二种方法，则对应着下面异常处理的代码：\ntry:\r...\rexcept Exception as e:\r... 这两种方法很大的一个区别是，第一种方法一旦抛出异常，那么程序就会终止；而在第二种方法中，如果抛出异常，会被程序捕获（catch），程序还会继续运行。这也是我们选择这两种方法的重要依据。当然，在实际工作中，到底使用哪一种方法，还是取决于具体的场景。\n比方说，一个模块的功能是对输入进行检测，如果输入不合法，则弹出对话框进行提示，并终止程序。那么，这种情况下，使用第一种方法更加合理。\n但是，如果换成一个产品的服务器端，它需要应对各种可能发生的情况，以保证服务器不崩溃。比如在连接数据库时，如果网络异常，无法连接，那就需要捕获（catch）这个异常（exception），进行记录，并同时保证其他功能不受影响。这种情况下，我们通常会选择第二种方式。\n问题二：先写出能跑起来的代码，后期再优化可以吗？ link 第二个问题，夜路破晓同学提到了很多程序员传授的“经验之谈”，即先写出能跑起来的代码，后期再优化。很明显，这种认知是错误的。我们从一开始写代码时，就必须对功能和规范这两者双管齐下。\n代码功能完整和规范完整的优先级是不分先后的，应该是同时进行的。如果你一开始只注重代码的功能完整，而不关注其质量、规范，那么规范问题很容易越积越多。这样就会导致产品的bug越来越多，相应的代码库越发难以维护，到最后不得已只能推倒重来。\n我在Facebook工作时就遇到过这样的情况，参与过类似的项目。当时，某些功能模块因为赶时间，code review很宽松，代码写得很不规范，留下了隐患。时间一长，bug越来越多，legacy越来越多。到最后，万分无奈的情况下，我们几个工程师专门立项，花了三个多月时间，重写了这一模块的代码，才解决了这个问题。\n问题三：代码中写多少注释才合适？ link 第三个问题，小侠龙旋风同学留言说，自己的同事要求代码中有70%的注释，这显然有点过了。但是反过来说，如果你的代码中没有注释或者注释很少，仅凭规范的变量名肯定是远远不够的。\n通常来说，我们会在类的开头、函数的开头或者是某一个功能块的开头加上一段描述性的注释，来说明这段代码的功能，并指明所有的输入和输出。除此之外，我们也要求在一些比较tricky的代码上方加上注释，帮助阅读者理解代码的含义。\n总的来说，代码中到底需要有多少注释，其实并没有一个统一的要求，还是要根据代码量和代码的复杂度来决定。不过，我们平常书写时，只要满足这样的规范就可以了。\n另外，必须提醒一点，如果在写好之后修改了代码，那么代码对应的注释一定也要做出相应的修改，不然很容易造成“文不对题”的现象，给别人也给你自己带来困扰。\n问题四：项目的API文档重要吗？ link 第四个问题，是未来已来同学的留言。他提到了项目的API文档的问题，这一点说得非常好，在这里我也简单介绍一下。\n我在专栏中主要讲的是代码的规范问题，但很多情况下，光有规范的代码还是远远不够的。因为一个系统，一个产品，甚至一个功能模块的代码，都有可能非常复杂。少则几千行，动辄几十万行，尤其是对于刚加入的新人来说，在ramp up阶段光看代码可能就是一个噩梦了。\n因此，在这方面做得比较规范的公司，通常也会要求书写文档。项目的文档，主要是对相应的系统、产品或是功能模块做一个概述，有助于后人理解。以一个service为例，其对应的文档通常会包括下面几部分：\n第一点，系统的概述，包括各个组成部分以及工作流程的介绍； 第二点，每个组成部分的具体介绍，包括必要性、设计原理等等； 第三点，系统的performance，包括latency等等参数； 第四点主要说明如何对系统的各个部分进行修改，主要给出相应的code pointer及对应的测试方案。 这些内容，也希望屏幕前的你能够牢记。\n今天我主要回答这些问题，同时也欢迎你继续在留言区写下疑问和感想，我会持续不断地解答。希望每一次的留言和答疑，都能给你带来新的收获和价值。\n",
                content: "你好，我是景霄。\n不知不觉中，我们又一起完成了第三大章规范篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n大部分留言，我都在相对应的文章中回复过了。而一些手机上不方便回复，或是很有价值很典型的问题，我专门摘录了出来，作为今天的答疑内容，集中回复。\n问题一：应该使用哪种异常处理方式？ link 第一个问题是code2同学的疑惑。下面这两种处理的风格，哪一种风格更有效、更优雅？\n第一种，在代码中对数据进行检测，并直接处理与抛出异常。 第二种，在异常处理代码中进行处理。 其实，第一种方法，可以翻译成下面的“if…elif…”语句：\nif [condition1]:\rraise Exception1('exception 1')\relif [condition2]:\rraise Exception2('exception 2')\r... 而第二种方法，则对应着下面异常处理的代码：\ntry:\r...\rexcept Exception as e:\r... 这两种方法很大的一个区别是，第一种方法一旦抛出异常，那么程序就会终止；而在第二种方法中，如果抛出异常，会被程序捕获（catch），程序还会继续运行。这也是我们选择这两种方法的重要依据。当然，在实际工作中，到底使用哪一种方法，还是取决于具体的场景。\n比方说，一个模块的功能是对输入进行检测，如果输入不合法，则弹出对话框进行提示，并终止程序。那么，这种情况下，使用第一种方法更加合理。\n但是，如果换成一个产品的服务器端，它需要应对各种可能发生的情况，以保证服务器不崩溃。比如在连接数据库时，如果网络异常，无法连接，那就需要捕获（catch）这个异常（exception），进行记录，并同时保证其他功能不受影响。这种情况下，我们通常会选择第二种方式。\n问题二：先写出能跑起来的代码，后期再优化可以吗？ link 第二个问题，夜路破晓同学提到了很多程序员传授的“经验之谈”，即先写出能跑起来的代码，后期再优化。很明显，这种认知是错误的。我们从一开始写代码时，就必须对功能和规范这两者双管齐下。\n代码功能完整和规范完整的优先级是不分先后的，应该是同时进行的。如果你一开始只注重代码的功能完整，而不关注其质量、规范，那么规范问题很容易越积越多。这样就会导致产品的bug越来越多，相应的代码库越发难以维护，到最后不得已只能推倒重来。\n我在Facebook工作时就遇到过这样的情况，参与过类似的项目。当时，某些功能模块因为赶时间，code review很宽松，代码写得很不规范，留下了隐患。时间一长，bug越来越多，legacy越来越多。到最后，万分无奈的情况下，我们几个工程师专门立项，花了三个多月时间，重写了这一模块的代码，才解决了这个问题。\n问题三：代码中写多少注释才合适？ link 第三个问题，小侠龙旋风同学留言说，自己的同事要求代码中有70%的注释，这显然有点过了。但是反过来说，如果你的代码中没有注释或者注释很少，仅凭规范的变量名肯定是远远不够的。\n通常来说，我们会在类的开头、函数的开头或者是某一个功能块的开头加上一段描述性的注释，来说明这段代码的功能，并指明所有的输入和输出。除此之外，我们也要求在一些比较tricky的代码上方加上注释，帮助阅读者理解代码的含义。\n总的来说，代码中到底需要有多少注释，其实并没有一个统一的要求，还是要根据代码量和代码的复杂度来决定。不过，我们平常书写时，只要满足这样的规范就可以了。\n另外，必须提醒一点，如果在写好之后修改了代码，那么代码对应的注释一定也要做出相应的修改，不然很容易造成“文不对题”的现象，给别人也给你自己带来困扰。\n问题四：项目的API文档重要吗？ link 第四个问题，是未来已来同学的留言。他提到了项目的API文档的问题，这一点说得非常好，在这里我也简单介绍一下。\n我在专栏中主要讲的是代码的规范问题，但很多情况下，光有规范的代码还是远远不够的。因为一个系统，一个产品，甚至一个功能模块的代码，都有可能非常复杂。少则几千行，动辄几十万行，尤其是对于刚加入的新人来说，在ramp up阶段光看代码可能就是一个噩梦了。\n因此，在这方面做得比较规范的公司，通常也会要求书写文档。项目的文档，主要是对相应的系统、产品或是功能模块做一个概述，有助于后人理解。以一个service为例，其对应的文档通常会包括下面几部分：\n第一点，系统的概述，包括各个组成部分以及工作流程的介绍； 第二点，每个组成部分的具体介绍，包括必要性、设计原理等等； 第三点，系统的performance，包括latency等等参数； 第四点主要说明如何对系统的各个部分进行修改，主要给出相应的code pointer及对应的测试方案。 这些内容，也希望屏幕前的你能够牢记。\n今天我主要回答这些问题，同时也欢迎你继续在留言区写下疑问和感想，我会持续不断地解答。希望每一次的留言和答疑，都能给你带来新的收获和价值。\n"
            }
        );
    index.add(
            {
                id:  42 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/33---%E5%B8%A6%E4%BD%A0%E5%88%9D%E6%8E%A2%E9%87%8F%E5%8C%96%E4%B8%96%E7%95%8C\/",
                title: "带你初探量化世界",
                description: "你好，我是景霄。\n在2000 年顶峰时期，高盛雇佣了 600 名交易员为机构客户买卖现金股票。可如今，这个数字只有 2 名（Ref. 经济学人）。到了2009 年，金融危机余音未散，专家面对股票和证券交易中越来越多的机器参与提出了警告，因为机器的崛起，逐渐导致了手操交易工作的消失。\n很久之前，瑞银集团（UBS）的交易大厅是下面这样的：\n8 年之后，交易大厅就已经只有这些人了：\n事实上，随着数据处理技术的飞速发展，和量化交易模型研究理论的逐渐成熟，现金股票交易、债券市场、期货市场以及投行的相当一部分业务，都在朝着自动化的方向迈进。\n而发展到2017 年，WannyCry 席卷全球，随之而来的比特币，在短短几个月内从小众玩家走入了公众视野，币价也是一飞冲天，很多炒币的人赚得盆满钵满。更有一部分人，将金融业的量化策略应用其中，无论是搬砖（套利），还是波段，在不成熟的市场初期都赚了个爽快。\n这节课开始，我们就来探索一下量化的世界。作为我们 Python 专栏的综合实践模块，希望你能在这一部分内容中，收获自己独特的东西。\n交易是什么？ link市场，是人类有史以来最伟大的发明之一。亚当·斯密在国富论中，用“看不见的手”这个概念，生动形象地阐释了市场和理性人之间是如何交互，最终让整个社会受益的。\n而市场的核心，是交换。人类发展最开始是物物交换，原始的“以物易物”的方式产生于货币诞生之前。不过，这种方式非常低效，不便于流通交换，经常会出现的情况是，要走很长的交换链条才能拿到自己想要的物品。于是，一般等价物出现了，社会分工也逐渐出现了。人们把自己生产的商品换成一般等价物，然后再换成自己需要的其他商品。\n而交换的核心，就是买和卖。当买卖双方对价格预期相等的时候，交易达成。随着金融和技术的发展，逐渐出现了股票、债券、期权、期货等越来越多的金融工具，金融衍生品也朝着复杂的方向发展。\n在我们经常听到的投资银行中，量化基金交易员这种角色，所做的事情，就是在这些复杂的衍生品基础上，分析投资标的的价值，然后以某种策略来管理持有仓位，进行买进和卖出。\n为什么交易能赚钱，是很多人疑惑不解的地方。市场究竟有没有规律可循呢？可以肯定是有的，但虽有迹可循却无法可依。交易的多样性和人性的复杂性，使得金融数据的噪音极大，我们无法简单地从某一两个因子来确定地推导行情变化。\n所以交易员这个行业本身，对自身素质要求是极高的。除了要具备扎实的专业素养（包括金融功底、数理逻辑、分析能力、决策能力），对心理素质的要求也非常高。这种直接和钱打交道、并直面人性深处欲望的行业，也因此吸引了无数高手的参与，很多人因此暴富，也有不少人破产，一无所有。\n那么，有什么办法可以规避这种，因为心理素质原因带来的风险呢？\n量化交易 link回答这个问题之前，我先插一句题外话。刚接触量化交易的朋友，都很容易被这几个词绕晕：量化交易（Quantitative Trading）、程序化交易（Program Trading）、算法交易（Algo-Trading）、高频交易（High Frequency Trading）和自动化交易平台（Automated Trading System）。\n虽然我遇到过不少行业内的人也混用这词，但是作为初学者来说，厘清这些术语还是很有帮助的。至少，在别人说出这些高大上的词时，我们心里不用犯怵了。\n先来看程序化交易，它通常用计算机程序代替交易员，来具体执行金融产品的买卖。比如，一个基金经理需要卖出大量股票。如果直接挂一个大的卖单，可能会影响市场，那就用计算机程序拆分成小单慢慢执行。所以，量化交易的下层通常是程序交易。\n而算法交易通常用于高频交易中。它指的是，通过算法快速判定买卖的时间点，快速买卖多个产品。\n量化交易则通常是指使用数学、统计甚至机器学习的方法，去找寻合适的买卖时机。所以，在这个维度的定义之下，算法交易、高频交易还有统计套利（Statistical Arbitrage）都可以算作量化交易。\n简单而言，我们可以认为量化交易的涵盖范围最大。因此，当你不确定用哪个词的时候，用量化交易就行了。\n回到我们刚刚的问题，规避心理素质原因带来的风险的方法，自然就是量化交易了。量化交易的好处显而易见。最直观来看，计算机不眠不休，不需要交易员实时操盘，满足了人们“躺着挣钱”的愿景。当然，这只是美好的想象，真要这么做的话，不久之后就要回工地搬砖了。现实场景中，成熟的量化交易也需要有人蹲守，适时干预，防止算法突然失效造成巨额的交易亏损。\n在数字货币领域的交易，这一点更加显著。数字货币的交易在全球许多交易所进行，和股票不同，一支股票可能只在少数几个交易所交易，而一种数字货币可以在所有的交易所同时进行交易。同时，因为没有股市的开盘、收盘限制，数字货币的交易通常是 7 x 24 小时不眠不休，比前世的 “996 福报”凶残多了。要是真有交易员能在这个市场活下来，我们尊称一声“神仙”也不为过了。\n多交易所交易，也意味着全球数字货币市场每时每刻都是紧密相连的。一个市场、一个局部的巨大变动，都会影响所有的市场。比如，2017年朝鲜氢弹炸了的当天，新闻还没出来，隔壁韩国、日本的比特币价格马上拉升了一波；再比如，当比特币的负面消息半夜里传出来的时候，其价格也马上跟着暴跌一波。\n2019年6月比特币在全球头部交易所的价格\n因此，我们经常看到比特币的价格波动巨大。很有可能今天还是财富自由状态，明天的财富就没那么自由了。显然，在这种市场中交易，人力很难持久支撑，而量化交易就很合适了。\n通常的电子盘交易（比如股票，数字货币），是通过券商或者软件，直接把买卖请求发送给交易所；而算法交易的底层，就是让程序来自动实现这类操作。券商或者交易所，通常也会提供API接口给投资者。比如，盈透证券（Interactive Broker）的接口，就可以支持股票、期权的行情数据获取和交易；而 Gemini、OKCoin等交易所，也提供了对应的接口进行数字货币行情获取和交易。\nGemini交易所的公开行情API，就可以通过下面这种简单的HTTP GET请求，来获取最近的比特币（BTC）对美元（USD）的价格和最近的成交量。\n",
                content: "你好，我是景霄。\n在2000 年顶峰时期，高盛雇佣了 600 名交易员为机构客户买卖现金股票。可如今，这个数字只有 2 名（Ref. 经济学人）。到了2009 年，金融危机余音未散，专家面对股票和证券交易中越来越多的机器参与提出了警告，因为机器的崛起，逐渐导致了手操交易工作的消失。\n很久之前，瑞银集团（UBS）的交易大厅是下面这样的：\n8 年之后，交易大厅就已经只有这些人了：\n事实上，随着数据处理技术的飞速发展，和量化交易模型研究理论的逐渐成熟，现金股票交易、债券市场、期货市场以及投行的相当一部分业务，都在朝着自动化的方向迈进。\n而发展到2017 年，WannyCry 席卷全球，随之而来的比特币，在短短几个月内从小众玩家走入了公众视野，币价也是一飞冲天，很多炒币的人赚得盆满钵满。更有一部分人，将金融业的量化策略应用其中，无论是搬砖（套利），还是波段，在不成熟的市场初期都赚了个爽快。\n这节课开始，我们就来探索一下量化的世界。作为我们 Python 专栏的综合实践模块，希望你能在这一部分内容中，收获自己独特的东西。\n交易是什么？ link市场，是人类有史以来最伟大的发明之一。亚当·斯密在国富论中，用“看不见的手”这个概念，生动形象地阐释了市场和理性人之间是如何交互，最终让整个社会受益的。\n而市场的核心，是交换。人类发展最开始是物物交换，原始的“以物易物”的方式产生于货币诞生之前。不过，这种方式非常低效，不便于流通交换，经常会出现的情况是，要走很长的交换链条才能拿到自己想要的物品。于是，一般等价物出现了，社会分工也逐渐出现了。人们把自己生产的商品换成一般等价物，然后再换成自己需要的其他商品。\n而交换的核心，就是买和卖。当买卖双方对价格预期相等的时候，交易达成。随着金融和技术的发展，逐渐出现了股票、债券、期权、期货等越来越多的金融工具，金融衍生品也朝着复杂的方向发展。\n在我们经常听到的投资银行中，量化基金交易员这种角色，所做的事情，就是在这些复杂的衍生品基础上，分析投资标的的价值，然后以某种策略来管理持有仓位，进行买进和卖出。\n为什么交易能赚钱，是很多人疑惑不解的地方。市场究竟有没有规律可循呢？可以肯定是有的，但虽有迹可循却无法可依。交易的多样性和人性的复杂性，使得金融数据的噪音极大，我们无法简单地从某一两个因子来确定地推导行情变化。\n所以交易员这个行业本身，对自身素质要求是极高的。除了要具备扎实的专业素养（包括金融功底、数理逻辑、分析能力、决策能力），对心理素质的要求也非常高。这种直接和钱打交道、并直面人性深处欲望的行业，也因此吸引了无数高手的参与，很多人因此暴富，也有不少人破产，一无所有。\n那么，有什么办法可以规避这种，因为心理素质原因带来的风险呢？\n量化交易 link回答这个问题之前，我先插一句题外话。刚接触量化交易的朋友，都很容易被这几个词绕晕：量化交易（Quantitative Trading）、程序化交易（Program Trading）、算法交易（Algo-Trading）、高频交易（High Frequency Trading）和自动化交易平台（Automated Trading System）。\n虽然我遇到过不少行业内的人也混用这词，但是作为初学者来说，厘清这些术语还是很有帮助的。至少，在别人说出这些高大上的词时，我们心里不用犯怵了。\n先来看程序化交易，它通常用计算机程序代替交易员，来具体执行金融产品的买卖。比如，一个基金经理需要卖出大量股票。如果直接挂一个大的卖单，可能会影响市场，那就用计算机程序拆分成小单慢慢执行。所以，量化交易的下层通常是程序交易。\n而算法交易通常用于高频交易中。它指的是，通过算法快速判定买卖的时间点，快速买卖多个产品。\n量化交易则通常是指使用数学、统计甚至机器学习的方法，去找寻合适的买卖时机。所以，在这个维度的定义之下，算法交易、高频交易还有统计套利（Statistical Arbitrage）都可以算作量化交易。\n简单而言，我们可以认为量化交易的涵盖范围最大。因此，当你不确定用哪个词的时候，用量化交易就行了。\n回到我们刚刚的问题，规避心理素质原因带来的风险的方法，自然就是量化交易了。量化交易的好处显而易见。最直观来看，计算机不眠不休，不需要交易员实时操盘，满足了人们“躺着挣钱”的愿景。当然，这只是美好的想象，真要这么做的话，不久之后就要回工地搬砖了。现实场景中，成熟的量化交易也需要有人蹲守，适时干预，防止算法突然失效造成巨额的交易亏损。\n在数字货币领域的交易，这一点更加显著。数字货币的交易在全球许多交易所进行，和股票不同，一支股票可能只在少数几个交易所交易，而一种数字货币可以在所有的交易所同时进行交易。同时，因为没有股市的开盘、收盘限制，数字货币的交易通常是 7 x 24 小时不眠不休，比前世的 “996 福报”凶残多了。要是真有交易员能在这个市场活下来，我们尊称一声“神仙”也不为过了。\n多交易所交易，也意味着全球数字货币市场每时每刻都是紧密相连的。一个市场、一个局部的巨大变动，都会影响所有的市场。比如，2017年朝鲜氢弹炸了的当天，新闻还没出来，隔壁韩国、日本的比特币价格马上拉升了一波；再比如，当比特币的负面消息半夜里传出来的时候，其价格也马上跟着暴跌一波。\n2019年6月比特币在全球头部交易所的价格\n因此，我们经常看到比特币的价格波动巨大。很有可能今天还是财富自由状态，明天的财富就没那么自由了。显然，在这种市场中交易，人力很难持久支撑，而量化交易就很合适了。\n通常的电子盘交易（比如股票，数字货币），是通过券商或者软件，直接把买卖请求发送给交易所；而算法交易的底层，就是让程序来自动实现这类操作。券商或者交易所，通常也会提供API接口给投资者。比如，盈透证券（Interactive Broker）的接口，就可以支持股票、期权的行情数据获取和交易；而 Gemini、OKCoin等交易所，也提供了对应的接口进行数字货币行情获取和交易。\nGemini交易所的公开行情API，就可以通过下面这种简单的HTTP GET请求，来获取最近的比特币（BTC）对美元（USD）的价格和最近的成交量。\n########## GEMINI行情接口 ##########\r## https://api.gemini.com/v1/pubticker/:symbol\rimport json\rimport requests\rgemini_ticker = 'https://api.gemini.com/v1/pubticker/{}'\rsymbol = 'btcusd'\rbtc_data = requests.get(gemini_ticker.format(symbol)).json()\rprint(json.dumps(btc_data, indent=4))\r########## 输出 ##########\r{\r\"bid\": \"8825.88\",\r\"ask\": \"8827.52\",\r\"volume\": {\r\"BTC\": \"910.0838782726\",\r\"USD\": \"7972904.560901317851\",\r\"timestamp\": 1560643800000\r},\r\"last\": \"8838.45\"\r} 对算法交易系统来说，API只是最下层的结构。通常而言，一个基本的交易系统应该包括：行情模块、策略模块和执行模块。为了辅助策略的开发，通常还有回测系统辅助。它们的分工示意图大致如下：\n其中，\n行情模块的主要功能是，尝试获取市场的行情数据，通常也负责获取交易账户的状态。 策略模块的主要功能是，订阅市场的数据，根据设定的算法发出买、卖指令给执行模块。 执行模块的主要功能是，接受并把策略模块发过来的买、卖指令封装并转发到交易所；同时，监督并确保策略买卖的完整执行。 Python算法交易 link了解了这么多关于量化交易的知识，接下来我们就来说说Python算法交易。Python 在金融行业的许多方面都有用到，在算法交易领域，更是发挥了日益重要的作用。 Python 之所以能在这个行业这么流行，主要是因为下面四个原因。\n数据分析能力 link第一个原因，是Python的数据分析能力。算法交易领域的一个基本需求，就是高效数据处理能力，而数据处理则是Python的强项。特别是NumPy+Pandas的组合，简直让算法交易开发者的生活质量直线上升。\n我们可以用一个简单的例子来展示一下，如何抓取、格式化和绘制，比特币过去一个小时在Gemini交易所的价格曲线。相关的代码我都附了详细注释，这里就不再多讲，你阅读了解一下即可。\nimport matplotlib.pyplot as plt\rimport pandas as pd\rimport requests\r# 选择要获取的数据时间段\rperiods = '3600'\r# 通过Http抓取btc历史价格数据\rresp = requests.get('https://api.cryptowat.ch/markets/gemini/btcusd/ohlc', params={\r'periods': periods\r})\rdata = resp.json()\r# 转换成pandas data frame\rdf = pd.DataFrame(\rdata['result'][periods], columns=[\r'CloseTime',\r'OpenPrice',\r'HighPrice',\r'LowPrice',\r'ClosePrice',\r'Volume',\r'NA'])\r# 输出DataFrame的头部几行\rprint(df.head())\r# 绘制btc价格曲线\rdf['ClosePrice'].plot(figsize=(14, 7))\rplt.show()\r########### 输出 ###############\rCloseTime OpenPrice HighPrice ... ClosePrice Volume NA\r0 1558843200 8030.55 8046.30 ... 8011.20 11.642968 93432.459964\r1 1558846800 8002.76 8050.33 ... 8034.48 8.575682 68870.145895\r2 1558850400 8031.61 8036.14 ... 8000.00 15.659680 125384.519063\r3 1558854000 8000.00 8016.29 ... 8001.46 38.171420 304342.048892\r4 1558857600 8002.69 8023.11 ... 8009.24 3.582830 28716.385009 通过执行这样的一段代码，我们便可以得到下面这张图所示的价格曲线。\n大量专有库 link除了强大的数据处理能力之外，Python 还有许许多多已经开发成熟的算法交易库可供使用。比如，你可以使用Zipline进行策略回测，或者用Pyfolio进行投资组合分析。而许多交易所也都提供了基于Python的API客户端。\n便利的交易平台 link第三个原因，是因为便利的交易平台。有一些算法交易平台可以执行自定义 Python 策略，无需搭建量化交易框架。算法交易平台，实际上等效于帮用户完成了行情模块和执行模块。用户只需要在其中定义策略模块，即可进行算法交易和回测。\n比如，Quantopian，就提供了基于Zipline的标准回测环境。用户可以选择Python作为开发语言，并且和社区的网友分享自己的策略。此外，国内也有诸如BigQuant、果仁网等类似平台，提供不同市场和金融产品的交易。\n广泛的行业应用 link最后一个原因，则是Python本身广泛的行业应用了。目前，越来越多投资机构的交易部门，都开始使用Python，因此也对优秀的Python开发者产生了更多的需求。自然，这也让学习Python，成为了更有意义的“投资”。\n总结 link这一节课，我们介绍了交易，以及算法交易中的基本概念，也简单介绍了为什么要学习 Python 来搭建量化交易系统。量化交易是交易行业的大趋势；同时， Python 作为最适合量化从业者的语言之一，对于初学者而言也有着非常重要的地位。\n接下来的几节课，我们将从细节深入量化交易的每一个模块，由浅入深地为你揭开量化交易神秘的面纱。\n思考题 link最后给你留一道思考题。高频交易和中低频交易，哪个更适合使用 Python？为什么？欢迎在留言区写下你的想法，也欢迎你把这篇文章分享给更多对量化交易感兴趣的人，我们一起交流和探讨。\n"
            }
        );
    index.add(
            {
                id:  43 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/34---restful--socket%E6%90%AD%E5%BB%BA%E4%BA%A4%E6%98%93%E6%89%A7%E8%A1%8C%E5%B1%82%E6%A0%B8%E5%BF%83\/",
                title: "RESTful \u0026 Socket：搭建交易执行层核心",
                description: "你好，我是景霄。\n上一节，我们简单介绍了量化交易的历史、严谨的定义和它的基本组成结构。有了这些高层次的基本知识，接下来我们就分模块，开始讲解量化交易系统中具体的部分。\n从这节课开始，我们将实打实地从代码出发，一步步设计出一套清晰完整、易于理解的量化交易系统。\n一个量化交易系统，可以说是一个黑箱。这个黑箱连接交易所获取到的数据，通过策略运算，然后再连接交易所进行下单操作。正如我们在输入输出那节课说的那样，黑箱的特性是输入和输出。每一个设计网络交互的同学，都需要在大脑中形成清晰的交互状态图：\n知道包是怎样在网络间传递的； 知道每一个节点是如何处理不同的输入包，然后输出并分发给下一级的。 在你搞不明白的时候，可以先在草稿纸上画出交互拓扑图，标注清楚每个节点的输入和输出格式，然后想清楚网络是怎么流动的。这一点，对网络编程至关重要。\n现在，我假设你对网络编程只有很基本的了解。所以接下来，我将先从 REST 的定义讲起，然后过渡到具体的交互方式——如何通过 Python 和交易所进行交互，从而执行下单、撤单、查询订单等网络交互方式。\nREST 简介 link什么是 REST API？什么是 Socket？有过网络编程经验的同学，一定对这两个词汇不陌生。\nREST的全称是表征层状态转移（REpresentational State Transfer），本意是指一种操作资源方法。不过，你不用纠结于这个绕口的名字。换种方式来说，REST的实质可以理解为：通过URL定位资源，用GET、POST、PUT、DELETE等动词来描述操作。而满足REST要求的接口，就被称为RESTful的接口。\n为了方便你更容易理解这些概念，这里我举个例子来类比。小明同学不是很聪明但很懂事，每天会在他的妈妈下班回来后给妈妈泡茶。刚开始，他的妈妈会发出这样的要求：\n用红色杯子，去厨房泡一杯放了糖的37.5度的普洱茶。\n可是小明同学不够聪明，很难理解这个定语很多的句子。于是，他妈妈为了让他更简单明白需要做的事情，把这个指令设计成了更简洁的样子：\n泡厨房的茶，要求如下：\n类型=普洱； 杯子=红色； 放糖=True； 温度=37.5度。 这里的“茶”就是资源，“厨房的茶”就是资源的地址（URI）；“泡”是动词；后面的要求，都是接口参数。这样的一个接口，就是小明提供的一个REST接口。\n如果小明是一台机器，那么解析这个请求就会非常容易；而我们作为维护者，查看小明的代码也很简单。当小明把这个接口暴露到网上时，这就是一个RESTful的接口。\n总的来说，RESTful接口通常以HTTP GET和POST形式出现。但并非所有的GET、POST请求接口，都是RESTful的接口。\n这话可能有些拗口，我们举个例子来看。上节课中，我们获取了Gemini交易所中，BTC对USD价格的ticker接口：\nGET https://api.gemini.com/v1/pubticker/btcusd 这里的“GET”是动词，后边的URI是“Ticker”这个资源的地址。所以，这是一个RESTful的接口。\n但下面这样的接口，就不是一个严格的RESTful接口：\nPOST https://api.restful.cn/accounts/delete/:username 因为URI中包含动词“delete”（删除），所以这个URI并不是指向一个资源。如果要修改成严格的RESTful接口，我们可以把它改成下面这样：\nDELETE https://api.rest.cn/accounts/:username 然后，我们带着这个观念去看Gemini的取消订单接口：\nPOST https://api.gemini.com/v1/order/cancel 你会发现，这个接口不够“RESTful”的地方有：\n动词设计不准确，接口使用“POST”而不是重用HTTP动词“DELETE”； URI里包含动词cancel； ID代表的订单是资源，但订单ID是放在参数列表而不是URI里的，因此URI并没有指向资源。 所以严格来说，这不是一个RESTful的接口。\n此外，如果我们去检查Gemini的其他私有接口（Private，私有接口是指需要附加身份验证信息才能访问的接口），我们会发现，那些接口的设计都不是严格RESTful的。不仅如此，大部分的交易所，比如Bitmex、Bitfinex、OKCoin等等，它们提供的“REST接口”，也都不是严格RESTful的。这些接口之所以还能被称为“REST接口”，是因为他们大部分满足了REST接口的另一个重要要求：无状态。\n无状态的意思是，每个REST请求都是独立的，不需要服务器在会话（Session）中缓存中间状态来完成这个请求。简单来说，如果服务器A接收到请求的时候宕机了，而此时把这个请求发送给交易所的服务器B，也能继续完成，那么这个接口就是无状态的。\n这里，我再给你举一个简单的有状态的接口的例子。服务器要求，在客户端请求取消订单的时候，必须发送两次不一样的HTTP请求。并且，第一次发送让服务器“等待取消”；第二次发送“确认取消”。那么，就算这个接口满足了RESTful的动词、资源分离原则，也不是一个REST接口。\n当然，对于交易所的REST接口，你并不需要过于纠结“RESTful”这个概念，否则很容易就被这些名词给绕晕了。你只需要把握住最核心的一点：一个HTTP请求完成一次完整操作。\n交易所 API 简介 link现在，你对 REST 和 Web Socket 应该有一个大致了解了吧。接下来，我们就开始做点有意思的事情。\n",
                content: "你好，我是景霄。\n上一节，我们简单介绍了量化交易的历史、严谨的定义和它的基本组成结构。有了这些高层次的基本知识，接下来我们就分模块，开始讲解量化交易系统中具体的部分。\n从这节课开始，我们将实打实地从代码出发，一步步设计出一套清晰完整、易于理解的量化交易系统。\n一个量化交易系统，可以说是一个黑箱。这个黑箱连接交易所获取到的数据，通过策略运算，然后再连接交易所进行下单操作。正如我们在输入输出那节课说的那样，黑箱的特性是输入和输出。每一个设计网络交互的同学，都需要在大脑中形成清晰的交互状态图：\n知道包是怎样在网络间传递的； 知道每一个节点是如何处理不同的输入包，然后输出并分发给下一级的。 在你搞不明白的时候，可以先在草稿纸上画出交互拓扑图，标注清楚每个节点的输入和输出格式，然后想清楚网络是怎么流动的。这一点，对网络编程至关重要。\n现在，我假设你对网络编程只有很基本的了解。所以接下来，我将先从 REST 的定义讲起，然后过渡到具体的交互方式——如何通过 Python 和交易所进行交互，从而执行下单、撤单、查询订单等网络交互方式。\nREST 简介 link什么是 REST API？什么是 Socket？有过网络编程经验的同学，一定对这两个词汇不陌生。\nREST的全称是表征层状态转移（REpresentational State Transfer），本意是指一种操作资源方法。不过，你不用纠结于这个绕口的名字。换种方式来说，REST的实质可以理解为：通过URL定位资源，用GET、POST、PUT、DELETE等动词来描述操作。而满足REST要求的接口，就被称为RESTful的接口。\n为了方便你更容易理解这些概念，这里我举个例子来类比。小明同学不是很聪明但很懂事，每天会在他的妈妈下班回来后给妈妈泡茶。刚开始，他的妈妈会发出这样的要求：\n用红色杯子，去厨房泡一杯放了糖的37.5度的普洱茶。\n可是小明同学不够聪明，很难理解这个定语很多的句子。于是，他妈妈为了让他更简单明白需要做的事情，把这个指令设计成了更简洁的样子：\n泡厨房的茶，要求如下：\n类型=普洱； 杯子=红色； 放糖=True； 温度=37.5度。 这里的“茶”就是资源，“厨房的茶”就是资源的地址（URI）；“泡”是动词；后面的要求，都是接口参数。这样的一个接口，就是小明提供的一个REST接口。\n如果小明是一台机器，那么解析这个请求就会非常容易；而我们作为维护者，查看小明的代码也很简单。当小明把这个接口暴露到网上时，这就是一个RESTful的接口。\n总的来说，RESTful接口通常以HTTP GET和POST形式出现。但并非所有的GET、POST请求接口，都是RESTful的接口。\n这话可能有些拗口，我们举个例子来看。上节课中，我们获取了Gemini交易所中，BTC对USD价格的ticker接口：\nGET https://api.gemini.com/v1/pubticker/btcusd 这里的“GET”是动词，后边的URI是“Ticker”这个资源的地址。所以，这是一个RESTful的接口。\n但下面这样的接口，就不是一个严格的RESTful接口：\nPOST https://api.restful.cn/accounts/delete/:username 因为URI中包含动词“delete”（删除），所以这个URI并不是指向一个资源。如果要修改成严格的RESTful接口，我们可以把它改成下面这样：\nDELETE https://api.rest.cn/accounts/:username 然后，我们带着这个观念去看Gemini的取消订单接口：\nPOST https://api.gemini.com/v1/order/cancel 你会发现，这个接口不够“RESTful”的地方有：\n动词设计不准确，接口使用“POST”而不是重用HTTP动词“DELETE”； URI里包含动词cancel； ID代表的订单是资源，但订单ID是放在参数列表而不是URI里的，因此URI并没有指向资源。 所以严格来说，这不是一个RESTful的接口。\n此外，如果我们去检查Gemini的其他私有接口（Private，私有接口是指需要附加身份验证信息才能访问的接口），我们会发现，那些接口的设计都不是严格RESTful的。不仅如此，大部分的交易所，比如Bitmex、Bitfinex、OKCoin等等，它们提供的“REST接口”，也都不是严格RESTful的。这些接口之所以还能被称为“REST接口”，是因为他们大部分满足了REST接口的另一个重要要求：无状态。\n无状态的意思是，每个REST请求都是独立的，不需要服务器在会话（Session）中缓存中间状态来完成这个请求。简单来说，如果服务器A接收到请求的时候宕机了，而此时把这个请求发送给交易所的服务器B，也能继续完成，那么这个接口就是无状态的。\n这里，我再给你举一个简单的有状态的接口的例子。服务器要求，在客户端请求取消订单的时候，必须发送两次不一样的HTTP请求。并且，第一次发送让服务器“等待取消”；第二次发送“确认取消”。那么，就算这个接口满足了RESTful的动词、资源分离原则，也不是一个REST接口。\n当然，对于交易所的REST接口，你并不需要过于纠结“RESTful”这个概念，否则很容易就被这些名词给绕晕了。你只需要把握住最核心的一点：一个HTTP请求完成一次完整操作。\n交易所 API 简介 link现在，你对 REST 和 Web Socket 应该有一个大致了解了吧。接下来，我们就开始做点有意思的事情。\n首先，我来介绍一下交易所是什么。区块链交易所是个撮合交易平台： 它兼容了传统撮合规则撮合引擎，将资金托管和交割方式替换为区块链。数字资产交易所，则是一个中心化的平台，通过 Web 页面或 PC、手机客户端的形式，让用户将数字资产充值到指定钱包地址（交易所创建的钱包），然后在平台挂买单、卖单以实现数字资产之间的兑换。\n通俗来说，交易所就是一个买和卖的菜市场。有人在摊位上大声喊着：“二斤羊肉啊，二斤羊肉，四斤牛肉来换！”这种人被称为 maker（挂单者）。有的人则游走于不同摊位，不动声色地掏出两斤牛肉，顺手拿走一斤羊肉。这种人被称为 taker（吃单者）。\n交易所存在的意义，一方面是为 maker 和 taker 提供足够的空间活动；另一方面，让一个名叫撮合引擎的玩意儿，尽可能地把单子撮合在一起，然后收取一定比例的保护费…啊不对，是手续费，从而保障游戏继续进行下去。\n市场显然是个很伟大的发明，这里我们就不进行更深入的哲学讨论了。\n然后，我再来介绍一个叫作 Gemini 的交易所。Gemini，双子星交易所，全球首个获得合法经营许可的、首个推出期货合约的、专注于撮合大宗交易的数字货币交易所。Gemini 位于纽约，是一家数字货币交易所和托管机构，允许客户交易和存储数字资产，并直接受纽约州金融服务部门（NYDFS）的监管。\nGemini 的界面清晰，API 完整而易用，更重要的是，还提供了完整的测试网络，也就是说，功能和正常的 Gemini 完全一样。但是他家的交易采用虚拟币，非常方便从业者在平台上进行对接测试。\n另一个做得很好的交易所，是 Bitmex，他家的 API UI 界面和测试网络也是币圈一流。不过，鉴于这家是期货交易所，对于量化初学者来说有一定的门槛，我们还是选择 Gemini 更方便一些。\n在进入正题之前，我们最后再以比特币和美元之间的交易为例，介绍四个基本概念（orderbook 的概念这里就不介绍了，你也不用深究，你只需要知道比特币的价格是什么就行了）。\n买（buy）：用美元买入比特币的行为。 卖（sell）：用比特币换取美元的行为。 市价单（market order）：给交易所一个方向（买或者卖）和一个数量，交易所把给定数量的美元（或者比特币）换成比特币（或者美元）的单子。 限价单（limit order）：给交易所一个价格、一个方向（买或者卖）和一个数量，交易所在价格达到给定价格的时候，把给定数量的美元（或者比特币）换成比特币（或者美元）的单子。 这几个概念都不难懂。其中，市价单和限价单，最大的区别在于，限价单多了一个给定价格。如何理解这一点呢？我们可以来看下面这个例子。\n小明在某一天中午12:00:00，告诉交易所，我要用1000美元买比特币。交易所收到消息，在 12:00:01 回复小明，现在你的账户多了 0.099 个比特币，少了 1000 美元，交易成功。这是一个市价买单。\n而小强在某一天中午 11:59:00，告诉交易所，我要挂一个单子，数量为 0.1 比特币，1个比特币的价格为 10000 美元，低于这个价格不卖。交易所收到消息，在11:59:01 告诉小强，挂单成功，你的账户余额中 0.1 比特币的资金被冻结。又过了一分钟，交易所告诉小强，你的单子被完全执行了（fully executed），现在你的账户多了 1000 美元，少了 0.1 个比特币。这就是一个限价卖单。\n（这里肯定有人发现不对了：貌似少了一部分比特币，到底去哪儿了呢？嘿嘿，你不妨自己猜猜看。）\n显然，市价单，在交给交易所后，会立刻得到执行，当然执行价格也并不受你的控制。它很快，但是也非常不安全。而限价单，则限定了交易价格和数量，安全性相对高很多。缺点呢，自然就是如果市场朝相反方向走，你挂的单子可能没有任何人去接，也就变成了干吆喝却没人买。因为我没有讲解 orderbook，所以这里的说辞不完全严谨，但是对于初学者理解今天的内容，已经够用了。\n储备了这么久的基础知识，想必你已经跃跃欲试了吧？下面，我们正式进入正题，手把手教你使用API下单。\n手把手教你使用 API 下单 link手动挂单显然太慢，也不符合量化交易的初衷。我们就来看看如何用代码实现自动化下单吧。\n第一步，你需要做的是，注册一个 Gemini Sandbox 账号。请放心，这个测试账号不需要你充值任何金额，注册后即送大量虚拟现金。这口吻是不是听着特像网游宣传语，接下来就是“快来贪玩蓝月里找我吧”？哈哈，不过这个设定确实如此，所以赶紧来注册一个吧。\n注册后，为了满足好奇，你可以先尝试着使用 Web 界面自行下单。不过，事实上，未解锁的情况下是无法正常下单的，因此这样尝试并没啥太大意义。\n所以第二步，我们需要来配置 API Key。菜单栏User Settings-\u003eAPI Settings，然后点 GENERATE A NEW ACCOUNT API KEY，记下 Key 和 Secret 这两串字符。因为窗口一旦消失，这两个信息就再也找不到了，需要你重新生成。\n配置到此结束。接下来，我们来看具体实现。\n先强调一点，在量化系统开发的时候，你的心中一定要有清晰的数据流图。下单逻辑是一个很简单的 RESTful 的过程，和你在网页操作的一样，构造你的请求订单、加密请求，然后 POST 给 gemini 交易所即可。\n不过，因为涉及到的知识点较多，带你一步一步从零来写代码显然不太现实。所以，我们采用“先读懂后记忆并使用”的方法来学，下面即为这段代码：\nimport requests\rimport json\rimport base64\rimport hmac\rimport hashlib\rimport datetime\rimport time\rbase_url = \"https://api.sandbox.gemini.com\"\rendpoint = \"/v1/order/new\"\rurl = base_url + endpoint\rgemini_api_key = \"account-zmidXEwP72yLSSybXVvn\"\rgemini_api_secret = \"375b97HfE7E4tL8YaP3SJ239Pky9\".encode()\rt = datetime.datetime.now()\rpayload_nonce = str(int(time.mktime(t.timetuple())*1000))\rpayload = {\r\"request\": \"/v1/order/new\",\r\"nonce\": payload_nonce,\r\"symbol\": \"btcusd\",\r\"amount\": \"5\",\r\"price\": \"3633.00\",\r\"side\": \"buy\",\r\"type\": \"exchange limit\",\r\"options\": [\"maker-or-cancel\"]\r}\rencoded_payload = json.dumps(payload).encode()\rb64 = base64.b64encode(encoded_payload)\rsignature = hmac.new(gemini_api_secret, b64, hashlib.sha384).hexdigest()\rrequest_headers = {\r'Content-Type': \"text/plain\",\r'Content-Length': \"0\",\r'X-GEMINI-APIKEY': gemini_api_key,\r'X-GEMINI-PAYLOAD': b64,\r'X-GEMINI-SIGNATURE': signature,\r'Cache-Control': \"no-cache\"\r}\rresponse = requests.post(url,\rdata=None,\rheaders=request_headers)\rnew_order = response.json()\rprint(new_order)\r########## 输出 ##########\r{'order_id': '239088767', 'id': '239088767', 'symbol': 'btcusd', 'exchange': 'gemini', 'avg_execution_price': '0.00', 'side': 'buy', 'type': 'exchange limit', 'timestamp': '1561956976', 'timestampms': 1561956976535, 'is_live': True, 'is_cancelled': False, 'is_hidden': False, 'was_forced': False, 'executed_amount': '0', 'remaining_amount': '5', 'options': ['maker-or-cancel'], 'price': '3633.00', 'original_amount': '5'} 我们来深入看一下这段代码。\nRESTful 的 POST 请求，通过 requests.post 来实现。post 接受三个参数，url、data 和 headers。\n这里的 url 等价于 https://api.sandbox.gemini.com/v1/order/new，但是在代码中分两部分写。第一部分是交易所 API 地址；第二部分，以斜杠开头，用来表示统一的 API endpoint。我们也可以在其他交易所的 API 中看到类似的写法，两者连接在一起，就构成了最终的 url。\n而接下来大段命令的目的，是为了构造 request_headers。\n这里我简单说一下 HTTP request，这是互联网中基于 TCP 的基础协议。HTTP 协议是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，用于从万维网（WWW:World Wide Web）服务器传输超文本到本地浏览器的传送协议。而 TCP（Transmission Control Protocol）则是面向连接的、可靠的、基于字节流的传输层通信协议。\n多提一句，如果你开发网络程序，建议利用闲暇时间认真读一读《计算机网络：自顶向下方法》这本书，它也是国内外计算机专业必修课中广泛采用的课本之一。一边学习，一边应用，对于初学者的能力提升是全面而充分的。\n回到 HTTP，它的主要特点是，连接简单、灵活，可以使用“简单请求，收到回复，然后断开连接”的方式，也是一种无状态的协议，因此充分符合 RESTful 的思想。\nHTTP 发送需要一个请求头（request header），也就是代码中的 request_headers，用 Python 的语言表示，就是一个 str 对 str 的字典。\n这个字典里，有一些字段有特殊用途， 'Content-Type': \"text/plain\" 和 'Content-Length': \"0\" 描述 Content 的类型和长度，这里的 Content 对应于参数 data。但是 Gemini 这里的 request 的 data 没有任何用处，因此长度为 0。\n还有一些其他字段，例如 'keep-alive' 来表示连接是否可持续化等，你也可以适当注意一下。要知道，网络编程很多 bug 都会出现在不起眼的细节之处。\n继续往下走看代码。payload 是一个很重要的字典，它用来存储下单操作需要的所有的信息，也就是业务逻辑信息。这里我们可以下一个 limit buy，限价买单，价格为 3633 刀。\n另外，请注意 nonce，这是个很关键并且在网络通信中很常见的字段。\n因为网络通信是不可靠的，一个信息包有可能会丢失，也有可能重复发送，在金融操作中，这两者都会造成很严重的后果。丢包的话，我们重新发送就行了；但是重复的包，我们需要去重。虽然 TCP 在某种程度上可以保证，但为了在应用层面进一步减少错误发生的机会，Gemini 交易所要求所有的通信 payload 必须带有 nonce。\nnonce 是个单调递增的整数。当某个后来的请求的 nonce，比上一个成功收到的请求的 nouce 小或者相等的时候，Gemini 便会拒绝这次请求。这样一来，重复的包就不会被执行两次了。另一方面，这样也可以在一定程度上防止中间人攻击：\n一则是因为 nonce 的加入，使得加密后的同样订单的加密文本完全混乱； 二则是因为，这会使得中间人无法通过“发送同样的包来构造重复订单”进行攻击。 这样的设计思路是不是很巧妙呢？这就相当于每个包都增加了一个身份识别，可以极大地提高安全性。希望你也可以多注意，多思考一下这些巧妙的用法。\n接下来的代码就很清晰了。我们要对 payload 进行 base64 和 sha384 算法非对称加密，其中 gemini_api_secret 为私钥；而交易所存储着公钥，可以对你发送的请求进行解密。最后，代码再将加密后的请求封装到 request_headers 中，发送给交易所，并收到 response，这个订单就完成了。\n总结 link这节课我们介绍了什么是 RESTful API，带你了解了交易所的 RESTful API 是如何工作的，以及如何通过 RESTful API 来下单。同时，我简单讲述了网络编程中的一些技巧操作，希望你在网络编程中要注意思考每一个细节，尽可能在写代码之前，对业务逻辑和具体的技术细节有足够清晰的认识。\n下一节，我们同样将从 Web Socket 的定义开始，讲解量化交易中数据模块的具体实现。\n思考题 link最后留一个思考题。今天的内容里，能不能使用 timestamp 代替 nonce？为什么？欢迎留言写下你的思考，也欢迎你把这篇文章分享出去。\n思考题： 测试了一下timestamp效果，代码如下： import time import datetime current_time = datetime.datetime.now() print(int(datetime.datetime.timestamp(current_time)*1000)) print(int(time.mktime(current_time.timetuple())*1000))\n同样都是时间戳，timestamp是带毫秒的，具备单调递增、加密混乱的特质。 文中有句话是这么说的：\"当某个后来请求的nonce比上一个成功收到的请求的nonce小或者相等的时候，Gemini便会拒绝这次请求\"。 说明Gemini不希望http请求在一秒内发生多次。应该是反爬用的吧~ 用timestamp是可以精确到毫秒的，意味着每毫秒可以请求发送的nonce都不一样。\n另外，作为taker第二次运行该代码就报出下面的错： { \"result\": \"error\", \"reason\": \"InsufficientFunds\", \"message\": \"Failed to place buy order on symbol 'BTCUSD' for price $3,633.00 and quantity 5 BTC due to insufficient funds\" }2019-07-27瞳梦 👍（3） 💬（4）请问gemini sandbox账号怎么注册呢？我在官网只找到了Open a Personal Account和I Represent an Institution2019-07-26Xg huang 👍（1） 💬（1）哈哈，深入浅出，赞一个\n不过有个地方是否写错？\"而小宝在某一天中午 11:59:00，告诉交易所，我要挂一个单子，数量为 0.1 比特币，价格为 10000 美元，低于这个价格不卖。\"\n是不是1000才对？2019-07-26王帅帅 👍（0） 💬（1）我跑了一遍，提示gemini 交易所正在维护，怎么回事。2020-01-13SCAR 👍（13） 💬（0）思考题：\n纯粹使用timestamp应该不行，虽然timestamp也是递增的，但是在python里timestamp是float而不是int。 2.但如果基于timestamp抽取出部分应该是可以，比如老师例子中的： payload_nonce = str(int(time.mktime(t.timetuple())*1000)) 改成： payload_nonce = str(int(t.timestamp())*1000) 结果应该是一致的。2019-07-26Monroe He 👍（7） 💬（2）我想问一下老师，有针对国内股票的虚拟交易平台吗 可以提供一下相关方面的书籍资料吗2019-07-26devna 👍（6） 💬（0）前段时间刚看完《计算机网络：自顶自下方法》，确实不错，能很快提升对网络的认识，强烈推荐2020-01-19karofsky 👍（4） 💬（0）今天再看这篇文章的感受就是，BTC真的涨了好多啊…2021-01-12kang 👍（3） 💬（6）請問大家都是怎麼註冊Genimi 的? 我的註冊國家都被阻擋2019-08-23马建华 👍（2） 💬（3）我是报错： {'result': 'error', 'reason': 'MissingAccounts', 'message': 'Expected a JSON payload with accounts'} 有谁碰到吗？2020-07-20及時行樂 👍（2） 💬（0）现在程序跑起来都报错了，这是交易所把API地址改了吗？ {'result': 'error', 'reason': 'EndpointMismatch', 'message': 'EndpointMismatch'}2020-05-13知止。 👍（1） 💬（2）老师，是不是该针对运行可能出现的一些问题给出解答呢？如果网站变更过信息，那么课件相应也得更新一下吧，不然后来订阅学习的人没办法完整学习啊。比如我按照课件内容运行，提示{'result': 'error', 'reason': 'InvalidSignature', 'message': 'InvalidSignature'}，网上都找不到原因，想自己排查错误都不懂如何着手 "
            }
        );
    index.add(
            {
                id:  44 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/35---restful--socket%E8%A1%8C%E6%83%85%E6%95%B0%E6%8D%AE%E5%AF%B9%E6%8E%A5%E5%92%8C%E6%8A%93%E5%8F%96\/",
                title: "RESTful \u0026 Socket：行情数据对接和抓取",
                description: "你好，我是景霄。\n上一节课，我们介绍了交易所的交易模式，数字货币交易所RESTful接口的常见概念，以及如何调用RESTful接口进行订单操作。众所周知，买卖操作的前提，是你需要已知市场的最新情况。这节课里，我将介绍交易系统底层另一个最重要的部分，行情数据的对接和抓取。\n行情数据，最重要的是实时性和有效性。市场的情况瞬息万变，合适的买卖时间窗口可能只有几秒。在高频交易里，合适的买卖机会甚至在毫秒级别。要知道，一次从北京发往美国的网络请求，即使是光速传播，都需要几百毫秒的延迟。更别提用Python这种解释型语言，建立HTTP连接导致的时间消耗。\n经过上节课的学习，你对交易应该有了基本的了解，这也是我们今天学习的基础。接下来，我们先从交易所撮合模式讲起，然后介绍行情数据有哪些；之后，我将带你基于Websocket的行情数据来抓取模块。\n行情数据 link回顾上一节我们提到的，交易所是一个买方、卖方之间的公开撮合平台。买卖方把需要/可提供的商品数量和愿意出/接受的价格提交给交易所，交易所按照公平原则进行撮合交易。\n那么撮合交易是怎么进行的呢？假设你是一个人肉比特币交易所，大量的交易订单往你这里汇总，你应该如何选择才能让交易公平呢？\n显然，最直观的操作就是，把买卖订单分成两个表，按照价格由高到低排列。下面的图，就是买入和卖出的委托表。\n如果最高的买入价格小于最低的卖出价格，那就不会有任何交易发生。这通常是你看到的委托列表的常态。\n如果最高的买入价格和最低的卖出价格相同，那么就尝试进行撮合。比如BTC在9002.01就会发生撮合，最后按照9002.01的价格，成交0.0330个BTC。当然，交易完成后，小林未完成部分的订单（余下0.1126 - 0.0330 = 0.0796 个 BTC 未卖出），还会继续在委托表里。\n不过你可能会想，如果买入和卖出的价格有交叉，那么成交价格又是什么呢？事实上，这种情况并不会发生。我们来试想一下下面这样的场景。\n如果你尝试给一个委托列表里加入一个新买入订单，它的价格比所有已有的最高买入价格高，也比所有的卖出价格高。那么此时，它会直接从最低的卖出价格撮合。等到最低价格的卖出订单吃完了，它便开始吃价格第二低的卖出订单，直到这个买入订单完全成交。反之亦然。所以，委托列表价格不会出现交叉。\n当然，请注意，这里我说的只是限价订单的交易方式。而对于市价订单，交易规则会有一些轻微的区别，这里我就不详细解释了，主要是让你有个概念。\n其实说到这里，所谓的“交易所行情”概念就呼之欲出了。交易所主要有两种行情数据：委托账本（Order Book）和活动行情（Tick data）。\n我们把委托表里的具体用户隐去，相同价格的订单合并，就得到了下面这种委托账本。我们主要观察右边的数字部分，其中：\n上半部分里，第一列红色数字代表BTC的卖出价格，中间一列数字是这个价格区间的订单BTC总量，最右边一栏是从最低卖出价格到当前价格区间的积累订单量。 中间的大字部分，9994.10 USD是当前的市场价格，也就是上一次成交交易的价格。 下面绿色部分的含义与上半部分类似，不过指的是买入委托和对应的数量。 Gemini的委托账本，来自https://cryptowat.ch\n",
                content: "你好，我是景霄。\n上一节课，我们介绍了交易所的交易模式，数字货币交易所RESTful接口的常见概念，以及如何调用RESTful接口进行订单操作。众所周知，买卖操作的前提，是你需要已知市场的最新情况。这节课里，我将介绍交易系统底层另一个最重要的部分，行情数据的对接和抓取。\n行情数据，最重要的是实时性和有效性。市场的情况瞬息万变，合适的买卖时间窗口可能只有几秒。在高频交易里，合适的买卖机会甚至在毫秒级别。要知道，一次从北京发往美国的网络请求，即使是光速传播，都需要几百毫秒的延迟。更别提用Python这种解释型语言，建立HTTP连接导致的时间消耗。\n经过上节课的学习，你对交易应该有了基本的了解，这也是我们今天学习的基础。接下来，我们先从交易所撮合模式讲起，然后介绍行情数据有哪些；之后，我将带你基于Websocket的行情数据来抓取模块。\n行情数据 link回顾上一节我们提到的，交易所是一个买方、卖方之间的公开撮合平台。买卖方把需要/可提供的商品数量和愿意出/接受的价格提交给交易所，交易所按照公平原则进行撮合交易。\n那么撮合交易是怎么进行的呢？假设你是一个人肉比特币交易所，大量的交易订单往你这里汇总，你应该如何选择才能让交易公平呢？\n显然，最直观的操作就是，把买卖订单分成两个表，按照价格由高到低排列。下面的图，就是买入和卖出的委托表。\n如果最高的买入价格小于最低的卖出价格，那就不会有任何交易发生。这通常是你看到的委托列表的常态。\n如果最高的买入价格和最低的卖出价格相同，那么就尝试进行撮合。比如BTC在9002.01就会发生撮合，最后按照9002.01的价格，成交0.0330个BTC。当然，交易完成后，小林未完成部分的订单（余下0.1126 - 0.0330 = 0.0796 个 BTC 未卖出），还会继续在委托表里。\n不过你可能会想，如果买入和卖出的价格有交叉，那么成交价格又是什么呢？事实上，这种情况并不会发生。我们来试想一下下面这样的场景。\n如果你尝试给一个委托列表里加入一个新买入订单，它的价格比所有已有的最高买入价格高，也比所有的卖出价格高。那么此时，它会直接从最低的卖出价格撮合。等到最低价格的卖出订单吃完了，它便开始吃价格第二低的卖出订单，直到这个买入订单完全成交。反之亦然。所以，委托列表价格不会出现交叉。\n当然，请注意，这里我说的只是限价订单的交易方式。而对于市价订单，交易规则会有一些轻微的区别，这里我就不详细解释了，主要是让你有个概念。\n其实说到这里，所谓的“交易所行情”概念就呼之欲出了。交易所主要有两种行情数据：委托账本（Order Book）和活动行情（Tick data）。\n我们把委托表里的具体用户隐去，相同价格的订单合并，就得到了下面这种委托账本。我们主要观察右边的数字部分，其中：\n上半部分里，第一列红色数字代表BTC的卖出价格，中间一列数字是这个价格区间的订单BTC总量，最右边一栏是从最低卖出价格到当前价格区间的积累订单量。 中间的大字部分，9994.10 USD是当前的市场价格，也就是上一次成交交易的价格。 下面绿色部分的含义与上半部分类似，不过指的是买入委托和对应的数量。 Gemini的委托账本，来自https://cryptowat.ch\n这张图中，最低的卖出价格比最高的买入价格要高 6.51 USD，这个价差通常被称为Spread。这里验证了我们前面提到的，委托账本的价格永不交叉； 同时，Spread很小也能说明这是一个非常活跃的交易所。\n每一次撮合发生，意味着一笔交易（Trade）的发生。卖方买方都很开心，于是交易所也很开心地通知行情数据的订阅者：刚才发生了一笔交易，交易的价格是多少，成交数量是多少。这个数据就是活动行情Tick。\n有了这些数据，我们也就掌握了这个交易所的当前状态，可以开始搞事情了。\nWebsocket介绍 link在本文的开头我们提到过：行情数据很讲究时效性。所以，行情从交易所产生到传播给我们的程序之间的延迟，应该越低越好。通常，交易所也提供了REST的行情数据抓取接口。比如下面这段代码：\nimport requests\rimport timeit\rdef get_orderbook():\rorderbook = requests.get(\"https://api.gemini.com/v1/book/btcusd\").json()\rn = 10\rlatency = timeit.timeit('get_orderbook()', setup='from __main__ import get_orderbook', number=n) * 1.0 / n\rprint('Latency is {} ms'.format(latency * 1000))\r###### 输出 #######\rLatency is 196.67642089999663 ms 我在美国纽约附近城市的一个服务器上测试了这段代码，你可以看到，平均每次访问orderbook的延迟有0.25秒左右。显然，如果在国内，这个延迟只会更大。按理说，这两个美国城市的距离很短，为什么延迟会这么大呢？\n这是因为，REST接口本质上是一个HTTP接口，在这之下是TCP/TLS套接字（Socket）连接。每一次REST请求，通常都会重新建立一次TCP/TLS握手；然后，在请求结束之后，断开这个链接。这个过程，比我们想象的要慢很多。\n举个例子来验证这一点，在同一个城市我们试验一下。我从纽约附近的服务器和Gemini在纽约的服务器进行连接，TCP/SSL握手花了多少时间呢？\ncurl -w \"TCP handshake: %{time_connect}s, SSL handshake: %{time_appconnect}s\\n\" -so /dev/null https://www.gemini.com\rTCP handshake: 0.072758s, SSL handshake: 0.119409s 结果显示，HTTP连接构建的过程，就占了一大半时间！也就是说，我们每次用REST请求，都要浪费一大半的时间在和服务器建立连接上，这显然是非常低效的。很自然的你会想到，我们能否实现一次连接、多次通信呢？\n事实上，Python的某些HTTP请求库，也可以支持重用底层的TCP/SSL连接。但那种方法，一来比较复杂，二来也需要服务器的支持。该怎么办呢？其实，在有WebSocket的情况下，我们完全不需要舍近求远。\n我先来介绍一下WebSocket。WebSocket是一种在单个TCP/TLS连接上，进行全双工、双向通信的协议。WebSocket可以让客户端与服务器之间的数据交换变得更加简单高效，服务端也可以主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以直接创建持久性的连接，并进行双向数据传输。\n概念听着很痛快，不过还是有些抽象。为了让你快速理解刚刚的这段话，我们还是来看两个简单的例子。二话不说，先看一段代码：\nimport websocket\rimport thread\r# 在接收到服务器发送消息时调用\rdef on_message(ws, message):\rprint('Received: ' + message)\r# 在和服务器建立完成连接时调用 def on_open(ws):\r# 线程运行函数\rdef gao():\r# 往服务器依次发送0-4，每次发送完休息0.01秒\rfor i in range(5):\rtime.sleep(0.01)\rmsg=\"{0}\".format(i)\rws.send(msg)\rprint('Sent: ' + msg)\r# 休息1秒用于接收服务器回复的消息\rtime.sleep(1)\r# 关闭Websocket的连接\rws.close()\rprint(\"Websocket closed\")\r# 在另一个线程运行gao()函数\rthread.start_new_thread(gao, ())\rif __name__ == \"__main__\":\rws = websocket.WebSocketApp(\"ws://echo.websocket.org/\",\ron_message = on_message,\ron_open = on_open)\rws.run_forever()\r#### 输出 #####\rSent: 0\rSent: 1\rReceived: 0\rSent: 2\rReceived: 1\rSent: 3\rReceived: 2\rSent: 4\rReceived: 3\rReceived: 4\rWebsocket closed 这段代码尝试和wss://echo.websocket.org建立连接。当连接建立的时候，就会启动一条线程，连续向服务器发送5条消息。\n通过输出可以看出，我们在连续发送的同时，也在不断地接受消息。这并没有像REST一样，每发送一个请求，要等待服务器完成请求、完全回复之后，再进行下一个请求。换句话说，我们在请求的同时也在接受消息，这也就是前面所说的”全双工“。\nREST（HTTP）单工请求响应的示意图\nWebsocket全双工请求响应的示意图\n再来看第二段代码。为了解释”双向“，我们来看看获取Gemini的委托账单的例子。\nimport ssl\rimport websocket\rimport json\r# 全局计数器\rcount = 5\rdef on_message(ws, message):\rglobal count\rprint(message)\rcount -= 1\r# 接收了5次消息之后关闭websocket连接\rif count == 0:\rws.close()\rif __name__ == \"__main__\":\rws = websocket.WebSocketApp(\r\"wss://api.gemini.com/v1/marketdata/btcusd?top_of_book=true\u0026offers=true\",\ron_message=on_message)\rws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\r###### 输出 #######\r{\"type\":\"update\",\"eventId\":7275473603,\"socket_sequence\":0,\"events\":[{\"type\":\"change\",\"reason\":\"initial\",\"price\":\"11386.12\",\"delta\":\"1.307\",\"remaining\":\"1.307\",\"side\":\"ask\"}]}\r{\"type\":\"update\",\"eventId\":7275475120,\"timestamp\":1562380981,\"timestampms\":1562380981991,\"socket_sequence\":1,\"events\":[{\"type\":\"change\",\"side\":\"ask\",\"price\":\"11386.62\",\"remaining\":\"1\",\"reason\":\"top-of-book\"}]}\r{\"type\":\"update\",\"eventId\":7275475271,\"timestamp\":1562380982,\"timestampms\":1562380982387,\"socket_sequence\":2,\"events\":[{\"type\":\"change\",\"side\":\"ask\",\"price\":\"11386.12\",\"remaining\":\"1.3148\",\"reason\":\"top-of-book\"}]}\r{\"type\":\"update\",\"eventId\":7275475838,\"timestamp\":1562380986,\"timestampms\":1562380986270,\"socket_sequence\":3,\"events\":[{\"type\":\"change\",\"side\":\"ask\",\"price\":\"11387.16\",\"remaining\":\"0.072949\",\"reason\":\"top-of-book\"}]}\r{\"type\":\"update\",\"eventId\":7275475935,\"timestamp\":1562380986,\"timestampms\":1562380986767,\"socket_sequence\":4,\"events\":[{\"type\":\"change\",\"side\":\"ask\",\"price\":\"11389.22\",\"remaining\":\"0.06204196\",\"reason\":\"top-of-book\"}]} 可以看到，在和Gemini建立连接后，我们并没有向服务器发送任何消息，没有任何请求，但是服务器却源源不断地向我们推送数据。这可比REST接口“每请求一次获得一次回复”的沟通方式高效多了！\n因此，相对于REST来说，Websocket是一种更加实时、高效的数据交换方式。当然缺点也很明显：因为请求和回复是异步的，这让我们程序的状态控制逻辑更加复杂。这一点，后面的内容里我们会有更深刻的体会。\n行情抓取模块 link有了 Websocket 的基本概念，我们就掌握了和交易所连接的第二种方式。\n事实上，Gemini 提供了两种 Websocket 接口，一种是 Public 接口，一种为 Private 接口。\nPublic 接口，即公开接口，提供 orderbook 服务，即每个人都能看到的当前挂单价和深度，也就是我们这节课刚刚详细讲过的 orderbook。\n而 Private 接口，和我们上节课讲的挂单操作有关，订单被完全执行、被部分执行等等其他变动，你都会得到通知。\n我们以 orderbook 爬虫为例，先来看下如何抓取 orderbook 信息。下面的代码详细写了一个典型的爬虫，同时使用了类进行封装，希望你不要忘记我们这门课的目的，了解 Python 是如何应用于工程实践中的：\nimport copy\rimport json\rimport ssl\rimport time\rimport websocket\rclass OrderBook(object):\rBIDS = 'bid'\rASKS = 'ask'\rdef __init__(self, limit=20):\rself.limit = limit\r# (price, amount)\rself.bids = {}\rself.asks = {}\rself.bids_sorted = []\rself.asks_sorted = []\rdef insert(self, price, amount, direction):\rif direction == self.BIDS:\rif amount == 0:\rif price in self.bids:\rdel self.bids[price]\relse:\rself.bids[price] = amount\relif direction == self.ASKS:\rif amount == 0:\rif price in self.asks:\rdel self.asks[price]\relse:\rself.asks[price] = amount\relse:\rprint('WARNING: unknown direction {}'.format(direction))\rdef sort_and_truncate(self):\r# sort\rself.bids_sorted = sorted([(price, amount) for price, amount in self.bids.items()], reverse=True)\rself.asks_sorted = sorted([(price, amount) for price, amount in self.asks.items()])\r# truncate\rself.bids_sorted = self.bids_sorted[:self.limit]\rself.asks_sorted = self.asks_sorted[:self.limit]\r# copy back to bids and asks\rself.bids = dict(self.bids_sorted)\rself.asks = dict(self.asks_sorted)\rdef get_copy_of_bids_and_asks(self):\rreturn copy.deepcopy(self.bids_sorted), copy.deepcopy(self.asks_sorted)\rclass Crawler:\rdef __init__(self, symbol, output_file):\rself.orderbook = OrderBook(limit=10)\rself.output_file = output_file\rself.ws = websocket.WebSocketApp('wss://api.gemini.com/v1/marketdata/{}'.format(symbol),\ron_message = lambda ws, message: self.on_message(message))\rself.ws.run_forever(sslopt={'cert_reqs': ssl.CERT_NONE})\rdef on_message(self, message):\r# 对收到的信息进行处理，然后送给 orderbook\rdata = json.loads(message)\rfor event in data['events']:\rprice, amount, direction = float(event['price']), float(event['remaining']), event['side']\rself.orderbook.insert(price, amount, direction)\r# 整理 orderbook，排序，只选取我们需要的前几个\rself.orderbook.sort_and_truncate()\r# 输出到文件\rwith open(self.output_file, 'a+') as f:\rbids, asks = self.orderbook.get_copy_of_bids_and_asks()\routput = {\r'bids': bids,\r'asks': asks,\r'ts': int(time.time() * 1000)\r}\rf.write(json.dumps(output) + '\\n')\rif __name__ == '__main__':\rcrawler = Crawler(symbol='BTCUSD', output_file='BTCUSD.txt')\r###### 输出 #######\r{\"bids\": [[11398.73, 0.96304843], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.95, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11407.92, 1.0], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11412.42, 1.0], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558996535}\r{\"bids\": [[11398.73, 0.96304843], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.95, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11407.92, 1.0], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11412.42, 1.0], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558997377}\r{\"bids\": [[11398.73, 0.96304843], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.95, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11412.42, 1.0], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558997765}\r{\"bids\": [[11398.73, 0.96304843], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.95, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558998638}\r{\"bids\": [[11398.73, 0.97131753], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.95, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558998645}\r{\"bids\": [[11398.73, 0.97131753], [11398.72, 0.98914437], [11397.32, 1.0], [11396.13, 2.0], [11395.87, 1.0], [11394.09, 0.11803397], [11394.08, 1.0], [11393.59, 0.1612581], [11392.96, 1.0]], \"asks\": [[11407.42, 1.30814001], [11409.48, 2.0], [11409.66, 2.0], [11412.15, 0.525], [11413.77, 0.11803397], [11413.99, 0.5], [11414.28, 1.0], [11414.72, 1.0]], \"ts\": 1562558998748} 代码比较长，接下来我们具体解释一下。\n这段代码的最开始，封装了一个叫做 orderbook 的 class，专门用来存放与之相关的数据结构。其中的 bids 和 asks 两个字典，用来存储当前时刻下的买方挂单和卖方挂单。\n此外，我们还专门维护了一个排过序的 bids_sorted 和 asks_sorted。构造函数有一个参数 limit，用来指示 orderbook 的 bids 和 asks 保留多少条数据。对于很多策略，top 5 的数据往往足够，这里我们选择的是前 10 个。\n再往下看，insert() 函数用于向 orderbook 插入一条数据。需要注意，这里的逻辑是，如果某个 price 对应的 amount 是 0，那么意味着这一条数据已经不存在了，删除即可。insert 的数据可能是乱序的，因此在需要的时候，我们要对 bids 和 asks 进行排序，然后选取前面指定数量的数据。这其实就是 sort_and_truncate() 函数的作用，调用它来对 bids 和 asks 排序后截取，最后保存回 bids 和 asks。\n接下来的 get_copy_of_bids_and_asks()函数，用来返回排过序的 bids 和 asks 数组。这里使用深拷贝，是因为如果直接返回，将会返回 bids_sorted 和 asks_sorted 的指针；那么，在下一次调用 sort_and_truncate() 函数的时候，两个数组的内容将会被改变，这就造成了潜在的 bug。\n最后来看一下 Crawler 类。构造函数声明 orderbook，然后定义 Websocket 用来接收交易所数据。这里需要注意的一点是，回调函数 on_message() 是一个类成员函数。因此，应该你注意到了，它的第一个参数是 self，这里如果直接写成 on_message = self.on_message 将会出错。\n为了避免这个问题，我们需要将函数再次包装一下。这里我使用了前面学过的匿名函数，来传递中间状态，注意我们只需要 message，因此传入 message 即可。\n剩下的部分就很清晰了，on_message 回调函数在收到一个新的 tick 时，先将信息解码，枚举收到的所有改变；然后插入 orderbook，排序；最后连同 timestamp 一并输出即可。\n虽然这段代码看起来挺长，但是经过我这么一分解，是不是发现都是学过的知识点呢？这也是我一再强调基础的原因，如果对你来说哪部分内容变得陌生了（比如面向对象编程的知识点），一定要记得及时往前复习，这样你学起新的更复杂的东西，才能轻松很多。\n回到正题。刚刚的代码，主要是为了抓取 orderbook 的信息。事实上，Gemini 交易所在建立数据流 Websocket 的时候，第一条信息往往非常大，因为里面包含了那个时刻所有的 orderbook 信息。这就叫做初始数据。之后的消息，都是基于初始数据进行修改的，直接处理即可。\n总结 link这节课我们继承上一节，从委托账本讲起，然后讲述了 WebSocket 的定义、工作机制和使用方法，最后以一个例子收尾，带你学会如何爬取 Orderbook 的信息。希望你在学习这节课的内容时，能够和上节课的内容联系起来，仔细思考 Websocket 和 RESTFul 的区别，并试着总结网络编程中不同模型的适用范围。\n思考题 link最后给你留一道思考题。WebSocket 会丢包吗？如果丢包的话， Orderbook 爬虫又会发生什么？这一点应该如何避免呢？欢迎留言和我讨论，也欢迎你把这篇文章分享出去。\npip -m install websocket_client安装。\npip -m install websocket会安装另外一个完全不同的包2019-07-29tux 👍（16） 💬（0）干布球和tt 的提示，解决了报错。 import websocket #pip install websocket-client import _thread as thread\n在查找资料时，看到了： import websocket try: import thread except ImportError: import _thread as thread\n"
            }
        );
    index.add(
            {
                id:  45 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/36---pandas--numpy%E7%AD%96%E7%95%A5%E4%B8%8E%E5%9B%9E%E6%B5%8B%E7%B3%BB%E7%BB%9F\/",
                title: "Pandas \u0026 Numpy：策略与回测系统",
                description: "大家好，我是景霄。\n上节课，我们介绍了交易所的数据抓取，特别是orderbook和tick数据的抓取。今天这节课，我们考虑的是，怎么在这些历史数据上测试一个交易策略。\n首先我们要明确，对于很多策略来说，我们上节课抓取的密集的orderbook和tick数据，并不能简单地直接使用。因为数据量太密集，包含了太多细节；而且长时间连接时，网络随机出现的不稳定，会导致丢失部分tick数据。因此，我们还需要进行合适的清洗、聚合等操作。\n此外，为了进行回测，我们需要一个交易策略，还需要一个测试框架。目前已存在很多成熟的回测框架，但是为了Python学习，我决定带你搭建一个简单的回测框架，并且从中简单一窥Pandas的优势。\nOHLCV数据 link了解过一些股票交易的同学，可能知道K线这种东西。K线又称“蜡烛线”，是一种反映价格走势的图线。它的特色在于，一个线段内记录了多项讯息，相当易读易懂且实用有效，因此被广泛用于股票、期货、贵金属、数字货币等行情的技术分析。下面便是一个K线示意图。\nK线示意图\n其中，每一个小蜡烛，都代表着当天的开盘价（Open）、最高价（High）、最低价（Low）和收盘价（Close），也就是我画的第二张图表示的这样。\nK线的“小蜡烛” – OHLC\n类似的，除了日K线之外，还有周K线、小时K线、分钟K线等等。那么这个K线是怎么计算来的呢？\n我们以小时K线图为例，还记得我们当时抓取的tick数据吗？也就是每一笔交易的价格和数量。那么，如果从上午10:00开始，我们开始积累tick的交易数据，以10:00开始的第一个交易作为Open数据，11:00前的最后一笔交易作为Close值，并把这一个小时最低和最高的成交价格分别作为High和Low的值，我们就可以绘制出这一个小时对应的“小蜡烛”形状了。\n如果再加上这一个小时总的成交量（Volumn），就得到了OHLCV数据。\n所以，如果我们一直抓取着tick底层原始数据，我们就能在上层聚合出1分钟K线、小时K线以及日、周k线等等。如果你对这一部分操作有兴趣，可以把此作为今天的课后作业来实践。\n接下来，我们将使用Gemini从2015年到2019年7月这个时间内，BTC对USD每个小时的OHLCV数据，作为策略和回测的输入。你可以在这里下载数据。\n数据下载完成后，我们可以利用Pandas读取，比如下面这段代码。\ndef assert_msg(condition, msg):\rif not condition:\rraise Exception(msg)\rdef read_file(filename):\r# 获得文件绝对路径\rfilepath = path.join(path.dirname(__file__), filename)\r# 判定文件是否存在\rassert_msg(path.exists(filepath), \"文件不存在\")\r# 读取CSV文件并返回\rreturn pd.read_csv(filepath,\rindex_col=0, parse_dates=True,\rinfer_datetime_format=True)\rBTCUSD = read_file('BTCUSD_GEMINI.csv')\rassert_msg(BTCUSD.__len__() \u003e 0, '读取失败')\rprint(BTCUSD.head())\r########## 输出 ##########\rTime Symbol Open High Low Close Volume\rDate 2019-07-08 00:00:00 BTCUSD 11475.07 11540.33 11469.53 11506.43 10.770731\r2019-07-07 23:00:00 BTCUSD 11423.00 11482.72 11423.00 11475.07 32.996559\r2019-07-07 22:00:00 BTCUSD 11526.25 11572.74 11333.59 11423.00 48.937730\r2019-07-07 21:00:00 BTCUSD 11515.80 11562.65 11478.20 11526.25 25.323908\r2019-07-07 20:00:00 BTCUSD 11547.98 11624.88 11423.94 11515.80 63.211972 这段代码提供了两个工具函数。\n",
                content: "大家好，我是景霄。\n上节课，我们介绍了交易所的数据抓取，特别是orderbook和tick数据的抓取。今天这节课，我们考虑的是，怎么在这些历史数据上测试一个交易策略。\n首先我们要明确，对于很多策略来说，我们上节课抓取的密集的orderbook和tick数据，并不能简单地直接使用。因为数据量太密集，包含了太多细节；而且长时间连接时，网络随机出现的不稳定，会导致丢失部分tick数据。因此，我们还需要进行合适的清洗、聚合等操作。\n此外，为了进行回测，我们需要一个交易策略，还需要一个测试框架。目前已存在很多成熟的回测框架，但是为了Python学习，我决定带你搭建一个简单的回测框架，并且从中简单一窥Pandas的优势。\nOHLCV数据 link了解过一些股票交易的同学，可能知道K线这种东西。K线又称“蜡烛线”，是一种反映价格走势的图线。它的特色在于，一个线段内记录了多项讯息，相当易读易懂且实用有效，因此被广泛用于股票、期货、贵金属、数字货币等行情的技术分析。下面便是一个K线示意图。\nK线示意图\n其中，每一个小蜡烛，都代表着当天的开盘价（Open）、最高价（High）、最低价（Low）和收盘价（Close），也就是我画的第二张图表示的这样。\nK线的“小蜡烛” – OHLC\n类似的，除了日K线之外，还有周K线、小时K线、分钟K线等等。那么这个K线是怎么计算来的呢？\n我们以小时K线图为例，还记得我们当时抓取的tick数据吗？也就是每一笔交易的价格和数量。那么，如果从上午10:00开始，我们开始积累tick的交易数据，以10:00开始的第一个交易作为Open数据，11:00前的最后一笔交易作为Close值，并把这一个小时最低和最高的成交价格分别作为High和Low的值，我们就可以绘制出这一个小时对应的“小蜡烛”形状了。\n如果再加上这一个小时总的成交量（Volumn），就得到了OHLCV数据。\n所以，如果我们一直抓取着tick底层原始数据，我们就能在上层聚合出1分钟K线、小时K线以及日、周k线等等。如果你对这一部分操作有兴趣，可以把此作为今天的课后作业来实践。\n接下来，我们将使用Gemini从2015年到2019年7月这个时间内，BTC对USD每个小时的OHLCV数据，作为策略和回测的输入。你可以在这里下载数据。\n数据下载完成后，我们可以利用Pandas读取，比如下面这段代码。\ndef assert_msg(condition, msg):\rif not condition:\rraise Exception(msg)\rdef read_file(filename):\r# 获得文件绝对路径\rfilepath = path.join(path.dirname(__file__), filename)\r# 判定文件是否存在\rassert_msg(path.exists(filepath), \"文件不存在\")\r# 读取CSV文件并返回\rreturn pd.read_csv(filepath,\rindex_col=0, parse_dates=True,\rinfer_datetime_format=True)\rBTCUSD = read_file('BTCUSD_GEMINI.csv')\rassert_msg(BTCUSD.__len__() \u003e 0, '读取失败')\rprint(BTCUSD.head())\r########## 输出 ##########\rTime Symbol Open High Low Close Volume\rDate 2019-07-08 00:00:00 BTCUSD 11475.07 11540.33 11469.53 11506.43 10.770731\r2019-07-07 23:00:00 BTCUSD 11423.00 11482.72 11423.00 11475.07 32.996559\r2019-07-07 22:00:00 BTCUSD 11526.25 11572.74 11333.59 11423.00 48.937730\r2019-07-07 21:00:00 BTCUSD 11515.80 11562.65 11478.20 11526.25 25.323908\r2019-07-07 20:00:00 BTCUSD 11547.98 11624.88 11423.94 11515.80 63.211972 这段代码提供了两个工具函数。\n一个是read_file，它的作用是，用pandas读取csv文件。 另一个是assert_msg，它的作用类似于assert，如果传入的条件（contidtion）为否，就会抛出异常。不过，你需要提供一个参数，用于指定要抛出的异常信息。 回测框架 link说完了数据，我们接着来看回测数据。常见的回测框架有两类。一类是向量化回测框架，它通常基于Pandas+Numpy来自己搭建计算核心；后端则是用MySQL或者MongoDB作为源。这种框架通过Pandas+Numpy对OHLC数组进行向量运算，可以在较长的历史数据上进行回测。不过，因为这类框架一般只用OHLC，所以模拟会比较粗糙。\n另一类则是事件驱动型回测框架。这类框架，本质上是针对每一个tick的变动或者orderbook的变动生成事件；然后，再把一个个事件交给策略进行执行。因此，虽然它的拓展性很强，可以允许更加灵活的策略，但回测速度是很慢的。\n我们想要学习量化交易，使用大型成熟的回测框架，自然是第一选择。\n比如Zipline，就是一个热门的事件驱动型回测框架，背后有大型社区和文档的支持。 PyAlgoTrade也是事件驱动的回测框架，文档相对完整，整合了知名的技术分析（Techique Analysis）库TA-Lib。在速度和灵活方面，它比Zipline 强。不过，它的一大硬伤是不支持 Pandas 的模块和对象。 显然，对于我们Python学习者来说，第一类也就是向量型回测框架，才是最适合我们练手的项目了。那么，我们就开始吧。\n首先，我先为你梳理下回测流程，也就是下面五步：\n读取OHLC数据； 对OHLC进行指标运算； 策略根据指标向量决定买卖； 发给模拟的”交易所“进行交易； 最后，统计结果。 对此，使用之前学到的面向对象思维方式，我们可以大致抽取三个类：\n交易所类（ ExchangeAPI）：负责维护账户的资金和仓位，以及进行模拟的买卖； 策略类（Strategy）：负责根据市场信息生成指标，根据指标决定买卖； 回测类框架（Backtest）：包含一个策略类和一个交易所类，负责迭代地对每个数据点调用策略执行。 接下来，我们先从最外层的大框架开始。这样的好处在于，我们是从上到下、从外往内地思考，虽然还没有开始设计依赖项（Backtest的依赖项是ExchangeAPI和Strategy），但我们可以推测出它们应有的接口形式。推测接口的本质，其实就是推测程序的输入。\n这也是我在一开始提到过的，对于程序这个“黑箱”，你在一开始设计的时候，就要想好输入和输出。\n回到最外层Backtest类。我们需要知道，输出是最后的收益，那么显然，输入应该是初始输入的资金数量（cash）。\n此外，为了模拟得更加真实，我们还要考虑交易所的手续费（commission）。手续费的多少取决于券商（broker）或者交易所，比如我们买卖股票的券商手续费可能是万七，那么就是0.0007。但是在比特币交易领域，手续费通常会稍微高一点，可能是千分之二左右。当然，无论怎么多，一般也不会超过5 %。否则我们大家交易几次就破产了，也就不会有人去交易了。\n这里说一句题外话，不知道你有没有发现，无论数字货币的价格是涨还是跌，总有一方永远不亏，那就是交易所。因为只要有人交易，他们就有白花花的银子进账。\n回到正题，至此，我们就确定了Backtest的输入和输出。\n它的输入是：\nOHLC数据； 初始资金； 手续费率； 交易所类； 策略类。 输出则是：\n最后剩余市值。 对此，你可以参考下面这段代码：\nclass Backtest:\r\"\"\"\rBacktest回测类，用于读取历史行情数据、执行策略、模拟交易并估计\r收益。\r初始化的时候调用Backtest.run来时回测\rinstance, or `backtesting.backtesting.Backtest.optimize` to\roptimize it.\r\"\"\"\rdef __init__(self,\rdata: pd.DataFrame,\rstrategy_type: type(Strategy),\rbroker_type: type(ExchangeAPI),\rcash: float = 10000,\rcommission: float = .0):\r\"\"\"\r构造回测对象。需要的参数包括：历史数据，策略对象，初始资金数量，手续费率等。\r初始化过程包括检测输入类型，填充数据空值等。\r参数：\r:param data: pd.DataFrame pandas Dataframe格式的历史OHLCV数据\r:param broker_type: type(ExchangeAPI) 交易所API类型，负责执行买卖操作以及账户状态的维护\r:param strategy_type: type(Strategy) 策略类型\r:param cash: float 初始资金数量\r:param commission: float 每次交易手续费率。如2%的手续费此处为0.02\r\"\"\"\rassert_msg(issubclass(strategy_type, Strategy), 'strategy_type不是一个Strategy类型')\rassert_msg(issubclass(broker_type, ExchangeAPI), 'strategy_type不是一个Strategy类型')\rassert_msg(isinstance(commission, Number), 'commission不是浮点数值类型')\rdata = data.copy(False)\r# 如果没有Volumn列，填充NaN\rif 'Volume' not in data:\rdata['Volume'] = np.nan\r# 验证OHLC数据格式\rassert_msg(len(data.columns \u0026 {'Open', 'High', 'Low', 'Close', 'Volume'}) == 5,\r(\"输入的`data`格式不正确，至少需要包含这些列：\"\r\"'Open', 'High', 'Low', 'Close'\"))\r# 检查缺失值\rassert_msg(not data[['Open', 'High', 'Low', 'Close']].max().isnull().any(),\r('部分OHLC包含缺失值，请去掉那些行或者通过差值填充. '))\r# 如果行情数据没有按照时间排序，重新排序一下\rif not data.index.is_monotonic_increasing:\rdata = data.sort_index()\r# 利用数据，初始化交易所对象和策略对象。\rself._data = data # type: pd.DataFrame\rself._broker = broker_type(data, cash, commission)\rself._strategy = strategy_type(self._broker, self._data)\rself._results = None\rdef run(self):\r\"\"\"\r运行回测，迭代历史数据，执行模拟交易并返回回测结果。\rRun the backtest. Returns `pd.Series` with results and statistics.\rKeyword arguments are interpreted as strategy parameters.\r\"\"\"\rstrategy = self._strategy\rbroker = self._broker\r# 策略初始化\rstrategy.init()\r# 设定回测开始和结束位置\rstart = 100\rend = len(self._data)\r# 回测主循环，更新市场状态，然后执行策略\rfor i in range(start, end):\r# 注意要先把市场状态移动到第i时刻，然后再执行策略。\rbroker.next(i)\rstrategy.next(i)\r# 完成策略执行之后，计算结果并返回\rself._results = self._compute_result(broker)\rreturn self._results\rdef _compute_result(self, broker):\rs = pd.Series()\rs['初始市值'] = broker.initial_cash\rs['结束市值'] = broker.market_value\rs['收益'] = broker.market_value - broker.initial_cash\rreturn s 这段代码有点长，但是核心其实就两部分。\n初始化函数（init）：传入必要参数，对OHLC数据进行简单清洗、排序和验证。我们从不同地方下载的数据，可能格式不一样；而排序的方式也可能是从前往后。所以，这里我们把数据统一设置为按照时间从之前往现在的排序。 执行函数（run）：这是回测框架的主要循环部分，核心是更新市场还有更新策略的时间。迭代完成所有的历史数据后，它会计算收益并返回。 你应该注意到了，此时，我们还没有定义策略和交易所API的结构。不过，通过回测的执行函数，我们可以确定这两个类的接口形式。\n策略类（Strategy）的接口形式为：\n初始化函数init()，根据历史数据进行指标（Indicator）计算。 步进函数next()，根据当前时间和指标，决定买卖操作，并发给交易所类执行。 交易所类（ExchangeAPI）的接口形式为：\n步进函数next()，根据当前时间，更新最新的价格； 买入操作buy()，买入资产； 卖出操作sell()，卖出资产。 交易策略 link接下来我们来看交易策略。交易策略的开发是一个非常复杂的学问。为了达到学习的目的，我们来想一个简单的策略——移动均值交叉策略。\n为了了解这个策略，我们先了解一下，什么叫做简单移动均值（Simple Moving Average，简称为SMA，以下皆用SMA表示简单移动均值）。我们知道，N个数的序列 x[0]、x[1] .…… x[N] 的均值，就是这N个数的和除以N。\n现在，我假设一个比较小的数K，比N小很多。我们用一个K大小的滑动窗口，在原始的数组上滑动。通过对每次框住的K个元素求均值，我们就可以得到，原始数组的窗口大小为K的SMA了。\nSMA，实质上就是对原始数组进行了一个简单平滑处理。比如，某支股票的价格波动很大，那么，我们用SMA平滑之后，就会得到下面这张图的效果。\n某个投资品价格的SMA，窗口大小为50\n你可以看出，如果窗口大小越大，那么SMA应该越平滑，变化越慢；反之，如果SMA比较小，那么短期的变化也会越快地反映在SMA上。\n于是，我们想到，能不能对投资品的价格设置两个指标呢？这俩指标，一个是小窗口的SMA，一个是大窗口的SMA。\n如果小窗口的SMA曲线从下面刺破或者穿过大窗口SMA，那么说明，这个投资品的价格在短期内快速上涨，同时这个趋势很强烈，可能是一个买入的信号； 反之，如果大窗口的SMA从下方突破小窗口SMA，那么说明，投资品的价格在短期内快速下跌，我们应该考虑卖出。 下面这幅图，就展示了这两种情况。\n明白了这里的概念和原理后，接下来的操作就不难了。利用Pandas，我们可以非常简单地计算SMA和SMA交叉。比如，你可以引入下面两个工具函数：\ndef SMA(values, n):\r\"\"\"\r返回简单滑动平均\r\"\"\"\rreturn pd.Series(values).rolling(n).mean()\rdef crossover(series1, series2) -\u003e bool:\r\"\"\"\r检查两个序列是否在结尾交叉\r:param series1: 序列1\r:param series2: 序列2\r:return: 如果交叉返回True，反之False\r\"\"\"\rreturn series1[-2] \u003c series2[-2] and series1[-1] \u003e series2[-1] 如代码所示，对于输入的一个数组，Pandas的rolling(k)函数，可以方便地计算窗内口大小为K的SMA数组；而想要检查某个时刻两个SMA是否交叉，你只需要查看两个数组末尾的两个元素即可。\n那么，基于此，我们就可以开发出一个简单的策略了。下面这段代码表示策略的核心思想，我做了详细的注释，你理解起来应该没有问题：\ndef next(self, tick):\r# 如果此时快线刚好越过慢线，买入全部\rif crossover(self.sma1[:tick], self.sma2[:tick]):\rself.buy()\r# 如果是慢线刚好越过快线，卖出全部\relif crossover(self.sma2[:tick], self.sma1[:tick]):\rself.sell()\r# 否则，这个时刻不执行任何操作。\relse:\rpass 说完策略的核心思想，我们开始搭建策略类的框子。\n首先，我们要考虑到，策略类Strategy应该是一个可以被继承的类，同时应该包含一些固定的接口。这样，回测器才能方便地调用。\n于是，我们可以定义一个Strategy抽象类，包含两个接口方法init和next，分别对应我们前面说的指标计算和步进函数。不过注意，抽象类是不能被实例化的。所以，我们必须定义一个具体的子类，同时实现了init和next方法才可以。\n这个类的定义，你可以参考下面代码的实现：\nimport abc\rimport numpy as np\rfrom typing import Callable\rclass Strategy(metaclass=abc.ABCMeta):\r\"\"\"\r抽象策略类，用于定义交易策略。\r如果要定义自己的策略类，需要继承这个基类，并实现两个抽象方法：\rStrategy.init\rStrategy.next\r\"\"\"\rdef __init__(self, broker, data):\r\"\"\"\r构造策略对象。\r@params broker: ExchangeAPI 交易API接口，用于模拟交易\r@params data: list 行情数据数据\r\"\"\"\rself._indicators = []\rself._broker = broker # type: _Broker\rself._data = data # type: _Data\rself._tick = 0\rdef I(self, func: Callable, *args) -\u003e np.ndarray:\r\"\"\"\r计算买卖指标向量。买卖指标向量是一个数组，长度和历史数据对应；\r用于判定这个时间点上需要进行\"买\"还是\"卖\"。\r例如计算滑动平均：\rdef init():\rself.sma = self.I(utils.SMA, self.data.Close, N)\r\"\"\"\rvalue = func(*args)\rvalue = np.asarray(value)\rassert_msg(value.shape[-1] == len(self._data.Close), '指示器长度必须和data长度相同')\rself._indicators.append(value)\rreturn value\r@property\rdef tick(self):\rreturn self._tick\r@abc.abstractmethod\rdef init(self):\r\"\"\"\r初始化策略。在策略回测/执行过程中调用一次，用于初始化策略内部状态。\r这里也可以预计算策略的辅助参数。比如根据历史行情数据：\r计算买卖的指示器向量；\r训练模型/初始化模型参数\r\"\"\"\rpass\r@abc.abstractmethod\rdef next(self, tick):\r\"\"\"\r步进函数，执行第tick步的策略。tick代表当前的\"时间\"。比如data[tick]用于访问当前的市场价格。\r\"\"\"\rpass\rdef buy(self):\rself._broker.buy()\rdef sell(self):\rself._broker.sell()\r@property\rdef data(self):\rreturn self._data 为了方便访问成员，我们还定义了一些Python property。同时，我们的买卖请求是由策略类发出、由交易所API来执行的，所以我们的策略类里依赖于ExchangeAPI类。\n现在，有了这个框架，我们实现移动均线交叉策略就很简单了。你只需要在init函数中，定义计算大小窗口SMA的逻辑；同时，在next函数中完成交叉检测和买卖调用就行了。具体实现，你可以参考下面这段代码：\nfrom utils import assert_msg, crossover, SMA\rclass SmaCross(Strategy):\r# 小窗口SMA的窗口大小，用于计算SMA快线\rfast = 10\r# 大窗口SMA的窗口大小，用于计算SMA慢线\rslow = 20\rdef init(self):\r# 计算历史上每个时刻的快线和慢线\rself.sma1 = self.I(SMA, self.data.Close, self.fast)\rself.sma2 = self.I(SMA, self.data.Close, self.slow)\rdef next(self, tick):\r# 如果此时快线刚好越过慢线，买入全部\rif crossover(self.sma1[:tick], self.sma2[:tick]):\rself.buy()\r# 如果是慢线刚好越过快线，卖出全部\relif crossover(self.sma2[:tick], self.sma1[:tick]):\rself.sell()\r# 否则，这个时刻不执行任何操作。\relse:\rpass 模拟交易 link到这里，我们的回测就只差最后一块儿了。胜利就在眼前，我们继续加油。\n我们前面提到过，交易所类负责模拟交易，而模拟的基础，就是需要当前市场的价格。这里，我们可以用OHLC中的Close，作为那个时刻的价格。\n此外，为了简化设计，我们假设买卖操作都利用的是当前账户的所有资金、仓位，且市场容量足够大。这样，我们的下单请求就能够马上完全执行。\n也别忘了手续费这个大头。考虑到有手续费的情况，此时，我们最核心的买卖函数应该怎么来写呢？\n我们一起来想这个问题。假设，我们现在有1000.0元，此时BTC的价格是100.00元（当然没有这么好的事情啊，这里只是假设），并且交易手续费为1%。那么，我们能买到多少BTC呢？\n我们可以采用这种算法：\n买到的数量 = 投入的资金 * (1.0 - 手续费) / 价格 那么此时，你就能收到9.9个BTC。\n类似的，卖出的时候结算方式如下，也不难理解：\n卖出的收益 = 持有的数量 * 价格 * (1.0 - 手续费) 所以，最终模拟交易所类的实现，你可以参考下面这段代码：\nfrom utils import read_file, assert_msg, crossover, SMA\rclass ExchangeAPI:\rdef __init__(self, data, cash, commission):\rassert_msg(0 \u003c cash, \"初始现金数量大于0，输入的现金数量：{}\".format(cash))\rassert_msg(0 \u003c= commission \u003c= 0.05, \"合理的手续费率一般不会超过5%，输入的费率：{}\".format(commission))\rself._inital_cash = cash\rself._data = data\rself._commission = commission\rself._position = 0\rself._cash = cash\rself._i = 0\r@property\rdef cash(self):\r\"\"\"\r:return: 返回当前账户现金数量\r\"\"\"\rreturn self._cash\r@property\rdef position(self):\r\"\"\"\r:return: 返回当前账户仓位\r\"\"\"\rreturn self._position\r@property\rdef initial_cash(self):\r\"\"\"\r:return: 返回初始现金数量\r\"\"\"\rreturn self._inital_cash\r@property\rdef market_value(self):\r\"\"\"\r:return: 返回当前市值\r\"\"\"\rreturn self._cash + self._position * self.current_price\r@property\rdef current_price(self):\r\"\"\"\r:return: 返回当前市场价格\r\"\"\"\rreturn self._data.Close[self._i]\rdef buy(self):\r\"\"\"\r用当前账户剩余资金，按照市场价格全部买入\r\"\"\"\rself._position = float(self._cash / (self.current_price * (1 + self._commission)))\rself._cash = 0.0\rdef sell(self):\r\"\"\"\r卖出当前账户剩余持仓\r\"\"\"\rself._cash += float(self._position * self.current_price * (1 - self._commission))\rself._position = 0.0\rdef next(self, tick):\rself._i = tick 其中的current_price（当前价格），可以方便地获得模拟交易所当前时刻的商品价格；而market_value，则可以获得当前总市值。在初始化函数的时候，我们检查手续费率和输入的现金数量，是不是在一个合理的范围。\n有了所有的这些部分，我们就可以来模拟回测啦！\n首先，我们设置初始资金量为10000.00美元，交易所手续费率为0。这里你可以猜一下，如果我们从2015年到现在，都按照SMA来买卖，现在应该有多少钱呢？\ndef main():\rBTCUSD = read_file('BTCUSD_GEMINI.csv')\rret = Backtest(BTCUSD, SmaCross, ExchangeAPI, 10000.0, 0.00).run()\rprint(ret)\rif __name__ == '__main__':\rmain() 铛铛铛，答案揭晓，程序将输出：\n初始市值 10000.000000\r结束市值 576361.772884\r收益 566361.772884 哇，结束时，我们将有57万美元，翻了整整57倍啊！简直不要太爽。不过，等等，这个手续费率为0，实在是有点碍眼，因为根本不可能啊。我们现在来设一个比较真实的值吧，大概千分之三，然后再来试试：\n初始市值 10000.000000\r结束市值 2036.562001\r收益 -7963.437999 什么鬼？我们变成赔钱了，只剩下2000美元了！这是真的吗？\n这是真的，也是假的。\n我说的“真”是指，如果你真的用SMA交叉这种简单的方法去交易，那么手续费摩擦和滑点等因素，确实可能让你的高频策略赔钱。\n而我说是“假”是指，这种模拟交易的方式非常粗糙。真实的市场情况，并非这么理想——比如买卖请求永远马上执行；再比如，我们在市场中进行交易的同时不会影响市场价格等，这些理想情况都是不可能的。所以，很多时候，回测永远赚钱，但实盘马上赔钱。\n总结 link这节课，我们继承上一节，介绍了回测框架的分类、数据的格式，并且带你从头开始写了一个简单的回测系统。你可以把今天的代码片段“拼”起来，这样就会得到一个简化的回测系统样例。同时，我们实现了一个简单的交易策略，并且在真实的历史数据上运行了回测结果。我们观察到，在加入手续费后，策略的收益情况发生了显著的变化。\n思考题 link最后，给你留一个思考题。之前我们介绍了如何抓取tick数据，你可以根据抓取的tick数据，生成5分钟、每小时和每天的OHLCV数据吗？欢迎在留言区写下你的答案和问题，也欢迎你把这篇文章分享出去。\n老师，这里应该是：self._position = float(self._cash * (1-self._commission) / (self.current_price))吧？2020-08-11马建华 👍（3） 💬（0）assert_msg(isinstance(commission, Number), 'commission不是浮点数值类型')为何不是用float而是number2020-08-10宋强 👍（2） 💬（1）按照代码逻辑实现了一遍，发现即便是交易经手费是0，最后的收益也很大取决于数据本身。策略并不一定能盈利2020-02-11小侠龙旋风 👍（1） 💬（0）SMA函数只做了一件事：pd.Series(values).rolling(n).mean() 将传入的values转成一位数组以n个数据为单位滚动切分取平均值，返回一个均值数组 SMA的调用位置： SmaCross在继承Strategy后必须要重写的抽象方法init中： self.sma1 = self.I(SMA, self.data.Close, self.fast) # 用收盘价计算的10日均线 self.sma2 = self.I(SMA, self.data.Close, self.slow) # 用收盘价计算的20日均线\n提议：数据可视化更能直观表达实现策略的方案。2019-09-01小侠龙旋风 👍（1） 💬（0）30日均线、10日均线、5日均线、小时、分钟… 大窗口SMA -\u003e 小窗口SMA 策略：小窗口SMA从下穿过大窗口SMA，买入。大窗口SMA从下方突破小窗口 SMA，卖出。 这要先看看股市的简单策略分析才能明白。刚开始看，完全不懂。。。2019-09-01长青 👍（1） 💬（1）老师iself._indicators.append(value)这一步有有什么意义呢 没大看明白。还有 buy和sell是不是应该在下一根K线执行才对？比如我指标计算时用的15分钟K线 在10:15分出现买卖信号后，应该在10:30执行操作 ，因为指标时根据收盘价计算的\n"
            }
        );
    index.add(
            {
                id:  46 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/37---kafka--zmq%E8%87%AA%E5%8A%A8%E5%8C%96%E4%BA%A4%E6%98%93%E6%B5%81%E6%B0%B4%E7%BA%BF\/",
                title: "Kafka \u0026 ZMQ：自动化交易流水线",
                description: "你好，我是景霄。\n在进行这节课的学习前，我们先来回顾一下，前面三节课，我们学了些什么。\n第 34 讲，我们介绍了如何通过 RESTful API 在交易所下单；第 35 讲，我们讲解了如何通过 Websocket ，来获取交易所的 orderbook 数据；第 36 讲，我们介绍了如何实现一个策略，以及如何对策略进行历史回测。\n事实上，到这里，一个简单的、可以运作的量化交易系统已经成型了。你可以对策略进行反复修改，期待能得到不错的 PnL。但是，对于一个完善的量化交易系统来说，只有基本骨架还是不够的。\n在大型量化交易公司，系统一般是分布式运行的，各个模块独立在不同的机器上，然后互相连接来实现。即使是个人的交易系统，在进行诸如高频套利等算法时，也需要将执行层布置在靠近交易所的机器节点上。\n所以，从今天这节课开始，我们继续回到 Python 的技术栈，从量化交易系统这个角度切入，为你讲解如何实现分布式系统之间的复杂协作。\n中间件 link我们先来介绍一下中间件这个概念。中间件，是将技术底层工具和应用层进行连接的组件。它要实现的效果则是，让我们这些需要利用服务的工程师，不必去关心底层的具体实现。我们只需要拿着中间件的接口来用就好了。\n这个概念听起来并不难理解，我们再举个例子让你彻底明白。比如拿数据库来说，底层数据库有很多很多种，从关系型数据库 MySQL 到非关系型数据库 NoSQL，从分布式数据库 Spanner 到内存数据库 Redis，不同的数据库有不同的使用场景，也有着不同的优缺点，更有着不同的调用方式。那么中间件起什么作用呢？\n中间件，等于在这些不同的数据库上加了一层逻辑，这一层逻辑专门用来和数据库打交道，而对外只需要暴露同一个接口即可。这样一来，上层的程序员调用中间件接口时，只需要让中间件指定好数据库即可，其他参数完全一致，极大地方便了上层的开发；同时，下层技术栈在更新换代的时候，也可以做到和上层完全分离，不影响程序员的使用。\n它们之间的逻辑关系，你可以参照下面我画的这张图。我习惯性把中间件的作用调侃为：没有什么事情是加一层解决不了的；如果有，那就加两层。\n当然，这只是其中一个例子，也只是中间件的一种形式。事实上，比如在阿里，中间件主要有分布式关系型数据库 DRDS、消息队列和分布式服务这么三种形式。而我们今天，主要会用到消息队列，因为它非常符合量化交易系统的应用场景，即事件驱动模型。\n消息队列 link那么，什么是消息队列呢？一如其名，消息，即互联网信息传递的个体；而队列，学过算法和数据结构的你，应该很清楚这个 FIFO（先进先出）的数据结构吧。（如果算法基础不太牢，建议你可以学习极客时间平台上王争老师的“数据结构与算法之美”专栏，第 09讲即为队列知识）\n",
                content: "你好，我是景霄。\n在进行这节课的学习前，我们先来回顾一下，前面三节课，我们学了些什么。\n第 34 讲，我们介绍了如何通过 RESTful API 在交易所下单；第 35 讲，我们讲解了如何通过 Websocket ，来获取交易所的 orderbook 数据；第 36 讲，我们介绍了如何实现一个策略，以及如何对策略进行历史回测。\n事实上，到这里，一个简单的、可以运作的量化交易系统已经成型了。你可以对策略进行反复修改，期待能得到不错的 PnL。但是，对于一个完善的量化交易系统来说，只有基本骨架还是不够的。\n在大型量化交易公司，系统一般是分布式运行的，各个模块独立在不同的机器上，然后互相连接来实现。即使是个人的交易系统，在进行诸如高频套利等算法时，也需要将执行层布置在靠近交易所的机器节点上。\n所以，从今天这节课开始，我们继续回到 Python 的技术栈，从量化交易系统这个角度切入，为你讲解如何实现分布式系统之间的复杂协作。\n中间件 link我们先来介绍一下中间件这个概念。中间件，是将技术底层工具和应用层进行连接的组件。它要实现的效果则是，让我们这些需要利用服务的工程师，不必去关心底层的具体实现。我们只需要拿着中间件的接口来用就好了。\n这个概念听起来并不难理解，我们再举个例子让你彻底明白。比如拿数据库来说，底层数据库有很多很多种，从关系型数据库 MySQL 到非关系型数据库 NoSQL，从分布式数据库 Spanner 到内存数据库 Redis，不同的数据库有不同的使用场景，也有着不同的优缺点，更有着不同的调用方式。那么中间件起什么作用呢？\n中间件，等于在这些不同的数据库上加了一层逻辑，这一层逻辑专门用来和数据库打交道，而对外只需要暴露同一个接口即可。这样一来，上层的程序员调用中间件接口时，只需要让中间件指定好数据库即可，其他参数完全一致，极大地方便了上层的开发；同时，下层技术栈在更新换代的时候，也可以做到和上层完全分离，不影响程序员的使用。\n它们之间的逻辑关系，你可以参照下面我画的这张图。我习惯性把中间件的作用调侃为：没有什么事情是加一层解决不了的；如果有，那就加两层。\n当然，这只是其中一个例子，也只是中间件的一种形式。事实上，比如在阿里，中间件主要有分布式关系型数据库 DRDS、消息队列和分布式服务这么三种形式。而我们今天，主要会用到消息队列，因为它非常符合量化交易系统的应用场景，即事件驱动模型。\n消息队列 link那么，什么是消息队列呢？一如其名，消息，即互联网信息传递的个体；而队列，学过算法和数据结构的你，应该很清楚这个 FIFO（先进先出）的数据结构吧。（如果算法基础不太牢，建议你可以学习极客时间平台上王争老师的“数据结构与算法之美”专栏，第 09讲即为队列知识）\n简而言之，消息队列就是一个临时存放消息的容器，有人向消息队列中推送消息；有人则监听消息队列，发现新消息就会取走。根据我们刚刚对中间件的解释，清晰可见，消息队列也是一种中间件。\n目前，市面上使用较多的消息队列有 RabbitMQ、Kafka、RocketMQ、ZMQ 等。不过今天，我只介绍最常用的 ZMQ 和 Kafka。\n我们先来想想，消息队列作为中间件有什么特点呢？\n首先是严格的时序性。刚刚说了，队列是一种先进先出的数据结构，你丢给它 1, 2, 3，然后另一个人从里面取数据，那么取出来的一定也是 1, 2, 3，严格保证了先进去的数据先出去，后进去的数据后出去。显然，这也是消息机制中必须要保证的一点，不然颠三倒四的结果一定不是我们想要的。\n说到队列的特点，简单提一句，与“先进先出“相对的是栈这种数据结构，它是先进后出的，你丢给它 1, 2, 3，再从里面取出来的时候，拿到的就是3, 2, 1了，这一点一定要区分清楚。\n其次，是分布式网络系统的老生常谈问题。如何保证消息不丢失？如何保证消息不重复？这一切，消息队列在设计的时候都已经考虑好了，你只需要拿来用就可以，不必过多深究。\n不过，很重要的一点，消息队列是如何降低系统复杂度，起到中间件的解耦作用呢？我们来看下面这张图。\n消息队列的模式是发布和订阅，一个或多个消息发布者可以发布消息，一个或多个消息接受者可以订阅消息。 从图中你可以看到，消息发布者和消息接受者之间没有直接耦合，其中，\n消息发布者将消息发送到分布式消息队列后，就结束了对消息的处理； 消息接受者从分布式消息队列获取该消息后，即可进行后续处理，并不需要探寻这个消息从何而来。 至于新增业务的问题，只要你对这类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，所以也就实现了业务的可扩展性设计。\n讲了这么多概念层的东西，想必你迫不及待地想看具体代码了吧。接下来，我们来看一下 ZMQ 的实现。\nZMQ link先来看 ZMQ，这是一个非常轻量级的消息队列实现。\n作者 Pieter Hintjens 是一位大牛，他本人的经历也很传奇，2010年诊断出胆管癌，并成功做了手术切除。但2016年4月，却发现癌症大面积扩散到了肺部，已经无法治疗。他写的最后一篇通信模式是关于死亡协议的，之后在比利时选择接受安乐死。\nZMQ 是一个简单好用的传输层，它有三种使用模式：\nRequest - Reply 模式； Publish - Subscribe 模式； Parallel Pipeline 模式。 第一种模式很简单，client 发消息给 server，server 处理后返回给 client，完成一次交互。这个场景你一定很熟悉吧，没错，和 HTTP 模式非常像，所以这里我就不重点介绍了。至于第三种模式，与今天内容无关，这里我也不做深入讲解。\n我们需要详细来看的是第二种，即“PubSub”模式。下面是它的具体实现，代码很清晰，你应该很容易理解：\n# 订阅者 1\rimport zmq\rdef run():\rcontext = zmq.Context()\rsocket = context.socket(zmq.SUB)\rsocket.connect('tcp://127.0.0.1:6666')\rsocket.setsockopt_string(zmq.SUBSCRIBE, '')\rprint('client 1')\rwhile True:\rmsg = socket.recv()\rprint(\"msg: %s\" % msg)\rif __name__ == '__main__':\rrun()\r########## 输出 ##########\rclient 1\rmsg: b'server cnt 1'\rmsg: b'server cnt 2'\rmsg: b'server cnt 3'\rmsg: b'server cnt 4'\rmsg: b'server cnt 5' # 订阅者 2\rimport zmq\rdef run():\rcontext = zmq.Context()\rsocket = context.socket(zmq.SUB)\rsocket.connect('tcp://127.0.0.1:6666')\rsocket.setsockopt_string(zmq.SUBSCRIBE, '')\rprint('client 2')\rwhile True:\rmsg = socket.recv()\rprint(\"msg: %s\" % msg)\rif __name__ == '__main__':\rrun()\r########## 输出 ##########\rclient 2\rmsg: b'server cnt 1'\rmsg: b'server cnt 2'\rmsg: b'server cnt 3'\rmsg: b'server cnt 4'\rmsg: b'server cnt 5' # 发布者\rimport time\rimport zmq\rdef run():\rcontext = zmq.Context()\rsocket = context.socket(zmq.PUB)\rsocket.bind('tcp://*:6666')\rcnt = 1\rwhile True:\rtime.sleep(1)\rsocket.send_string('server cnt {}'.format(cnt))\rprint('send {}'.format(cnt))\rcnt += 1\rif __name__ == '__main__':\rrun()\r########## 输出 ##########\rsend 1\rsend 2\rsend 3\rsend 4\rsend 5 这里要注意的一点是，如果你想要运行代码，请先运行两个订阅者，然后再打开发布者。\n接下来，我来简单讲解一下。\n对于订阅者，我们要做的是创建一个 zmq Context，连接 socket 到指定端口。其中，setsockopt_string() 函数用来过滤特定的消息，而下面这行代码：\nsocket.setsockopt_string(zmq.SUBSCRIBE, '') 则表示不过滤任何消息。最后，我们调用 socket.recv() 来接受消息就行了，这条语句会阻塞在这里，直到有新消息来临。\n对于发布者，我们同样要创建一个 zmq Context，绑定到指定端口，不过请注意，这里用的是 bind 而不是 connect。因为在任何情况下，同一个地址端口 bind 只能有一个，但却可以有很多个 connect 链接到这个地方。初始化完成后，再调用 socket.send_string ，即可将我们想要发送的内容发送给 ZMQ。\n当然，这里还有几个需要注意的地方。首先，有了 send_string，我们其实已经可以通过 JSON 序列化，来传递几乎我们想要的所有数据结构，这里的数据流结构就已经很清楚了。\n另外，把发布者的 time.sleep(1) 放在 while 循环的最后，严格来说应该是不影响结果的。这里你可以尝试做个实验，看看会发生什么。\n你还可以思考下另一个问题，如果这里是多个发布者，那么 ZMQ 应该怎么做呢？\nKafka link接着我们再来看一下 Kafka。\n通过代码实现你也可以发现，ZMQ 的优点主要在轻量、开源和方便易用上，但在工业级别的应用中，大部分人还是会转向 Kafka 这样的有充足支持的轮子上。\n相比而言，Kafka 提供了点对点网络和发布订阅模型的支持，这也是用途最广泛的两种消息队列模型。而且和 ZMQ 一样，Kafka 也是完全开源的，因此你也能得到开源社区的充分支持。\nKafka的代码实现，和ZMQ大同小异，这里我就不专门讲解了。关于Kafka的更多内容，极客时间平台也有对 Kafka 的专门详细的介绍，对此有兴趣的同学，可以在极客时间中搜索“Kafka核心技术与实战”，这个专栏里，胡夕老师用详实的篇幅，讲解了 Kafka 的实战和内核，你可以加以学习和使用。\n来自极客时间专栏“Kafka核心技术与实战”\n基于消息队列的 Orderbook 数据流 link最后回到我们的量化交易系统上。\n量化交易系统中，获取 orderbook 一般有两种用途：策略端获取实时数据，用来做决策；备份在文件或者数据库中，方便让策略和回测系统将来使用。\n如果我们直接单机监听交易所的消息，风险将会变得很大，这在分布式系统中叫做 Single Point Failure。一旦这台机器出了故障，或者网络连接突然中断，我们的交易系统将立刻暴露于风险中。\n于是，一个很自然的想法就是，我们可以在不同地区放置不同的机器，使用不同的网络同时连接到交易所，然后将这些机器收集到的信息汇总、去重，最后生成我们需要的准确数据。相应的拓扑图如下：\n当然，这种做法也有很明显的缺点：因为要同时等待多个数据服务器的数据，再加上消息队列的潜在处理延迟和网络延迟，对策略服务器而言，可能要增加几十到数百毫秒的延迟。如果是一些高频或者滑点要求比较高的策略，这种做法需要谨慎考虑。\n但是，对于低频策略、波段策略，这种延迟换来的整个系统的稳定性和架构的解耦性，还是非常值得的。不过，你仍然需要注意，这种情况下，消息队列服务器有可能成为瓶颈，也就是刚刚所说的Single Point Failure，一旦此处断开，依然会将系统置于风险之中。\n事实上，我们可以使用一些很成熟的系统，例如阿里的消息队列，AWS 的 Simple Queue Service 等等，使用这些非常成熟的消息队列系统，风险也将会最小化。\n总结 link这节课，我们分析了现代化软件工程领域中的中间件系统，以及其中的主要应用——消息队列。我们讲解了最基础的消息队列的模式，包括点对点模型、发布者订阅者模型，和一些其他消息队列自己支持的模型。\n在真实的项目设计中，我们要根据自己的产品需求，来选择使用不同的模型；同时也要在编程实践中，加深对不同技能点的了解，对系统复杂性进行解耦，这才是设计出高质量系统的必经之路。\n思考题 link今天的思考题，文中我也提到过，这里再专门列出强调一下。在ZMQ 那里，我提出了两个问题：\n如果你试着把发布者的 time.sleep(1) 放在 while 循环的最后，会发生什么？为什么？ 如果有多个发布者，ZMQ 应该怎么做呢？ 欢迎留言写下你的思考和疑惑，也欢迎你把这篇文章分享给更多的人一起学习。\n（2）对于有多个发布者，zmq要求不同的发布者绑定到不同的端口，多个发布者还是可以正常发送信息，而对于订阅者，需要绑定对应的发布者端口才能接受到发布者发送的信息。\n以上见解，有错误之处请老师指正。2020-03-07hel793 👍（1） 💬（0）需安装 pyzmq2019-09-14小侠龙旋风 👍（1） 💬（0）socket.bind('tcp://:6666')这句话里域名写成是不是指任意域名？2019-08-04张申傲 👍（0） 💬（0）第37讲打卡~2024-07-17Geek_fc975d 👍（0） 💬（0）老师，使用pip install zmq的安装方式安装后，发现很多函数不能用，请教这是怎么回事？2022-04-2306 👍（0） 💬（0）文章提到中低频策略可以使用消息队列提高稳定性，那么高频策略有没有类似的实现？2021-09-04\n"
            }
        );
    index.add(
            {
                id:  47 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/38---mysql%E6%97%A5%E5%BF%97%E5%92%8C%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F\/",
                title: "MySQL：日志和数据存储系统",
                description: "你好，我是景霄。今天这节课，我们来聊聊日志和存储系统。\n在互联网公司中，日志系统是一个非常重要的技术底层。在每一次重要的交互行为中，关键信息都会被记录下来存档，以供日后线下分析，或者线上实时分析。这些数据，甚至可以说是硅谷互联网大公司的命脉所在。\n有了它们，你才能建立机器学习模型来预测用户的行为，从而可以精确描绘用户画像，然后针对性地使用推荐系统、分类器，将用户进一步留下，并精准推送广告来盈利。\n在量化交易中，日志同样有着非常重要的作用。一如前面所讲，我们重要的数据有：行情数据、策略信号、执行情况、仓位信息等等非常多的信息。\n对于简单的、小规模的数据，例如 orderbook 信息，我们完全可以把数据存在 txt、csv 文件中，这样做简单高效。不过，缺点是，随着数据量上升，一个文件将会变得非常大，检索起来也不容易。这时，一个很直观的方式出现了，我们可以把每天的数据存在一个文件中，这样就暂时缓解了尴尬。\n但是，随着数据量的上升，或者是你的算法逐渐来到高频交易领域时，简单地把数据存在文件上，已经不足以满足新的需求，更无法应对分布式量化交易系统的需求。于是，一个显而易见的想法就是，我们可以把日志存在数据库系统中。\n这节课，我们就以 MySQL 这种传统型关系数据库为例，讲解一下数据库在日志中的运用。\n快速理解MySQL link担心一些同学没有数据库的基础，我先来简单介绍一下 MySQL 数据库。\nMySQL 属于典型的关系型数据库（RDBMS），所谓的关系型数据库，就是指建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法，来处理数据库中的数据。基本上任何学习资料都会告诉你，它有着下面这几个特征：\n数据是以表格的形式出现的； 每一行是各种记录名称； 每一列是记录名称所对应的数据域； 许多的行和列，组成一张表单； 若干的表单，组成数据库（database）这个整体。 不过，抛开这些抽象的特征不谈，你首先需要掌握的，是下面这些术语的概念。\n数据库，是一些关联表的集合；而数据表则是数据的矩阵。在一个数据库中，数据表看起来就像是一个简单的电子表格。 在数据表中，每一列包含的是相同类型的数据；每一行则是一组相关的数据。 主键也是数据表中的一个列，只不过，这一列的每行元素都是唯一的，且一个数据表中只能包含一个主键；而外键则用于关联两个表。 除此之外，你还需要了解索引。索引是对数据库表中一列或多列的值进行排序的一种结构。使用索引，我们可以快速访问数据库表中的特定信息。一般来说，你可以对很多列设置索引，这样在检索指定列的时候，就大大加快了速度，当然，代价是插入数据会变得更慢。\n至于操作 MySQL，一般用的是结构化查询语言SQL。SQL是一种典型的领域专用语言（domain-specific language，简称DSL），这里我就不做过多介绍了，如果你感兴趣，可以学习极客时间平台上的“SQL必知必会”专栏。\n",
                content: "你好，我是景霄。今天这节课，我们来聊聊日志和存储系统。\n在互联网公司中，日志系统是一个非常重要的技术底层。在每一次重要的交互行为中，关键信息都会被记录下来存档，以供日后线下分析，或者线上实时分析。这些数据，甚至可以说是硅谷互联网大公司的命脉所在。\n有了它们，你才能建立机器学习模型来预测用户的行为，从而可以精确描绘用户画像，然后针对性地使用推荐系统、分类器，将用户进一步留下，并精准推送广告来盈利。\n在量化交易中，日志同样有着非常重要的作用。一如前面所讲，我们重要的数据有：行情数据、策略信号、执行情况、仓位信息等等非常多的信息。\n对于简单的、小规模的数据，例如 orderbook 信息，我们完全可以把数据存在 txt、csv 文件中，这样做简单高效。不过，缺点是，随着数据量上升，一个文件将会变得非常大，检索起来也不容易。这时，一个很直观的方式出现了，我们可以把每天的数据存在一个文件中，这样就暂时缓解了尴尬。\n但是，随着数据量的上升，或者是你的算法逐渐来到高频交易领域时，简单地把数据存在文件上，已经不足以满足新的需求，更无法应对分布式量化交易系统的需求。于是，一个显而易见的想法就是，我们可以把日志存在数据库系统中。\n这节课，我们就以 MySQL 这种传统型关系数据库为例，讲解一下数据库在日志中的运用。\n快速理解MySQL link担心一些同学没有数据库的基础，我先来简单介绍一下 MySQL 数据库。\nMySQL 属于典型的关系型数据库（RDBMS），所谓的关系型数据库，就是指建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法，来处理数据库中的数据。基本上任何学习资料都会告诉你，它有着下面这几个特征：\n数据是以表格的形式出现的； 每一行是各种记录名称； 每一列是记录名称所对应的数据域； 许多的行和列，组成一张表单； 若干的表单，组成数据库（database）这个整体。 不过，抛开这些抽象的特征不谈，你首先需要掌握的，是下面这些术语的概念。\n数据库，是一些关联表的集合；而数据表则是数据的矩阵。在一个数据库中，数据表看起来就像是一个简单的电子表格。 在数据表中，每一列包含的是相同类型的数据；每一行则是一组相关的数据。 主键也是数据表中的一个列，只不过，这一列的每行元素都是唯一的，且一个数据表中只能包含一个主键；而外键则用于关联两个表。 除此之外，你还需要了解索引。索引是对数据库表中一列或多列的值进行排序的一种结构。使用索引，我们可以快速访问数据库表中的特定信息。一般来说，你可以对很多列设置索引，这样在检索指定列的时候，就大大加快了速度，当然，代价是插入数据会变得更慢。\n至于操作 MySQL，一般用的是结构化查询语言SQL。SQL是一种典型的领域专用语言（domain-specific language，简称DSL），这里我就不做过多介绍了，如果你感兴趣，可以学习极客时间平台上的“SQL必知必会”专栏。\n接下来，我们就来简单看一下，如何使用 Python 来操作 MySQL 数据库。\nPython 连接数据库的方式有好多种，这里我简单介绍其中两种。我们以 Ubuntu 为例，假设你的系统中已经安装过 MySQL Server。（安装 MySQL可以参考这篇文章 https://www.jianshu.com/p/3111290b87f4，或者你可以自行搜索解决）\nmysqlclient link事实上， Python 连接 MySQL 最流行的一个驱动是 MySQL-python，又叫 MySQLdb，很多框架都也是基于此库进行开发。不过，遗憾的是，它只支持 Python2.x，而且安装的时候有很多前置条件。因为它是基于C开发的库，在 Windows 平台安装非常不友好，经常出现失败的情况。所以，现在我们基本不再推荐使用，取代者是它的衍生版本——mysqlclient。\nmysqlclient 完全兼容 MySQLdb，同时支持 Python3.x，是 Django ORM的依赖工具。如果你想使用原生 SQL 来操作数据库，那么我优先推荐使用这个框架。\n它的安装方式很简单：\nsudo apt-get install python3-dev\rpip install mysqlclient 我们来看一个样例代码：\nimport MySQLdb\rdef test_pymysql():\rconn = MySQLdb.connect(\rhost='localhost',\rport=3306,\ruser='your_username',\rpasswd=your_password’,\rdb='mysql'\r)\rcur = conn.cursor()\rcur.execute('''\rCREATE TABLE price (\rtimestamp TIMESTAMP NOT NULL,\rBTCUSD FLOAT(8,2),\rPRIMARY KEY (timestamp)\r);\r''')\rcur.execute('''\rINSERT INTO price VALUES(\r\"2019-07-14 14:12:17\",\r11234.56\r);\r''')\rconn.commit()\rconn.close()\rtest_pymy 代码的思路很清晰明了，首先是通过 connect 命令连接数据库，来创建一个连接；之后，通过 conn.cursor() 函数创建一个游标。这里你可能会问，为什么要使用游标呢？\n一个主要的原因就是，这样可以把集合操作转换成单个记录处理的方式。如果用 SQL 语言从数据库中检索数据，结果会放在内存的一块区域中，并且这个结果往往是一个含有多个记录的集合。而游标机制，则允许用户在 MySQL 内逐行地访问这些记录，这样你就可以按照自己的意愿，来显示和处理这些记录。\n继续回到代码中，再往下走，我们创建了一个 price table，同时向里面插入一条 orderbook 数据。这里为了简化代码突出重点，我只保留了 timestamp 和 price。\n最后，我们使用 conn.commit() 来提交更改，然后 close() 掉连接就可以了。\npeewee link不过，大家逐渐发现，写原生的 SQL 命令很麻烦。因为你需要根据特定的业务逻辑，来构造特定的插入和查询语句，这样可以说就完全抛弃了面向对象的思维。因此，又诞生了很多封装 wrapper 包和 ORM 框架。\n这里所说的ORM（Object Relational Mapping，简称ORM） ，是 Python 对象与数据库关系表的一种映射关系，有了 ORM 后，我们就不再需要写 SQL 语句，而可以直接使用 Python 的数据结构了。\nORM 框架的优点，是提高了写代码的速度，同时兼容多种数据库系统，如SQLite、MySQL、PostgreSQL等这些数据库；而付出的代价，可能就是性能上的一些损失。\n接下来要讲的peewee，正是其中一种基于 Python 的 ORM 框架，它的学习成本非常低，可以说是 Python 中最流行的 ORM 框架。\n它的安装方式也很简单：\npip install peewee 我们来看一个样例代码：\nimport peewee\rfrom peewee import *\rdb = MySQLDatabase('mysql', user='your_username', passwd=your_password’)\rclass Price(peewee.Model):\rtimestamp = peewee.DateTimeField(primary_key=True)\rBTCUSD = peewee.FloatField()\rclass Meta:\rdatabase = db\rdef test_peewee():\rPrice.create_table()\rprice = Price(timestamp='2019-06-07 13:17:18', BTCUSD='12345.67')\rprice.save()\rtest_p 如果你写过 Django，你会发现，这个写法和 Django 简直一模一样。我们通过一个 Python class ，映射了 MySQL 中的一张数据表；只要对其中每一列数据格式进行定义，便可按照 Python 的方式进行操作。\n显而易见，peewee的最大优点，就是让 SQL 语言瞬间变成强类型语言，这样不仅极大地增强了可读性，也能有效减少出 bug 的概率。\n不过，事实上，作为一名数据科学家，或者作为一名量化从业者（quant ），你要处理的数据远比这些复杂很多。互联网工业界有大量的脏数据，金融行业的信噪比更是非常之低，数据处理只能算是基本功。\n如果你对数据分析有兴趣和志向，在学生时期就应该先打牢数学和统计的基础，之后在实习和工作中快速掌握数据处理的方法。当然，如果你已经错过学生时期的话，现在开始也是个不错的选择，毕竟，逐渐形成自己的核心竞争力，才是我们每个人的正道。\n量化数据分析系统 link数据库有了量化数据存入后，接下来，我们便可以开始进行一些量化分析了。这一块儿也是一个很大的学术领域，叫做时间序列分析，不过就今天这节课的主题来说，我们仅做抛砖引玉，列举一个非常简单的例子，即求过去一个小时 BTC/USD 的最高价和最低价。\n我们来看下面这段代码：\nimport MySQLdb\rimport numpy as np\rdef test_pymysql():\rconn = MySQLdb.connect(\rhost='localhost',\rport=3306,\ruser='your_username',\rpasswd='your_password',\rdb='mysql'\r)\rcur = conn.cursor()\rcur.execute('''\rSELECT\rBTCUSD\rFROM\rprice\rWHERE\rtimestamp \u003e now() - interval 60 minute\r''')\rBTCUSD = np.array(cur.fetchall())\rprint(BTCUSD.max(), BTCUSD.min())\rconn.close()\rtest_pym 代码看起来很简单吧！显然，通过 SQL 语句，我们可以抓取到过去一小时的时间序列片段，拿到我们想要的 BTC/USD 价格向量，然后通过 numpy 处理一下即可。不过这里需要注意一点，我们并不需要调用 conn.commit()，因为我们的操作是只读的，对数据库没有任何影响。\n分布式日志系统 link明白了上面的内容后，我们现在来看一下分布式日志系统。\n对量化交易而言，我们需要的模块主要有数据系统、策略系统、交易执行系统、线下模型训练、线上风控系统以及实时监控系统。它们之间的对应关系，我画了一张图，你可以参考来理解。\n这里的每个子系统都是独立运行的，并且还有许多模块需要迭代更新，所以我们简单保存本地日志显然不是一个明智之举。于是，我们可以专门开一台服务器来运行 MySQL server，并且开放指定端口和其他系统进行交互。\n另外，图中的收集系统，其实类似于上一节我们所讲的消息队列体系，在各个上游系统中运行代理工具，负责将各个模块的 log 收集起来，然后发送到收集系统中。收集系统整理过后，再将信息存到日志系统。当然，除了简单的消息队列，我们还能用很多工具，比如阿里云的Logtail、 Apache 的 Flume Agent等等。\n而到了后期，对于日志系统来说，越来越需要注意的就是存储效率和分析效率。随着使用的增加，数据会越来越多，因此我们可以考虑对一些数据进行压缩和保存。而越是久远的数据，越是粗粒度的数据，被调用的概率也就越低，所以它们也就首当其冲，成了我们压缩、保存的目标。\n日志分析 link最后，我再来补充讲一讲日志的分析。前面提到过，分析一般分为两种，离线分析和在线分析。\n在离线分析中，比较常见的是生成报告。\n比如，总结某天某月或某季度内的，收益亏损情况（PnL）、最大回撤、夏普比率等数据。这种基于时间窗口的统计，在关系型数据库中也能得到很方便的支持。\n而另一类常见的离线使用方式，则是回测系统。在一个新策略研发的周期中，我们需要对历史数据进行回测，这样就可以得到历史数据中交易的收益率等数据。回测系统对于评估一个新的策略非常重要，然而，回测往往需要大量的资源，所以选取好数据库、数据存储方式，优化数据连接和计算，就显得至关重要。\n在线分析，则更多应用于风控和警报系统。这种方式，对数据的实时性要求更高一些，于是，一种方法就是，从消息队列中直接拿最快的数据进行操作。当然，这个前提是时间窗口较小，这样你就不需要风控系统来维护大量的本地数据。\n至于实时警报，最关键的依然是数据。\n比如，数据系统异常停止，被监视的表没有更新； 或者，交易系统的连接出了故障，委托订单的某些状态超过了一定的阈值； 再或者，仓位信息出现了较大的、预计之外的变动。 这些情况都需要进行报警，也就是硅谷大公司所说的“oncall”。一旦发生意外，负责人会迅速收到电话、短信和邮件，然后通过监控平台来确认，是真的出了事故还是监控误报。\n当然，现在已经有了不少开源的工具可以在云端使用，其中 AWS 属于全球领先的云计算平台。如果你的服务器架设在美国，那就可以考虑选择它家的各种各样的云服务。这样做的好处是，对于小型量化交易团队而言，避免自己搭建复杂的日志系统，而是把主要精力放在策略的开发迭代之上，提高了不少效率。\n总结 link这一节课，我从工程的角度，为你介绍了量化系统中的存储系统。我们从基础的 MySQL 的使用方法讲起，再讲到后面的量化系统框架。数据库和数据在绝大部分互联网行业都是核心，对量化从业者来说也是重要的生产资料。而搭建一套负载合理、数据可靠的数据系统，也需要一个量化团队长期打磨，并根据需求进行迭代。\n思考题 link最后给你留一道思考题。量化交易需要的数据量不是很大，但是有可能出现调用频率极高的情况，例如回测系统。那么，你能想到哪些优化手段，来降低调用代价吗？欢迎留言和我讨论，也欢迎你把这篇文章分享出去。\n"
            }
        );
    index.add(
            {
                id:  48 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/39---django%E6%90%AD%E5%BB%BA%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0\/",
                title: "Django：搭建监控平台",
                description: "你好，我是景霄。\n通过前几节课的学习，相信你对量化交易系统已经有了一个最基本的认知，也能通过自己的代码，搭建一个简单的量化交易系统来进行盈利。\n前面几节课，我们的重点在后台代码、中间件、分布式系统和设计模式上。这节课，我们重点来看前端交互。\n监控和运维，是互联网工业链上非常重要的一环。监控的目的就是防患于未然。通过监控，我们能够及时了解到企业网络的运行状态。一旦出现安全隐患，你就可以及时预警，或者是以其他方式通知运维人员，让运维监控人员有时间处理和解决隐患，避免影响业务系统的正常使用，将一切问题的根源扼杀在摇篮当中。\n在硅谷互联网大公司中，监控和运维被称为 SRE，是公司正常运行中非常重要的一环。作为 billion 级别的 Facebook，内部自然也有着大大小小、各种各样的监控系统和运维工具，有的对标业务数据，有的对标服务器的健康状态，有的则是面向数据库和微服务的控制信息。\n不过，万变不离其宗，运维工作最重要的就是维护系统的稳定性。除了熟悉运用各种提高运维效率的工具来辅助工作外，云资源费用管理、安全管理、监控等，都需要耗费不少精力和时间。运维监控不是一朝一夕得来的，而是随着业务发展的过程中同步和发展的。\n作为量化实践内容的最后一节，今天我们就使用 Django 这个 Web 框架，来搭建一个简单的量化监控平台。\nDjango 简介和安装 linkDjango 是用 Python 开发的一个免费开源的 Web 框架，可以用来快速搭建优雅的高性能网站。它采用的是“MVC”的框架模式，即模型 M、视图 V 和控制器 C。\nDjango 最大的特色，在于将网页和数据库中复杂的关系，转化为 Python 中对应的简单关系。它的设计目的，是使常见的Web开发任务变得快速而简单。Django是开源的，不是商业项目或者科研项目，并且集中力量解决Web开发中遇到的一系列问题。所以，Django 每天都会在现有的基础上进步，以适应不断更迭的开发需求。这样既节省了开发时间，也提高了后期维护的效率。\n说了这么多，接下来，我们通过上手使用进一步来了解。先来看一下，如何安装和使用 Django。你可以先按照下面代码块的内容来操作，安装Django ：\npip3 install Django\rdjango-admin --version\r########## 输出 ##########\r2.2.3 接着，我们来创建一个新的 Django 项目：\ndjango-admin startproject TradingMonitor\rcd TradingMonitor/\rpython3 manage.py migrate\r########## 输出 ########## Applying contenttypes.0001_initial... OK\rApplying auth.0001_initial... OK\rApplying admin.0001_initial... OK\rApplying admin.0002_logentry_remove_auto_add... OK\rApplying admin.0003_logentry_add_action_flag_choices... OK\rApplying contenttypes.0002_remove_content_type_name... OK\rApplying auth.0002_alter_permission_name_max_length... OK\rApplying auth.0003_alter_user_email_max_length... OK\rApplying auth.0004_alter_user_username_opts... OK\rApplying auth.0005_alter_user_last_login_null... OK\rApplying auth.0006_require_contenttypes_0002... OK\rApplying auth.0007_alter_validators_add_error_messages... OK\rApplying auth.0008_alter_user_username_max_length... OK\rApplying auth.0009_alter_user_last_name_max_length... OK\rApplying auth.0010_alter_group_name_max_length... OK\rApplying auth.0011_update_proxy_permissions... OK\rApplying sessions.0001_initial... OK 这时，你能看到文件系统大概是下面这样的：\n",
                content: "你好，我是景霄。\n通过前几节课的学习，相信你对量化交易系统已经有了一个最基本的认知，也能通过自己的代码，搭建一个简单的量化交易系统来进行盈利。\n前面几节课，我们的重点在后台代码、中间件、分布式系统和设计模式上。这节课，我们重点来看前端交互。\n监控和运维，是互联网工业链上非常重要的一环。监控的目的就是防患于未然。通过监控，我们能够及时了解到企业网络的运行状态。一旦出现安全隐患，你就可以及时预警，或者是以其他方式通知运维人员，让运维监控人员有时间处理和解决隐患，避免影响业务系统的正常使用，将一切问题的根源扼杀在摇篮当中。\n在硅谷互联网大公司中，监控和运维被称为 SRE，是公司正常运行中非常重要的一环。作为 billion 级别的 Facebook，内部自然也有着大大小小、各种各样的监控系统和运维工具，有的对标业务数据，有的对标服务器的健康状态，有的则是面向数据库和微服务的控制信息。\n不过，万变不离其宗，运维工作最重要的就是维护系统的稳定性。除了熟悉运用各种提高运维效率的工具来辅助工作外，云资源费用管理、安全管理、监控等，都需要耗费不少精力和时间。运维监控不是一朝一夕得来的，而是随着业务发展的过程中同步和发展的。\n作为量化实践内容的最后一节，今天我们就使用 Django 这个 Web 框架，来搭建一个简单的量化监控平台。\nDjango 简介和安装 linkDjango 是用 Python 开发的一个免费开源的 Web 框架，可以用来快速搭建优雅的高性能网站。它采用的是“MVC”的框架模式，即模型 M、视图 V 和控制器 C。\nDjango 最大的特色，在于将网页和数据库中复杂的关系，转化为 Python 中对应的简单关系。它的设计目的，是使常见的Web开发任务变得快速而简单。Django是开源的，不是商业项目或者科研项目，并且集中力量解决Web开发中遇到的一系列问题。所以，Django 每天都会在现有的基础上进步，以适应不断更迭的开发需求。这样既节省了开发时间，也提高了后期维护的效率。\n说了这么多，接下来，我们通过上手使用进一步来了解。先来看一下，如何安装和使用 Django。你可以先按照下面代码块的内容来操作，安装Django ：\npip3 install Django\rdjango-admin --version\r########## 输出 ##########\r2.2.3 接着，我们来创建一个新的 Django 项目：\ndjango-admin startproject TradingMonitor\rcd TradingMonitor/\rpython3 manage.py migrate\r########## 输出 ########## Applying contenttypes.0001_initial... OK\rApplying auth.0001_initial... OK\rApplying admin.0001_initial... OK\rApplying admin.0002_logentry_remove_auto_add... OK\rApplying admin.0003_logentry_add_action_flag_choices... OK\rApplying contenttypes.0002_remove_content_type_name... OK\rApplying auth.0002_alter_permission_name_max_length... OK\rApplying auth.0003_alter_user_email_max_length... OK\rApplying auth.0004_alter_user_username_opts... OK\rApplying auth.0005_alter_user_last_login_null... OK\rApplying auth.0006_require_contenttypes_0002... OK\rApplying auth.0007_alter_validators_add_error_messages... OK\rApplying auth.0008_alter_user_username_max_length... OK\rApplying auth.0009_alter_user_last_name_max_length... OK\rApplying auth.0010_alter_group_name_max_length... OK\rApplying auth.0011_update_proxy_permissions... OK\rApplying sessions.0001_initial... OK 这时，你能看到文件系统大概是下面这样的：\nTradingMonitor/\r├── TradingMonitor\r│ ├── __init__.py\r│ ├── settings.py\r│ ├── urls.py\r│ └── wsgi.py\r├── db.sqlite3\r└── manage.py 我简单解释一下它的意思：\nTradingMonitor/TradingMonitor，表示项目最初的 Python 包； TradingMonitor/init.py，表示一个空文件，声明所在目录的包为一个 Python 包； TradingMonitor/settings.py，管理项目的配置信息； TradingMonitor/urls.py，声明请求 URL 的映射关系； TradingMonitor/wsgi.py，表示Python 程序和 Web 服务器的通信协议； manage.py，表示一个命令行工具，用来和 Django 项目进行交互； Db.sqlite3，表示默认的数据库，可以在设置中替换成其他数据库。 另外，你可能注意到了上述命令中的python3 manage.py migrate，这个命令表示创建或更新数据库模式。每当 model 源代码被改变后，如果我们要将其应用到数据库上，就需要执行一次这个命令。\n接下来，我们为这个系统添加管理员账户：\npython3 manage.py createsuperuser\r########## 输出 ##########\rUsername (leave blank to use 'ubuntu'): admin\rEmail address: Password: Password (again): Superuser created successfully. 然后，我们来启动 Django 的 debugging 模式：\npython3 manage.py runserver 最后，打开浏览器输入：http://127.0.0.1:8000。如果你能看到下面这个画面，就说明 Django 已经部署成功了。\nDjango 的安装是不是非常简单呢？这其实也是 Python 一贯的理念，简洁，并简化入门的门槛。\nOK，现在我们再定位到 http://127.0.0.1:8000/admin，你会看到 Django 的后台管理网页，这里我就不过多介绍了。\n到此，Django 就已经成功安装，并且正常启动啦。\nMVC 架构 link刚刚我说过，MVC 架构是 Django 设计模式的精髓。接下来，我们就来具体看一下这个架构，并通过 Django 动手搭建一个服务端。\n设计模型 Model link在之前的日志和存储系统这节课中，我介绍过 peewee 这个库，它能避开通过繁琐的 SQL 语句来操作 MySQL，直接使用 Python 的 class 来进行转换。事实上，这也是 Django 采取的方式。\nDjango 无需数据库就可以使用，它通过对象关系映射器（object-relational mapping），仅使用Python代码就可以描述数据结构。\n我们先来看下面这段 Model 代码：\n# TradingMonitor/models.py\rfrom django.db import models\rclass Position(models.Model):\rasset = models.CharField(max_length=10)\rtimestamp = models.DateTimeField()\ramount = models.DecimalField(max_digits=10, decimal_places=3) models.py 文件主要用一个 Python 类来描述数据表，称为模型 。运用这个类，你可以通过简单的 Python 代码来创建、检索、更新、删除数据库中的记录，而不用写一条又一条的SQL语句，这也是我们之前所说的避免通过 SQL 操作数据库。\n在这里，我们创建了一个 Position 模型，用来表示我们的交易仓位信息。其中，\nasset 表示当前持有资产的代码，例如 btc； timestamp 表示时间戳； amount 则表示时间戳时刻的持仓信息。 设计视图 Views link在模型被定义之后，我们便可以在视图中引用模型了。通常，视图会根据参数检索数据，加载一个模板，并使用检索到的数据呈现模板。\n设计视图，则是我们用来实现业务逻辑的地方。我们来看 render_positions 这个代码，它接受 request 和 asset 两个参数，我们先不用管 request。这里的 asset 表示指定一个资产名称，例如 btc，然后这个函数返回一个渲染页面。\n# TradingMonitor/views.py\rfrom django.shortcuts import render\rfrom .models import Position\rdef render_positions(request, asset):\rpositions = Position.objects.filter(asset = asset)\rcontext = {'asset': asset, 'positions': positions}\rreturn render(request, 'positions.html', context) 不过，这个函数具体是怎么工作的呢？我们一行行来看。\npositions = Position.objects.filter(asset = asset)，这行代码向数据库中执行一个查询操作，其中， filter 表示筛选，意思是从数据库中选出所有我们需要的 asset 的信息。不过，这里我只是为你举例做示范；真正做监控的时候，我们一般会更有针对性地从数据库中筛选读取信息，而不是一口气读取出所有的信息。\ncontext = {'asset': asset, 'positions': positions}，这行代码没什么好说的，封装一个字典。至于这个字典的用处，下面的内容中可以体现。\nreturn render(request, 'positions.html', context)，最后这行代码返回一个页面。这里我们采用的模板设计，这也是 Django 非常推荐的开发方式，也就是让模板和数据分离，这样，数据只需要向其中填充即可。\n最后的模板文件是 position.html，你应该注意到了， context 作为变量传给了模板，下面我们就来看一下设计模板的内容。\n设计模板Templates link模板文件，其实就是 HTML 文件和部分代码的综合。你可以想象成，这个HTML 在最终送给用户之前，需要被我们预先处理一下，而预先处理的方式就是找到对应的地方进行替换。\n我们来看下面这段示例代码：\n# TradingMonitor/templates/positions.html\r\u003c!DOCTYPE html\u003e\rPositions for {{asset}}\rPositions for {{asset}}\rTime\rAmount\r{% for position in positions %}\r{{position.timestamp}}\r{{position.amount}}\r{% endfor %}\r我重点说一下几个地方。首先是Positions for {{asset}}，这里双大括号括住 asset 这个变量，这个变量对应的正是前面 context 字典中的 asset key。Django 的渲染引擎会将 asset ，替换成 context 中 asset 对应的内容，此处是替换成了 btc。\n再来看{% for position in positions %}，这是个很关键的地方。我们需要处理一个列表的情况，用 for 对 positions 进行迭代就行了。这里的 positions ，同样对应的是 context 中的 positions。\n末尾的{% endfor %}，自然就表示结束了。这样，我们就将数据封装到了一个列表之中。\n设计链接 Urls link最后，我们需要为我们的操作提供 URL 接口，具体操作我放在了下面的代码中，内容比较简单，我就不详细展开讲解了。\n# TradingMonitor/urls.py\rfrom django.contrib import admin\rfrom django.urls import path\rfrom . import views\rurlpatterns = [\rpath('admin/', admin.site.urls),\rpath('positions/', views.render_positions),\r] 到这里，我们就可以通过 http://127.0.0.1:8000/positions/btc 来访问啦！\n测试 link当然，除了主要流程外，我还需要强调几个很简单但非常关键的细节，不然，我们这些改变就不能被真正地应用。\n第一步，在 TradingMonitor/TradingMonitor 下，新建一个文件夹 migrations；并在这个文件夹中，新建一个空文件 __init__.py。\nmkdir TradingMonitor/migrations\rtouch TradingMonitor/migrations/__init__.py 此时，你的目录结构应该长成下面这样：\nTradingMonitor/\r├── TradingMonitor\r│ ├── migrations\r│ └── __init__.py\r│ ├── templates\r│ └── positions.html\r│ ├── __init__.py\r│ ├── settings.py\r│ ├── urls.py\r│ ├── models.py\r│ ├── views.py\r│ └── wsgi.py\r├── db.sqlite3\r└── manage.py 第二步，修改 TradingMonitor/settings.py：\nINSTALLED_APPS = [\r'django.contrib.admin',\r'django.contrib.auth',\r'django.contrib.contenttypes',\r'django.contrib.sessions',\r'django.contrib.messages',\r'django.contrib.staticfiles',\r'TradingMonitor', # 这里把我们的 app 加上\r] TEMPLATES = [\r{\r'BACKEND': 'django.template.backends.django.DjangoTemplates',\r'DIRS': [os.path.join(BASE_DIR, 'TradingMonitor/templates')], # 这里把 templates 的目录加上\r'APP_DIRS': True,\r'OPTIONS': {\r'context_processors': [\r'django.template.context_processors.debug',\r'django.template.context_processors.request',\r'django.contrib.auth.context_processors.auth',\r'django.contrib.messages.context_processors.messages',\r],\r},\r},\r] 第三步，运行 python manage.py makemigrations：\npython manage.py makemigrations\r########## 输出 ##########\rMigrations for 'TradingMonitor':\rTradingMonitor/migrations/0001_initial.py\r- Create model Position 第四步，运行 python manage.py migrate：\npython manage.py migrate\r########## 输出 ##########\rOperations to perform:\rApply all migrations: TradingMonitor, admin, auth, contenttypes, sessions\rRunning migrations:\rApplying TradingMonitor.0001_initial... OK 这几步的具体操作，我都用代码和注释表示了出来，你完全可以同步进行操作。操作完成后，现在，我们的数据结构就已经被成功同步到数据库中了。\n最后，输入 python manage.py runserver，然后打开浏览器输入http://127.0.0.1:8000/positions/btc，你就能看到效果啦。\n现在，我们再回过头来看一下 MVC 模式，通过我画的这张图，你可以看到，M、V、C这三者，以一种插件似的、松耦合的方式连接在一起：\n当然，我带你写的只是一个简单的 Django 应用程序，对于真正的量化平台监控系统而言，这还只是一个简单的开始。\n除此之外，对于监控系统来说，其实还有着非常多的开源插件可以使用。有一些界面非常酷炫，有一些可以做到很高的稳定性和易用性，它们很多都可以结合 Django 做出很好的效果来。比较典型的有：\nGraphite 是一款存储时间序列数据，并通过 Django Web 应用程序在图形中显示的插件； Vimeo 则是一个基于 Graphite 的仪表板，具有附加功能和平滑的设计； Scout 监控 Django和Flask应用程序的性能，提供自动检测视图、SQL查询、模板等。 总结 link这一节课的内容更靠近上游应用层，我们以 Django 这个 Python 后端为例，讲解了搭建一个服务端的过程。你应该发现了，使用 RESTful Framework 搭建服务器，是一个如此简单的过程，你可以去开一个自己的交易所了（笑）。相比起具体的技术，今天我所讲的 MVC 框架和 Django 的思想，更值得你去深入学习和领会。\n思考题 link今天我想给你留一个难度比较高的作业。RESTful API 在 Django 中是如何实现安全认证的？你能通过搜索和自学掌握这个知识点吗？希望可以在留言区看到你的认真学习记录和总结，我会一一给出建议。也欢迎你把这篇文章分享给你的朋友、同事，一起交流、一起进步。\n########## 输出 ##########\n2.2.3 老师 django的这些命令再Windows CMD命令框执行后不行，访问不了https://127.0.0.1:8000, 再centos 执行完所有代码 启动后django 服务，命令显示[root@localhost TradingMonitor]# python3 manage.py runserver Watching for file changes with StatReloader Performing system checks…\nSystem check identified no issues (0 silenced). August 12, 2020 - 15:59:14 Django version 3.1, using settings 'TradingMonitor.settings' Starting development server at http://127.0.0.1:8000/ Quit the server with CONTROL-C. ，但是浏览器访问失败 是什么原因2020-08-12Geek_aa780e 👍（1） 💬（0）可以讲一下在web项目中，对于非法情况，比如说数据库链接错误报的异常，该怎么处理吗？ 是直接抛到handler层，还是在哪进行捕获？ 2020-08-05\n"
            }
        );
    index.add(
            {
                id:  49 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/40---%E6%80%BB%E7%BB%93python%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%85%A8%E6%99%AF\/",
                title: "总结：Python中的数据结构与算法全景",
                description: "你好，我是景霄。\n不知不觉中，我们又一起完成了量化交易实战篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n实战篇的主要用意，是通过一个完整的技术领域，讲明白 Python 在这个领域中如何发挥作用。所以，我们在每节课都会梳理一个小知识点；同时，也在第 36 讲中，我用大量篇幅讲解了策略和回测系统，作为量化交易中最重要内容的解释。\n对于本章答疑，因为不断有同学留言询问Python中数据结构和算法相关的问题，我在这里也简单说一下。\n首先，希望你明白，我们Python 专栏的定位是有一定计算机知识基础的进阶课程，重点在 Python 的核心知识点上，默认你对基础的算法和数据结构有一定的了解。因此，在语法和技术知识点的讲解过程中，我会综合性地穿插不少数据结构的基本知识，但并不会进行深入地讲解。涉及到数据结构中的关键名词和难点，自然都会有所提及，但还是希望你有一定的自学能力来掌握。\n不过，为了进一步方便你理解Python的数据结构和算法，加深对 Python 基础内容的掌握，我在这里总结了一个综合性的提纲。如果你在这方面有所欠缺，可以参考性地借鉴学习一下。当然，有时间和精力的话，我最鼓励的是你可以通过 Python 把所有数据结构和算法实现一下。\n基础数据结构：数组，堆，栈，队列，链表 link数组自不必多说，Python 中的基础数组，满足 O(1) 的随机查找，和 O(n) 的随机插入。\n堆，严格来讲，是一种特殊的二叉树，满足 O(nlogn) 的随机插入和删除，以及 O(1) 时间复杂度拿到最大值或者最小值。堆可以用来实现优先队列，还可以在项目中实现多任务调度，有着非常广泛的应用。\n栈，是一种先进后出的数据结构，入栈和出栈操作都是 O(1) 时间复杂度。\n队列和栈对应，不过功能刚好相反，它是一种先进先出的数据结构，一如其名，先排队者先服务。入队和出队也是 O(1) 的时间复杂度。栈和队列都能用数组来实现，但是对空间的规划需要注意，特别是用数组实现的队列，我们通常用的是循环队列。\n链表则是另一种线性表，和数组的不同是，它不支持随机访问，你不能通过下标来获取链表的元素。链表的元素通过指针相连，单链表中元素可以指向后者，双链表则是让相邻的元素互相连接。\n这些基础数据结构，在 Python 中都有很好的库和包支持，从使用上来说都非常方便，但我仍然希望你对原理能有一定的了解，这样，处理起复杂问题也能得心应手不胆怯。\n进阶数据结构：无向图，有向图，树，DAG 图，字典树，哈希表 link无向图，是由顶点和边组成的数据结构，一条边连接两个顶点（如果两个顶点是一个，这条边称为自环）。一如其名，“无向”，所以它的边没有指向性。\n有向图，和无向图一样都是“图”这种数据结构，不同的是有向图的边有指向性，方向为一个顶点指向另一个顶点。\n树这种数据结构，则可以分为有根树和无根树。前者中，最常见的就是我们的二叉树，从顶点开始一级级向下，每个父结点最多有两个子结点。至于无根树，则是一种特殊的无向图，无环连通的无向图被称为无根树，它有很多特别的性质和优点，在离散数学中应用广泛。\nDAG 图，也叫做有向无环图，是一种特殊应用的数据结构，在图的动态规划问题中出现甚多。遍历 DAG 图的方式，也就是我们常说的拓扑排序，是一种图算法。DAG 可以认为是链表的图版本，如果说区块链是链表，那么区块链 3.0 时代可能就是 DAG 图。\n字典树，又被称为 Trie 树，是一种边为字符的有向图，它在字符串处理中有着非常强大的应用。广为人知的 AC 自动机，就是用 Trie 树来解决多模式字符串匹配问题。Trie 树在工业界也常被拿来做搜索提示，例如你在百度中搜索 “极客时”，就会自动跳出 “极客时间”。\n哈希表，这一定是程序员应用最广、自觉最简单的一个数据结构，比如 Python 的 dict() 就可以拿来即用，简单而自然。不过，哈希表其实有着非常深刻的内涵，冲突算法、哈希算法、扩容算法，都很值得我们去深究一下。\n",
                content: "你好，我是景霄。\n不知不觉中，我们又一起完成了量化交易实战篇的学习。我非常高兴看到很多同学一直在坚持积极地学习，并且留下了很多高质量的留言，值得我们互相思考交流。也有一些同学反复推敲，指出了文章中一些表达不严谨或是不当的地方，我也表示十分感谢。\n实战篇的主要用意，是通过一个完整的技术领域，讲明白 Python 在这个领域中如何发挥作用。所以，我们在每节课都会梳理一个小知识点；同时，也在第 36 讲中，我用大量篇幅讲解了策略和回测系统，作为量化交易中最重要内容的解释。\n对于本章答疑，因为不断有同学留言询问Python中数据结构和算法相关的问题，我在这里也简单说一下。\n首先，希望你明白，我们Python 专栏的定位是有一定计算机知识基础的进阶课程，重点在 Python 的核心知识点上，默认你对基础的算法和数据结构有一定的了解。因此，在语法和技术知识点的讲解过程中，我会综合性地穿插不少数据结构的基本知识，但并不会进行深入地讲解。涉及到数据结构中的关键名词和难点，自然都会有所提及，但还是希望你有一定的自学能力来掌握。\n不过，为了进一步方便你理解Python的数据结构和算法，加深对 Python 基础内容的掌握，我在这里总结了一个综合性的提纲。如果你在这方面有所欠缺，可以参考性地借鉴学习一下。当然，有时间和精力的话，我最鼓励的是你可以通过 Python 把所有数据结构和算法实现一下。\n基础数据结构：数组，堆，栈，队列，链表 link数组自不必多说，Python 中的基础数组，满足 O(1) 的随机查找，和 O(n) 的随机插入。\n堆，严格来讲，是一种特殊的二叉树，满足 O(nlogn) 的随机插入和删除，以及 O(1) 时间复杂度拿到最大值或者最小值。堆可以用来实现优先队列，还可以在项目中实现多任务调度，有着非常广泛的应用。\n栈，是一种先进后出的数据结构，入栈和出栈操作都是 O(1) 时间复杂度。\n队列和栈对应，不过功能刚好相反，它是一种先进先出的数据结构，一如其名，先排队者先服务。入队和出队也是 O(1) 的时间复杂度。栈和队列都能用数组来实现，但是对空间的规划需要注意，特别是用数组实现的队列，我们通常用的是循环队列。\n链表则是另一种线性表，和数组的不同是，它不支持随机访问，你不能通过下标来获取链表的元素。链表的元素通过指针相连，单链表中元素可以指向后者，双链表则是让相邻的元素互相连接。\n这些基础数据结构，在 Python 中都有很好的库和包支持，从使用上来说都非常方便，但我仍然希望你对原理能有一定的了解，这样，处理起复杂问题也能得心应手不胆怯。\n进阶数据结构：无向图，有向图，树，DAG 图，字典树，哈希表 link无向图，是由顶点和边组成的数据结构，一条边连接两个顶点（如果两个顶点是一个，这条边称为自环）。一如其名，“无向”，所以它的边没有指向性。\n有向图，和无向图一样都是“图”这种数据结构，不同的是有向图的边有指向性，方向为一个顶点指向另一个顶点。\n树这种数据结构，则可以分为有根树和无根树。前者中，最常见的就是我们的二叉树，从顶点开始一级级向下，每个父结点最多有两个子结点。至于无根树，则是一种特殊的无向图，无环连通的无向图被称为无根树，它有很多特别的性质和优点，在离散数学中应用广泛。\nDAG 图，也叫做有向无环图，是一种特殊应用的数据结构，在图的动态规划问题中出现甚多。遍历 DAG 图的方式，也就是我们常说的拓扑排序，是一种图算法。DAG 可以认为是链表的图版本，如果说区块链是链表，那么区块链 3.0 时代可能就是 DAG 图。\n字典树，又被称为 Trie 树，是一种边为字符的有向图，它在字符串处理中有着非常强大的应用。广为人知的 AC 自动机，就是用 Trie 树来解决多模式字符串匹配问题。Trie 树在工业界也常被拿来做搜索提示，例如你在百度中搜索 “极客时”，就会自动跳出 “极客时间”。\n哈希表，这一定是程序员应用最广、自觉最简单的一个数据结构，比如 Python 的 dict() 就可以拿来即用，简单而自然。不过，哈希表其实有着非常深刻的内涵，冲突算法、哈希算法、扩容算法，都很值得我们去深究一下。\n算法：排序 link从排序开始入门算法有一定的难度，因为这需要你理解时间复杂度的概念，开始接触到基本的二分思想以及严谨的数学证明过程。不过，不管难度如何，我想强调的是，在学习的过程中一定不要跳过这些必需的科学训练。如果你忽略基础，只会调用 list.sort()，未来遇到稍复杂的问题基本懵圈，需要花费更多的时间来重走基础路，得不偿失。\n我们可以从基础的冒泡排序开始理解排序，这是一个很好理解正确性和代码的算法；然后是选择排序和插入排序，它们和冒泡排序一样，都是 O(n^2) 时间复杂度的算法。\n从归并排序开始，算法复杂度骤降到 O(nlogn) 的理论下界，这里也开始涉及到算法中的一个经典思想——分治（Divide and Conquer）。然后就是快速排序、堆排序这些算法，他们和快速排序一样都是 O(nlogn) 级别。\n除此之外，还有一些针对性的优化排序，比如计数排序、桶排序、基数排序等，在特定条件下可以做到 O(n) 的时间复杂度。\n关于各种算法，我推荐你可以查看这个B站的视频：https://www.bilibili.com/video/av685670\n算法：二分搜索 link二分搜索也是一种思想，甚至在生活中都有很广泛的应用（笑），比如书本的翻页设计是一种二分，你不需要查找很多次，就能找到自己想要的那一页。再比如就是很有名的，就是女生通过图书馆的笑话了。\n图书馆自习的时候，一女生背着一堆书进阅览室，结果警报响了，大妈让女生看是哪本书把警报弄响了，女生把书倒出来，一本一本地测。大妈见状急了，把书分成两份，第一份过了一下，响了。又把这一份分成两份接着测，三回就找到了，大妈用鄙视的眼神看着女生，仿佛在说O(n)和O(log2n)都分不清。\n对于二分搜索算法，你千万不要只是套用 API 和简单的代码，一定要从本质上理解二分思想，做到活学活用。\n算法：深度优先搜索（DFS）和广度优先搜索（BFS） linkDFS 和 BFS是图论算法中的基础。你需要先把这两个基础知识点掌握下来，然后学习几个经典算法，比如最短路算法、并查集、记忆化深度优先搜索、拓扑排序、DAG 图上的 DP 等等。\n这里要注意，我们的重点还是学习思想。对于业务逻辑而言，图算法的重要性可能并没有那么大，但是当你开始接触技术栈深层，接触大数据（Hadoop， Spark），接触神经网络和人工智能时，你会发现，图的基本思想早已渗透到了设计模式中，而 DFS 和 BFS 正是操作图的最基础的两把钥匙。\n算法：贪心和动态规划 link这两个算法依然是两种重要的思维。虽然在绝大部分程序员的工作中，这两个算法可能一年都不会被用到过几次，但同样的，这些都是向更高技术能力升级必备的基本功。你不需要掌握到能够参加 ACM 世界总决赛的级别，但是，我们哪怕是对基本的方法论能有所了解，都将受益匪浅。\n曾有参加过 ACM 竞赛的朋友和我讲过，说他学懂动态规划后，感觉整个人生观和方法论都有了变化。在那之后，他自己去思考一些现实生活中的决策时，就会明白哪些是短视的贪心，哪些才是长远考虑的动态规划（笑）。\n总结 link作为Python语言专栏，我确实不可能给你把每一种数据结构和算法都详细讲解一遍，但是，还是那句话，基础的数据结构和算法，一定是每个程序员的基本功。\n这里，我推荐你可以学习极客时间上王争老师的《数据结构与算法之美》专栏，以及覃超老师的《算法面试通关40讲》视频课程。这两位在 Google和 Facebook 工作过的老师，同样底子扎实、实战经验丰富，将会给你带来不同角度的更翔实的算法精讲。\n在数据爆炸的互联网的今天，学习资料触手可及，时间就显得更加宝贵。我在这里列出这些纲要的目的，也是希望能够帮你节省时间，为你整理出适合入门学习、掌握的基础知识点，让你可以带着全局观更有针对性地去学习。\n当然，一切可以取得成果的学习，都离不开我们自己付出的努力。也只有这样，掌握了数据结构和算法的你，才能在数学基础上对 Python 的理解更进一步。同时，在未来的项目设计中，这些思维亦会在无形之中，帮你设计出更高质量的系统和架构，可以说是终生受益的学习投资了。\n希望你可以学会并且切实有所收获，如果在哪个地方有所困惑，也欢迎在留言区和我交流讨论，我们一起精进和提高！\n"
            }
        );
    index.add(
            {
                id:  50 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/41---%E7%A1%85%E8%B0%B7%E4%B8%80%E7%BA%BF%E4%BA%92%E8%81%94%E7%BD%91%E5%85%AC%E5%8F%B8%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%BD%93%E9%AA%8C\/",
                title: "硅谷一线互联网公司的工作体验",
                description: "你好， 我是景霄。\n前面四个版块，我们一起由浅入深地学习了Python这门语言，而最后一个版块，我想与你分享一些我的技术与工作见闻，谈谈我的领悟与理解。\n首先，我想带你去了解一下，硅谷Top互联网公司的工作体验与文化，这里就以我工作的Facebook为例。\n扁平化的管理制度 link硅谷的一线互联网公司，都会实行扁平化的管理制度，当然FB也不例外。在这里，虽然也有上下级之分，比如 Software Engineer -\u003e Engineering Manager -\u003e Director -\u003e VP，但是我们大家的思想中，并没有严格上下级这样的概念。\n公司鼓励每个人积极发表自己的观点。比如，一个应届毕业生，因为一个问题和自己的老板，乃至老板的老板据理力争，这样的场景也是很常见的。\n另外，公司每隔一段时间便会组织一次Q\u0026A，我们大家可以向CEO、CTO等提问。比如你想了解某个产品的发展方向，公司目前的侧重点，甚至是一些敏感的问题，都可以提问。\n同时，公司的领导，哪怕是上到CEO、CTO、COO这样的高层，都没有自己的单独办公室，都是和我们一起坐在开放的区域内办公，这样即拉近了距离，也是为了方便交流和讨论。\n开放式的讨论平台 link第二点是开放式的讨论平台。我一直觉得这个方式非常好，也很喜欢。FB用的是自己开发的workplace，相当于一个开放的社区，里面会有不同的群组，无论你有什么问题，都可以去相应的群组提问，那里会有各个领域的高手来帮你解答。\n举个例子，如果你有Python相关的问题，便可以去Python的群组问；你如果有Spark的问题，就去Spark 群组问。\n很多时候，各个组开发的产品，都会涉及很多的跨组合作，要用到其他组开发的一些API、算法、框架等等。这样，在使用的时候就难免会遇到一些问题，这个时候我们大家通常便会在对应的群组中提问。问题解决后也保存了下来，之后再有人遇到相同的问题时，便能直接搜索到对应的帖子及答案，大大提高了办公的效率。\n除了上述Q\u0026A形式的群组外，我们也会有很多其他形式的群组。比如，自己工作组内的群组，用于发布一些重要消息及技术交流；A/B测试的群组，用于大家讨论某个实验的结果等等。当然，还有很多非技术的群组，比如足球俱乐部、篮球俱乐部等用于休闲娱乐的平台。\n在有了这么一个生态系统后，员工可以很方便地获取到自己想要的信息，也大大方便了公司内部员工的交流，可以算是一举多得的事情了。\n数据驱动为中心 linkFB是一个典型的数据驱动型的公司，一切都以数据为依据，这样实际上极大地提高了工程师的地位。比如，在决定一个实验要不要最终发起时，我们都会首先关注各项指标，是不是能带来正向影响，是不是提高了用户的体验等等。\n再比如，每次提出一个新项目时，我们都需要做大量的数据分析与调研，然后与组内的同事及上级领导 review 后再做决定。这样，每次绩效考核时，证明自己最好的依据，便是自己发起的实验对指标的提升等等。这样的一种策略，对于公司及个人的发展都更为有利。\n举一个反例，之前的Snapchat，就是一个典型的不以数据驱动为中心的公司。他们产品的发布、改变，大多依赖一些产品经理和设计师的主观臆断，这样实际上是很偏颇的。后来的结局我们也都知道了，产品变得越来越不受用户喜欢，股价大跌，而我大部分在那里工作的同学，也都纷纷离职了。\nBootcamp linkBootcamp是FB中很著名的一个项目，所有入职FB的员工，在正式进入具体的工作组之前，都会参加4-10周的Bootcamp；而每个员工也会分配一个导师，帮助其了解FB的技术栈、文化以及吃喝玩乐等等。\nBootcamp的前两周，通常会安排不少的课程，帮助新员工了解FB的内部工具。之后就会进入选组阶段，组和员工之间进行双向选择，形式通常是“聊天+做组内的项目”，这样双方都能对彼此有更深入的了解。\n在Bootcamp期间，特别是对于应届毕业生来说，你可以尝试各种不同的方向，这对于未来的职业发展是非常有裨益的。公司也鼓励Bootcamp的员工参加各种娱乐活动，增进交流，而且这期间的吃喝玩乐都可以报销。我身边的每个同事都会有这样的感受：Bootcamp真是在公司最舒服的日子了。\n鼓励工程师更换工作方向 link在FB，无论是内部换组，还是更换工作方向都是非常普遍的现象。很多工程师在一个组做的时间久了，就会想尝试一些新的方向，这在公司是非常鼓励的。\n方法也很简单，一般来说让你去新组做几个任务，或者花一个月的时间做一个Hackamonth就可以了。这种形式是对双方的考量，新组会对工程师的能力有一个大概的了解；而工程师也会对新组的工作、技术有所掌握，并进一步判断自己是否感兴趣。\n因此，在FB，你会看到很多全栈工程师，比如我就是其中一个，对移动端、服务器端以及机器学习都有所涉猎。显然，这样的制度，非常有利于工程师的全面发展。\n福利政策 linkFB的福利，应该可以算是全球互联网公司中最好之一了。公司为了留住人才，提供了很多外人看来非比寻常的福利。\n首先从工位说起，其装备都是业内顶级标准。电脑是可以自己随意选配的，比如你可以随意选配7000多美金的iMac Pro，显示器也可以随意选配价值1000多美金的4K屏幕。至于可升降桌子和椅子，都是Herman Miller 标配，桌椅总价在2000美金以上。\n在技术交流方面，除了正常的学习培训外，公司还鼓励员工每年外出参加一次会议，比如机器学习方向的ICML、KDD等等，给予全程报销。\n另外，公司包一日三餐，包括内部的零食、甜品等全部免费。我们拥有一年21天带薪休假，女性还拥有6个月的带薪产假，同时提供免费的健身房、游泳池等，每年还会提供 720美金的健身私教报销等等。\n写在最后 link以上就是我在FB工作的主要工作体验。其实，在硅谷工作，不仅仅有技术上的收获，比如你可以直接接触到业内顶级大牛，了解到最新最前沿的技术；还有很多认知和思维方式上的影响，比如对于流程、合作、开源等的思考。\n接下来的几篇文章，我会继续讲述，关于技术研发我这些年的工作经验和总结，以及对于职业方向的认识和思考。欢迎你在留言区和我一起讨论交流这些问题，经验分享和交流，是每个技术人成长必不可少的环节。\n",
                content: "你好， 我是景霄。\n前面四个版块，我们一起由浅入深地学习了Python这门语言，而最后一个版块，我想与你分享一些我的技术与工作见闻，谈谈我的领悟与理解。\n首先，我想带你去了解一下，硅谷Top互联网公司的工作体验与文化，这里就以我工作的Facebook为例。\n扁平化的管理制度 link硅谷的一线互联网公司，都会实行扁平化的管理制度，当然FB也不例外。在这里，虽然也有上下级之分，比如 Software Engineer -\u003e Engineering Manager -\u003e Director -\u003e VP，但是我们大家的思想中，并没有严格上下级这样的概念。\n公司鼓励每个人积极发表自己的观点。比如，一个应届毕业生，因为一个问题和自己的老板，乃至老板的老板据理力争，这样的场景也是很常见的。\n另外，公司每隔一段时间便会组织一次Q\u0026A，我们大家可以向CEO、CTO等提问。比如你想了解某个产品的发展方向，公司目前的侧重点，甚至是一些敏感的问题，都可以提问。\n同时，公司的领导，哪怕是上到CEO、CTO、COO这样的高层，都没有自己的单独办公室，都是和我们一起坐在开放的区域内办公，这样即拉近了距离，也是为了方便交流和讨论。\n开放式的讨论平台 link第二点是开放式的讨论平台。我一直觉得这个方式非常好，也很喜欢。FB用的是自己开发的workplace，相当于一个开放的社区，里面会有不同的群组，无论你有什么问题，都可以去相应的群组提问，那里会有各个领域的高手来帮你解答。\n举个例子，如果你有Python相关的问题，便可以去Python的群组问；你如果有Spark的问题，就去Spark 群组问。\n很多时候，各个组开发的产品，都会涉及很多的跨组合作，要用到其他组开发的一些API、算法、框架等等。这样，在使用的时候就难免会遇到一些问题，这个时候我们大家通常便会在对应的群组中提问。问题解决后也保存了下来，之后再有人遇到相同的问题时，便能直接搜索到对应的帖子及答案，大大提高了办公的效率。\n除了上述Q\u0026A形式的群组外，我们也会有很多其他形式的群组。比如，自己工作组内的群组，用于发布一些重要消息及技术交流；A/B测试的群组，用于大家讨论某个实验的结果等等。当然，还有很多非技术的群组，比如足球俱乐部、篮球俱乐部等用于休闲娱乐的平台。\n在有了这么一个生态系统后，员工可以很方便地获取到自己想要的信息，也大大方便了公司内部员工的交流，可以算是一举多得的事情了。\n数据驱动为中心 linkFB是一个典型的数据驱动型的公司，一切都以数据为依据，这样实际上极大地提高了工程师的地位。比如，在决定一个实验要不要最终发起时，我们都会首先关注各项指标，是不是能带来正向影响，是不是提高了用户的体验等等。\n再比如，每次提出一个新项目时，我们都需要做大量的数据分析与调研，然后与组内的同事及上级领导 review 后再做决定。这样，每次绩效考核时，证明自己最好的依据，便是自己发起的实验对指标的提升等等。这样的一种策略，对于公司及个人的发展都更为有利。\n举一个反例，之前的Snapchat，就是一个典型的不以数据驱动为中心的公司。他们产品的发布、改变，大多依赖一些产品经理和设计师的主观臆断，这样实际上是很偏颇的。后来的结局我们也都知道了，产品变得越来越不受用户喜欢，股价大跌，而我大部分在那里工作的同学，也都纷纷离职了。\nBootcamp linkBootcamp是FB中很著名的一个项目，所有入职FB的员工，在正式进入具体的工作组之前，都会参加4-10周的Bootcamp；而每个员工也会分配一个导师，帮助其了解FB的技术栈、文化以及吃喝玩乐等等。\nBootcamp的前两周，通常会安排不少的课程，帮助新员工了解FB的内部工具。之后就会进入选组阶段，组和员工之间进行双向选择，形式通常是“聊天+做组内的项目”，这样双方都能对彼此有更深入的了解。\n在Bootcamp期间，特别是对于应届毕业生来说，你可以尝试各种不同的方向，这对于未来的职业发展是非常有裨益的。公司也鼓励Bootcamp的员工参加各种娱乐活动，增进交流，而且这期间的吃喝玩乐都可以报销。我身边的每个同事都会有这样的感受：Bootcamp真是在公司最舒服的日子了。\n鼓励工程师更换工作方向 link在FB，无论是内部换组，还是更换工作方向都是非常普遍的现象。很多工程师在一个组做的时间久了，就会想尝试一些新的方向，这在公司是非常鼓励的。\n方法也很简单，一般来说让你去新组做几个任务，或者花一个月的时间做一个Hackamonth就可以了。这种形式是对双方的考量，新组会对工程师的能力有一个大概的了解；而工程师也会对新组的工作、技术有所掌握，并进一步判断自己是否感兴趣。\n因此，在FB，你会看到很多全栈工程师，比如我就是其中一个，对移动端、服务器端以及机器学习都有所涉猎。显然，这样的制度，非常有利于工程师的全面发展。\n福利政策 linkFB的福利，应该可以算是全球互联网公司中最好之一了。公司为了留住人才，提供了很多外人看来非比寻常的福利。\n首先从工位说起，其装备都是业内顶级标准。电脑是可以自己随意选配的，比如你可以随意选配7000多美金的iMac Pro，显示器也可以随意选配价值1000多美金的4K屏幕。至于可升降桌子和椅子，都是Herman Miller 标配，桌椅总价在2000美金以上。\n在技术交流方面，除了正常的学习培训外，公司还鼓励员工每年外出参加一次会议，比如机器学习方向的ICML、KDD等等，给予全程报销。\n另外，公司包一日三餐，包括内部的零食、甜品等全部免费。我们拥有一年21天带薪休假，女性还拥有6个月的带薪产假，同时提供免费的健身房、游泳池等，每年还会提供 720美金的健身私教报销等等。\n写在最后 link以上就是我在FB工作的主要工作体验。其实，在硅谷工作，不仅仅有技术上的收获，比如你可以直接接触到业内顶级大牛，了解到最新最前沿的技术；还有很多认知和思维方式上的影响，比如对于流程、合作、开源等的思考。\n接下来的几篇文章，我会继续讲述，关于技术研发我这些年的工作经验和总结，以及对于职业方向的认识和思考。欢迎你在留言区和我一起讨论交流这些问题，经验分享和交流，是每个技术人成长必不可少的环节。\n"
            }
        );
    index.add(
            {
                id:  51 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/42---%E7%BB%86%E6%95%B0%E6%8A%80%E6%9C%AF%E7%A0%94%E5%8F%91%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9\/",
                title: "细数技术研发的注意事项",
                description: "你好，我是景霄。\n技术研发一直以来都是各大公司的核心部分之一，其质量的好坏直接影响到了产品的质量以及用户对产品的体验。如何建立一套规范、健全的开发体系，就显得尤为重要。今天我就和你聊聊技术研发的注意事项。\n选择合适的编程语言 link比如我们正在开发一个系统，首先，根据具体的需求，我们需要对系统的各个部分选择合适的编程语言。一般来说，infra这层我们更偏向于使用C++，而纯的服务器端则是以Python、Java、PHP等等为主。以搜索引擎为例，下面我画了一个它的简略架构图：\n你可以看到，大概的工作流程是：用户在客户端（client）输入一个查询（query），发送请求（request）到达服务器端（server-side）；服务器端首先向NLP service发请求，并对请求进行分析，等到拿到各项信号（signal）后，再向后端（backend）发送请求；后端会做特征抽取（feature extraction），利用ML 模型进行结果的检索（candidate retrieval）、排序，最后再把结果返回给服务器端和客户端。\n这里的NLP Service和后端，我们都会使用C++。因为这部分的处理最为复杂和耗时，都涉及到了特征抽取和model serving，对延迟（latency）的要求极高，只有C/C++这类语言才能满足需求。\n而服务器端或者叫中间层（middle tier），我们则会使用Python、Java、PHP等语言。因为这部分并没有特别复杂的处理和对延迟的高需求，主要是以一些业务逻辑为主；并且，对程序员来说，使用这种高级语言也更容易上手和调试。\n合理使用缓存 link缓存（cache）在实际工程中十分重要，可以想像，如果没了缓存，我们今天所用的绝大多数产品估计都会崩溃。缓存为我们节约了大量的CPU 容量（capacity）和延迟。\n还是以刚刚的搜索引擎系统为例，我们在客户端、服务器端和后端都会设置缓存。在客户端，我们一般会缓存用户的搜索记录，比如当你点击搜索框时，自动弹出的建议关键词的前几个，就可以是缓存的结果。这不需要向服务器端发请求，可以直接从客户端下载。\n而在服务器端，我们也会设置缓存来存储一些搜索结果。这样，如果同一个用户多次发送相同的请求，就不需要再向后端请求，直接从缓存里面拿结果就可以了，快速又高效。\n同样的，后端也需要缓存。比如在model serving这块儿，我们通常会有几个小时的缓存，不然每次提供实时的在线服务时，对CPU的负荷很大，延迟也会很高。\n总而言之，如果没了缓存，容易造成很多问题。\n服务器负荷迅速飙升，崩溃的几率大大增加。 端对端的延迟迅速飙升，请求超时的概率大大增加。 但是不是缓存越多就越好呢？显然也不是。\n第一，通常来说，缓存比较昂贵，所以在使用上，我们都会有一个限度，不能无限制索取。\n第二，缓存不是万能的，过度增加缓存，也会损害用户的产品体验。比如搜索结果的retrieval和排序这两块，理想状况下，肯定是做实时的model serving最好，因为这样对用户的个性化推荐更准确和实时。之所以会对model有几个小时的缓存，更多的是出于性能的考虑，但如果把缓存从几小时改为几天，显然不合适，无疑会对用户的产品体验造成极大的负面影响。\n因此，缓存到底取多久、取多少，往往是用户对产品参与度和性能的一个权衡，需要根据一些具体的分析以及A/B测试做出决定。\n健全的日志记录系统 link健全的日志记录系统也是尤其关键的一点。大型公司的系统，往往由成千十万个小系统组合而来，如果发生故障，比如Google、Facebook的某项服务突然宕机了，我们就需要以最快的速度找出原因并做出修复。这靠的是什么呢？靠的正是健全的日志记录系统，使得我们能够方便地分解错误原因，一层一层追溯，直到找到根源。\n一般来说，在线上环境中，我们需要两种类型的日志记录模式。\n一种是实时logging，考虑到服务器的压力，通常会做降采样（downsampling），比如log实际流量的1%。这样的好处是，可以及时跟踪各项指标，如果有情况，立即触发警报（alert）。\n比如，某天的中午12点，一位工程师push了一段会造成服务器奔溃的代码进入产品，实时logging检测到异常，发出警报，这时有关人员便会进行排查。如果发现这个代码的push时间和警报触发时间一致，就能够最快地恢复（revert），最小化其带来的负面影响。\n同时，实时logging也有利于我们进行各种线上实验。比如，ML组的A/B测试常常需要调参，我们的通常做法，就是每隔几小时查看实时 logging的table，根据各项指标，适度调整参数。\n第二种是每天更新一次也就是daily的 full logging，有助于我们统计一些信息，进行分析，比如做成仪表板（dashboard），方便查看每天的各项指标，来跟踪进度。此外，full logging的table，也常常用于ML组的训练数据（training data）。\nProfiling必不可少 link关于profile，之前我们也提到过，在实际开发中是非常重要的一项功能，能够帮助开发人员详细了解系统每个部分的效率，并加以提高。\n在线上环境中，我们通常会在许多必要的地方加上profile的代码，这样我们就能够知道这段代码的延迟是多少，哪个部分的延迟特别严重等等，然后对症下药。\n如果没有profile，很容易导致开发人员随意增加功能而不进行优化，这样以来，随着时间的推移，系统越来越冗余，延迟也会越来越高。因此，一个成熟的系统，一定会有profile的代码，帮助开发人员随时监控内部的各项指标变化。\ntest、test、test link这一点，我也已经在前面的文章中强调过了，测试（test）一定不能少。无论是单元测试（unit test）、集成测试（integration test）还是其他，都是保证代码质量、减小bug发生概率的一个有效手段。\n在真正规范的公司或是小组里，开发人员如果新增或改变了一个功能而不写测试，是过不了代码评审的。因此，测试一定要写，尤其是系统复杂了以后，很多工程师都要在上面开发各种不同的新功能，很难保证各个部分不受影响，测试便是一种很好的解决方法。\n除了日常开发中所写的测试外，在代码push到线上之前，最好还要加一层测试。还是以刚刚的搜索引擎系统为例，我所知道的，Google或者Facebook的代码在push的过程中，都会有专门的service，去模拟不同的用户发送请求，然后看返回的响应是不是符合要求。如果出错，就会阻止代码的push，这也就告诉了开发人员，他们所写的代码可能存在问题，需要再次检查。\n写在最后 link关于技术研发的注意事项，我主要强调这些内容。事实上，日常开发工作中，很多的细节都值得特别关注，而对于易错的地方，用系统化的流程解决不失为一个高效的方案。那么，在你的日常工作中，有哪些特别留心的地方值得分享，或者有哪些疑惑的地方想要交流吗？欢迎在留言区写下你的想法。\n",
                content: "你好，我是景霄。\n技术研发一直以来都是各大公司的核心部分之一，其质量的好坏直接影响到了产品的质量以及用户对产品的体验。如何建立一套规范、健全的开发体系，就显得尤为重要。今天我就和你聊聊技术研发的注意事项。\n选择合适的编程语言 link比如我们正在开发一个系统，首先，根据具体的需求，我们需要对系统的各个部分选择合适的编程语言。一般来说，infra这层我们更偏向于使用C++，而纯的服务器端则是以Python、Java、PHP等等为主。以搜索引擎为例，下面我画了一个它的简略架构图：\n你可以看到，大概的工作流程是：用户在客户端（client）输入一个查询（query），发送请求（request）到达服务器端（server-side）；服务器端首先向NLP service发请求，并对请求进行分析，等到拿到各项信号（signal）后，再向后端（backend）发送请求；后端会做特征抽取（feature extraction），利用ML 模型进行结果的检索（candidate retrieval）、排序，最后再把结果返回给服务器端和客户端。\n这里的NLP Service和后端，我们都会使用C++。因为这部分的处理最为复杂和耗时，都涉及到了特征抽取和model serving，对延迟（latency）的要求极高，只有C/C++这类语言才能满足需求。\n而服务器端或者叫中间层（middle tier），我们则会使用Python、Java、PHP等语言。因为这部分并没有特别复杂的处理和对延迟的高需求，主要是以一些业务逻辑为主；并且，对程序员来说，使用这种高级语言也更容易上手和调试。\n合理使用缓存 link缓存（cache）在实际工程中十分重要，可以想像，如果没了缓存，我们今天所用的绝大多数产品估计都会崩溃。缓存为我们节约了大量的CPU 容量（capacity）和延迟。\n还是以刚刚的搜索引擎系统为例，我们在客户端、服务器端和后端都会设置缓存。在客户端，我们一般会缓存用户的搜索记录，比如当你点击搜索框时，自动弹出的建议关键词的前几个，就可以是缓存的结果。这不需要向服务器端发请求，可以直接从客户端下载。\n而在服务器端，我们也会设置缓存来存储一些搜索结果。这样，如果同一个用户多次发送相同的请求，就不需要再向后端请求，直接从缓存里面拿结果就可以了，快速又高效。\n同样的，后端也需要缓存。比如在model serving这块儿，我们通常会有几个小时的缓存，不然每次提供实时的在线服务时，对CPU的负荷很大，延迟也会很高。\n总而言之，如果没了缓存，容易造成很多问题。\n服务器负荷迅速飙升，崩溃的几率大大增加。 端对端的延迟迅速飙升，请求超时的概率大大增加。 但是不是缓存越多就越好呢？显然也不是。\n第一，通常来说，缓存比较昂贵，所以在使用上，我们都会有一个限度，不能无限制索取。\n第二，缓存不是万能的，过度增加缓存，也会损害用户的产品体验。比如搜索结果的retrieval和排序这两块，理想状况下，肯定是做实时的model serving最好，因为这样对用户的个性化推荐更准确和实时。之所以会对model有几个小时的缓存，更多的是出于性能的考虑，但如果把缓存从几小时改为几天，显然不合适，无疑会对用户的产品体验造成极大的负面影响。\n因此，缓存到底取多久、取多少，往往是用户对产品参与度和性能的一个权衡，需要根据一些具体的分析以及A/B测试做出决定。\n健全的日志记录系统 link健全的日志记录系统也是尤其关键的一点。大型公司的系统，往往由成千十万个小系统组合而来，如果发生故障，比如Google、Facebook的某项服务突然宕机了，我们就需要以最快的速度找出原因并做出修复。这靠的是什么呢？靠的正是健全的日志记录系统，使得我们能够方便地分解错误原因，一层一层追溯，直到找到根源。\n一般来说，在线上环境中，我们需要两种类型的日志记录模式。\n一种是实时logging，考虑到服务器的压力，通常会做降采样（downsampling），比如log实际流量的1%。这样的好处是，可以及时跟踪各项指标，如果有情况，立即触发警报（alert）。\n比如，某天的中午12点，一位工程师push了一段会造成服务器奔溃的代码进入产品，实时logging检测到异常，发出警报，这时有关人员便会进行排查。如果发现这个代码的push时间和警报触发时间一致，就能够最快地恢复（revert），最小化其带来的负面影响。\n同时，实时logging也有利于我们进行各种线上实验。比如，ML组的A/B测试常常需要调参，我们的通常做法，就是每隔几小时查看实时 logging的table，根据各项指标，适度调整参数。\n第二种是每天更新一次也就是daily的 full logging，有助于我们统计一些信息，进行分析，比如做成仪表板（dashboard），方便查看每天的各项指标，来跟踪进度。此外，full logging的table，也常常用于ML组的训练数据（training data）。\nProfiling必不可少 link关于profile，之前我们也提到过，在实际开发中是非常重要的一项功能，能够帮助开发人员详细了解系统每个部分的效率，并加以提高。\n在线上环境中，我们通常会在许多必要的地方加上profile的代码，这样我们就能够知道这段代码的延迟是多少，哪个部分的延迟特别严重等等，然后对症下药。\n如果没有profile，很容易导致开发人员随意增加功能而不进行优化，这样以来，随着时间的推移，系统越来越冗余，延迟也会越来越高。因此，一个成熟的系统，一定会有profile的代码，帮助开发人员随时监控内部的各项指标变化。\ntest、test、test link这一点，我也已经在前面的文章中强调过了，测试（test）一定不能少。无论是单元测试（unit test）、集成测试（integration test）还是其他，都是保证代码质量、减小bug发生概率的一个有效手段。\n在真正规范的公司或是小组里，开发人员如果新增或改变了一个功能而不写测试，是过不了代码评审的。因此，测试一定要写，尤其是系统复杂了以后，很多工程师都要在上面开发各种不同的新功能，很难保证各个部分不受影响，测试便是一种很好的解决方法。\n除了日常开发中所写的测试外，在代码push到线上之前，最好还要加一层测试。还是以刚刚的搜索引擎系统为例，我所知道的，Google或者Facebook的代码在push的过程中，都会有专门的service，去模拟不同的用户发送请求，然后看返回的响应是不是符合要求。如果出错，就会阻止代码的push，这也就告诉了开发人员，他们所写的代码可能存在问题，需要再次检查。\n写在最后 link关于技术研发的注意事项，我主要强调这些内容。事实上，日常开发工作中，很多的细节都值得特别关注，而对于易错的地方，用系统化的流程解决不失为一个高效的方案。那么，在你的日常工作中，有哪些特别留心的地方值得分享，或者有哪些疑惑的地方想要交流吗？欢迎在留言区写下你的想法。\n"
            }
        );
    index.add(
            {
                id:  52 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/43---qa%E8%81%8A%E4%B8%80%E8%81%8A%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%E5%92%8C%E9%80%89%E6%8B%A9\/",
                title: "Q\u0026A：聊一聊职业发展和选择",
                description: "你好，我是景霄。\n在前面几节课中，我分享了在FB工作的一些经验和感想，不少同学都提出了自己的困惑，也希望我能给出一些职业发展方面的建议。综合这些问题，我主要选取了下面三个主题，来说说职业发展、职业选择方面我的看法。\nQ：程序员的岗位主要有哪些类型？我该如何选择？ linkA：无论是在求职阶段，还是正式进入公司工作后，你都会发现，工程师普遍按技术的不同，分为下面几个岗位。\n前端：包括移动（Android、iOS）以及Web前端（JavaScript、CSS）开发。 后端（服务器端）：主要是服务器端的开发，简单来说，就是输入为请求，输出为响应，发送给客户端。 算法：主要涉及到的是机器学习，比如推荐系统如何更好地实现个性化推荐，搜索引擎返回的结果如何才能更符合地用户的需求等等。 架构：涉及系统架构，偏底层，语言以C++为主。 从薪酬的角度来看，普遍来说：算法 \u003e 架构 \u003e 后端 \u003e 前端。当然，这主要是由市场的供需关系决定的。\n就拿算法岗来说，国内市场普遍缺少算法人才，也是因为这个岗位的培养难度更大，需要投入更大的精力。在顶尖互联网公司，参与核心产品研发的算法工程师们，工作三年，年收入100-200W人民币是很常见的。\n不过，我这里所说的算法人才，绝不是指类似在校生那种，看过几篇论文，写过一些MATLAB，在学校做过几个科研项目的程度。算法工作岗位需要的算法能力，是你必须身体力行，有某些产品线的实践经历。还需要你真正了解市场，比如今日头条的推荐算法是怎样的，Google搜索引擎是怎么工作的，头条里的广告排序又是怎么做的等等。\n再来说说架构，这也是目前一个热门的方向。我一直认为这是一个很偏工程、很硬核的领域，发展前景也相当不错，可以说是一个产品的基石。就拿刚刚提到的推荐系统来说，广告的定位和排序系统背后，都需要强有力的架构支撑。因此，这一行也可以称得上是人才紧缺，是企业舍得花高薪聘请的对象之一。\n与算法不同的是，这个领域不会涉及很深的数学知识，工程师的主要关注点，在于如何提高系统性能，包括如何使系统高扩展、减小系统的延迟和所需CPU的容量等等。架构师需要很强的编程能力，常用的语言是C++；当然，最重要的还是不断积累大型项目中获得的第一手经验，对常见的问题有最principle的处理方式。\n最后说说后端和前端，这是绝大多数程序员从事的岗位，也是我刚进公司时的选择。也许比起前两个岗位，不少人会认为，后端、前端工程师的薪酬较低，没有什么发展前景。这其实大错特错了！从一个产品的角度出发，你可以没有算法工程师、没有架构师，但是你能缺少后端和前端的开发人员吗？显然是不可能的。\n后端和前端，相当于是一个产品的框架。框架搭好了，才会有机器学习、算法等的锦上添花。诚然，这两年来看，后端和前端没有前两者那么热门（还是市场供需关系的问题），但这并不代表，这些岗位没有发展前景，或者你就可以小看其技术含量。\n比起算法和架构，后端、前端确实门槛更低些，但是其工作依然存在很高的技术含量。比如对一个产品或者其中的某些部件来说，如何设计搭建前后端的开发框架结构，使系统更加合理、可维护性更高，就是很多资深的开发工程师正在做的事。\n前面聊了这么多，最后回到最根本的问题上：到底如何选择呢？\n这里我给出的建议是：首先以自己的兴趣为出发点，因为只有自己感兴趣的东西，你才能做到最好。比如，一些人就是对前端感兴趣，那么为啥偏要去趟机器学习这趟浑水呢？当然不少人可能没有明确的偏好，那么这种情况下，我建议你尽可能多地去尝试，这是了解自己兴趣最好的方法。\n另外，从广义的角度来看，计算机这门技术存在着study deep和study broad这两个方向，你得想清楚你属于哪类。所谓的study deep，就意味着数十年专攻一个领域，励志成为某个领域的专家；而study broad，便是类似于全栈工程师，对一个产品、系统的end to end都有一个了解，能够随时胜任任意角色的工作，这一点在初创公司身上体现得最为明显。\nQ：如何成为一个全栈工程师？ linkA：相信屏幕前的不少同学是在创业公司工作的，刚刚也提到了，创业公司里全栈工程师的需求尤为突出。那么，如何成为一个优秀的全栈工程师呢？\n简单来说，最好的方法就是“尽可能地多接触、多实践不同领域的项目”。身体力行永远是学习新知识、提高能力的最好办法。\n当然，在每个领域的初始阶段，你可能会感觉到异常艰难，比如从未接触过前端的人被要求写一个页面，一时间内显然会不知从何下手。这个时候，我建议你可以先从“依葫芦画瓢”开始，通过阅读别人相似的代码，并在此基础上加以修改，完成你要实现的功能。时间久了，你看的多了，用的多了，理解自然就越来越深，动起手来也就越来越熟练了。\n有条件的同学，比如工作在类似于FB这种文化的公司，可以通过在公司内部换组的方式，去接触不同的项目。这自然是最好不过了，因为和特定领域的人合作，永远比一个人单干强得多，你能够迅速学到更多的东西。\n不过，没这种条件的同学也不必绝望，你还可以利用业余时间“充电“，自己做一些项目来培养和加强别的领域的能力。毕竟，对于成年人来说，自学才是精进自己的主要方式。\n这样，到了最后，你应该达到的结果便是，自己一个人能够扛起整条产品线的开发，也对系统的整个工作流程有一个全面而深入的理解。\nQ：学完本专栏后，在Python领域我该如何继续进阶呢？ linkA：在我看来，这个专栏的主要目的，是带你掌握Python这门语言的常见基本和高阶用法。接下来的进阶，便是Python本身在各种不同方向的运用，拿后端开发这个方向来说，比如，如何搭建大型系统的后台便是你需要掌握的。一个好的后端，自然离不开：\n合理的系统、框架设计； 简约高效的代码质量； 稳健齐全的单元测试； 出色的性能表现。 具体来说，你搭建的系统后端是不是易于拓展呢？比如过半年后，有了新的产品需求，需要增加新的功能。那么，在你的框架下，是否可以尽可能少地改动来实现新的功能，而不需要把某部分推倒重来呢？\n再比如，你搭建的系统是不是符合可维护性高、可靠性高、单元测试齐全的要求，从而不容易在线上发生bug呢？\n总之，在某一领域到了进阶的阶段，你需要关注的，绝不仅仅只是某些功能的实现，更需要你考虑所写代码的性能、质量，甚至于整个系统的设计等等。\n虽然讲了这么多东西，但最后我想说的是，三百六十行，行行出状元。对于计算机行业，乃至整个职场来说，每一个领域都没有优劣之分，每个领域你都可以做得很牛逼，前提是你不懈地学习、实践和思考。\n那么，对于职业选择和发展，你又是如何看待和理解的呢？欢迎留言和我一起交流探讨，也希望屏幕前的一直不懈学习的你，能找到属于自己的方向，不断前进和创新，实现自己的人生理想。\n",
                content: "你好，我是景霄。\n在前面几节课中，我分享了在FB工作的一些经验和感想，不少同学都提出了自己的困惑，也希望我能给出一些职业发展方面的建议。综合这些问题，我主要选取了下面三个主题，来说说职业发展、职业选择方面我的看法。\nQ：程序员的岗位主要有哪些类型？我该如何选择？ linkA：无论是在求职阶段，还是正式进入公司工作后，你都会发现，工程师普遍按技术的不同，分为下面几个岗位。\n前端：包括移动（Android、iOS）以及Web前端（JavaScript、CSS）开发。 后端（服务器端）：主要是服务器端的开发，简单来说，就是输入为请求，输出为响应，发送给客户端。 算法：主要涉及到的是机器学习，比如推荐系统如何更好地实现个性化推荐，搜索引擎返回的结果如何才能更符合地用户的需求等等。 架构：涉及系统架构，偏底层，语言以C++为主。 从薪酬的角度来看，普遍来说：算法 \u003e 架构 \u003e 后端 \u003e 前端。当然，这主要是由市场的供需关系决定的。\n就拿算法岗来说，国内市场普遍缺少算法人才，也是因为这个岗位的培养难度更大，需要投入更大的精力。在顶尖互联网公司，参与核心产品研发的算法工程师们，工作三年，年收入100-200W人民币是很常见的。\n不过，我这里所说的算法人才，绝不是指类似在校生那种，看过几篇论文，写过一些MATLAB，在学校做过几个科研项目的程度。算法工作岗位需要的算法能力，是你必须身体力行，有某些产品线的实践经历。还需要你真正了解市场，比如今日头条的推荐算法是怎样的，Google搜索引擎是怎么工作的，头条里的广告排序又是怎么做的等等。\n再来说说架构，这也是目前一个热门的方向。我一直认为这是一个很偏工程、很硬核的领域，发展前景也相当不错，可以说是一个产品的基石。就拿刚刚提到的推荐系统来说，广告的定位和排序系统背后，都需要强有力的架构支撑。因此，这一行也可以称得上是人才紧缺，是企业舍得花高薪聘请的对象之一。\n与算法不同的是，这个领域不会涉及很深的数学知识，工程师的主要关注点，在于如何提高系统性能，包括如何使系统高扩展、减小系统的延迟和所需CPU的容量等等。架构师需要很强的编程能力，常用的语言是C++；当然，最重要的还是不断积累大型项目中获得的第一手经验，对常见的问题有最principle的处理方式。\n最后说说后端和前端，这是绝大多数程序员从事的岗位，也是我刚进公司时的选择。也许比起前两个岗位，不少人会认为，后端、前端工程师的薪酬较低，没有什么发展前景。这其实大错特错了！从一个产品的角度出发，你可以没有算法工程师、没有架构师，但是你能缺少后端和前端的开发人员吗？显然是不可能的。\n后端和前端，相当于是一个产品的框架。框架搭好了，才会有机器学习、算法等的锦上添花。诚然，这两年来看，后端和前端没有前两者那么热门（还是市场供需关系的问题），但这并不代表，这些岗位没有发展前景，或者你就可以小看其技术含量。\n比起算法和架构，后端、前端确实门槛更低些，但是其工作依然存在很高的技术含量。比如对一个产品或者其中的某些部件来说，如何设计搭建前后端的开发框架结构，使系统更加合理、可维护性更高，就是很多资深的开发工程师正在做的事。\n前面聊了这么多，最后回到最根本的问题上：到底如何选择呢？\n这里我给出的建议是：首先以自己的兴趣为出发点，因为只有自己感兴趣的东西，你才能做到最好。比如，一些人就是对前端感兴趣，那么为啥偏要去趟机器学习这趟浑水呢？当然不少人可能没有明确的偏好，那么这种情况下，我建议你尽可能多地去尝试，这是了解自己兴趣最好的方法。\n另外，从广义的角度来看，计算机这门技术存在着study deep和study broad这两个方向，你得想清楚你属于哪类。所谓的study deep，就意味着数十年专攻一个领域，励志成为某个领域的专家；而study broad，便是类似于全栈工程师，对一个产品、系统的end to end都有一个了解，能够随时胜任任意角色的工作，这一点在初创公司身上体现得最为明显。\nQ：如何成为一个全栈工程师？ linkA：相信屏幕前的不少同学是在创业公司工作的，刚刚也提到了，创业公司里全栈工程师的需求尤为突出。那么，如何成为一个优秀的全栈工程师呢？\n简单来说，最好的方法就是“尽可能地多接触、多实践不同领域的项目”。身体力行永远是学习新知识、提高能力的最好办法。\n当然，在每个领域的初始阶段，你可能会感觉到异常艰难，比如从未接触过前端的人被要求写一个页面，一时间内显然会不知从何下手。这个时候，我建议你可以先从“依葫芦画瓢”开始，通过阅读别人相似的代码，并在此基础上加以修改，完成你要实现的功能。时间久了，你看的多了，用的多了，理解自然就越来越深，动起手来也就越来越熟练了。\n有条件的同学，比如工作在类似于FB这种文化的公司，可以通过在公司内部换组的方式，去接触不同的项目。这自然是最好不过了，因为和特定领域的人合作，永远比一个人单干强得多，你能够迅速学到更多的东西。\n不过，没这种条件的同学也不必绝望，你还可以利用业余时间“充电“，自己做一些项目来培养和加强别的领域的能力。毕竟，对于成年人来说，自学才是精进自己的主要方式。\n这样，到了最后，你应该达到的结果便是，自己一个人能够扛起整条产品线的开发，也对系统的整个工作流程有一个全面而深入的理解。\nQ：学完本专栏后，在Python领域我该如何继续进阶呢？ linkA：在我看来，这个专栏的主要目的，是带你掌握Python这门语言的常见基本和高阶用法。接下来的进阶，便是Python本身在各种不同方向的运用，拿后端开发这个方向来说，比如，如何搭建大型系统的后台便是你需要掌握的。一个好的后端，自然离不开：\n合理的系统、框架设计； 简约高效的代码质量； 稳健齐全的单元测试； 出色的性能表现。 具体来说，你搭建的系统后端是不是易于拓展呢？比如过半年后，有了新的产品需求，需要增加新的功能。那么，在你的框架下，是否可以尽可能少地改动来实现新的功能，而不需要把某部分推倒重来呢？\n再比如，你搭建的系统是不是符合可维护性高、可靠性高、单元测试齐全的要求，从而不容易在线上发生bug呢？\n总之，在某一领域到了进阶的阶段，你需要关注的，绝不仅仅只是某些功能的实现，更需要你考虑所写代码的性能、质量，甚至于整个系统的设计等等。\n虽然讲了这么多东西，但最后我想说的是，三百六十行，行行出状元。对于计算机行业，乃至整个职场来说，每一个领域都没有优劣之分，每个领域你都可以做得很牛逼，前提是你不懈地学习、实践和思考。\n那么，对于职业选择和发展，你又是如何看待和理解的呢？欢迎留言和我一起交流探讨，也希望屏幕前的一直不懈学习的你，能找到属于自己的方向，不断前进和创新，实现自己的人生理想。\n"
            }
        );
    index.add(
            {
                id:  53 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/44---%E5%8A%A0%E9%A4%90---%E5%B8%A6%E4%BD%A0%E4%B8%8A%E6%89%8Bswig%E4%B8%80%E4%BB%BD%E6%B8%85%E6%99%B0%E5%A5%BD%E7%94%A8%E7%9A%84swig%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97\/",
                title: "加餐 - 带你上手SWIG：一份清晰好用的SWIG编程实践指南",
                description: "你好，我是卢誉声，Autodesk 数据平台和计算平台资深软件工程师，也是《移动平台深度神经网络实战》和《分布式实时处理系统：原理架构与实现》的作者，主要从事C/C++、JavaScript开发工作和平台架构方面的研发工作，对SWIG也有比较深的研究。很高兴受极客时间邀请来做本次分享，今天，我们就来聊一聊SWIG这个话题。\n我们都知道，Python 是一门易于上手并实验友好的胶水语言。现在有很多机器学习开发或研究人员，都选择Python作为主力编程语言；流行的机器学习框架也都会提供Python语言的支持作为调用接口和工具。因此，相较于学习成本更高的C++来说，把Python作为进入机器学习世界的首选编程语言，就再合适不过了。\n不过，像TensorFlow或PyTorch这样的机器学习框架的核心，是使用Python编写的吗？\n显然不是。这里面的原因比较多，但最为显著的一个原因就是“性能”。通过C++编写的机器学习框架内核，加上编译器的优化能力，为系统提供了接近于机器码执行的效率。这种得天独厚的优势，让C++在机器学习的核心领域站稳了脚跟。我们前面所说的TensorFlow和PyTorch的核心，便都是使用C/C++开发的。其中，TensorFlow的内核，就是由高度优化的C++代码和CUDA编写而成。\n因此，我们可以理解为，TensorFlow通过Python来描述模型，而实际的运算则是由高性能C++代码执行的。而且，在绝大多数情况下，不同操作之间传递的数据，并不会拷贝回Python代码的执行空间。机器学习框架，正是通过这样的方式确保了计算性能，同时兼顾了对框架易用性方面的考虑。\n因此，当Python和C++结合使用的时候，Python本身的性能瓶颈就不那么重要了。它足够胜任我们给它的任务就可以了，至于对计算有更高要求的任务，就交给C++来做吧！\n今天，我们就来讨论下，如何通过SWIG对C++程序进行Python封装。我会先带你编写一段Python脚本，来执行一个简单的机器学习任务；接着，尝试将计算密集的部分改写成C++程序，再通过SWIG对其进行封装。最后的结果就是，Python把计算密集的任务委托给C++执行。\n我们会对性能做一个简单比较，并在这个过程中，讲解使用SWIG的方法。同时，在今天这节课的最后，我会为你提供一个学习路径，作为日后提高的参考。\n明确了今天的学习目的，也就是使用SWIG来实现Python对C++代码的调用，那么，我们今天的内容，其实可以看成一份关于SWIG的编程实践指南。学习这份指南之前，我们先来简单了解一下SWIG。\nSWIG 是什么？ linkSWIG，是一款能够连接C/C++与多种高级编程语言（我们在这里特别强调Python）的软件开发工具。SWIG支持多种不同类型的目标语言，这其中，支持的常见脚本语言包括JavaScript、Perl、PHP、Tcl、Ruby和Python等，支持的高级编程语言则包括C#、D、Go语言、Java（包括对Android的支持）、Lua、OCaml、Octave、Scilab和R。\n我们通常使用SWIG来创建高级解释或编译型的编程环境和接口，它也常被用来当作C/C++编写原型的测试工具。一个典型的应用场景，便是解析和创建C/C++接口，生成胶水代码供像Python这样的高级编程语言调用。近期发布的4.0.0版本，更是带来了对C++的显著改进和支持，这其中包括（不局限于）下面几点。\n针对C#、Java和Ruby而改进的STL包装器。 针对Java、Python和Ruby，增加C++11标准下的STL容器的支持。 改进了对C++11和C++14代码的支持。 修正了C++中对智能指针shared_ptr的一系列bug修复。 一系列针对C预处理器的极端case修复。 一系列针对成员函数指针问题的修复。 低支持的Python版本为2.7、3.2-3.7。 使用Python实现PCA算法 link借助于SWIG，我们可以简单地实现用Python调用C/C++库，甚至可以用Python继承和使用C++类。接下来，我们先来看一个你十分熟悉的使用Python编写的PCA（Principal Component Analysis，主成分分析）算法。\n因为我们今天的目标不是讲解PCA算法，所以如果你对这个算法还不是很熟悉，也没有关系，我会直接给出具体的代码，我们把焦点放在如何使用SWIG上就可以了。下面，我先给出代码清单1。\n代码清单1，基于Python编写的PCA算法 testPCAPurePython.py ：\nimport numpy as np\rdef compute_pca(data):\rm = np.mean(data, axis=0)\rdatac = np.array([obs - m for obs in data])\rT = np.dot(datac, datac.T)\r[u,s,v] = np.linalg.svd(T)\rpcs = [np.dot(datac.T, item) for item in u.T ]\rpcs = np.array([d / np.linalg.norm(d) for d in pcs])\rreturn pcs, m, s, T, u\rdef compute_projections(I,pcs,m):\rprojections = []\rfor i in I:\rw = []\rfor p in pcs:\rw.append(np.dot(i - m, p))\rprojections.append(w)\rreturn projections\rdef reconstruct(w, X, m,dim = 5):\rreturn np.dot(w[:dim],X[:dim,:]) + m\rdef normalize(samples, maxs = None):\rif not maxs:\rmaxs = np.max(samples)\rreturn np.array([np.ravel(s) / maxs for s in samples]) 现在，我们保存这段编写好的代码，并通过下面的命令来执行：\n",
                content: "你好，我是卢誉声，Autodesk 数据平台和计算平台资深软件工程师，也是《移动平台深度神经网络实战》和《分布式实时处理系统：原理架构与实现》的作者，主要从事C/C++、JavaScript开发工作和平台架构方面的研发工作，对SWIG也有比较深的研究。很高兴受极客时间邀请来做本次分享，今天，我们就来聊一聊SWIG这个话题。\n我们都知道，Python 是一门易于上手并实验友好的胶水语言。现在有很多机器学习开发或研究人员，都选择Python作为主力编程语言；流行的机器学习框架也都会提供Python语言的支持作为调用接口和工具。因此，相较于学习成本更高的C++来说，把Python作为进入机器学习世界的首选编程语言，就再合适不过了。\n不过，像TensorFlow或PyTorch这样的机器学习框架的核心，是使用Python编写的吗？\n显然不是。这里面的原因比较多，但最为显著的一个原因就是“性能”。通过C++编写的机器学习框架内核，加上编译器的优化能力，为系统提供了接近于机器码执行的效率。这种得天独厚的优势，让C++在机器学习的核心领域站稳了脚跟。我们前面所说的TensorFlow和PyTorch的核心，便都是使用C/C++开发的。其中，TensorFlow的内核，就是由高度优化的C++代码和CUDA编写而成。\n因此，我们可以理解为，TensorFlow通过Python来描述模型，而实际的运算则是由高性能C++代码执行的。而且，在绝大多数情况下，不同操作之间传递的数据，并不会拷贝回Python代码的执行空间。机器学习框架，正是通过这样的方式确保了计算性能，同时兼顾了对框架易用性方面的考虑。\n因此，当Python和C++结合使用的时候，Python本身的性能瓶颈就不那么重要了。它足够胜任我们给它的任务就可以了，至于对计算有更高要求的任务，就交给C++来做吧！\n今天，我们就来讨论下，如何通过SWIG对C++程序进行Python封装。我会先带你编写一段Python脚本，来执行一个简单的机器学习任务；接着，尝试将计算密集的部分改写成C++程序，再通过SWIG对其进行封装。最后的结果就是，Python把计算密集的任务委托给C++执行。\n我们会对性能做一个简单比较，并在这个过程中，讲解使用SWIG的方法。同时，在今天这节课的最后，我会为你提供一个学习路径，作为日后提高的参考。\n明确了今天的学习目的，也就是使用SWIG来实现Python对C++代码的调用，那么，我们今天的内容，其实可以看成一份关于SWIG的编程实践指南。学习这份指南之前，我们先来简单了解一下SWIG。\nSWIG 是什么？ linkSWIG，是一款能够连接C/C++与多种高级编程语言（我们在这里特别强调Python）的软件开发工具。SWIG支持多种不同类型的目标语言，这其中，支持的常见脚本语言包括JavaScript、Perl、PHP、Tcl、Ruby和Python等，支持的高级编程语言则包括C#、D、Go语言、Java（包括对Android的支持）、Lua、OCaml、Octave、Scilab和R。\n我们通常使用SWIG来创建高级解释或编译型的编程环境和接口，它也常被用来当作C/C++编写原型的测试工具。一个典型的应用场景，便是解析和创建C/C++接口，生成胶水代码供像Python这样的高级编程语言调用。近期发布的4.0.0版本，更是带来了对C++的显著改进和支持，这其中包括（不局限于）下面几点。\n针对C#、Java和Ruby而改进的STL包装器。 针对Java、Python和Ruby，增加C++11标准下的STL容器的支持。 改进了对C++11和C++14代码的支持。 修正了C++中对智能指针shared_ptr的一系列bug修复。 一系列针对C预处理器的极端case修复。 一系列针对成员函数指针问题的修复。 低支持的Python版本为2.7、3.2-3.7。 使用Python实现PCA算法 link借助于SWIG，我们可以简单地实现用Python调用C/C++库，甚至可以用Python继承和使用C++类。接下来，我们先来看一个你十分熟悉的使用Python编写的PCA（Principal Component Analysis，主成分分析）算法。\n因为我们今天的目标不是讲解PCA算法，所以如果你对这个算法还不是很熟悉，也没有关系，我会直接给出具体的代码，我们把焦点放在如何使用SWIG上就可以了。下面，我先给出代码清单1。\n代码清单1，基于Python编写的PCA算法 testPCAPurePython.py ：\nimport numpy as np\rdef compute_pca(data):\rm = np.mean(data, axis=0)\rdatac = np.array([obs - m for obs in data])\rT = np.dot(datac, datac.T)\r[u,s,v] = np.linalg.svd(T)\rpcs = [np.dot(datac.T, item) for item in u.T ]\rpcs = np.array([d / np.linalg.norm(d) for d in pcs])\rreturn pcs, m, s, T, u\rdef compute_projections(I,pcs,m):\rprojections = []\rfor i in I:\rw = []\rfor p in pcs:\rw.append(np.dot(i - m, p))\rprojections.append(w)\rreturn projections\rdef reconstruct(w, X, m,dim = 5):\rreturn np.dot(w[:dim],X[:dim,:]) + m\rdef normalize(samples, maxs = None):\rif not maxs:\rmaxs = np.max(samples)\rreturn np.array([np.ravel(s) / maxs for s in samples]) 现在，我们保存这段编写好的代码，并通过下面的命令来执行：\npython3 testPCAPurePython.py 准备SWIG link这样，我们已经获得了一些进展——使用Python编写了一个PCA算法，并得到了一些结果。接下来，我们看一下如何开始SWIG的开发工作。我会先从编译相关组件开始，再介绍一个简单使用的例子，为后续内容做准备。\n首先，我们从SWIG的网站（http://swig.org/download.html）下载源代码包，并开始构建：\n$ wget https://newcontinuum.dl.sourceforge.net/project/swig/swig/swig-4.0.0/swig-4.0.0.tar.gz # 下载路径可能会有所变化\r$ tar -xvf swig-4.0.0.tar.gz\r$ cd swig-4.0.0\r$ wget https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gz # SWIG需要依赖pcre工作\r$ sh ./Tools/pcre-build.sh # 该脚本会将pcre自动构建成SWIG使用的静态库\r$ ./configure # 注意需要安装bison，如果没有安装需要读者手动安装\r$ make\r$ sudo make install 一切就绪后，我们就来编写一个简单的例子吧。这个例子同样来源于SWIG网站（http://swig.org/tutorial.html）。我们先来创建一个简单的c文件，你可以通过你习惯使用的文本编辑器（比如vi），创建一个名为example.c的文件，并编写代码。代码内容我放在了代码清单2中。\n代码清单2，example.c：\n#include double My_variable = 3.0;\rint fact(int n) {\rif (n \u003c= 1) return 1;\relse return n*fact(n-1);\r}\rint my_mod(int x, int y) {\rreturn (x%y);\r}\rchar *get_time()\r{\rtime_t ltime;\rtime(\u0026ltime);\rreturn ctime(\u0026ltime);\r} 接下来，我们编写一个名为example.i的接口定义文件，和稍后用作测试的Python脚本，内容如代码清单3和代码清单4所示。\n代码清单3，example.i：\n%module example\r%{\r/* Put header files here or function declarations like below */\rextern double My_variable;\rextern int fact(int n);\rextern int my_mod(int x, int y);\rextern char *get_time();\r%}\rextern double My_variable;\rextern int fact(int n);\rextern int my_mod(int x, int y);\rextern char *get_time(); 我来解释下清单3这段代码。第1行，我们定义了模块的名称为example。第2-8行，我们直接指定了example.c中的函数定义，也可以定义一个example.h头文件，并将这些定义加入其中；然后，在 %{ … %}结构体中包含example.h，来实现相同的功能。第10-13行，则是定义了导出的接口，以便你在Python中直接调用这些接口。\n代码清单4，testExample.py：\nimport example\rprint(example.fact(5))\rprint(example.my_mod(7,3))\rprint(example.get_time()) 好了， 到现在为止，我们已经准备就绪了。现在，我们来执行下面的代码，创建目标文件和最后链接的文件吧：\nswig -python example.i\rgcc -c -fPIC example.c example_wrap.c -I/usr/include/python3.6\rgcc -shared example.o example_wrap.o -o _example.so\rpython3 testExample.py # 测试调用 其实，从代码清单4中你也能够看到，通过导入example，我们可以直接在Python脚本中，调用使用C实现的函数接口，并获得返回值。\n通过SWIG封装基于C++编写的Python模块 link到这一步，我们已经准备好了一份使用C++编写的PCA算法，接下来，我们就要对其进行一个简单的封装。由于C++缺少线性代数的官方支持，因此，为了简化线性代数运算，我这里用了一个第三方库Armadillo。在Ubuntu下，它可以使用apt-get install libarmadillo-dev安装支持。\n另外，还是要再三说明一下，我们今天这节课的重点并不是讲解PCA算法本身，所以希望你不要困于此处，而错过了真正的使用方法。当然，为了完整性考虑，我还是会对代码做出最基本的解释。\n封装正式开始。我们先来编写一个名为pca.h的头文件定义，内容我放在了代码清单5中。\n代码清单5，pca.h：\n#pragma once\r#include #include #include class pca {\rpublic:\rpca();\rexplicit pca(long num_vars);\rvirtual ~pca();\rbool operator==(const pca\u0026 other);\rvoid set_num_variables(long num_vars);\rlong get_num_variables() const;\rvoid add_record(const std::vector\u0026 record);\rstd::vector get_record(long record_index) const;\rlong get_num_records() const;\rvoid set_do_normalize(bool do_normalize);\rbool get_do_normalize() const;\rvoid set_solver(const std::string\u0026 solver);\rstd::string get_solver() const;\rvoid solve();\rdouble check_eigenvectors_orthogonal() const;\rdouble check_projection_accurate() const;\rvoid save(const std::string\u0026 basename) const;\rvoid load(const std::string\u0026 basename);\rvoid set_num_retained(long num_retained);\rlong get_num_retained() const;\rstd::vector to_principal_space(const std::vector\u0026 record) const;\rstd::vector to_variable_space(const std::vector\u0026 data) const;\rdouble get_energy() const;\rdouble get_eigenvalue(long eigen_index) const;\rstd::vector get_eigenvalues() const;\rstd::vector get_eigenvector(long eigen_index) const;\rstd::vector get_principal(long eigen_index) const;\rstd::vector get_mean_values() const;\rstd::vector get_sigma_values() const;\rprotected:\rlong num_vars_;\rlong num_records_;\rlong record_buffer_;\rstd::string solver_;\rbool do_normalize_;\rlong num_retained_;\rarma::Mat data_;\rarma::Col energy_;\rarma::Col eigval_;\rarma::Mat eigvec_;\rarma::Mat proj_eigvec_;\rarma::Mat princomp_;\rarma::Col mean_;\rarma::Col sigma_;\rvoid initialize_();\rvoid assert_num_vars_();\rvoid resize_data_if_needed_();\r}; 接着，我们再来编写具体实现pca.cpp，也就是代码清单6的内容。\n代码清单6，pca.cpp：\n#include \"pca.h\"\r#include \"utils.h\"\r#include #include pca::pca()\r: num_vars_(0),\rnum_records_(0),\rrecord_buffer_(1000),\rsolver_(\"dc\"),\rdo_normalize_(false),\rnum_retained_(1),\renergy_(1)\r{}\rpca::pca(long num_vars)\r: num_vars_(num_vars),\rnum_records_(0),\rrecord_buffer_(1000),\rsolver_(\"dc\"),\rdo_normalize_(false),\rnum_retained_(num_vars_),\rdata_(record_buffer_, num_vars_),\renergy_(1),\reigval_(num_vars_),\reigvec_(num_vars_, num_vars_),\rproj_eigvec_(num_vars_, num_vars_),\rprincomp_(record_buffer_, num_vars_),\rmean_(num_vars_),\rsigma_(num_vars_)\r{\rassert_num_vars_();\rinitialize_();\r}\rpca::~pca()\r{}\rbool pca::operator==(const pca\u0026 other) {\rconst double eps = 1e-5;\rif (num_vars_ == other.num_vars_ \u0026\u0026\rnum_records_ == other.num_records_ \u0026\u0026\rrecord_buffer_ == other.record_buffer_ \u0026\u0026\rsolver_ == other.solver_ \u0026\u0026\rdo_normalize_ == other.do_normalize_ \u0026\u0026\rnum_retained_ == other.num_retained_ \u0026\u0026\rutils::is_approx_equal_container(eigval_, other.eigval_, eps) \u0026\u0026\rutils::is_approx_equal_container(eigvec_, other.eigvec_, eps) \u0026\u0026\rutils::is_approx_equal_container(princomp_, other.princomp_, eps) \u0026\u0026\rutils::is_approx_equal_container(energy_, other.energy_, eps) \u0026\u0026\rutils::is_approx_equal_container(mean_, other.mean_, eps) \u0026\u0026\rutils::is_approx_equal_container(sigma_, other.sigma_, eps) \u0026\u0026\rutils::is_approx_equal_container(proj_eigvec_, other.proj_eigvec_, eps))\rreturn true;\relse\rreturn false;\r}\rvoid pca::resize_data_if_needed_() {\rif (num_records_ == record_buffer_) {\rrecord_buffer_ += record_buffer_;\rdata_.resize(record_buffer_, num_vars_);\r}\r}\rvoid pca::assert_num_vars_() {\rif (num_vars_ \u003c 2)\rthrow std::invalid_argument(\"Number of variables smaller than two.\");\r}\rvoid pca::initialize_() {\rdata_.zeros();\reigval_.zeros();\reigvec_.zeros();\rprincomp_.zeros();\rmean_.zeros();\rsigma_.zeros();\renergy_.zeros();\r}\rvoid pca::set_num_variables(long num_vars) {\rnum_vars_ = num_vars;\rassert_num_vars_();\rnum_retained_ = num_vars_;\rdata_.resize(record_buffer_, num_vars_);\reigval_.resize(num_vars_);\reigvec_.resize(num_vars_, num_vars_);\rmean_.resize(num_vars_);\rsigma_.resize(num_vars_);\rinitialize_();\r}\rvoid pca::add_record(const std::vector\u0026 record) {\rassert_num_vars_();\rif (num_vars_ != long(record.size()))\rthrow std::domain_error(utils::join(\"Record has the wrong size: \", record.size()));\rresize_data_if_needed_();\rarma::Row row(\u0026record.front(), record.size());\rdata_.row(num_records_) = std::move(row);\r++num_records_;\r}\rstd::vector pca::get_record(long record_index) const {\rreturn std::move(utils::extract_row_vector(data_, record_index));\r}\rvoid pca::set_do_normalize(bool do_normalize) {\rdo_normalize_ = do_normalize;\r}\rvoid pca::set_solver(const std::string\u0026 solver) {\rif (solver!=\"standard\" \u0026\u0026 solver!=\"dc\")\rthrow std::invalid_argument(utils::join(\"No such solver available: \", solver));\rsolver_ = solver;\r}\rvoid pca::solve() {\rassert_num_vars_();\rif (num_records_ \u003c 2)\rthrow std::logic_error(\"Number of records smaller than two.\");\rdata_.resize(num_records_, num_vars_);\rmean_ = utils::compute_column_means(data_);\rutils::remove_column_means(data_, mean_);\rsigma_ = utils::compute_column_rms(data_);\rif (do_normalize_) utils::normalize_by_column(data_, sigma_);\rarma::Col eigval(num_vars_);\rarma::Mat eigvec(num_vars_, num_vars_);\rarma::Mat cov_mat = utils::make_covariance_matrix(data_);\rarma::eig_sym(eigval, eigvec, cov_mat, solver_.c_str());\rarma::uvec indices = arma::sort_index(eigval, 1);\rfor (long i=0; i"
            }
        );
    index.add(
            {
                id:  54 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/45---%E7%BB%93%E8%AF%BE%E6%B5%8B%E8%AF%95---%E5%85%B3%E4%BA%8Epython%E7%9A%84%E8%BF%99%E4%BA%9B%E7%9F%A5%E8%AF%86%E4%BD%A0%E9%83%BD%E6%8E%8C%E6%8F%A1%E4%BA%86%E5%90%97\/",
                title: "结课测试 - 关于Python的这些知识，你都掌握了吗？",
                description: "你好，我是景霄。\n《Python核心技术与实战》这门课程已经完结一段时间了，在完结的这段时间里，我依然会收到很多留言，很感谢你一直以来的认真学习和支持！\n为了帮助你检验自己的学习效果，我特别给你准备了一套结课测试题。这套测试题共有20道题目，包括5道单选题和15道多选题，满分 100 分。\n还等什么，点击下面按钮开始测试吧！\n",
                content: "你好，我是景霄。\n《Python核心技术与实战》这门课程已经完结一段时间了，在完结的这段时间里，我依然会收到很多留言，很感谢你一直以来的认真学习和支持！\n为了帮助你检验自己的学习效果，我特别给你准备了一套结课测试题。这套测试题共有20道题目，包括5道单选题和15道多选题，满分 100 分。\n还等什么，点击下面按钮开始测试吧！\n"
            }
        );
    index.add(
            {
                id:  55 ,
                href: "\/docs\/python\/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98\/46---%E7%BB%93%E6%9D%9F%E8%AF%AD---%E6%8A%80%E6%9C%AF%E4%B9%8B%E5%A4%96%E7%9A%84%E5%87%A0%E7%82%B9%E6%88%90%E9%95%BF%E5%BB%BA%E8%AE%AE\/",
                title: "结束语 - 技术之外的几点成长建议",
                description: "你好，我是景霄。\n不知不觉，专栏上线已经4个月了，终于到了和你们说再见的时候，心中既有兴奋，又有不舍。说兴奋，是因为自己坚持完成了40多篇文章的写作，这对我而言是一项体力与脑力的“马拉松”，颇有成就感；说不舍，是因为你们的热情远超乎我当时的想象，和你们一起交流学习真的很高兴，收获也很大。\n这里也非常感谢极客时间能提供这个平台，让我得以和一万多的学员分享经验。当然，虽然课程结束了，但是技术人的学习并未终止，最后我还想再着重强调这么几点。\n计算机科学是一门需要实践的学科 link无论是对于Python这门课程，还是其他语言，或是计算机的其他领域，我认为实践永远是至关重要的。计算机科学是一门偏向工程的学科，所以一定要多实践，多写代码，多交流，多思考。实际生活中，我见过不少同学虽然看了很多的书籍，但是代码功底非常差，这是一个很严重的问题。\n那么，怎么提高呢？答案就是，请尽可能地参与更多的项目。俗话说“实践出真知”，说的正是这个道理。当你做的东西多了以后，你就会发现，很多的知识都会自然而然地串接起来，感觉自己的任督二脉似乎被打通了一般。\n选择适合自己的职业方向 link关于职业方向的问题，我还是那句话，对于尚不清晰自己兴趣所在的同学，最好的办法就是多尝试，因为在尝试的过程中，你就会发现自己的特长，发现自己的喜好，从而坚定不移、一步一步地走下去。\n当然，我了解到很多同学都是转行做程序员，以前都不是学计算机的，所以，很多人首先都会遇到“找工作”或者“跳槽”的难题。这种情况下，请不要气馁或是放弃。我也不完全算是科班出身的，我身边好多同事都不是科班出身，但是几年以后，你就会发现，好多当年非科班出身的同学，干得甚至比科班出身的都要好。因此，只要你坚定信念，不要放弃，风雨之后必有彩虹。\n能用代码解决的问题都不是问题 link这句话，主要送给有一定工作经验的朋友。其实，有了一定的积累后，你就会发现，能用代码解决的问题都不是问题。职场上，要想出类拔萃，除了能在技术上独当一面，如何与他人进行沟通交流，如何正确地处理同事间的关系，都是你额外需要学习的东西。实际工作中，我也见过不少人，代码能力天赋异禀，但是沟通交流不行，这同样也会阻碍你向上晋升。\n就拿一个很简单的例子来说。如果你和周围的同事合作一个项目，你觉得他有一样东西做得不好，你会直接说诸如“你很傻”，“你这样做大错特错”的话吗？你如果这样说了，那可真的是“大错特错了”。事实上，我们通常的一个措辞是，“我觉得你这里做得很好，不过，如果你可以……的话，那就更好了”。\n说了这么多，最后，还是要感谢你的订阅，感谢你的一路陪伴，祝你的生活学习一帆风顺，永远幸福！课程虽然已经结束，但是你仍然可以留言，我会尽可能多地一一回复，让你的学习没有遗憾。\n结束不是终点，而是更高阶旅程的重新启航。最后的最后，我们专栏的编辑同学，特意为你准备了一份毕业调查问卷，希望你能抽出两三分钟时间，写下你的学习经历和感受。这既是你课程学习的仪式感，作为你这几个月学习的记录和总结；也是我后续为你优化课程的重要参考资料，很有价值。感谢你的反馈，学习不停，精进不止！\n",
                content: "你好，我是景霄。\n不知不觉，专栏上线已经4个月了，终于到了和你们说再见的时候，心中既有兴奋，又有不舍。说兴奋，是因为自己坚持完成了40多篇文章的写作，这对我而言是一项体力与脑力的“马拉松”，颇有成就感；说不舍，是因为你们的热情远超乎我当时的想象，和你们一起交流学习真的很高兴，收获也很大。\n这里也非常感谢极客时间能提供这个平台，让我得以和一万多的学员分享经验。当然，虽然课程结束了，但是技术人的学习并未终止，最后我还想再着重强调这么几点。\n计算机科学是一门需要实践的学科 link无论是对于Python这门课程，还是其他语言，或是计算机的其他领域，我认为实践永远是至关重要的。计算机科学是一门偏向工程的学科，所以一定要多实践，多写代码，多交流，多思考。实际生活中，我见过不少同学虽然看了很多的书籍，但是代码功底非常差，这是一个很严重的问题。\n那么，怎么提高呢？答案就是，请尽可能地参与更多的项目。俗话说“实践出真知”，说的正是这个道理。当你做的东西多了以后，你就会发现，很多的知识都会自然而然地串接起来，感觉自己的任督二脉似乎被打通了一般。\n选择适合自己的职业方向 link关于职业方向的问题，我还是那句话，对于尚不清晰自己兴趣所在的同学，最好的办法就是多尝试，因为在尝试的过程中，你就会发现自己的特长，发现自己的喜好，从而坚定不移、一步一步地走下去。\n当然，我了解到很多同学都是转行做程序员，以前都不是学计算机的，所以，很多人首先都会遇到“找工作”或者“跳槽”的难题。这种情况下，请不要气馁或是放弃。我也不完全算是科班出身的，我身边好多同事都不是科班出身，但是几年以后，你就会发现，好多当年非科班出身的同学，干得甚至比科班出身的都要好。因此，只要你坚定信念，不要放弃，风雨之后必有彩虹。\n能用代码解决的问题都不是问题 link这句话，主要送给有一定工作经验的朋友。其实，有了一定的积累后，你就会发现，能用代码解决的问题都不是问题。职场上，要想出类拔萃，除了能在技术上独当一面，如何与他人进行沟通交流，如何正确地处理同事间的关系，都是你额外需要学习的东西。实际工作中，我也见过不少人，代码能力天赋异禀，但是沟通交流不行，这同样也会阻碍你向上晋升。\n就拿一个很简单的例子来说。如果你和周围的同事合作一个项目，你觉得他有一样东西做得不好，你会直接说诸如“你很傻”，“你这样做大错特错”的话吗？你如果这样说了，那可真的是“大错特错了”。事实上，我们通常的一个措辞是，“我觉得你这里做得很好，不过，如果你可以……的话，那就更好了”。\n说了这么多，最后，还是要感谢你的订阅，感谢你的一路陪伴，祝你的生活学习一帆风顺，永远幸福！课程虽然已经结束，但是你仍然可以留言，我会尽可能多地一一回复，让你的学习没有遗憾。\n结束不是终点，而是更高阶旅程的重新启航。最后的最后，我们专栏的编辑同学，特意为你准备了一份毕业调查问卷，希望你能抽出两三分钟时间，写下你的学习经历和感受。这既是你课程学习的仪式感，作为你这几个月学习的记录和总结；也是我后续为你优化课程的重要参考资料，很有价值。感谢你的反馈，学习不停，精进不止！\n"
            }
        );
    search.addEventListener('input', show_results, true);

    function show_results(){
        const maxResult =  5 ;
        const minlength =  0 ;
        var searchQuery = sanitizeHTML(this.value);
        var results = index.search(searchQuery, {limit: maxResult, enrich: true});

        
        const flatResults = new Map(); 
        for (const result of results.flatMap(r => r.result)) {
        if (flatResults.has(result.doc.href)) continue;
        flatResults.set(result.doc.href, result.doc);
        }

        suggestions.innerHTML = "";
        suggestions.classList.remove('d-none');

        
        if (searchQuery.length < minlength) {
            const minCharMessage = document.createElement('div')
            minCharMessage.innerHTML = `Please type at least <strong>${minlength}</strong> characters`
            minCharMessage.classList.add("suggestion__no-results");
            suggestions.appendChild(minCharMessage);
            return;
        } else {
            
            if (flatResults.size === 0 && searchQuery) {
                const noResultsMessage = document.createElement('div')
                noResultsMessage.innerHTML = "No results for" + ` "<strong>${searchQuery}</strong>"`
                noResultsMessage.classList.add("suggestion__no-results");
                suggestions.appendChild(noResultsMessage);
                return;
            }
        }

        
        for(const [href, doc] of flatResults) {
            const entry = document.createElement('div');
            suggestions.appendChild(entry);

            const a = document.createElement('a');
            a.href = href;
            entry.appendChild(a);

            const title = document.createElement('span');
            title.textContent = doc.title;
            title.classList.add("suggestion__title");
            a.appendChild(title);

            const description = document.createElement('span');
            description.textContent = doc.description;
            description.classList.add("suggestion__description");
            a.appendChild(description);

            suggestions.appendChild(entry);

            if(suggestions.childElementCount == maxResult) break;
        }
    }
    }());
</script>
        
    </body>
</html>
